{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramyrahmeni/gpt2-from-scratch/blob/main/gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvVo5uW7jSq3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j69znrEB5HH5",
        "outputId": "76f099aa-6681-4e20-ae38-21e141d1312a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: datasets in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tiktoken) (2025.7.34)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (2.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (0.34.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tiktoken datasets pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw99MV405HH6",
        "outputId": "aff3aebc-5399-4e3a-dcea-40c66ee10b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (2.7.1+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (0.22.1+cu118)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (2.7.1+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torchvision) (2.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Example for CUDA 11.8\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAZnPWYX5HH6",
        "outputId": "6d3cf418-6845-4a40-e9ed-9c2bd4d4fd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (0.34.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4c9dS1-5HH6",
        "outputId": "1a066157-71ff-4c89-a01b-5d676a6b439d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (2025.7.34)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_cpLL4h5HH6",
        "outputId": "646fdfda-6af1-441e-c9bc-a760618064b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: stack_data in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.14.1)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install  ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m06_Sae5HH6",
        "outputId": "adda1855-bef8-45c3-ba8d-233dcc7c3fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (3.10.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install  matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ3u4b4N5HH6",
        "outputId": "99a19106-9bfb-40af-9f94-8979883650ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\documents\\gpt2\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install  tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF3oGHcC5HH7",
        "outputId": "c07b73ad-ebec-443c-ecea-71ddeeb6c678",
        "colab": {
          "referenced_widgets": [
            "3f97c56bf60e4e7abaaee97565e6928f"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f97c56bf60e4e7abaaee97565e6928f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6hKkP08swS4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "import tiktoken\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQyWy0ri5HH7"
      },
      "outputs": [],
      "source": [
        "import matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_x5u444jUkH"
      },
      "source": [
        "# Part 1 : GPT 2 Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxF4MIzXjdlK"
      },
      "source": [
        "![gpt2overview.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-dEP4gAk2X5"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s3eG9O9lg-o"
      },
      "source": [
        "For tokenization, I applied Byte Pair Encoding (BPE) to break text into subword units, effectively addressing the outâ€‘ofâ€‘vocabulary problem found in traditional wordâ€‘level encoders, and used the tiktoken library to map text into the GPTâ€‘2 token IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO-iy-JpjZg-"
      },
      "outputs": [],
      "source": [
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqoCnoqvmdJB",
        "outputId": "b79380cb-2b31-41d7-bf6c-97dd7b433fe4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Size of vocabloary\n",
        "enc.n_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD7MII8Zmk1G",
        "outputId": "a49cc475-c4bb-4802-f733-a4566b35be62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5661, 318, 257, 1332, 50256]\n",
            "this is a test<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "tokens=enc.encode(\"this is a test\")\n",
        "tokens.append(enc.eot_token) # End of text token\n",
        "print(tokens)\n",
        "decoded_text=enc.decode(tokens)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EmRy0M4njh5"
      },
      "outputs": [],
      "source": [
        "def encode_text(text):\n",
        "  \"\"\"Encodes text using the GPT-2 encoding and appends the end-of-text token.\"\"\"\n",
        "  tokens = enc.encode(text)\n",
        "  tokens.append(enc.eot_token)\n",
        "  return tokens\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "  \"\"\"Decodes a list of tokens using the GPT-2 encoding.\"\"\"\n",
        "  return enc.decode(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f67d92"
      },
      "source": [
        "These functions serve as the foundational text encoding and decoding utilities within the GPT architecture. They facilitate the conversion of human-readable text into numerical token representations for processing by the model, and vice versa, enabling the model to generate coherent and meaningful text outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF6kSe_Eoo0O"
      },
      "source": [
        "## Token Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZdKf2NZqNiG"
      },
      "source": [
        "Token embeddings convert discrete input tokens (words or subwords) into continuous numerical vectors, enabling the model to process and represent language. They serve as the foundation for capturing the semantic meaning of tokens and form the first step in how the model understands text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c348tqccvBb9"
      },
      "source": [
        "![1_4RjkuWOltnKxBmfg9QcH8Q.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_r9ruuepAPs"
      },
      "outputs": [],
      "source": [
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()  # initialize nn.Module\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.embedding(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSi6wsAsqFy5",
        "outputId": "83b4f702-32d2-41eb-aed7-af185f22c020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 5661,   318,   257,  1332, 50256]])\n",
            "torch.Size([1, 5])\n",
            "tensor([[[ 0.5438,  1.0335,  0.3444,  ...,  0.8690, -0.0450, -0.3707],\n",
            "         [ 0.3170,  0.4535, -0.3945,  ...,  1.1892,  1.9888,  0.0176],\n",
            "         [-0.4145,  0.7562,  0.9617,  ...,  0.5720,  1.3171, -0.6009],\n",
            "         [-1.3095,  1.4812, -0.3612,  ...,  0.3200, -2.4145, -0.3844],\n",
            "         [ 0.4270, -1.1371, -1.4918,  ...,  0.6557, -0.0594,  0.9376]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([1, 5, 768])\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "\n",
        "tokens_tensor = torch.tensor(tokens).unsqueeze(0)\n",
        "\n",
        "print(tokens_tensor)\n",
        "print(tokens_tensor.shape)\n",
        "embedding = EmbeddingLayer(vocab_size=50257, embedding_size=768)\n",
        "\n",
        "# Get embeddings\n",
        "emb = embedding(tokens_tensor)\n",
        "\n",
        "print(emb)  # (1, 3, 768)\n",
        "print(emb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5oIL2jjwvdz"
      },
      "source": [
        "## Postional Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMaV-UpMAwau"
      },
      "source": [
        "Token embeddings capture *what* a word (or subword) means, but they do not encode *where* it appears in a sequence.  \n",
        "To solve this, we introduce **positional embeddings**, which assign each position in the input a unique continuous vector.\n",
        "\n",
        "### Key Requirements\n",
        "- **Consistent Identifiers**  \n",
        "  Each position must always map to the **same unique identifier**, so the model can recognize order consistently.\n",
        "\n",
        "- **Preserve Semantic Meaning**  \n",
        "  Positiona[link text](https://)l signals should not overpower token embeddings.  \n",
        "  If positional values are too large, they may **wipe out semantic similarity** between tokens.  \n",
        "  To avoid this, we use functions like **sine and cosine** that produce values in a bounded range `[-1, 1]`.\n",
        "\n",
        "### Core Idea\n",
        "The goal is to transform every position index into a **continuous vector signal** that:\n",
        "- Reflects the relative and absolute position of words  \n",
        "- Integrates smoothly with token embeddings  \n",
        "- Allows the model to capture sequence order **without erasing the semantic meaning** of the tokens\n",
        "\n",
        "### Formula (Sinusoidal Encoding)\n",
        "For a given position `pos` and embedding dimension `i`:\n",
        "\n",
        "$$\n",
        "PE_{(pos, 2i)}   = \\sin\\left(\\frac{pos}{10000^{2i/d}}\\right), \\quad\n",
        "PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d}}\\right)\n",
        "$$\n",
        "Here, `d` is the embedding size.  \n",
        "This ensures:\n",
        "- Every position has a **unique pattern** of sine and cosine values  \n",
        "- Nearby positions produce **similar signals**, preserving order information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXXsjl94tBvG"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len):\n",
        "        super().__init__()\n",
        "        positions = torch.arange(max_len).unsqueeze(1)\n",
        "\n",
        "        # frequencies: (1, embedding_size/2)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        # compute pe: (max_len, embedding_size)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(positions * div_term)  # even indices\n",
        "        pe[:, 1::2] = torch.cos(positions * div_term)  # odd indices\n",
        "\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, embedding_size)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyUHnAA93AUP",
        "outputId": "b7aac56b-9dcb-4ec1-a54c-3141f156941f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.5438,  2.0335,  0.3444,  ...,  1.8690, -0.0450,  0.6293],\n",
            "         [ 1.1584,  0.9938,  0.4339,  ...,  2.1892,  1.9889,  1.0176],\n",
            "         [ 0.4948,  0.3401,  1.8897,  ...,  1.5720,  1.3173,  0.3991],\n",
            "         [-1.1683,  0.4913, -0.1501,  ...,  1.3200, -2.4142,  0.6156],\n",
            "         [-0.3298, -1.7908, -2.1834,  ...,  1.6557, -0.0590,  1.9376]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "torch.Size([1, 5, 768])\n",
            "tensor([[[ 1.0877,  3.0670,  0.6888,  ...,  2.7380, -0.0900,  0.2585],\n",
            "         [ 1.4754,  1.4474,  0.0394,  ...,  3.3784,  3.9776,  1.0351],\n",
            "         [ 0.0803,  1.0963,  2.8513,  ...,  2.1439,  2.6344, -0.2019],\n",
            "         [-2.4778,  1.9725, -0.5112,  ...,  1.6399, -4.8287,  0.2312],\n",
            "         [ 0.0972, -2.9279, -3.6752,  ...,  2.3115, -0.1185,  2.8752]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "torch.Size([1, 5, 768])\n"
          ]
        }
      ],
      "source": [
        "postional_embedding = PositionalEncoding(d_model=768,max_len=5)\n",
        "pos_emb=postional_embedding(emb)\n",
        "print(pos_emb)\n",
        "print(pos_emb.shape)\n",
        "input_embeddings = pos_emb + emb\n",
        "print(input_embeddings)\n",
        "print(input_embeddings.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d58-Ax0MF0FH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hLUHnelJABv"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw6ieIE-NGXj"
      },
      "source": [
        "The **Transformer Block** is the fundamental building unit of GPTâ€‘2.  \n",
        "I designed it by dividing each core component into its own class and then tying them together in a single block for clarity and modularity.\n",
        "\n",
        "### Structure\n",
        "\n",
        "1. **LayerNorm â†’ Masked Multi-Head Attention (MMHA)**\n",
        "   - Normalizes inputs for stability.\n",
        "   - Applies masked multi-head attention to capture relationships between tokens while preventing access to future positions.\n",
        "   - Output is added back to the input through a residual connection with dropout.\n",
        "\n",
        "2. **LayerNorm â†’ Feed-Forward Network (FFN)**\n",
        "   - Normalizes the updated representation.\n",
        "   - Passes each token independently through a feed-forward network with a GELU activation.\n",
        "   - Expands the dimensionality (`4 Ã— embed_dim`) and projects back down.\n",
        "   - Residual connection and dropout are applied again.\n",
        "\n",
        "### Why this design?\n",
        "- **Modularity:** Each component (MMHA, FFN, LayerNorm, Dropout) is implemented as a separate class, making the code clean and reusable.\n",
        "- **Pre-Norm Architecture:** Normalization happens before MMHA and FFN for more stable training in deep networks.\n",
        "- **Residual Connections:** Ensure stable gradient flow and prevent vanishing gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUeecULaJ7Xu"
      },
      "source": [
        "![GPT-2-model-architecture-The-GPT-2-model-contains-N-Transformer-decoder-blocks-as-shown.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6H4bOsSLPfD"
      },
      "source": [
        "**Masked multi Head Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnTOv4yVzhGA"
      },
      "source": [
        "Masked multi-head attention is the fundamental mechanism in transformer blocks that captures intricate relationships between tokens, such as syntactic structure, semantic similarity, and long-range dependencies.\n",
        "\n",
        "It operates on three learned projections â€” **queries (Q)**, **keys (K)**, and **values (V)** â€” each split across multiple heads to attend to diverse aspects of the input.\n",
        "\n",
        "The process is as follows:  \n",
        "1. **Compute attention scores** by multiplying queries with the transposed keys, quantifying the relevance of each token to every other.  \n",
        "2. **Scale the scores** by the square root of the head dimension to maintain numerical stability and ensure well-behaved gradients.  \n",
        "3. **Apply a causal mask** to prevent information leakage from future tokens, preserving the autoregressive property.  \n",
        "4. **Normalize with softmax** to convert raw scores into interpretable probabilities that sum to one.  \n",
        "5. **Weight the values** by these probabilities to produce context-aware token representations that integrate relevant information across the sequence.\n",
        "\n",
        "This elegant mechanism enables the model to dynamically focus on multiple relational aspects simultaneously, enriching its contextual understanding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY-XNnqVtfTM"
      },
      "source": [
        "![0_kRbHxnTgrgNqo0Ct.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByeBTK8J2tYF"
      },
      "source": [
        "Remark:\n",
        "We scale the attention scores by dividing by the square root of the head dimension primarily to mitigate covariate shift and stabilize gradients during training. Without this scaling, the dot products can grow large in magnitude as the dimension increases, causing the softmax function to produce extremely small gradients and making training unstable. Dividing by âˆš(head_dim) keeps the values in a manageable range, ensuring more effective learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDKln1CTK_cf"
      },
      "outputs": [],
      "source": [
        "class MMHAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, embed_dim, num_heads, seq_len):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(d_in, d_out)\n",
        "        self.k_proj = nn.Linear(d_in, d_out)\n",
        "        self.v_proj = nn.Linear(d_in, d_out)\n",
        "\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        queries = self.q_proj(x)\n",
        "        keys    = self.k_proj(x)\n",
        "        values  = self.v_proj(x)\n",
        "\n",
        "        queries = queries.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        keys    = keys.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values  = values.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        mask = self.mask[:, :, :seq_len, :seq_len].to(x.device)\n",
        "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, values)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)\n",
        "\n",
        "        attn_output = self.dropout(self.out_proj(attn_output))\n",
        "        return attn_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpqIhzH22-vV",
        "outputId": "a2b0474a-f700-45d3-c681-018ae0ece2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64 64 64 8 10\n",
            "Input shape: torch.Size([2, 10, 64])\n",
            "Output shape: torch.Size([2, 10, 64])\n"
          ]
        }
      ],
      "source": [
        "#Example Hyperparameters for test\n",
        "batch_size = 2\n",
        "seq_len = 10\n",
        "d_in = 64       # input feature dimension\n",
        "d_out = 64      # output feature dimension (usually same as embed_dim)\n",
        "embed_dim = 64\n",
        "num_heads = 8\n",
        "\n",
        "# Attention layer\n",
        "print(d_in, d_out, embed_dim, num_heads, seq_len)\n",
        "attn = MMHAttention(d_in, d_out, embed_dim, num_heads, seq_len)\n",
        "# Dummy input tensor (batch_size, seq_len, d_in)\n",
        "x = torch.randn(batch_size, seq_len, d_in)\n",
        "\n",
        "# Forward pass\n",
        "output = attn(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjnFAx5v5vhJ"
      },
      "source": [
        "**Layer Normalization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osqHT9yw9ee9"
      },
      "source": [
        "We use Layer Normalization to stabilize and speed up training by normalizing each tokenâ€™s feature vector, which helps prevent issues like internal covariate shift.\n",
        "\n",
        "The normalization is computed as follows:\n",
        "\n",
        "$$\n",
        "\\mu = \\text{mean}(x), \\quad \\sigma^2 = \\text{var}(x)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\quad,\\quad y_i = \\gamma \\hat{x}_i + \\beta\n",
        "$$\n",
        "\n",
        "where the mean and variance are computed across the feature dimension for each input vector:\n",
        "\n",
        "$$\n",
        "\\mu = \\text{mean}(x), \\quad \\sigma^2 = \\text{var}(x)\n",
        "$$\n",
        "Epsilon is a small constant added for numerical stability to avoid division by 0.\n",
        "\n",
        "\n",
        "The scale and shift parameters are learnable:\n",
        "\n",
        "$$\n",
        "\\gamma, \\quad \\beta\n",
        "$$\n",
        "- **Objective:** Normalize each feature vector to have zero mean and unit variance, then apply learnable scaling (`Î³`) and shifting (`Î²`).\n",
        "\n",
        "- **Input:** A tensor of shape `(batch_size, seq_len, embedding_dim)`, e.g., `(2, 3, 4)`.\n",
        "\n",
        "- **Process:**\n",
        "  1. Compute mean and variance across the last dimension (features) for each vector.\n",
        "  2. Normalize features by subtracting the mean and dividing by the standard deviation.\n",
        "  3. Scale and shift normalized values using learnable parameters `Î³` (gamma) and `Î²` (beta).\n",
        "\n",
        "- **Expected Output:** Each feature vector is normalized. Initially, since `Î³ = 1` and `Î² = 0`, output vectors have zero mean and unit variance.\n",
        "\n",
        "This test verifies that the LayerNorm implementation correctly normalizes input data on the feature dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmc0SYh62_Sb"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(dim))  # scale parameter\n",
        "        self.beta = nn.Parameter(torch.zeros(dim))  # shift parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute mean and variance along the last dimension (features)\n",
        "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
        "        var = torch.var(x, dim=-1, keepdim=True, unbiased=False)\n",
        "\n",
        "        # Normalize input\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "        # Scale and shift\n",
        "        return self.gamma * x_norm + self.beta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUL4Igpo88Hw",
        "outputId": "378bef54-58bf-4f6b-8430-935ae4523a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " tensor([[[2., 4., 6., 8.],\n",
            "         [1., 3., 5., 7.],\n",
            "         [0., 2., 4., 6.]],\n",
            "\n",
            "        [[8., 6., 4., 2.],\n",
            "         [7., 5., 3., 1.],\n",
            "         [6., 4., 2., 0.]]])\n",
            "Output:\n",
            " tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
            "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
            "         [-1.3416, -0.4472,  0.4472,  1.3416]],\n",
            "\n",
            "        [[ 1.3416,  0.4472, -0.4472, -1.3416],\n",
            "         [ 1.3416,  0.4472, -0.4472, -1.3416],\n",
            "         [ 1.3416,  0.4472, -0.4472, -1.3416]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "layer_norm = LayerNorm(dim=4)\n",
        "\n",
        "# Sample input tensor (batch_size=2, seq_len=3, embedding_dim=4)\n",
        "x = torch.tensor([\n",
        "    [[2.0, 4.0, 6.0, 8.0],\n",
        "     [1.0, 3.0, 5.0, 7.0],\n",
        "     [0.0, 2.0, 4.0, 6.0]],\n",
        "    [[8.0, 6.0, 4.0, 2.0],\n",
        "     [7.0, 5.0, 3.0, 1.0],\n",
        "     [6.0, 4.0, 2.0, 0.0]]\n",
        "])\n",
        "\n",
        "# Forward pass\n",
        "output = layer_norm(x)\n",
        "print(\"Input:\\n\", x)\n",
        "print(\"Output:\\n\", output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkr4npEv925b"
      },
      "source": [
        "**Dropout Layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFvOJGTaBAj7"
      },
      "source": [
        "Dropout is a regularization technique used during training to prevent overfitting. It works by randomly â€œdroppingâ€ (setting to zero) a fraction of the input units during each forward pass. This forces the model to not rely too heavily on any one feature, promoting redundancy and robustness.\n",
        "\n",
        "- **How it works:** Each input element has a probability `p` (called dropout rate) of being zeroed out.\n",
        "- **Scaling:** To keep the expected sum of inputs unchanged, the remaining active inputs are scaled up by `1/(1-p)` during training.\n",
        "- **Effect:** This encourages the network to learn more distributed and generalizable features.\n",
        "- **During inference:** Dropout is turned off, and inputs pass through unchanged.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUrG3OdS885Q"
      },
      "outputs": [],
      "source": [
        "class DropoutLayer(nn.Module):\n",
        "    def __init__(self, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLztUAl0BSP1"
      },
      "source": [
        "**Feed Forward Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mokXYHUDDt6i"
      },
      "source": [
        "\n",
        "The **Feed-Forward Network (FFN)** is a core component of each Transformer block.  \n",
        "It complements the Masked Multi-Head Attention (MMHA) mechanism by further transforming token representations.\n",
        "\n",
        "- **Role in the architecture:**  \n",
        "  After MMHA captures relationships between tokens, the FFN processes each token *independently* to enrich its representation and introduce non-linearity.  \n",
        "  This helps the model learn more complex transformations beyond attention.\n",
        "\n",
        "- **Difference from MMHA:**  \n",
        "  - MMHA mixes information *across tokens* to model dependencies.  \n",
        "  - FFN operates *within each token position*, applying the same feed-forward layers to all tokens in parallel.\n",
        "\n",
        "- **Why GELU is used:**  \n",
        "  The **GELU (Gaussian Error Linear Unit)** activation is smoother than ReLU and better suited for capturing subtle patterns in language.  \n",
        "  It improves performance in NLP models like GPT by balancing linearity with non-linearity, leading to more stable training and richer feature extraction.\n",
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Nz8AitZAtPK"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, d_in, d_hidden):\n",
        "        super().__init__()\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_in, d_hidden),  # expand\n",
        "            nn.GELU(),                  # non-linearity\n",
        "            nn.Linear(d_hidden, d_in)   # project back\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE1yIqM3MRnE"
      },
      "source": [
        "**Transformer Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahQ40kivDSCz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, seq_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # Layer normalization before attention\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # Masked Multi-Head Attention\n",
        "        self.attn = MMHAttention(\n",
        "            d_in=embed_dim,\n",
        "            d_out=embed_dim,\n",
        "            embed_dim=embed_dim,\n",
        "            num_heads=num_heads,\n",
        "            seq_len=seq_len\n",
        "        )\n",
        "\n",
        "        # Dropout after attention\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Layer normalization before FFN\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # Feed-Forward Network (expansion: 4 * embed_dim typical for GPT-2)\n",
        "        self.ffn = FFN(embed_dim, embed_dim * 4)\n",
        "\n",
        "        # Dropout after FFN\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=x+self.dropout1(self.attn(self.norm1(x)))\n",
        "        x=x+self.dropout2(self.ffn(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thDNnUaZNgxI",
        "outputId": "7f3b3303-dad9-414c-ecdf-4ac1d65ca790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Shape: torch.Size([2, 10, 64])\n",
            "\n",
            "-- Forward Pass Logs --\n",
            "After norm1: torch.Size([2, 10, 64])\n",
            "After attention: torch.Size([2, 10, 64])\n",
            "After first residual: torch.Size([2, 10, 64])\n",
            "After norm2: torch.Size([2, 10, 64])\n",
            "After FFN: torch.Size([2, 10, 64])\n",
            "After second residual: torch.Size([2, 10, 64])\n",
            "\n",
            "Final Output Shape: torch.Size([2, 10, 64])\n"
          ]
        }
      ],
      "source": [
        "# Test script for TransformerBlock\n",
        "\n",
        "embed_dim = 64\n",
        "num_heads = 8\n",
        "seq_len = 10\n",
        "batch_size = 2\n",
        "\n",
        "block = TransformerBlock(embed_dim, num_heads, seq_len, dropout=0.1)\n",
        "\n",
        "# Dummy input (batch_size, seq_len, embed_dim)\n",
        "x = torch.randn(batch_size, seq_len, embed_dim)\n",
        "\n",
        "print(\"Input Shape:\", x.shape)\n",
        "\n",
        "# Forward pass with logs\n",
        "with torch.no_grad():\n",
        "    print(\"\\n-- Forward Pass Logs --\")\n",
        "\n",
        "    norm1_out = block.norm1(x)\n",
        "    print(\"After norm1:\", norm1_out.shape)\n",
        "\n",
        "    attn_out = block.attn(norm1_out)\n",
        "    print(\"After attention:\", attn_out.shape)\n",
        "\n",
        "    x1 = x + block.dropout1(attn_out)\n",
        "    print(\"After first residual:\", x1.shape)\n",
        "\n",
        "    norm2_out = block.norm2(x1)\n",
        "    print(\"After norm2:\", norm2_out.shape)\n",
        "\n",
        "    ffn_out = block.ffn(norm2_out)\n",
        "    print(\"After FFN:\", ffn_out.shape)\n",
        "\n",
        "    x2 = x1 + block.dropout2(ffn_out)\n",
        "    print(\"After second residual:\", x2.shape)\n",
        "\n",
        "print(\"\\nFinal Output Shape:\", x2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ic2ehNMNhav"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N78Y5v3JOWOG"
      },
      "source": [
        "## GPT 2 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZasVmRQuOa_A"
      },
      "outputs": [],
      "source": [
        "class GPT2_Architecture(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "        self.embedding = EmbeddingLayer(\n",
        "            vocab_size=self.config[\"vocab_size\"],\n",
        "            embedding_size=self.config[\"emb_dim\"]\n",
        "        )\n",
        "        self.positional_encoding = nn.Embedding(\n",
        "            num_embeddings=self.config[\"context_length\"],\n",
        "            embedding_dim=self.config[\"emb_dim\"]\n",
        "        )\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(\n",
        "                embed_dim=self.config[\"emb_dim\"],\n",
        "                num_heads=self.config[\"n_heads\"],\n",
        "                seq_len=self.config[\"context_length\"],\n",
        "                dropout=self.config[\"drop_rate\"]\n",
        "            )\n",
        "            for i in range(self.config[\"n_layers\"])\n",
        "        ])\n",
        "        self.layer_norm = nn.LayerNorm(self.config[\"emb_dim\"])\n",
        "        self.lm_head = nn.Linear(self.config[\"emb_dim\"], self.config[\"vocab_size\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)  # shape: [1, T]\n",
        "        x = x + self.positional_encoding(positions)  # broadcast to [B, T, D]\n",
        "\n",
        "\n",
        "        for i, block in enumerate(self.transformer_blocks, 1):\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVuWKBHzWI4b"
      },
      "source": [
        "### Why the Generated Text Looks Random\n",
        "\n",
        "The output token (`\" research\"`) may appear random because our GPTâ€‘2 architecture is **still untrained**.  \n",
        "Right now, the model's parameters are randomly initialized, so it has **no learned knowledge of language**.  \n",
        "\n",
        "- **Embeddings**: The token and positional embeddings are random, so they donâ€™t capture semantic meaning.  \n",
        "- **Attention Weights**: The attention mechanism hasnâ€™t been trained to recognize patterns or dependencies in text.  \n",
        "- **Feed-Forward Layers**: These layers are randomly initialized and havenâ€™t learned how to transform representations meaningfully.  \n",
        "- **Logits & Argmax**: Since all layers produce random activations, the final logits over the vocabulary are effectively random scores, and taking the `argmax` just picks one of them arbitrarily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSFKpgllW2Ef"
      },
      "source": [
        "# Part 2 : Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfY2SuEuiqit"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGsWV0aA5HIN"
      },
      "source": [
        "**Loading the Dataset**\n",
        "\n",
        "In this step, we use the ðŸ¤— **Hugging Face `datasets` library** to load the  \n",
        "[`nvidia/HelpSteer`](https://huggingface.co/datasets/nvidia/HelpSteer) dataset.  \n",
        "\n",
        "- `load_dataset(\"nvidia/HelpSteer\")` automatically downloads and prepares the dataset.  \n",
        "- The returned object (`ds`) is a `DatasetDict` containing one or more splits  \n",
        "  (such as *train*, *validation*, or *test*).  \n",
        "- This dataset will be the foundation for our data processing and model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEQLdNWYbQar"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"nvidia/HelpSteer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iEOeqo6n5GU",
        "outputId": "2f7fc7ca-5cae-4c3e-ac82-75a86ed0f591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity'],\n",
              "        num_rows: 35331\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity'],\n",
              "        num_rows: 1789\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4N25IfmoDWH",
        "outputId": "d2a7a3ef-57ec-477f-fb2d-83ad747a06d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': 'What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?', 'response': \"To build an assistive device to help an elderly person with basic needs, one must consider three crucial things: safety, compatibility, and ease of use. Safety is paramount, as the device must not cause harm to the user. Compatibility with the user's environment and other devices is also essential. Finally, the device must be simple enough for the elderly person to operate.\", 'helpfulness': 3, 'correctness': 4, 'coherence': 4, 'complexity': 2, 'verbosity': 2}\n",
            "['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity']\n"
          ]
        }
      ],
      "source": [
        "print(ds[\"train\"][0])\n",
        "\n",
        "print(ds[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb21FEBtolfo",
        "outputId": "e76dee27-a05f-4780-dcb2-630cb8a6e5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 35331\n",
            "Number of test examples: 1789\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of training examples:\", len(ds[\"train\"]))\n",
        "print(\"Number of test examples:\", len(ds[\"validation\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE0qYp145HIO"
      },
      "source": [
        "\n",
        "To better understand the structure of the dataset, we first create a small **example DataFrame** manually.  \n",
        "Each entry includes:  \n",
        "\n",
        "- **prompt** â†’ the input question or instruction  \n",
        "- **response** â†’ the modelâ€™s expected output  \n",
        "- **helpfulness, correctness, coherence, complexity, verbosity** â†’ evaluation scores for the response  \n",
        "\n",
        "We then generate a new column called **`train_text`**, which concatenates the  \n",
        "prompt and response into a single string separated by a special token `<|eos|>`.  \n",
        "\n",
        "This combined text will later serve as training input for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVC04IXKpEab",
        "outputId": "30b10c54-0c21-4d2d-f756-81b0bd6c369b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What are the three most important things... <|eos|> To build an assistive device...\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    {\n",
        "        'prompt': \"What are the three most important things...\",\n",
        "        'response': \"To build an assistive device...\",\n",
        "        'helpfulness': 3, 'correctness': 4, 'coherence': 4,\n",
        "        'complexity': 2, 'verbosity': 2\n",
        "    }\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create training text\n",
        "df[\"train_text\"] = df[\"prompt\"] + \" <|eos|> \" + df[\"response\"]\n",
        "\n",
        "print(df[\"train_text\"].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyyxCTk35HIO"
      },
      "source": [
        "**Filtering Examples by Context Size**\n",
        "\n",
        "We define a helper function `filter_examples` to remove dataset entries that are\n",
        "too short for the model's context window.  \n",
        "\n",
        "Steps performed:\n",
        "1. **Concatenate prompt and response**  \n",
        "   Each entry is combined into one string with the `<|eos|>` token separating them.  \n",
        "\n",
        "2. **Tokenize and measure length**  \n",
        "   The text is passed through the tokenizer (`enc.encode`) to count tokens.  \n",
        "\n",
        "3. **Apply the context size filter**  \n",
        "   Only examples whose token length is greater than or equal to the specified  \n",
        "   `context_size` are kept.  \n",
        "\n",
        "4. **Report filtering results**  \n",
        "   The function prints how many examples were retained versus the total.  \n",
        "\n",
        "This ensures that the training data fits within the modelâ€™s context window,  \n",
        "preventing truncation or wasted computation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jiS5NDStrmG"
      },
      "outputs": [],
      "source": [
        "def filter_examples(ds,context_length):\n",
        "  examples=[]\n",
        "  for x in ds:\n",
        "      example=x[\"prompt\"]+\" <|eos|> \"+x[\"response\"]\n",
        "      examples.append(example)\n",
        "  filtered_examples = [\n",
        "    text for text in examples\n",
        "    if len(enc.encode(text)) >= context_length\n",
        "  ]\n",
        "\n",
        "  print(f\"Kept {len(filtered_examples)} examples out of {len(examples)}\")\n",
        "  return filtered_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZhzhBzMxR4K",
        "outputId": "7534c261-eccd-4f80-efa5-6d2ea94567a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token IDs: [28065, 314, 1816, 284, 262, 3952, 290, 2497, 257, 4950, 26428, 13, 383, 6766, 373, 13055, 351, 289, 947, 286] ...\n",
            "\n",
            "ðŸ“¦ Batch 0\n",
            "Input IDs:\n",
            " tensor([[28065,   314,  1816,   284,   262,  3952,   290,  2497],\n",
            "        [  262,  3952,   290,  2497,   257,  4950, 26428,    13],\n",
            "        [  257,  4950, 26428,    13,   383,  6766,   373, 13055],\n",
            "        [  383,  6766,   373, 13055,   351,   289,   947,   286],\n",
            "        [  351,   289,   947,   286, 10912,   290, 11398,    11],\n",
            "        [10912,   290, 11398,    11,   290,   340, 14516,   502],\n",
            "        [  290,   340, 14516,   502,   286,   262,  8737,   286],\n",
            "        [  286,   262,  8737,   286,  3450,    13,   314,  3332]])\n",
            "Target IDs:\n",
            " tensor([[  314,  1816,   284,   262,  3952,   290,  2497,   257],\n",
            "        [ 3952,   290,  2497,   257,  4950, 26428,    13,   383],\n",
            "        [ 4950, 26428,    13,   383,  6766,   373, 13055,   351],\n",
            "        [ 6766,   373, 13055,   351,   289,   947,   286, 10912],\n",
            "        [  289,   947,   286, 10912,   290, 11398,    11,   290],\n",
            "        [  290, 11398,    11,   290,   340, 14516,   502,   286],\n",
            "        [  340, 14516,   502,   286,   262,  8737,   286,  3450],\n",
            "        [  262,  8737,   286,  3450,    13,   314,  3332,   319]])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Example\n",
        "# -------------------------------\n",
        "text = \"Yesterday I went to the park and saw a beautiful sunset. The sky was painted with hues of orange and pink, and it reminded me of the beauty of nature. I sat on a bench, enjoying the moment, and thought about how lucky I am to experience such wonders.\"\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Custom Dataset\n",
        "# -------------------------------\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text into token IDs\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Print tokens for understanding\n",
        "        print(\"Token IDs:\", token_ids[:20], \"...\")\n",
        "\n",
        "        # Chunk the tokens into overlapping sequences\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# -------------------------------\n",
        "# 3. DataLoader Wrapper\n",
        "# -------------------------------\n",
        "def create_dataloader_v1(txt, batch_size=2, max_length=8, stride=4):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return dataloader\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Instantiate & Iterate\n",
        "# -------------------------------\n",
        "dataloader = create_dataloader_v1(text, batch_size=8, max_length=8, stride=4)\n",
        "\n",
        "# Iterate and print\n",
        "for batch_idx, (input_ids, target_ids) in enumerate(dataloader):\n",
        "    print(f\"\\nðŸ“¦ Batch {batch_idx}\")\n",
        "    print(\"Input IDs:\\n\", input_ids)\n",
        "    print(\"Target IDs:\\n\", target_ids)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdRdvxPZ5HIO"
      },
      "source": [
        "##### **Understanding the Sliding Window, Shifting, and Stride**\n",
        "\n",
        "When preparing data for GPT training, we need both **inputs** (what the model sees)  \n",
        "and **targets** (what the model should predict).  \n",
        "\n",
        " ##### 1. Creating Input and Target Sequences\n",
        "- **Input sequence (`input_chunk`)** â†’ tokens from position *i* to *i + max_length*.  \n",
        "- **Target sequence (`target_chunk`)** â†’ the same tokens, but shifted by **one position**.  \n",
        "  - Example:  \n",
        "    ```\n",
        "    Input : [The, cat, sat, on, the]\n",
        "    Target: [cat, sat, on, the, mat]\n",
        "    ```\n",
        "- This shifting trains the model to predict the **next token** for every position.\n",
        "\n",
        "##### 2. Using a Sliding Window\n",
        "- We process long tokenized texts in overlapping chunks:\n",
        "  ```python\n",
        "  for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk  = token_ids[i : i + max_length]\n",
        "      target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
        "##### 3. Role of the Stride\n",
        "stride controls how far the window moves after each chunk:\n",
        "\n",
        "If stride < max_length â†’ overlapping chunks (context preserved).\n",
        "\n",
        "If stride == max_length â†’ no overlap (disjoint chunks).\n",
        "\n",
        "Overlap ensures that context spanning across chunk boundaries is not lost.\n",
        "\n",
        "##### 4. Eliminating Redundant Overlap\n",
        "Because the stride is smaller than max_length, chunks overlap.\n",
        "\n",
        "However, the shifting of targets ensures each token is only ever used to predict the next token,\n",
        "so even in overlaps, the learning task remains consistent and non-redundant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfENCRZty5N1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "class GPTDatasetExamples(Dataset):\n",
        "    def __init__(self, examples, tokenizer, max_length=1024, stride=512):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "\n",
        "        for example in examples:\n",
        "             token_ids = tokenizer.encode(example, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "              # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "             for i in range(0, len(token_ids) - max_length, stride):\n",
        "                  input_chunk = token_ids[i:i + max_length]\n",
        "                  target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "                  self.input_ids.append(torch.tensor(input_chunk))\n",
        "                  self.target_ids.append(torch.tensor(target_chunk))\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZaWYSzxxSUX"
      },
      "outputs": [],
      "source": [
        "def create_dataloader_from_examples(examples, batch_size=4, max_length=512, shuffle=True,stride=512,num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetExamples(examples, tokenizer, max_length,stride)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,num_workers=num_workers,drop_last=True)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vzLsPzlOzcVo",
        "outputId": "845a9d65-f6a0-4a7b-ca37-65868583ad4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kept 31454 examples out of 35331\n",
            "Kept 1601 examples out of 1789\n",
            "\n",
            "ðŸ“¦ Batch 0\n",
            "Input shape: torch.Size([8, 128])\n",
            "Target shape: torch.Size([8, 128])\n",
            "\n",
            "ðŸ“¦ Batch 1\n",
            "Input shape: torch.Size([8, 128])\n",
            "Target shape: torch.Size([8, 128])\n"
          ]
        }
      ],
      "source": [
        "# DataLoader\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 128,\n",
        "    \"n_embd\": 768,\n",
        "    \"n_layer\": 12,\n",
        "    \"n_head\": 12,\n",
        "    \"dropout\": 0.1\n",
        "}\n",
        "filtered_training_examples = filter_examples(ds[\"train\"], context_length=GPT_CONFIG_124M[\"context_length\"])\n",
        "filtered_validation_examples = filter_examples(ds[\"validation\"], context_length=GPT_CONFIG_124M[\"context_length\"])\n",
        "train_loader = create_dataloader_from_examples(filtered_training_examples, batch_size=8, max_length=GPT_CONFIG_124M[\"context_length\"],stride=GPT_CONFIG_124M[\"context_length\"])\n",
        "validation_loader = create_dataloader_from_examples(filtered_validation_examples, batch_size=8, max_length=GPT_CONFIG_124M[\"context_length\"],stride=GPT_CONFIG_124M[\"context_length\"])\n",
        "\n",
        "# Preview a few batches\n",
        "for batch_idx, (input_ids, target_ids) in enumerate(train_loader):\n",
        "    print(f\"\\nðŸ“¦ Batch {batch_idx}\")\n",
        "    print(\"Input shape:\", input_ids.shape)\n",
        "    print(\"Target shape:\", target_ids.shape)\n",
        "\n",
        "    if batch_idx == 1: break  # stop early"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gZA1ma1Kzerp",
        "outputId": "f7da80e5-bbb3-4201-a386-a86bb48556a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“¦ Batch 0\n",
            "Input shape: torch.Size([8, 128])\n",
            "Target shape: torch.Size([8, 128])\n",
            "\n",
            "ðŸ”¹ Sample 0\n",
            "ðŸ“ Input Text:\n",
            " \n",
            "Based on that,\n",
            "Extract only the sentences that mention the TUV organizations in reverse alphabetical order. Arrange then in a list using hyphens for each sentence. <|eos|> -Most countries are represented by a single accreditation body, which will administer the certification program to meet existing regulations. Some standard-setting bodies include CSA in Canada, CE in the European Union, FCC in the United States, and TUV in Germany.\n",
            "-Probably most known for automobile safety inspections in Europe, TUV companies also overlook several key industries such as energy, infrastructure, medical, manufacturing, technology, and consumer\n",
            "ðŸŽ¯ Target Text:\n",
            " Based on that,\n",
            "Extract only the sentences that mention the TUV organizations in reverse alphabetical order. Arrange then in a list using hyphens for each sentence. <|eos|> -Most countries are represented by a single accreditation body, which will administer the certification program to meet existing regulations. Some standard-setting bodies include CSA in Canada, CE in the European Union, FCC in the United States, and TUV in Germany.\n",
            "-Probably most known for automobile safety inspections in Europe, TUV companies also overlook several key industries such as energy, infrastructure, medical, manufacturing, technology, and consumer products\n",
            "\n",
            "ðŸ”¹ Sample 1\n",
            "ðŸ“ Input Text:\n",
            " uated 39.49% within the last five trades and 57.40% within the last 30 trades, which was a significant change from the beginning of this year. Despite the fact that the share price decreased -40.48% in the last 6 months and 21.73% was added to its value over the previous 3 months. ACRX stock is trading at a margin of 63.32%, 57.54% and -28.98% apart from the 20-Day, 50-Day and 200-Day Simple Moving Average prices.\n",
            "\n",
            "As of the close of trading, ACRX deals in the Healthcare domain.\n",
            "ðŸŽ¯ Target Text:\n",
            "  39.49% within the last five trades and 57.40% within the last 30 trades, which was a significant change from the beginning of this year. Despite the fact that the share price decreased -40.48% in the last 6 months and 21.73% was added to its value over the previous 3 months. ACRX stock is trading at a margin of 63.32%, 57.54% and -28.98% apart from the 20-Day, 50-Day and 200-Day Simple Moving Average prices.\n",
            "\n",
            "As of the close of trading, ACRX deals in the Healthcare domain. The\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Batch inspection\"\"\"\n",
        "for batch_idx, (input_ids, target_ids) in enumerate(validation_loader):\n",
        "    print(f\"\\nðŸ“¦ Batch {batch_idx}\")\n",
        "    print(\"Input shape:\", input_ids.shape)\n",
        "    print(\"Target shape:\", target_ids.shape)\n",
        "\n",
        "    # Decode and print one sample\n",
        "    for i in range(min(2, len(input_ids))):  # show first 2 examples in batch\n",
        "        input_text = enc.decode(input_ids[i].tolist())\n",
        "        target_text = enc.decode(target_ids[i].tolist())\n",
        "\n",
        "        print(f\"\\nðŸ”¹ Sample {i}\")\n",
        "        print(\"ðŸ“ Input Text:\\n\", input_text)\n",
        "        print(\"ðŸŽ¯ Target Text:\\n\", target_text)\n",
        "\n",
        "    break  # stop after first batch for now\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4_QC2kd2_KK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrWTV_9z1_-4"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D83h8Urw5HIO"
      },
      "source": [
        "### Loss Calculation for Language Modeling\n",
        "\n",
        "We train the GPT model using **cross-entropy loss**, which measures how well the predicted probabilities match the true next tokens.\n",
        "\n",
        "#### 1. Single Batch Loss\n",
        "For each token:\n",
        "- **Input** â†’ what the model sees  \n",
        "- **Target** â†’ the next token it should predict  \n",
        "- **Logits** â†’ raw scores from the model  \n",
        "\n",
        "The loss is:\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(y_i \\;|\\; x_{<i})\n",
        "$$\n",
        "\n",
        "- $N$: number of tokens  \n",
        "- $y_i$: correct token at position $i$  \n",
        "- $P(y_i \\mid x_{<i})$: predicted probability of $y_i$ given previous tokens  \n",
        "\n",
        "\n",
        "#### 2. Averaging Over Batches\n",
        "Across batches:\n",
        "\n",
        "$$\n",
        "\\text{Average Loss} = \\frac{1}{B} \\sum_{b=1}^{B} \\text{Loss}_b\n",
        "$$\n",
        "\n",
        "- \\(B\\): number of batches  \n",
        "\n",
        "#### 3. Example\n",
        "If the model predicts after  \n",
        "*â€œThe cat sat on theâ€*:\n",
        "\n",
        "- True word: **mat**  \n",
        "- Predicted: mat (0.7), dog (0.2), floor (0.1)  \n",
        "\n",
        "Loss =  \n",
        "$$\n",
        "-\\log(0.7) \\approx 0.36\n",
        "$$  \n",
        "\n",
        "Higher probability for the correct token â†’ **lower loss**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHLXIODE1qfK"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "    logits = model(input_batch)\n",
        "\n",
        "\n",
        "    loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), target_batch.view(-1))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i >= num_batches:\n",
        "            break\n",
        "\n",
        "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        print(f\"[Batch {i}] Current Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return total_loss / num_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6eIWtgzhTbp",
        "outputId": "97cd47d9-1d0c-4a03-aecd-34b61c01d0ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIqmBNJX5HIP",
        "outputId": "5820ea2f-2fbe-4974-edfa-680bd22a431e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch CUDA available: True\n",
            "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "print(\"PyTorch CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wZVHFG_b5uf"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X3U_yBqcAvK"
      },
      "source": [
        "Step 1: Initialize lists to track losses and tokens seen\n",
        "\n",
        "Step 2: Start the main training loop\n",
        "\n",
        "Step 3: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 4: Calculate loss gradients\n",
        "\n",
        "Step 5: Update model weights using loss gradients\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Print a sample text after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nJu6t4JTyoj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer,\n",
        "                       save_path=\"last_model.pt\"):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "    # âœ… Save only once at the end\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"âœ… Final model weights saved to: {save_path}\")\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLQctvWcb88p"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u1Y114rc_E9"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgesTCrUdJu-"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zawWFJM7czw0"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    # Get context length from model config or positional embedding weight shape\n",
        "    context_size = model.config[\"context_length\"]\n",
        "    # Alternatively:\n",
        "    # context_size = model.positional_encoding.weight.shape[0]\n",
        "\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liQKQPqMX5BE",
        "outputId": "3d451c59-8f3b-48e9-e775-cb6166e05beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Batch 0] Current Loss: 10.3633\n",
            "[Batch 1] Current Loss: 10.2848\n",
            "[Batch 2] Current Loss: 10.3461\n",
            "[Batch 3] Current Loss: 10.3137\n",
            "[Batch 4] Current Loss: 10.3680\n",
            "[Batch 5] Current Loss: 10.3652\n",
            "[Batch 6] Current Loss: 10.4101\n",
            "[Batch 7] Current Loss: 10.3786\n",
            "[Batch 8] Current Loss: 10.3371\n",
            "[Batch 9] Current Loss: 10.4251\n",
            "[Batch 0] Current Loss: 10.2695\n",
            "[Batch 1] Current Loss: 10.3675\n",
            "[Batch 2] Current Loss: 10.3650\n",
            "[Batch 3] Current Loss: 10.3761\n",
            "[Batch 4] Current Loss: 10.2723\n",
            "[Batch 5] Current Loss: 10.3753\n",
            "[Batch 6] Current Loss: 10.3187\n",
            "[Batch 7] Current Loss: 10.2874\n",
            "[Batch 8] Current Loss: 10.3441\n",
            "[Batch 9] Current Loss: 10.4447\n",
            "Ep 1 (Step 000000): Train loss 10.359, Val loss 10.342\n",
            "[Batch 0] Current Loss: 7.6338\n",
            "[Batch 1] Current Loss: 7.6949\n",
            "[Batch 2] Current Loss: 7.8984\n",
            "[Batch 3] Current Loss: 7.8161\n",
            "[Batch 4] Current Loss: 7.9295\n",
            "[Batch 5] Current Loss: 7.5881\n",
            "[Batch 6] Current Loss: 7.7191\n",
            "[Batch 7] Current Loss: 7.8620\n",
            "[Batch 8] Current Loss: 7.8553\n",
            "[Batch 9] Current Loss: 7.5728\n",
            "[Batch 0] Current Loss: 8.1226\n",
            "[Batch 1] Current Loss: 8.0054\n",
            "[Batch 2] Current Loss: 7.8580\n",
            "[Batch 3] Current Loss: 7.7403\n",
            "[Batch 4] Current Loss: 7.5315\n",
            "[Batch 5] Current Loss: 8.1368\n",
            "[Batch 6] Current Loss: 8.0788\n",
            "[Batch 7] Current Loss: 8.2608\n",
            "[Batch 8] Current Loss: 7.9031\n",
            "[Batch 9] Current Loss: 7.6694\n",
            "Ep 1 (Step 000020): Train loss 7.757, Val loss 7.931\n",
            "[Batch 0] Current Loss: 7.6543\n",
            "[Batch 1] Current Loss: 7.2886\n",
            "[Batch 2] Current Loss: 7.6647\n",
            "[Batch 3] Current Loss: 8.0647\n",
            "[Batch 4] Current Loss: 7.8316\n",
            "[Batch 5] Current Loss: 7.5404\n",
            "[Batch 6] Current Loss: 7.4196\n",
            "[Batch 7] Current Loss: 7.6680\n",
            "[Batch 8] Current Loss: 7.7470\n",
            "[Batch 9] Current Loss: 7.7944\n",
            "[Batch 0] Current Loss: 7.5594\n",
            "[Batch 1] Current Loss: 7.5609\n",
            "[Batch 2] Current Loss: 7.4307\n",
            "[Batch 3] Current Loss: 7.5499\n",
            "[Batch 4] Current Loss: 7.2788\n",
            "[Batch 5] Current Loss: 7.7829\n",
            "[Batch 6] Current Loss: 7.8081\n",
            "[Batch 7] Current Loss: 7.6308\n",
            "[Batch 8] Current Loss: 7.8338\n",
            "[Batch 9] Current Loss: 7.6636\n",
            "Ep 1 (Step 000040): Train loss 7.667, Val loss 7.610\n",
            "[Batch 0] Current Loss: 7.5394\n",
            "[Batch 1] Current Loss: 7.4018\n",
            "[Batch 2] Current Loss: 7.4737\n",
            "[Batch 3] Current Loss: 7.5924\n",
            "[Batch 4] Current Loss: 7.5550\n",
            "[Batch 5] Current Loss: 7.5612\n",
            "[Batch 6] Current Loss: 7.1903\n",
            "[Batch 7] Current Loss: 7.4304\n",
            "[Batch 8] Current Loss: 7.5174\n",
            "[Batch 9] Current Loss: 7.3983\n",
            "[Batch 0] Current Loss: 7.3152\n",
            "[Batch 1] Current Loss: 7.4444\n",
            "[Batch 2] Current Loss: 7.7093\n",
            "[Batch 3] Current Loss: 7.6401\n",
            "[Batch 4] Current Loss: 7.4542\n",
            "[Batch 5] Current Loss: 7.8434\n",
            "[Batch 6] Current Loss: 7.5888\n",
            "[Batch 7] Current Loss: 7.6063\n",
            "[Batch 8] Current Loss: 7.4333\n",
            "[Batch 9] Current Loss: 7.7939\n",
            "Ep 1 (Step 000060): Train loss 7.466, Val loss 7.583\n",
            "[Batch 0] Current Loss: 7.1521\n",
            "[Batch 1] Current Loss: 7.4265\n",
            "[Batch 2] Current Loss: 7.4459\n",
            "[Batch 3] Current Loss: 7.1907\n",
            "[Batch 4] Current Loss: 7.8718\n",
            "[Batch 5] Current Loss: 7.3314\n",
            "[Batch 6] Current Loss: 7.3305\n",
            "[Batch 7] Current Loss: 7.2992\n",
            "[Batch 8] Current Loss: 7.6651\n",
            "[Batch 9] Current Loss: 7.5607\n",
            "[Batch 0] Current Loss: 7.2191\n",
            "[Batch 1] Current Loss: 7.9147\n",
            "[Batch 2] Current Loss: 7.6483\n",
            "[Batch 3] Current Loss: 7.2317\n",
            "[Batch 4] Current Loss: 7.4980\n",
            "[Batch 5] Current Loss: 7.7569\n",
            "[Batch 6] Current Loss: 7.2478\n",
            "[Batch 7] Current Loss: 7.4057\n",
            "[Batch 8] Current Loss: 7.2314\n",
            "[Batch 9] Current Loss: 7.4682\n",
            "Ep 1 (Step 000080): Train loss 7.427, Val loss 7.462\n",
            "[Batch 0] Current Loss: 7.3399\n",
            "[Batch 1] Current Loss: 6.9160\n",
            "[Batch 2] Current Loss: 6.9217\n",
            "[Batch 3] Current Loss: 7.4684\n",
            "[Batch 4] Current Loss: 7.4168\n",
            "[Batch 5] Current Loss: 7.1383\n",
            "[Batch 6] Current Loss: 7.0344\n",
            "[Batch 7] Current Loss: 7.5181\n",
            "[Batch 8] Current Loss: 7.1240\n",
            "[Batch 9] Current Loss: 7.7012\n",
            "[Batch 0] Current Loss: 7.0326\n",
            "[Batch 1] Current Loss: 7.6204\n",
            "[Batch 2] Current Loss: 7.2832\n",
            "[Batch 3] Current Loss: 7.3059\n",
            "[Batch 4] Current Loss: 7.3003\n",
            "[Batch 5] Current Loss: 7.0819\n",
            "[Batch 6] Current Loss: 6.7354\n",
            "[Batch 7] Current Loss: 7.1949\n",
            "[Batch 8] Current Loss: 7.7055\n",
            "[Batch 9] Current Loss: 7.2380\n",
            "Ep 1 (Step 000100): Train loss 7.258, Val loss 7.250\n",
            "[Batch 0] Current Loss: 7.1054\n",
            "[Batch 1] Current Loss: 7.6995\n",
            "[Batch 2] Current Loss: 7.3376\n",
            "[Batch 3] Current Loss: 7.0300\n",
            "[Batch 4] Current Loss: 7.0629\n",
            "[Batch 5] Current Loss: 7.0940\n",
            "[Batch 6] Current Loss: 6.9709\n",
            "[Batch 7] Current Loss: 7.4079\n",
            "[Batch 8] Current Loss: 7.2895\n",
            "[Batch 9] Current Loss: 7.4294\n",
            "[Batch 0] Current Loss: 7.4940\n",
            "[Batch 1] Current Loss: 7.1969\n",
            "[Batch 2] Current Loss: 6.9934\n",
            "[Batch 3] Current Loss: 7.2276\n",
            "[Batch 4] Current Loss: 6.8689\n",
            "[Batch 5] Current Loss: 6.7099\n",
            "[Batch 6] Current Loss: 7.3713\n",
            "[Batch 7] Current Loss: 7.1791\n",
            "[Batch 8] Current Loss: 7.2933\n",
            "[Batch 9] Current Loss: 7.4259\n",
            "Ep 1 (Step 000120): Train loss 7.243, Val loss 7.176\n",
            "[Batch 0] Current Loss: 7.4361\n",
            "[Batch 1] Current Loss: 7.2389\n",
            "[Batch 2] Current Loss: 7.3597\n",
            "[Batch 3] Current Loss: 7.0042\n",
            "[Batch 4] Current Loss: 7.3383\n",
            "[Batch 5] Current Loss: 7.3078\n",
            "[Batch 6] Current Loss: 6.9215\n",
            "[Batch 7] Current Loss: 6.8382\n",
            "[Batch 8] Current Loss: 6.9592\n",
            "[Batch 9] Current Loss: 7.3173\n",
            "[Batch 0] Current Loss: 6.8800\n",
            "[Batch 1] Current Loss: 7.4063\n",
            "[Batch 2] Current Loss: 7.3445\n",
            "[Batch 3] Current Loss: 7.3424\n",
            "[Batch 4] Current Loss: 7.3393\n",
            "[Batch 5] Current Loss: 7.3696\n",
            "[Batch 6] Current Loss: 7.3054\n",
            "[Batch 7] Current Loss: 7.2216\n",
            "[Batch 8] Current Loss: 7.1313\n",
            "[Batch 9] Current Loss: 6.9897\n",
            "Ep 1 (Step 000140): Train loss 7.172, Val loss 7.233\n",
            "[Batch 0] Current Loss: 6.7825\n",
            "[Batch 1] Current Loss: 6.6634\n",
            "[Batch 2] Current Loss: 7.2382\n",
            "[Batch 3] Current Loss: 7.2706\n",
            "[Batch 4] Current Loss: 7.0734\n",
            "[Batch 5] Current Loss: 6.9724\n",
            "[Batch 6] Current Loss: 6.7702\n",
            "[Batch 7] Current Loss: 7.0900\n",
            "[Batch 8] Current Loss: 6.8326\n",
            "[Batch 9] Current Loss: 7.3244\n",
            "[Batch 0] Current Loss: 7.3892\n",
            "[Batch 1] Current Loss: 7.2891\n",
            "[Batch 2] Current Loss: 6.5718\n",
            "[Batch 3] Current Loss: 6.8396\n",
            "[Batch 4] Current Loss: 6.8540\n",
            "[Batch 5] Current Loss: 7.0935\n",
            "[Batch 6] Current Loss: 6.9957\n",
            "[Batch 7] Current Loss: 6.7994\n",
            "[Batch 8] Current Loss: 6.2952\n",
            "[Batch 9] Current Loss: 6.9753\n",
            "Ep 1 (Step 000160): Train loss 7.002, Val loss 6.910\n",
            "[Batch 0] Current Loss: 6.7165\n",
            "[Batch 1] Current Loss: 7.3509\n",
            "[Batch 2] Current Loss: 7.0789\n",
            "[Batch 3] Current Loss: 6.7661\n",
            "[Batch 4] Current Loss: 7.2723\n",
            "[Batch 5] Current Loss: 7.0184\n",
            "[Batch 6] Current Loss: 6.8288\n",
            "[Batch 7] Current Loss: 6.8494\n",
            "[Batch 8] Current Loss: 6.5007\n",
            "[Batch 9] Current Loss: 6.6990\n",
            "[Batch 0] Current Loss: 7.0065\n",
            "[Batch 1] Current Loss: 6.6965\n",
            "[Batch 2] Current Loss: 6.8705\n",
            "[Batch 3] Current Loss: 6.9196\n",
            "[Batch 4] Current Loss: 6.8179\n",
            "[Batch 5] Current Loss: 7.1093\n",
            "[Batch 6] Current Loss: 6.8842\n",
            "[Batch 7] Current Loss: 7.4704\n",
            "[Batch 8] Current Loss: 6.8609\n",
            "[Batch 9] Current Loss: 6.9237\n",
            "Ep 1 (Step 000180): Train loss 6.908, Val loss 6.956\n",
            "[Batch 0] Current Loss: 7.1568\n",
            "[Batch 1] Current Loss: 6.5875\n",
            "[Batch 2] Current Loss: 6.4776\n",
            "[Batch 3] Current Loss: 6.9130\n",
            "[Batch 4] Current Loss: 7.0149\n",
            "[Batch 5] Current Loss: 6.9934\n",
            "[Batch 6] Current Loss: 7.2207\n",
            "[Batch 7] Current Loss: 6.7315\n",
            "[Batch 8] Current Loss: 6.3695\n",
            "[Batch 9] Current Loss: 7.1758\n",
            "[Batch 0] Current Loss: 6.9773\n",
            "[Batch 1] Current Loss: 6.8603\n",
            "[Batch 2] Current Loss: 7.3667\n",
            "[Batch 3] Current Loss: 7.2598\n",
            "[Batch 4] Current Loss: 6.8601\n",
            "[Batch 5] Current Loss: 6.9155\n",
            "[Batch 6] Current Loss: 6.2949\n",
            "[Batch 7] Current Loss: 6.4546\n",
            "[Batch 8] Current Loss: 7.2822\n",
            "[Batch 9] Current Loss: 6.6151\n",
            "Ep 1 (Step 000200): Train loss 6.864, Val loss 6.889\n",
            "[Batch 0] Current Loss: 6.7413\n",
            "[Batch 1] Current Loss: 6.5972\n",
            "[Batch 2] Current Loss: 6.5715\n",
            "[Batch 3] Current Loss: 7.2238\n",
            "[Batch 4] Current Loss: 6.5380\n",
            "[Batch 5] Current Loss: 6.8648\n",
            "[Batch 6] Current Loss: 6.5662\n",
            "[Batch 7] Current Loss: 7.2194\n",
            "[Batch 8] Current Loss: 6.6472\n",
            "[Batch 9] Current Loss: 6.5637\n",
            "[Batch 0] Current Loss: 6.8446\n",
            "[Batch 1] Current Loss: 6.8732\n",
            "[Batch 2] Current Loss: 6.5765\n",
            "[Batch 3] Current Loss: 6.5673\n",
            "[Batch 4] Current Loss: 6.4164\n",
            "[Batch 5] Current Loss: 6.8154\n",
            "[Batch 6] Current Loss: 6.6906\n",
            "[Batch 7] Current Loss: 6.9579\n",
            "[Batch 8] Current Loss: 6.7788\n",
            "[Batch 9] Current Loss: 6.4963\n",
            "Ep 1 (Step 000220): Train loss 6.753, Val loss 6.702\n",
            "[Batch 0] Current Loss: 6.3411\n",
            "[Batch 1] Current Loss: 6.4871\n",
            "[Batch 2] Current Loss: 6.9759\n",
            "[Batch 3] Current Loss: 6.5749\n",
            "[Batch 4] Current Loss: 7.2417\n",
            "[Batch 5] Current Loss: 6.5131\n",
            "[Batch 6] Current Loss: 6.8933\n",
            "[Batch 7] Current Loss: 6.9280\n",
            "[Batch 8] Current Loss: 6.9897\n",
            "[Batch 9] Current Loss: 7.0822\n",
            "[Batch 0] Current Loss: 7.2749\n",
            "[Batch 1] Current Loss: 6.6184\n",
            "[Batch 2] Current Loss: 6.6784\n",
            "[Batch 3] Current Loss: 6.9936\n",
            "[Batch 4] Current Loss: 7.2172\n",
            "[Batch 5] Current Loss: 6.8258\n",
            "[Batch 6] Current Loss: 6.6132\n",
            "[Batch 7] Current Loss: 7.0657\n",
            "[Batch 8] Current Loss: 6.9678\n",
            "[Batch 9] Current Loss: 6.7375\n",
            "Ep 1 (Step 000240): Train loss 6.803, Val loss 6.899\n",
            "[Batch 0] Current Loss: 7.0645\n",
            "[Batch 1] Current Loss: 6.5584\n",
            "[Batch 2] Current Loss: 6.8157\n",
            "[Batch 3] Current Loss: 6.9165\n",
            "[Batch 4] Current Loss: 6.7105\n",
            "[Batch 5] Current Loss: 6.6171\n",
            "[Batch 6] Current Loss: 6.8789\n",
            "[Batch 7] Current Loss: 6.6383\n",
            "[Batch 8] Current Loss: 6.7782\n",
            "[Batch 9] Current Loss: 6.7685\n",
            "[Batch 0] Current Loss: 6.4716\n",
            "[Batch 1] Current Loss: 6.9441\n",
            "[Batch 2] Current Loss: 6.2498\n",
            "[Batch 3] Current Loss: 6.7906\n",
            "[Batch 4] Current Loss: 6.7645\n",
            "[Batch 5] Current Loss: 6.6020\n",
            "[Batch 6] Current Loss: 6.2951\n",
            "[Batch 7] Current Loss: 7.1502\n",
            "[Batch 8] Current Loss: 6.6252\n",
            "[Batch 9] Current Loss: 6.5658\n",
            "Ep 1 (Step 000260): Train loss 6.775, Val loss 6.646\n",
            "[Batch 0] Current Loss: 7.1854\n",
            "[Batch 1] Current Loss: 6.2920\n",
            "[Batch 2] Current Loss: 6.5923\n",
            "[Batch 3] Current Loss: 6.6268\n",
            "[Batch 4] Current Loss: 6.8733\n",
            "[Batch 5] Current Loss: 6.7551\n",
            "[Batch 6] Current Loss: 6.5146\n",
            "[Batch 7] Current Loss: 7.1259\n",
            "[Batch 8] Current Loss: 6.8218\n",
            "[Batch 9] Current Loss: 6.8630\n",
            "[Batch 0] Current Loss: 6.6144\n",
            "[Batch 1] Current Loss: 6.8859\n",
            "[Batch 2] Current Loss: 6.6115\n",
            "[Batch 3] Current Loss: 7.1512\n",
            "[Batch 4] Current Loss: 7.4051\n",
            "[Batch 5] Current Loss: 6.8251\n",
            "[Batch 6] Current Loss: 6.9661\n",
            "[Batch 7] Current Loss: 6.3749\n",
            "[Batch 8] Current Loss: 6.8476\n",
            "[Batch 9] Current Loss: 7.0239\n",
            "Ep 1 (Step 000280): Train loss 6.765, Val loss 6.871\n",
            "[Batch 0] Current Loss: 5.6844\n",
            "[Batch 1] Current Loss: 6.9595\n",
            "[Batch 2] Current Loss: 6.4407\n",
            "[Batch 3] Current Loss: 6.9181\n",
            "[Batch 4] Current Loss: 6.8042\n",
            "[Batch 5] Current Loss: 6.5929\n",
            "[Batch 6] Current Loss: 7.1987\n",
            "[Batch 7] Current Loss: 6.6594\n",
            "[Batch 8] Current Loss: 6.6139\n",
            "[Batch 9] Current Loss: 6.4642\n",
            "[Batch 0] Current Loss: 6.7008\n",
            "[Batch 1] Current Loss: 6.5452\n",
            "[Batch 2] Current Loss: 6.8185\n",
            "[Batch 3] Current Loss: 7.1653\n",
            "[Batch 4] Current Loss: 6.6398\n",
            "[Batch 5] Current Loss: 6.6112\n",
            "[Batch 6] Current Loss: 6.5433\n",
            "[Batch 7] Current Loss: 6.3808\n",
            "[Batch 8] Current Loss: 6.1937\n",
            "[Batch 9] Current Loss: 6.7909\n",
            "Ep 1 (Step 000300): Train loss 6.634, Val loss 6.639\n",
            "[Batch 0] Current Loss: 6.4028\n",
            "[Batch 1] Current Loss: 6.7454\n",
            "[Batch 2] Current Loss: 6.3554\n",
            "[Batch 3] Current Loss: 7.1216\n",
            "[Batch 4] Current Loss: 6.8812\n",
            "[Batch 5] Current Loss: 6.3798\n",
            "[Batch 6] Current Loss: 6.7797\n",
            "[Batch 7] Current Loss: 7.3081\n",
            "[Batch 8] Current Loss: 7.0204\n",
            "[Batch 9] Current Loss: 6.6528\n",
            "[Batch 0] Current Loss: 6.7736\n",
            "[Batch 1] Current Loss: 6.3944\n",
            "[Batch 2] Current Loss: 7.0811\n",
            "[Batch 3] Current Loss: 6.5040\n",
            "[Batch 4] Current Loss: 6.4548\n",
            "[Batch 5] Current Loss: 6.5062\n",
            "[Batch 6] Current Loss: 6.7597\n",
            "[Batch 7] Current Loss: 6.8671\n",
            "[Batch 8] Current Loss: 6.8140\n",
            "[Batch 9] Current Loss: 7.1005\n",
            "Ep 1 (Step 000320): Train loss 6.765, Val loss 6.726\n",
            "[Batch 0] Current Loss: 6.4102\n",
            "[Batch 1] Current Loss: 6.3613\n",
            "[Batch 2] Current Loss: 6.3695\n",
            "[Batch 3] Current Loss: 6.4192\n",
            "[Batch 4] Current Loss: 7.1565\n",
            "[Batch 5] Current Loss: 6.5930\n",
            "[Batch 6] Current Loss: 6.4402\n",
            "[Batch 7] Current Loss: 6.2603\n",
            "[Batch 8] Current Loss: 6.3680\n",
            "[Batch 9] Current Loss: 6.5529\n",
            "[Batch 0] Current Loss: 6.8267\n",
            "[Batch 1] Current Loss: 6.2090\n",
            "[Batch 2] Current Loss: 6.3799\n",
            "[Batch 3] Current Loss: 6.4948\n",
            "[Batch 4] Current Loss: 6.9104\n",
            "[Batch 5] Current Loss: 6.7551\n",
            "[Batch 6] Current Loss: 7.2950\n",
            "[Batch 7] Current Loss: 7.4011\n",
            "[Batch 8] Current Loss: 6.4881\n",
            "[Batch 9] Current Loss: 6.8048\n",
            "Ep 1 (Step 000340): Train loss 6.493, Val loss 6.757\n",
            "[Batch 0] Current Loss: 7.0073\n",
            "[Batch 1] Current Loss: 6.4325\n",
            "[Batch 2] Current Loss: 6.6924\n",
            "[Batch 3] Current Loss: 6.4230\n",
            "[Batch 4] Current Loss: 6.7980\n",
            "[Batch 5] Current Loss: 6.8592\n",
            "[Batch 6] Current Loss: 6.7510\n",
            "[Batch 7] Current Loss: 6.3331\n",
            "[Batch 8] Current Loss: 6.8596\n",
            "[Batch 9] Current Loss: 6.5422\n",
            "[Batch 0] Current Loss: 6.3742\n",
            "[Batch 1] Current Loss: 6.9977\n",
            "[Batch 2] Current Loss: 6.8029\n",
            "[Batch 3] Current Loss: 6.8207\n",
            "[Batch 4] Current Loss: 6.9848\n",
            "[Batch 5] Current Loss: 6.9214\n",
            "[Batch 6] Current Loss: 6.3630\n",
            "[Batch 7] Current Loss: 6.8671\n",
            "[Batch 8] Current Loss: 6.6920\n",
            "[Batch 9] Current Loss: 7.0002\n",
            "Ep 1 (Step 000360): Train loss 6.670, Val loss 6.782\n",
            "[Batch 0] Current Loss: 6.6413\n",
            "[Batch 1] Current Loss: 6.3654\n",
            "[Batch 2] Current Loss: 6.9140\n",
            "[Batch 3] Current Loss: 6.8484\n",
            "[Batch 4] Current Loss: 6.4636\n",
            "[Batch 5] Current Loss: 6.7498\n",
            "[Batch 6] Current Loss: 6.4757\n",
            "[Batch 7] Current Loss: 6.5162\n",
            "[Batch 8] Current Loss: 6.3570\n",
            "[Batch 9] Current Loss: 6.2940\n",
            "[Batch 0] Current Loss: 6.3990\n",
            "[Batch 1] Current Loss: 6.5554\n",
            "[Batch 2] Current Loss: 6.9687\n",
            "[Batch 3] Current Loss: 6.4162\n",
            "[Batch 4] Current Loss: 6.3810\n",
            "[Batch 5] Current Loss: 6.7451\n",
            "[Batch 6] Current Loss: 6.4241\n",
            "[Batch 7] Current Loss: 6.7626\n",
            "[Batch 8] Current Loss: 6.6661\n",
            "[Batch 9] Current Loss: 6.6920\n",
            "Ep 1 (Step 000380): Train loss 6.563, Val loss 6.601\n",
            "[Batch 0] Current Loss: 6.6324\n",
            "[Batch 1] Current Loss: 6.6574\n",
            "[Batch 2] Current Loss: 6.3772\n",
            "[Batch 3] Current Loss: 6.6460\n",
            "[Batch 4] Current Loss: 6.4404\n",
            "[Batch 5] Current Loss: 6.2256\n",
            "[Batch 6] Current Loss: 6.8199\n",
            "[Batch 7] Current Loss: 6.4470\n",
            "[Batch 8] Current Loss: 6.5051\n",
            "[Batch 9] Current Loss: 6.0979\n",
            "[Batch 0] Current Loss: 6.5117\n",
            "[Batch 1] Current Loss: 6.4404\n",
            "[Batch 2] Current Loss: 6.8888\n",
            "[Batch 3] Current Loss: 6.8313\n",
            "[Batch 4] Current Loss: 7.1950\n",
            "[Batch 5] Current Loss: 6.8120\n",
            "[Batch 6] Current Loss: 6.6848\n",
            "[Batch 7] Current Loss: 6.6670\n",
            "[Batch 8] Current Loss: 6.6195\n",
            "[Batch 9] Current Loss: 6.5584\n",
            "Ep 1 (Step 000400): Train loss 6.485, Val loss 6.721\n",
            "[Batch 0] Current Loss: 6.6980\n",
            "[Batch 1] Current Loss: 6.7288\n",
            "[Batch 2] Current Loss: 6.4507\n",
            "[Batch 3] Current Loss: 5.9512\n",
            "[Batch 4] Current Loss: 6.7114\n",
            "[Batch 5] Current Loss: 6.3955\n",
            "[Batch 6] Current Loss: 6.7238\n",
            "[Batch 7] Current Loss: 6.9477\n",
            "[Batch 8] Current Loss: 6.7628\n",
            "[Batch 9] Current Loss: 6.7877\n",
            "[Batch 0] Current Loss: 6.7307\n",
            "[Batch 1] Current Loss: 6.4179\n",
            "[Batch 2] Current Loss: 6.5574\n",
            "[Batch 3] Current Loss: 6.5057\n",
            "[Batch 4] Current Loss: 6.0192\n",
            "[Batch 5] Current Loss: 6.6429\n",
            "[Batch 6] Current Loss: 6.9353\n",
            "[Batch 7] Current Loss: 6.5459\n",
            "[Batch 8] Current Loss: 6.5579\n",
            "[Batch 9] Current Loss: 6.6989\n",
            "Ep 1 (Step 000420): Train loss 6.616, Val loss 6.561\n",
            "[Batch 0] Current Loss: 6.3777\n",
            "[Batch 1] Current Loss: 6.2058\n",
            "[Batch 2] Current Loss: 6.4600\n",
            "[Batch 3] Current Loss: 6.6328\n",
            "[Batch 4] Current Loss: 6.6782\n",
            "[Batch 5] Current Loss: 5.8733\n",
            "[Batch 6] Current Loss: 6.6776\n",
            "[Batch 7] Current Loss: 6.5265\n",
            "[Batch 8] Current Loss: 6.2127\n",
            "[Batch 9] Current Loss: 6.8690\n",
            "[Batch 0] Current Loss: 6.6527\n",
            "[Batch 1] Current Loss: 7.2176\n",
            "[Batch 2] Current Loss: 6.4395\n",
            "[Batch 3] Current Loss: 6.7024\n",
            "[Batch 4] Current Loss: 6.7088\n",
            "[Batch 5] Current Loss: 6.5984\n",
            "[Batch 6] Current Loss: 6.4764\n",
            "[Batch 7] Current Loss: 6.7289\n",
            "[Batch 8] Current Loss: 6.4034\n",
            "[Batch 9] Current Loss: 6.4712\n",
            "Ep 1 (Step 000440): Train loss 6.451, Val loss 6.640\n",
            "[Batch 0] Current Loss: 6.4231\n",
            "[Batch 1] Current Loss: 6.4451\n",
            "[Batch 2] Current Loss: 6.6091\n",
            "[Batch 3] Current Loss: 6.7066\n",
            "[Batch 4] Current Loss: 6.6133\n",
            "[Batch 5] Current Loss: 6.0879\n",
            "[Batch 6] Current Loss: 6.7328\n",
            "[Batch 7] Current Loss: 6.5202\n",
            "[Batch 8] Current Loss: 6.5972\n",
            "[Batch 9] Current Loss: 6.2764\n",
            "[Batch 0] Current Loss: 6.1021\n",
            "[Batch 1] Current Loss: 6.3655\n",
            "[Batch 2] Current Loss: 6.8612\n",
            "[Batch 3] Current Loss: 6.8154\n",
            "[Batch 4] Current Loss: 6.4518\n",
            "[Batch 5] Current Loss: 6.3227\n",
            "[Batch 6] Current Loss: 6.7788\n",
            "[Batch 7] Current Loss: 6.1218\n",
            "[Batch 8] Current Loss: 6.3091\n",
            "[Batch 9] Current Loss: 6.5834\n",
            "Ep 1 (Step 000460): Train loss 6.501, Val loss 6.471\n",
            "[Batch 0] Current Loss: 6.6998\n",
            "[Batch 1] Current Loss: 6.4305\n",
            "[Batch 2] Current Loss: 6.3491\n",
            "[Batch 3] Current Loss: 5.8098\n",
            "[Batch 4] Current Loss: 6.2092\n",
            "[Batch 5] Current Loss: 6.6014\n",
            "[Batch 6] Current Loss: 6.3896\n",
            "[Batch 7] Current Loss: 6.3644\n",
            "[Batch 8] Current Loss: 6.1494\n",
            "[Batch 9] Current Loss: 6.7307\n",
            "[Batch 0] Current Loss: 6.3060\n",
            "[Batch 1] Current Loss: 6.8142\n",
            "[Batch 2] Current Loss: 6.2910\n",
            "[Batch 3] Current Loss: 6.7984\n",
            "[Batch 4] Current Loss: 6.2534\n",
            "[Batch 5] Current Loss: 6.5571\n",
            "[Batch 6] Current Loss: 6.2100\n",
            "[Batch 7] Current Loss: 6.7976\n",
            "[Batch 8] Current Loss: 6.5373\n",
            "[Batch 9] Current Loss: 6.4301\n",
            "Ep 1 (Step 000480): Train loss 6.373, Val loss 6.500\n",
            "[Batch 0] Current Loss: 6.3793\n",
            "[Batch 1] Current Loss: 6.3914\n",
            "[Batch 2] Current Loss: 6.7816\n",
            "[Batch 3] Current Loss: 6.3830\n",
            "[Batch 4] Current Loss: 6.4588\n",
            "[Batch 5] Current Loss: 6.2201\n",
            "[Batch 6] Current Loss: 6.7749\n",
            "[Batch 7] Current Loss: 6.3791\n",
            "[Batch 8] Current Loss: 6.2183\n",
            "[Batch 9] Current Loss: 6.8973\n",
            "[Batch 0] Current Loss: 6.6368\n",
            "[Batch 1] Current Loss: 6.9353\n",
            "[Batch 2] Current Loss: 6.6832\n",
            "[Batch 3] Current Loss: 6.5554\n",
            "[Batch 4] Current Loss: 6.8607\n",
            "[Batch 5] Current Loss: 6.3293\n",
            "[Batch 6] Current Loss: 6.3926\n",
            "[Batch 7] Current Loss: 6.4186\n",
            "[Batch 8] Current Loss: 6.5894\n",
            "[Batch 9] Current Loss: 5.9961\n",
            "Ep 1 (Step 000500): Train loss 6.488, Val loss 6.540\n",
            "[Batch 0] Current Loss: 6.1170\n",
            "[Batch 1] Current Loss: 6.3758\n",
            "[Batch 2] Current Loss: 6.2868\n",
            "[Batch 3] Current Loss: 6.3919\n",
            "[Batch 4] Current Loss: 6.5681\n",
            "[Batch 5] Current Loss: 6.2259\n",
            "[Batch 6] Current Loss: 6.5076\n",
            "[Batch 7] Current Loss: 6.0850\n",
            "[Batch 8] Current Loss: 6.2205\n",
            "[Batch 9] Current Loss: 6.3367\n",
            "[Batch 0] Current Loss: 7.2313\n",
            "[Batch 1] Current Loss: 6.8525\n",
            "[Batch 2] Current Loss: 6.2076\n",
            "[Batch 3] Current Loss: 6.1837\n",
            "[Batch 4] Current Loss: 6.7024\n",
            "[Batch 5] Current Loss: 6.2989\n",
            "[Batch 6] Current Loss: 5.9516\n",
            "[Batch 7] Current Loss: 6.5349\n",
            "[Batch 8] Current Loss: 6.7556\n",
            "[Batch 9] Current Loss: 6.4122\n",
            "Ep 1 (Step 000520): Train loss 6.312, Val loss 6.513\n",
            "[Batch 0] Current Loss: 6.6173\n",
            "[Batch 1] Current Loss: 6.2846\n",
            "[Batch 2] Current Loss: 6.4663\n",
            "[Batch 3] Current Loss: 6.2889\n",
            "[Batch 4] Current Loss: 6.7938\n",
            "[Batch 5] Current Loss: 5.7173\n",
            "[Batch 6] Current Loss: 6.4050\n",
            "[Batch 7] Current Loss: 6.2185\n",
            "[Batch 8] Current Loss: 6.2565\n",
            "[Batch 9] Current Loss: 6.7288\n",
            "[Batch 0] Current Loss: 6.6802\n",
            "[Batch 1] Current Loss: 5.9573\n",
            "[Batch 2] Current Loss: 6.3464\n",
            "[Batch 3] Current Loss: 6.1700\n",
            "[Batch 4] Current Loss: 6.4004\n",
            "[Batch 5] Current Loss: 6.3027\n",
            "[Batch 6] Current Loss: 5.9659\n",
            "[Batch 7] Current Loss: 6.7059\n",
            "[Batch 8] Current Loss: 6.1243\n",
            "[Batch 9] Current Loss: 6.0064\n",
            "Ep 1 (Step 000540): Train loss 6.378, Val loss 6.266\n",
            "[Batch 0] Current Loss: 6.5778\n",
            "[Batch 1] Current Loss: 6.7874\n",
            "[Batch 2] Current Loss: 6.2591\n",
            "[Batch 3] Current Loss: 6.5258\n",
            "[Batch 4] Current Loss: 6.3424\n",
            "[Batch 5] Current Loss: 6.6006\n",
            "[Batch 6] Current Loss: 5.7953\n",
            "[Batch 7] Current Loss: 6.7624\n",
            "[Batch 8] Current Loss: 6.5411\n",
            "[Batch 9] Current Loss: 6.1933\n",
            "[Batch 0] Current Loss: 6.3058\n",
            "[Batch 1] Current Loss: 6.1753\n",
            "[Batch 2] Current Loss: 6.1509\n",
            "[Batch 3] Current Loss: 6.3622\n",
            "[Batch 4] Current Loss: 6.4447\n",
            "[Batch 5] Current Loss: 6.6717\n",
            "[Batch 6] Current Loss: 5.9825\n",
            "[Batch 7] Current Loss: 6.8013\n",
            "[Batch 8] Current Loss: 6.7875\n",
            "[Batch 9] Current Loss: 7.0557\n",
            "Ep 1 (Step 000560): Train loss 6.439, Val loss 6.474\n",
            "[Batch 0] Current Loss: 6.1496\n",
            "[Batch 1] Current Loss: 6.4761\n",
            "[Batch 2] Current Loss: 6.6505\n",
            "[Batch 3] Current Loss: 6.3212\n",
            "[Batch 4] Current Loss: 6.2973\n",
            "[Batch 5] Current Loss: 6.0495\n",
            "[Batch 6] Current Loss: 6.3816\n",
            "[Batch 7] Current Loss: 6.4819\n",
            "[Batch 8] Current Loss: 6.5003\n",
            "[Batch 9] Current Loss: 6.4081\n",
            "[Batch 0] Current Loss: 6.7224\n",
            "[Batch 1] Current Loss: 6.0271\n",
            "[Batch 2] Current Loss: 6.2243\n",
            "[Batch 3] Current Loss: 6.1930\n",
            "[Batch 4] Current Loss: 6.6571\n",
            "[Batch 5] Current Loss: 5.9615\n",
            "[Batch 6] Current Loss: 6.2941\n",
            "[Batch 7] Current Loss: 5.8791\n",
            "[Batch 8] Current Loss: 6.4104\n",
            "[Batch 9] Current Loss: 6.6388\n",
            "Ep 1 (Step 000580): Train loss 6.372, Val loss 6.301\n",
            "[Batch 0] Current Loss: 6.5317\n",
            "[Batch 1] Current Loss: 5.9923\n",
            "[Batch 2] Current Loss: 6.0994\n",
            "[Batch 3] Current Loss: 6.9161\n",
            "[Batch 4] Current Loss: 5.9306\n",
            "[Batch 5] Current Loss: 6.8835\n",
            "[Batch 6] Current Loss: 6.6233\n",
            "[Batch 7] Current Loss: 6.4568\n",
            "[Batch 8] Current Loss: 6.2360\n",
            "[Batch 9] Current Loss: 6.2971\n",
            "[Batch 0] Current Loss: 6.0501\n",
            "[Batch 1] Current Loss: 6.6538\n",
            "[Batch 2] Current Loss: 6.2881\n",
            "[Batch 3] Current Loss: 6.3463\n",
            "[Batch 4] Current Loss: 6.3160\n",
            "[Batch 5] Current Loss: 6.5768\n",
            "[Batch 6] Current Loss: 6.1123\n",
            "[Batch 7] Current Loss: 6.5799\n",
            "[Batch 8] Current Loss: 6.2063\n",
            "[Batch 9] Current Loss: 5.9780\n",
            "Ep 1 (Step 000600): Train loss 6.397, Val loss 6.311\n",
            "[Batch 0] Current Loss: 6.0953\n",
            "[Batch 1] Current Loss: 6.3455\n",
            "[Batch 2] Current Loss: 6.2617\n",
            "[Batch 3] Current Loss: 5.8883\n",
            "[Batch 4] Current Loss: 6.2925\n",
            "[Batch 5] Current Loss: 5.8202\n",
            "[Batch 6] Current Loss: 6.3193\n",
            "[Batch 7] Current Loss: 6.3802\n",
            "[Batch 8] Current Loss: 6.6311\n",
            "[Batch 9] Current Loss: 6.4126\n",
            "[Batch 0] Current Loss: 5.7669\n",
            "[Batch 1] Current Loss: 6.6657\n",
            "[Batch 2] Current Loss: 6.6867\n",
            "[Batch 3] Current Loss: 6.6192\n",
            "[Batch 4] Current Loss: 6.0470\n",
            "[Batch 5] Current Loss: 6.1969\n",
            "[Batch 6] Current Loss: 6.2340\n",
            "[Batch 7] Current Loss: 6.4638\n",
            "[Batch 8] Current Loss: 6.4038\n",
            "[Batch 9] Current Loss: 6.1253\n",
            "Ep 1 (Step 000620): Train loss 6.245, Val loss 6.321\n",
            "[Batch 0] Current Loss: 5.9913\n",
            "[Batch 1] Current Loss: 6.5406\n",
            "[Batch 2] Current Loss: 6.5573\n",
            "[Batch 3] Current Loss: 6.3869\n",
            "[Batch 4] Current Loss: 6.2139\n",
            "[Batch 5] Current Loss: 6.3220\n",
            "[Batch 6] Current Loss: 6.4090\n",
            "[Batch 7] Current Loss: 5.6800\n",
            "[Batch 8] Current Loss: 6.2176\n",
            "[Batch 9] Current Loss: 5.8729\n",
            "[Batch 0] Current Loss: 6.2026\n",
            "[Batch 1] Current Loss: 6.6485\n",
            "[Batch 2] Current Loss: 6.7846\n",
            "[Batch 3] Current Loss: 5.4664\n",
            "[Batch 4] Current Loss: 6.4634\n",
            "[Batch 5] Current Loss: 6.5811\n",
            "[Batch 6] Current Loss: 6.1394\n",
            "[Batch 7] Current Loss: 6.6282\n",
            "[Batch 8] Current Loss: 6.6512\n",
            "[Batch 9] Current Loss: 6.1172\n",
            "Ep 1 (Step 000640): Train loss 6.219, Val loss 6.368\n",
            "[Batch 0] Current Loss: 6.5423\n",
            "[Batch 1] Current Loss: 6.3207\n",
            "[Batch 2] Current Loss: 6.0786\n",
            "[Batch 3] Current Loss: 6.2234\n",
            "[Batch 4] Current Loss: 6.0802\n",
            "[Batch 5] Current Loss: 6.1086\n",
            "[Batch 6] Current Loss: 6.3700\n",
            "[Batch 7] Current Loss: 6.4220\n",
            "[Batch 8] Current Loss: 6.6004\n",
            "[Batch 9] Current Loss: 5.9738\n",
            "[Batch 0] Current Loss: 6.4460\n",
            "[Batch 1] Current Loss: 6.7793\n",
            "[Batch 2] Current Loss: 5.9196\n",
            "[Batch 3] Current Loss: 6.3675\n",
            "[Batch 4] Current Loss: 6.8602\n",
            "[Batch 5] Current Loss: 6.6878\n",
            "[Batch 6] Current Loss: 6.0055\n",
            "[Batch 7] Current Loss: 6.1960\n",
            "[Batch 8] Current Loss: 6.0493\n",
            "[Batch 9] Current Loss: 6.6506\n",
            "Ep 1 (Step 000660): Train loss 6.272, Val loss 6.396\n",
            "[Batch 0] Current Loss: 6.8911\n",
            "[Batch 1] Current Loss: 5.9685\n",
            "[Batch 2] Current Loss: 6.4168\n",
            "[Batch 3] Current Loss: 6.6450\n",
            "[Batch 4] Current Loss: 6.4968\n",
            "[Batch 5] Current Loss: 6.1690\n",
            "[Batch 6] Current Loss: 5.8137\n",
            "[Batch 7] Current Loss: 6.0814\n",
            "[Batch 8] Current Loss: 6.2357\n",
            "[Batch 9] Current Loss: 5.9379\n",
            "[Batch 0] Current Loss: 5.9934\n",
            "[Batch 1] Current Loss: 6.2438\n",
            "[Batch 2] Current Loss: 5.9091\n",
            "[Batch 3] Current Loss: 6.3789\n",
            "[Batch 4] Current Loss: 6.5691\n",
            "[Batch 5] Current Loss: 6.5587\n",
            "[Batch 6] Current Loss: 6.2328\n",
            "[Batch 7] Current Loss: 6.3208\n",
            "[Batch 8] Current Loss: 6.1736\n",
            "[Batch 9] Current Loss: 6.1699\n",
            "Ep 1 (Step 000680): Train loss 6.266, Val loss 6.255\n",
            "[Batch 0] Current Loss: 6.4217\n",
            "[Batch 1] Current Loss: 6.2151\n",
            "[Batch 2] Current Loss: 6.1331\n",
            "[Batch 3] Current Loss: 6.2045\n",
            "[Batch 4] Current Loss: 6.2670\n",
            "[Batch 5] Current Loss: 6.4327\n",
            "[Batch 6] Current Loss: 6.3104\n",
            "[Batch 7] Current Loss: 6.4288\n",
            "[Batch 8] Current Loss: 6.4644\n",
            "[Batch 9] Current Loss: 5.9952\n",
            "[Batch 0] Current Loss: 6.5550\n",
            "[Batch 1] Current Loss: 6.5133\n",
            "[Batch 2] Current Loss: 6.6098\n",
            "[Batch 3] Current Loss: 6.1352\n",
            "[Batch 4] Current Loss: 6.1408\n",
            "[Batch 5] Current Loss: 6.3584\n",
            "[Batch 6] Current Loss: 6.1059\n",
            "[Batch 7] Current Loss: 5.8177\n",
            "[Batch 8] Current Loss: 6.0108\n",
            "[Batch 9] Current Loss: 6.0060\n",
            "Ep 1 (Step 000700): Train loss 6.287, Val loss 6.225\n",
            "[Batch 0] Current Loss: 6.1429\n",
            "[Batch 1] Current Loss: 6.5771\n",
            "[Batch 2] Current Loss: 6.4792\n",
            "[Batch 3] Current Loss: 5.8395\n",
            "[Batch 4] Current Loss: 6.2517\n",
            "[Batch 5] Current Loss: 6.1628\n",
            "[Batch 6] Current Loss: 6.3901\n",
            "[Batch 7] Current Loss: 5.9363\n",
            "[Batch 8] Current Loss: 6.0285\n",
            "[Batch 9] Current Loss: 6.3134\n",
            "[Batch 0] Current Loss: 6.4407\n",
            "[Batch 1] Current Loss: 6.3376\n",
            "[Batch 2] Current Loss: 6.3918\n",
            "[Batch 3] Current Loss: 6.6463\n",
            "[Batch 4] Current Loss: 6.7629\n",
            "[Batch 5] Current Loss: 6.4923\n",
            "[Batch 6] Current Loss: 6.0464\n",
            "[Batch 7] Current Loss: 6.3637\n",
            "[Batch 8] Current Loss: 6.4955\n",
            "[Batch 9] Current Loss: 6.5517\n",
            "Ep 1 (Step 000720): Train loss 6.212, Val loss 6.453\n",
            "[Batch 0] Current Loss: 6.3692\n",
            "[Batch 1] Current Loss: 6.2067\n",
            "[Batch 2] Current Loss: 6.6052\n",
            "[Batch 3] Current Loss: 6.3547\n",
            "[Batch 4] Current Loss: 6.1054\n",
            "[Batch 5] Current Loss: 6.3468\n",
            "[Batch 6] Current Loss: 6.5884\n",
            "[Batch 7] Current Loss: 6.6102\n",
            "[Batch 8] Current Loss: 6.0156\n",
            "[Batch 9] Current Loss: 5.9789\n",
            "[Batch 0] Current Loss: 6.9080\n",
            "[Batch 1] Current Loss: 5.6180\n",
            "[Batch 2] Current Loss: 6.3644\n",
            "[Batch 3] Current Loss: 6.5952\n",
            "[Batch 4] Current Loss: 6.0536\n",
            "[Batch 5] Current Loss: 6.3652\n",
            "[Batch 6] Current Loss: 6.3458\n",
            "[Batch 7] Current Loss: 6.1945\n",
            "[Batch 8] Current Loss: 6.4196\n",
            "[Batch 9] Current Loss: 6.3492\n",
            "Ep 1 (Step 000740): Train loss 6.318, Val loss 6.321\n",
            "[Batch 0] Current Loss: 5.5307\n",
            "[Batch 1] Current Loss: 6.2318\n",
            "[Batch 2] Current Loss: 5.9165\n",
            "[Batch 3] Current Loss: 6.6064\n",
            "[Batch 4] Current Loss: 6.7300\n",
            "[Batch 5] Current Loss: 6.3023\n",
            "[Batch 6] Current Loss: 6.3502\n",
            "[Batch 7] Current Loss: 6.1489\n",
            "[Batch 8] Current Loss: 6.6783\n",
            "[Batch 9] Current Loss: 6.3955\n",
            "[Batch 0] Current Loss: 6.6945\n",
            "[Batch 1] Current Loss: 5.7141\n",
            "[Batch 2] Current Loss: 6.9405\n",
            "[Batch 3] Current Loss: 6.8101\n",
            "[Batch 4] Current Loss: 6.9686\n",
            "[Batch 5] Current Loss: 6.0886\n",
            "[Batch 6] Current Loss: 6.1157\n",
            "[Batch 7] Current Loss: 6.0523\n",
            "[Batch 8] Current Loss: 6.7153\n",
            "[Batch 9] Current Loss: 5.6972\n",
            "Ep 1 (Step 000760): Train loss 6.289, Val loss 6.380\n",
            "[Batch 0] Current Loss: 6.2595\n",
            "[Batch 1] Current Loss: 6.3517\n",
            "[Batch 2] Current Loss: 5.8015\n",
            "[Batch 3] Current Loss: 6.3369\n",
            "[Batch 4] Current Loss: 5.6726\n",
            "[Batch 5] Current Loss: 6.5847\n",
            "[Batch 6] Current Loss: 6.3227\n",
            "[Batch 7] Current Loss: 6.2843\n",
            "[Batch 8] Current Loss: 6.4348\n",
            "[Batch 9] Current Loss: 6.6395\n",
            "[Batch 0] Current Loss: 5.7908\n",
            "[Batch 1] Current Loss: 6.2768\n",
            "[Batch 2] Current Loss: 6.7104\n",
            "[Batch 3] Current Loss: 6.5788\n",
            "[Batch 4] Current Loss: 6.5123\n",
            "[Batch 5] Current Loss: 6.4308\n",
            "[Batch 6] Current Loss: 6.1402\n",
            "[Batch 7] Current Loss: 6.5552\n",
            "[Batch 8] Current Loss: 5.9260\n",
            "[Batch 9] Current Loss: 5.9805\n",
            "Ep 1 (Step 000780): Train loss 6.269, Val loss 6.290\n",
            "[Batch 0] Current Loss: 6.0054\n",
            "[Batch 1] Current Loss: 5.9784\n",
            "[Batch 2] Current Loss: 6.3229\n",
            "[Batch 3] Current Loss: 6.3736\n",
            "[Batch 4] Current Loss: 6.2216\n",
            "[Batch 5] Current Loss: 6.3370\n",
            "[Batch 6] Current Loss: 6.0332\n",
            "[Batch 7] Current Loss: 6.4201\n",
            "[Batch 8] Current Loss: 5.6986\n",
            "[Batch 9] Current Loss: 6.1218\n",
            "[Batch 0] Current Loss: 5.9804\n",
            "[Batch 1] Current Loss: 6.1392\n",
            "[Batch 2] Current Loss: 6.1349\n",
            "[Batch 3] Current Loss: 6.6327\n",
            "[Batch 4] Current Loss: 6.1224\n",
            "[Batch 5] Current Loss: 6.6006\n",
            "[Batch 6] Current Loss: 6.2175\n",
            "[Batch 7] Current Loss: 6.3824\n",
            "[Batch 8] Current Loss: 6.7640\n",
            "[Batch 9] Current Loss: 6.5308\n",
            "Ep 1 (Step 000800): Train loss 6.151, Val loss 6.350\n",
            "[Batch 0] Current Loss: 5.9625\n",
            "[Batch 1] Current Loss: 6.5634\n",
            "[Batch 2] Current Loss: 6.3632\n",
            "[Batch 3] Current Loss: 6.0180\n",
            "[Batch 4] Current Loss: 6.6838\n",
            "[Batch 5] Current Loss: 6.5520\n",
            "[Batch 6] Current Loss: 6.8260\n",
            "[Batch 7] Current Loss: 6.2975\n",
            "[Batch 8] Current Loss: 5.9080\n",
            "[Batch 9] Current Loss: 6.6722\n",
            "[Batch 0] Current Loss: 6.5773\n",
            "[Batch 1] Current Loss: 6.3618\n",
            "[Batch 2] Current Loss: 6.1266\n",
            "[Batch 3] Current Loss: 6.6886\n",
            "[Batch 4] Current Loss: 6.3625\n",
            "[Batch 5] Current Loss: 6.7005\n",
            "[Batch 6] Current Loss: 6.5506\n",
            "[Batch 7] Current Loss: 6.2905\n",
            "[Batch 8] Current Loss: 6.0487\n",
            "[Batch 9] Current Loss: 5.8311\n",
            "Ep 1 (Step 000820): Train loss 6.385, Val loss 6.354\n",
            "[Batch 0] Current Loss: 5.9129\n",
            "[Batch 1] Current Loss: 6.4170\n",
            "[Batch 2] Current Loss: 6.2460\n",
            "[Batch 3] Current Loss: 5.9947\n",
            "[Batch 4] Current Loss: 6.4107\n",
            "[Batch 5] Current Loss: 6.4026\n",
            "[Batch 6] Current Loss: 7.0137\n",
            "[Batch 7] Current Loss: 6.2259\n",
            "[Batch 8] Current Loss: 6.1237\n",
            "[Batch 9] Current Loss: 5.8090\n",
            "[Batch 0] Current Loss: 6.2521\n",
            "[Batch 1] Current Loss: 5.7506\n",
            "[Batch 2] Current Loss: 5.9687\n",
            "[Batch 3] Current Loss: 6.3935\n",
            "[Batch 4] Current Loss: 6.6144\n",
            "[Batch 5] Current Loss: 6.2460\n",
            "[Batch 6] Current Loss: 5.7228\n",
            "[Batch 7] Current Loss: 6.4032\n",
            "[Batch 8] Current Loss: 6.1014\n",
            "[Batch 9] Current Loss: 6.3996\n",
            "Ep 1 (Step 000840): Train loss 6.256, Val loss 6.185\n",
            "[Batch 0] Current Loss: 5.7358\n",
            "[Batch 1] Current Loss: 6.4318\n",
            "[Batch 2] Current Loss: 6.5738\n",
            "[Batch 3] Current Loss: 6.4907\n",
            "[Batch 4] Current Loss: 5.8381\n",
            "[Batch 5] Current Loss: 6.3598\n",
            "[Batch 6] Current Loss: 6.3183\n",
            "[Batch 7] Current Loss: 6.2720\n",
            "[Batch 8] Current Loss: 6.1379\n",
            "[Batch 9] Current Loss: 6.1816\n",
            "[Batch 0] Current Loss: 6.8353\n",
            "[Batch 1] Current Loss: 5.7671\n",
            "[Batch 2] Current Loss: 6.6638\n",
            "[Batch 3] Current Loss: 6.3334\n",
            "[Batch 4] Current Loss: 6.4342\n",
            "[Batch 5] Current Loss: 6.1603\n",
            "[Batch 6] Current Loss: 6.2187\n",
            "[Batch 7] Current Loss: 6.1631\n",
            "[Batch 8] Current Loss: 6.3862\n",
            "[Batch 9] Current Loss: 5.8893\n",
            "Ep 1 (Step 000860): Train loss 6.234, Val loss 6.285\n",
            "[Batch 0] Current Loss: 6.4499\n",
            "[Batch 1] Current Loss: 6.2194\n",
            "[Batch 2] Current Loss: 5.9025\n",
            "[Batch 3] Current Loss: 6.2517\n",
            "[Batch 4] Current Loss: 6.3925\n",
            "[Batch 5] Current Loss: 6.1903\n",
            "[Batch 6] Current Loss: 6.0399\n",
            "[Batch 7] Current Loss: 5.9442\n",
            "[Batch 8] Current Loss: 6.2358\n",
            "[Batch 9] Current Loss: 6.3333\n",
            "[Batch 0] Current Loss: 6.4980\n",
            "[Batch 1] Current Loss: 6.1925\n",
            "[Batch 2] Current Loss: 5.9158\n",
            "[Batch 3] Current Loss: 6.0041\n",
            "[Batch 4] Current Loss: 6.3584\n",
            "[Batch 5] Current Loss: 6.3943\n",
            "[Batch 6] Current Loss: 6.5530\n",
            "[Batch 7] Current Loss: 5.8136\n",
            "[Batch 8] Current Loss: 6.0898\n",
            "[Batch 9] Current Loss: 6.3868\n",
            "Ep 1 (Step 000880): Train loss 6.196, Val loss 6.221\n",
            "[Batch 0] Current Loss: 5.7559\n",
            "[Batch 1] Current Loss: 6.1282\n",
            "[Batch 2] Current Loss: 6.2513\n",
            "[Batch 3] Current Loss: 6.0406\n",
            "[Batch 4] Current Loss: 5.7196\n",
            "[Batch 5] Current Loss: 5.8445\n",
            "[Batch 6] Current Loss: 6.0595\n",
            "[Batch 7] Current Loss: 6.0855\n",
            "[Batch 8] Current Loss: 6.1540\n",
            "[Batch 9] Current Loss: 6.3791\n",
            "[Batch 0] Current Loss: 5.6177\n",
            "[Batch 1] Current Loss: 6.3261\n",
            "[Batch 2] Current Loss: 6.4543\n",
            "[Batch 3] Current Loss: 6.3783\n",
            "[Batch 4] Current Loss: 5.9495\n",
            "[Batch 5] Current Loss: 6.0656\n",
            "[Batch 6] Current Loss: 6.4230\n",
            "[Batch 7] Current Loss: 5.7383\n",
            "[Batch 8] Current Loss: 6.2218\n",
            "[Batch 9] Current Loss: 6.6969\n",
            "Ep 1 (Step 000900): Train loss 6.042, Val loss 6.187\n",
            "[Batch 0] Current Loss: 6.2578\n",
            "[Batch 1] Current Loss: 6.4148\n",
            "[Batch 2] Current Loss: 6.0190\n",
            "[Batch 3] Current Loss: 5.9444\n",
            "[Batch 4] Current Loss: 6.7187\n",
            "[Batch 5] Current Loss: 6.0695\n",
            "[Batch 6] Current Loss: 5.8823\n",
            "[Batch 7] Current Loss: 6.0315\n",
            "[Batch 8] Current Loss: 6.2795\n",
            "[Batch 9] Current Loss: 5.8177\n",
            "[Batch 0] Current Loss: 5.8309\n",
            "[Batch 1] Current Loss: 5.8296\n",
            "[Batch 2] Current Loss: 5.7934\n",
            "[Batch 3] Current Loss: 6.4574\n",
            "[Batch 4] Current Loss: 5.9194\n",
            "[Batch 5] Current Loss: 6.2401\n",
            "[Batch 6] Current Loss: 6.5640\n",
            "[Batch 7] Current Loss: 6.6821\n",
            "[Batch 8] Current Loss: 6.2093\n",
            "[Batch 9] Current Loss: 6.4375\n",
            "Ep 1 (Step 000920): Train loss 6.144, Val loss 6.196\n",
            "[Batch 0] Current Loss: 6.2248\n",
            "[Batch 1] Current Loss: 6.2521\n",
            "[Batch 2] Current Loss: 6.2876\n",
            "[Batch 3] Current Loss: 6.1384\n",
            "[Batch 4] Current Loss: 6.1155\n",
            "[Batch 5] Current Loss: 6.0357\n",
            "[Batch 6] Current Loss: 5.8299\n",
            "[Batch 7] Current Loss: 6.2559\n",
            "[Batch 8] Current Loss: 6.5377\n",
            "[Batch 9] Current Loss: 6.7561\n",
            "[Batch 0] Current Loss: 6.6663\n",
            "[Batch 1] Current Loss: 6.5773\n",
            "[Batch 2] Current Loss: 6.4245\n",
            "[Batch 3] Current Loss: 6.5166\n",
            "[Batch 4] Current Loss: 6.6012\n",
            "[Batch 5] Current Loss: 5.9027\n",
            "[Batch 6] Current Loss: 6.3858\n",
            "[Batch 7] Current Loss: 5.9780\n",
            "[Batch 8] Current Loss: 6.4265\n",
            "[Batch 9] Current Loss: 6.6199\n",
            "Ep 1 (Step 000940): Train loss 6.243, Val loss 6.410\n",
            "[Batch 0] Current Loss: 6.4071\n",
            "[Batch 1] Current Loss: 6.1087\n",
            "[Batch 2] Current Loss: 6.0983\n",
            "[Batch 3] Current Loss: 5.9820\n",
            "[Batch 4] Current Loss: 6.0500\n",
            "[Batch 5] Current Loss: 6.3854\n",
            "[Batch 6] Current Loss: 6.0374\n",
            "[Batch 7] Current Loss: 6.0677\n",
            "[Batch 8] Current Loss: 6.3958\n",
            "[Batch 9] Current Loss: 6.2336\n",
            "[Batch 0] Current Loss: 6.0796\n",
            "[Batch 1] Current Loss: 5.3516\n",
            "[Batch 2] Current Loss: 5.7208\n",
            "[Batch 3] Current Loss: 6.2446\n",
            "[Batch 4] Current Loss: 6.3079\n",
            "[Batch 5] Current Loss: 5.9782\n",
            "[Batch 6] Current Loss: 6.3472\n",
            "[Batch 7] Current Loss: 6.5774\n",
            "[Batch 8] Current Loss: 6.3272\n",
            "[Batch 9] Current Loss: 6.5256\n",
            "Ep 1 (Step 000960): Train loss 6.177, Val loss 6.146\n",
            "[Batch 0] Current Loss: 6.3099\n",
            "[Batch 1] Current Loss: 6.1744\n",
            "[Batch 2] Current Loss: 6.3121\n",
            "[Batch 3] Current Loss: 6.1348\n",
            "[Batch 4] Current Loss: 6.2014\n",
            "[Batch 5] Current Loss: 5.6071\n",
            "[Batch 6] Current Loss: 5.8494\n",
            "[Batch 7] Current Loss: 6.1965\n",
            "[Batch 8] Current Loss: 5.6775\n",
            "[Batch 9] Current Loss: 5.9300\n",
            "[Batch 0] Current Loss: 5.8026\n",
            "[Batch 1] Current Loss: 6.6729\n",
            "[Batch 2] Current Loss: 6.2774\n",
            "[Batch 3] Current Loss: 5.9825\n",
            "[Batch 4] Current Loss: 6.4081\n",
            "[Batch 5] Current Loss: 6.0591\n",
            "[Batch 6] Current Loss: 6.0990\n",
            "[Batch 7] Current Loss: 6.0715\n",
            "[Batch 8] Current Loss: 6.2299\n",
            "[Batch 9] Current Loss: 6.7347\n",
            "Ep 1 (Step 000980): Train loss 6.039, Val loss 6.234\n",
            "[Batch 0] Current Loss: 5.9931\n",
            "[Batch 1] Current Loss: 5.8431\n",
            "[Batch 2] Current Loss: 5.8903\n",
            "[Batch 3] Current Loss: 6.1732\n",
            "[Batch 4] Current Loss: 5.9588\n",
            "[Batch 5] Current Loss: 5.9123\n",
            "[Batch 6] Current Loss: 6.0874\n",
            "[Batch 7] Current Loss: 5.9872\n",
            "[Batch 8] Current Loss: 5.9396\n",
            "[Batch 9] Current Loss: 5.7971\n",
            "[Batch 0] Current Loss: 6.3237\n",
            "[Batch 1] Current Loss: 6.0287\n",
            "[Batch 2] Current Loss: 6.3077\n",
            "[Batch 3] Current Loss: 6.3268\n",
            "[Batch 4] Current Loss: 5.8246\n",
            "[Batch 5] Current Loss: 6.0522\n",
            "[Batch 6] Current Loss: 6.3706\n",
            "[Batch 7] Current Loss: 5.6472\n",
            "[Batch 8] Current Loss: 5.8571\n",
            "[Batch 9] Current Loss: 6.0627\n",
            "Ep 1 (Step 001000): Train loss 5.958, Val loss 6.080\n",
            "[Batch 0] Current Loss: 6.3295\n",
            "[Batch 1] Current Loss: 5.8362\n",
            "[Batch 2] Current Loss: 6.3050\n",
            "[Batch 3] Current Loss: 6.1329\n",
            "[Batch 4] Current Loss: 5.7075\n",
            "[Batch 5] Current Loss: 6.4081\n",
            "[Batch 6] Current Loss: 6.2532\n",
            "[Batch 7] Current Loss: 6.2967\n",
            "[Batch 8] Current Loss: 6.3810\n",
            "[Batch 9] Current Loss: 6.0597\n",
            "[Batch 0] Current Loss: 5.7568\n",
            "[Batch 1] Current Loss: 6.6224\n",
            "[Batch 2] Current Loss: 6.1293\n",
            "[Batch 3] Current Loss: 6.0153\n",
            "[Batch 4] Current Loss: 6.5516\n",
            "[Batch 5] Current Loss: 6.1269\n",
            "[Batch 6] Current Loss: 5.3784\n",
            "[Batch 7] Current Loss: 6.1454\n",
            "[Batch 8] Current Loss: 6.0096\n",
            "[Batch 9] Current Loss: 6.1302\n",
            "Ep 1 (Step 001020): Train loss 6.171, Val loss 6.087\n",
            "[Batch 0] Current Loss: 6.1247\n",
            "[Batch 1] Current Loss: 6.3743\n",
            "[Batch 2] Current Loss: 5.8993\n",
            "[Batch 3] Current Loss: 6.3711\n",
            "[Batch 4] Current Loss: 6.0953\n",
            "[Batch 5] Current Loss: 6.4133\n",
            "[Batch 6] Current Loss: 6.2065\n",
            "[Batch 7] Current Loss: 5.5073\n",
            "[Batch 8] Current Loss: 6.1083\n",
            "[Batch 9] Current Loss: 5.9349\n",
            "[Batch 0] Current Loss: 6.2329\n",
            "[Batch 1] Current Loss: 5.6762\n",
            "[Batch 2] Current Loss: 5.8081\n",
            "[Batch 3] Current Loss: 5.8602\n",
            "[Batch 4] Current Loss: 6.6744\n",
            "[Batch 5] Current Loss: 6.2750\n",
            "[Batch 6] Current Loss: 5.9949\n",
            "[Batch 7] Current Loss: 6.2186\n",
            "[Batch 8] Current Loss: 6.2166\n",
            "[Batch 9] Current Loss: 6.1911\n",
            "Ep 1 (Step 001040): Train loss 6.103, Val loss 6.115\n",
            "[Batch 0] Current Loss: 6.0707\n",
            "[Batch 1] Current Loss: 6.2664\n",
            "[Batch 2] Current Loss: 6.1424\n",
            "[Batch 3] Current Loss: 6.1729\n",
            "[Batch 4] Current Loss: 6.0377\n",
            "[Batch 5] Current Loss: 6.2376\n",
            "[Batch 6] Current Loss: 6.1510\n",
            "[Batch 7] Current Loss: 6.2043\n",
            "[Batch 8] Current Loss: 6.4616\n",
            "[Batch 9] Current Loss: 5.8341\n",
            "[Batch 0] Current Loss: 6.1822\n",
            "[Batch 1] Current Loss: 6.0896\n",
            "[Batch 2] Current Loss: 6.0957\n",
            "[Batch 3] Current Loss: 6.0132\n",
            "[Batch 4] Current Loss: 6.0260\n",
            "[Batch 5] Current Loss: 6.1313\n",
            "[Batch 6] Current Loss: 5.5748\n",
            "[Batch 7] Current Loss: 5.8382\n",
            "[Batch 8] Current Loss: 6.7595\n",
            "[Batch 9] Current Loss: 6.0172\n",
            "Ep 1 (Step 001060): Train loss 6.158, Val loss 6.073\n",
            "[Batch 0] Current Loss: 6.0731\n",
            "[Batch 1] Current Loss: 6.0044\n",
            "[Batch 2] Current Loss: 6.0722\n",
            "[Batch 3] Current Loss: 6.1102\n",
            "[Batch 4] Current Loss: 5.4443\n",
            "[Batch 5] Current Loss: 5.6236\n",
            "[Batch 6] Current Loss: 5.6445\n",
            "[Batch 7] Current Loss: 6.2980\n",
            "[Batch 8] Current Loss: 6.3184\n",
            "[Batch 9] Current Loss: 6.3025\n",
            "[Batch 0] Current Loss: 6.3316\n",
            "[Batch 1] Current Loss: 6.2678\n",
            "[Batch 2] Current Loss: 6.1662\n",
            "[Batch 3] Current Loss: 5.9038\n",
            "[Batch 4] Current Loss: 6.2914\n",
            "[Batch 5] Current Loss: 6.2062\n",
            "[Batch 6] Current Loss: 6.1537\n",
            "[Batch 7] Current Loss: 6.2113\n",
            "[Batch 8] Current Loss: 6.2372\n",
            "[Batch 9] Current Loss: 6.3574\n",
            "Ep 1 (Step 001080): Train loss 5.989, Val loss 6.213\n",
            "[Batch 0] Current Loss: 5.9359\n",
            "[Batch 1] Current Loss: 6.1367\n",
            "[Batch 2] Current Loss: 5.9136\n",
            "[Batch 3] Current Loss: 6.6451\n",
            "[Batch 4] Current Loss: 5.8383\n",
            "[Batch 5] Current Loss: 6.0790\n",
            "[Batch 6] Current Loss: 5.9581\n",
            "[Batch 7] Current Loss: 5.6202\n",
            "[Batch 8] Current Loss: 6.0490\n",
            "[Batch 9] Current Loss: 5.8206\n",
            "[Batch 0] Current Loss: 5.9228\n",
            "[Batch 1] Current Loss: 6.2755\n",
            "[Batch 2] Current Loss: 6.2161\n",
            "[Batch 3] Current Loss: 6.2699\n",
            "[Batch 4] Current Loss: 6.1515\n",
            "[Batch 5] Current Loss: 5.9340\n",
            "[Batch 6] Current Loss: 6.1921\n",
            "[Batch 7] Current Loss: 6.4139\n",
            "[Batch 8] Current Loss: 6.2677\n",
            "[Batch 9] Current Loss: 5.9390\n",
            "Ep 1 (Step 001100): Train loss 6.000, Val loss 6.158\n",
            "[Batch 0] Current Loss: 6.2425\n",
            "[Batch 1] Current Loss: 5.6552\n",
            "[Batch 2] Current Loss: 6.2673\n",
            "[Batch 3] Current Loss: 6.2736\n",
            "[Batch 4] Current Loss: 6.1174\n",
            "[Batch 5] Current Loss: 6.0882\n",
            "[Batch 6] Current Loss: 6.1278\n",
            "[Batch 7] Current Loss: 5.9672\n",
            "[Batch 8] Current Loss: 6.2273\n",
            "[Batch 9] Current Loss: 6.1976\n",
            "[Batch 0] Current Loss: 6.6234\n",
            "[Batch 1] Current Loss: 6.1606\n",
            "[Batch 2] Current Loss: 6.6509\n",
            "[Batch 3] Current Loss: 5.1886\n",
            "[Batch 4] Current Loss: 6.0417\n",
            "[Batch 5] Current Loss: 6.7792\n",
            "[Batch 6] Current Loss: 5.7947\n",
            "[Batch 7] Current Loss: 6.1206\n",
            "[Batch 8] Current Loss: 6.0187\n",
            "[Batch 9] Current Loss: 6.1340\n",
            "Ep 1 (Step 001120): Train loss 6.116, Val loss 6.151\n",
            "[Batch 0] Current Loss: 6.1507\n",
            "[Batch 1] Current Loss: 5.6580\n",
            "[Batch 2] Current Loss: 6.2367\n",
            "[Batch 3] Current Loss: 5.9658\n",
            "[Batch 4] Current Loss: 5.8881\n",
            "[Batch 5] Current Loss: 6.1208\n",
            "[Batch 6] Current Loss: 5.4202\n",
            "[Batch 7] Current Loss: 6.0444\n",
            "[Batch 8] Current Loss: 6.0953\n",
            "[Batch 9] Current Loss: 6.1351\n",
            "[Batch 0] Current Loss: 6.4988\n",
            "[Batch 1] Current Loss: 6.2477\n",
            "[Batch 2] Current Loss: 6.0719\n",
            "[Batch 3] Current Loss: 5.6664\n",
            "[Batch 4] Current Loss: 6.6681\n",
            "[Batch 5] Current Loss: 6.0727\n",
            "[Batch 6] Current Loss: 6.3886\n",
            "[Batch 7] Current Loss: 5.7834\n",
            "[Batch 8] Current Loss: 5.8654\n",
            "[Batch 9] Current Loss: 6.2609\n",
            "Ep 1 (Step 001140): Train loss 5.972, Val loss 6.152\n",
            "[Batch 0] Current Loss: 5.9215\n",
            "[Batch 1] Current Loss: 6.2650\n",
            "[Batch 2] Current Loss: 6.3824\n",
            "[Batch 3] Current Loss: 6.2947\n",
            "[Batch 4] Current Loss: 5.9051\n",
            "[Batch 5] Current Loss: 6.0784\n",
            "[Batch 6] Current Loss: 5.8499\n",
            "[Batch 7] Current Loss: 6.5443\n",
            "[Batch 8] Current Loss: 6.3678\n",
            "[Batch 9] Current Loss: 5.7044\n",
            "[Batch 0] Current Loss: 6.3602\n",
            "[Batch 1] Current Loss: 6.0026\n",
            "[Batch 2] Current Loss: 6.2298\n",
            "[Batch 3] Current Loss: 5.8341\n",
            "[Batch 4] Current Loss: 6.0800\n",
            "[Batch 5] Current Loss: 6.1303\n",
            "[Batch 6] Current Loss: 6.3357\n",
            "[Batch 7] Current Loss: 6.3353\n",
            "[Batch 8] Current Loss: 6.2478\n",
            "[Batch 9] Current Loss: 6.0970\n",
            "Ep 1 (Step 001160): Train loss 6.131, Val loss 6.165\n",
            "[Batch 0] Current Loss: 5.9461\n",
            "[Batch 1] Current Loss: 6.2289\n",
            "[Batch 2] Current Loss: 6.0758\n",
            "[Batch 3] Current Loss: 6.4347\n",
            "[Batch 4] Current Loss: 6.0185\n",
            "[Batch 5] Current Loss: 6.1212\n",
            "[Batch 6] Current Loss: 5.8238\n",
            "[Batch 7] Current Loss: 5.7702\n",
            "[Batch 8] Current Loss: 6.3677\n",
            "[Batch 9] Current Loss: 6.0049\n",
            "[Batch 0] Current Loss: 5.9470\n",
            "[Batch 1] Current Loss: 6.5247\n",
            "[Batch 2] Current Loss: 5.9219\n",
            "[Batch 3] Current Loss: 5.7792\n",
            "[Batch 4] Current Loss: 6.0588\n",
            "[Batch 5] Current Loss: 5.7672\n",
            "[Batch 6] Current Loss: 6.2250\n",
            "[Batch 7] Current Loss: 6.4686\n",
            "[Batch 8] Current Loss: 6.0253\n",
            "[Batch 9] Current Loss: 6.1397\n",
            "Ep 1 (Step 001180): Train loss 6.079, Val loss 6.086\n",
            "[Batch 0] Current Loss: 6.0094\n",
            "[Batch 1] Current Loss: 5.9972\n",
            "[Batch 2] Current Loss: 5.8916\n",
            "[Batch 3] Current Loss: 6.1329\n",
            "[Batch 4] Current Loss: 6.3666\n",
            "[Batch 5] Current Loss: 5.2295\n",
            "[Batch 6] Current Loss: 5.8746\n",
            "[Batch 7] Current Loss: 6.2156\n",
            "[Batch 8] Current Loss: 6.2449\n",
            "[Batch 9] Current Loss: 6.1489\n",
            "[Batch 0] Current Loss: 6.2918\n",
            "[Batch 1] Current Loss: 5.7772\n",
            "[Batch 2] Current Loss: 5.6884\n",
            "[Batch 3] Current Loss: 5.7276\n",
            "[Batch 4] Current Loss: 6.5964\n",
            "[Batch 5] Current Loss: 5.5380\n",
            "[Batch 6] Current Loss: 6.3805\n",
            "[Batch 7] Current Loss: 5.9659\n",
            "[Batch 8] Current Loss: 6.1018\n",
            "[Batch 9] Current Loss: 6.3027\n",
            "Ep 1 (Step 001200): Train loss 6.011, Val loss 6.037\n",
            "[Batch 0] Current Loss: 6.0089\n",
            "[Batch 1] Current Loss: 6.1643\n",
            "[Batch 2] Current Loss: 5.8461\n",
            "[Batch 3] Current Loss: 6.0083\n",
            "[Batch 4] Current Loss: 6.0162\n",
            "[Batch 5] Current Loss: 5.7738\n",
            "[Batch 6] Current Loss: 6.2792\n",
            "[Batch 7] Current Loss: 6.0237\n",
            "[Batch 8] Current Loss: 5.5605\n",
            "[Batch 9] Current Loss: 5.5089\n",
            "[Batch 0] Current Loss: 6.0136\n",
            "[Batch 1] Current Loss: 5.9203\n",
            "[Batch 2] Current Loss: 6.1733\n",
            "[Batch 3] Current Loss: 6.2486\n",
            "[Batch 4] Current Loss: 5.4916\n",
            "[Batch 5] Current Loss: 5.9248\n",
            "[Batch 6] Current Loss: 6.3036\n",
            "[Batch 7] Current Loss: 5.8506\n",
            "[Batch 8] Current Loss: 6.1153\n",
            "[Batch 9] Current Loss: 6.7268\n",
            "Ep 1 (Step 001220): Train loss 5.919, Val loss 6.077\n",
            "[Batch 0] Current Loss: 5.5838\n",
            "[Batch 1] Current Loss: 5.7554\n",
            "[Batch 2] Current Loss: 6.3828\n",
            "[Batch 3] Current Loss: 6.0949\n",
            "[Batch 4] Current Loss: 5.7434\n",
            "[Batch 5] Current Loss: 5.9489\n",
            "[Batch 6] Current Loss: 6.4301\n",
            "[Batch 7] Current Loss: 6.0376\n",
            "[Batch 8] Current Loss: 6.2273\n",
            "[Batch 9] Current Loss: 6.0866\n",
            "[Batch 0] Current Loss: 6.1291\n",
            "[Batch 1] Current Loss: 6.3150\n",
            "[Batch 2] Current Loss: 6.2185\n",
            "[Batch 3] Current Loss: 5.9516\n",
            "[Batch 4] Current Loss: 5.8157\n",
            "[Batch 5] Current Loss: 5.9135\n",
            "[Batch 6] Current Loss: 5.9226\n",
            "[Batch 7] Current Loss: 5.6974\n",
            "[Batch 8] Current Loss: 6.1337\n",
            "[Batch 9] Current Loss: 6.3169\n",
            "Ep 1 (Step 001240): Train loss 6.029, Val loss 6.041\n",
            "[Batch 0] Current Loss: 6.1408\n",
            "[Batch 1] Current Loss: 6.1645\n",
            "[Batch 2] Current Loss: 5.9623\n",
            "[Batch 3] Current Loss: 5.7956\n",
            "[Batch 4] Current Loss: 5.9249\n",
            "[Batch 5] Current Loss: 6.4631\n",
            "[Batch 6] Current Loss: 5.7892\n",
            "[Batch 7] Current Loss: 5.5076\n",
            "[Batch 8] Current Loss: 5.9371\n",
            "[Batch 9] Current Loss: 5.3469\n",
            "[Batch 0] Current Loss: 5.7203\n",
            "[Batch 1] Current Loss: 6.0773\n",
            "[Batch 2] Current Loss: 6.4615\n",
            "[Batch 3] Current Loss: 6.4735\n",
            "[Batch 4] Current Loss: 5.9828\n",
            "[Batch 5] Current Loss: 6.1828\n",
            "[Batch 6] Current Loss: 5.9328\n",
            "[Batch 7] Current Loss: 6.1776\n",
            "[Batch 8] Current Loss: 5.9753\n",
            "[Batch 9] Current Loss: 6.9376\n",
            "Ep 1 (Step 001260): Train loss 5.903, Val loss 6.192\n",
            "[Batch 0] Current Loss: 5.9985\n",
            "[Batch 1] Current Loss: 5.0121\n",
            "[Batch 2] Current Loss: 5.8028\n",
            "[Batch 3] Current Loss: 5.9399\n",
            "[Batch 4] Current Loss: 6.1853\n",
            "[Batch 5] Current Loss: 5.8842\n",
            "[Batch 6] Current Loss: 5.2875\n",
            "[Batch 7] Current Loss: 6.4900\n",
            "[Batch 8] Current Loss: 5.2238\n",
            "[Batch 9] Current Loss: 5.6733\n",
            "[Batch 0] Current Loss: 6.0470\n",
            "[Batch 1] Current Loss: 6.3489\n",
            "[Batch 2] Current Loss: 6.3269\n",
            "[Batch 3] Current Loss: 6.1155\n",
            "[Batch 4] Current Loss: 5.9645\n",
            "[Batch 5] Current Loss: 6.4464\n",
            "[Batch 6] Current Loss: 6.0792\n",
            "[Batch 7] Current Loss: 5.8030\n",
            "[Batch 8] Current Loss: 5.6726\n",
            "[Batch 9] Current Loss: 6.2172\n",
            "Ep 1 (Step 001280): Train loss 5.750, Val loss 6.102\n",
            "[Batch 0] Current Loss: 6.0172\n",
            "[Batch 1] Current Loss: 5.6709\n",
            "[Batch 2] Current Loss: 5.6401\n",
            "[Batch 3] Current Loss: 5.6862\n",
            "[Batch 4] Current Loss: 6.2378\n",
            "[Batch 5] Current Loss: 6.3527\n",
            "[Batch 6] Current Loss: 5.9155\n",
            "[Batch 7] Current Loss: 5.8129\n",
            "[Batch 8] Current Loss: 6.3218\n",
            "[Batch 9] Current Loss: 6.0370\n",
            "[Batch 0] Current Loss: 6.2104\n",
            "[Batch 1] Current Loss: 5.9851\n",
            "[Batch 2] Current Loss: 6.0493\n",
            "[Batch 3] Current Loss: 6.0380\n",
            "[Batch 4] Current Loss: 5.7874\n",
            "[Batch 5] Current Loss: 6.4329\n",
            "[Batch 6] Current Loss: 6.0663\n",
            "[Batch 7] Current Loss: 6.0715\n",
            "[Batch 8] Current Loss: 6.1432\n",
            "[Batch 9] Current Loss: 6.1952\n",
            "Ep 1 (Step 001300): Train loss 5.969, Val loss 6.098\n",
            "[Batch 0] Current Loss: 5.5033\n",
            "[Batch 1] Current Loss: 6.0665\n",
            "[Batch 2] Current Loss: 5.5960\n",
            "[Batch 3] Current Loss: 6.0969\n",
            "[Batch 4] Current Loss: 5.6625\n",
            "[Batch 5] Current Loss: 6.0519\n",
            "[Batch 6] Current Loss: 5.2809\n",
            "[Batch 7] Current Loss: 5.3823\n",
            "[Batch 8] Current Loss: 5.8135\n",
            "[Batch 9] Current Loss: 6.2039\n",
            "[Batch 0] Current Loss: 5.6948\n",
            "[Batch 1] Current Loss: 5.4465\n",
            "[Batch 2] Current Loss: 5.5407\n",
            "[Batch 3] Current Loss: 6.5124\n",
            "[Batch 4] Current Loss: 6.3028\n",
            "[Batch 5] Current Loss: 6.4558\n",
            "[Batch 6] Current Loss: 6.5908\n",
            "[Batch 7] Current Loss: 6.1863\n",
            "[Batch 8] Current Loss: 5.8797\n",
            "[Batch 9] Current Loss: 5.8298\n",
            "Ep 1 (Step 001320): Train loss 5.766, Val loss 6.044\n",
            "[Batch 0] Current Loss: 5.4237\n",
            "[Batch 1] Current Loss: 6.1259\n",
            "[Batch 2] Current Loss: 5.9537\n",
            "[Batch 3] Current Loss: 6.0526\n",
            "[Batch 4] Current Loss: 5.8432\n",
            "[Batch 5] Current Loss: 6.4678\n",
            "[Batch 6] Current Loss: 5.5849\n",
            "[Batch 7] Current Loss: 5.7248\n",
            "[Batch 8] Current Loss: 5.6009\n",
            "[Batch 9] Current Loss: 5.9798\n",
            "[Batch 0] Current Loss: 6.0846\n",
            "[Batch 1] Current Loss: 5.9494\n",
            "[Batch 2] Current Loss: 6.3247\n",
            "[Batch 3] Current Loss: 6.2455\n",
            "[Batch 4] Current Loss: 5.6203\n",
            "[Batch 5] Current Loss: 6.5938\n",
            "[Batch 6] Current Loss: 5.5536\n",
            "[Batch 7] Current Loss: 6.0239\n",
            "[Batch 8] Current Loss: 6.3242\n",
            "[Batch 9] Current Loss: 6.4491\n",
            "Ep 1 (Step 001340): Train loss 5.876, Val loss 6.117\n",
            "[Batch 0] Current Loss: 5.5116\n",
            "[Batch 1] Current Loss: 6.0703\n",
            "[Batch 2] Current Loss: 5.9137\n",
            "[Batch 3] Current Loss: 5.7115\n",
            "[Batch 4] Current Loss: 6.1672\n",
            "[Batch 5] Current Loss: 5.9759\n",
            "[Batch 6] Current Loss: 6.0667\n",
            "[Batch 7] Current Loss: 5.1288\n",
            "[Batch 8] Current Loss: 6.3476\n",
            "[Batch 9] Current Loss: 6.4523\n",
            "[Batch 0] Current Loss: 6.1740\n",
            "[Batch 1] Current Loss: 5.7019\n",
            "[Batch 2] Current Loss: 6.4967\n",
            "[Batch 3] Current Loss: 6.2743\n",
            "[Batch 4] Current Loss: 5.7173\n",
            "[Batch 5] Current Loss: 5.6361\n",
            "[Batch 6] Current Loss: 6.0462\n",
            "[Batch 7] Current Loss: 6.0959\n",
            "[Batch 8] Current Loss: 5.3760\n",
            "[Batch 9] Current Loss: 5.6383\n",
            "Ep 1 (Step 001360): Train loss 5.935, Val loss 5.916\n",
            "[Batch 0] Current Loss: 6.4164\n",
            "[Batch 1] Current Loss: 6.0333\n",
            "[Batch 2] Current Loss: 5.8060\n",
            "[Batch 3] Current Loss: 5.7997\n",
            "[Batch 4] Current Loss: 5.9278\n",
            "[Batch 5] Current Loss: 5.7481\n",
            "[Batch 6] Current Loss: 5.9834\n",
            "[Batch 7] Current Loss: 5.5867\n",
            "[Batch 8] Current Loss: 6.0958\n",
            "[Batch 9] Current Loss: 6.2088\n",
            "[Batch 0] Current Loss: 6.6520\n",
            "[Batch 1] Current Loss: 6.1471\n",
            "[Batch 2] Current Loss: 6.7447\n",
            "[Batch 3] Current Loss: 5.7394\n",
            "[Batch 4] Current Loss: 6.2250\n",
            "[Batch 5] Current Loss: 5.9943\n",
            "[Batch 6] Current Loss: 6.7461\n",
            "[Batch 7] Current Loss: 6.2792\n",
            "[Batch 8] Current Loss: 5.9748\n",
            "[Batch 9] Current Loss: 5.9864\n",
            "Ep 1 (Step 001380): Train loss 5.961, Val loss 6.249\n",
            "[Batch 0] Current Loss: 6.2058\n",
            "[Batch 1] Current Loss: 6.2153\n",
            "[Batch 2] Current Loss: 5.8247\n",
            "[Batch 3] Current Loss: 5.9225\n",
            "[Batch 4] Current Loss: 5.8001\n",
            "[Batch 5] Current Loss: 5.8834\n",
            "[Batch 6] Current Loss: 5.5454\n",
            "[Batch 7] Current Loss: 5.9931\n",
            "[Batch 8] Current Loss: 6.1139\n",
            "[Batch 9] Current Loss: 5.8245\n",
            "[Batch 0] Current Loss: 6.4450\n",
            "[Batch 1] Current Loss: 6.0413\n",
            "[Batch 2] Current Loss: 5.8389\n",
            "[Batch 3] Current Loss: 5.7989\n",
            "[Batch 4] Current Loss: 6.0248\n",
            "[Batch 5] Current Loss: 5.7258\n",
            "[Batch 6] Current Loss: 6.0675\n",
            "[Batch 7] Current Loss: 5.5274\n",
            "[Batch 8] Current Loss: 6.0596\n",
            "[Batch 9] Current Loss: 6.4750\n",
            "Ep 1 (Step 001400): Train loss 5.933, Val loss 6.000\n",
            "[Batch 0] Current Loss: 6.1825\n",
            "[Batch 1] Current Loss: 5.8115\n",
            "[Batch 2] Current Loss: 5.3533\n",
            "[Batch 3] Current Loss: 6.5857\n",
            "[Batch 4] Current Loss: 5.7484\n",
            "[Batch 5] Current Loss: 6.2103\n",
            "[Batch 6] Current Loss: 6.2686\n",
            "[Batch 7] Current Loss: 5.8474\n",
            "[Batch 8] Current Loss: 6.1596\n",
            "[Batch 9] Current Loss: 5.6838\n",
            "[Batch 0] Current Loss: 5.1021\n",
            "[Batch 1] Current Loss: 6.2548\n",
            "[Batch 2] Current Loss: 5.7279\n",
            "[Batch 3] Current Loss: 5.7476\n",
            "[Batch 4] Current Loss: 6.0755\n",
            "[Batch 5] Current Loss: 6.5888\n",
            "[Batch 6] Current Loss: 5.7108\n",
            "[Batch 7] Current Loss: 6.3679\n",
            "[Batch 8] Current Loss: 6.0635\n",
            "[Batch 9] Current Loss: 5.8450\n",
            "Ep 1 (Step 001420): Train loss 5.985, Val loss 5.948\n",
            "[Batch 0] Current Loss: 5.2150\n",
            "[Batch 1] Current Loss: 5.8873\n",
            "[Batch 2] Current Loss: 6.0732\n",
            "[Batch 3] Current Loss: 5.6697\n",
            "[Batch 4] Current Loss: 5.6845\n",
            "[Batch 5] Current Loss: 6.2070\n",
            "[Batch 6] Current Loss: 5.5671\n",
            "[Batch 7] Current Loss: 5.8836\n",
            "[Batch 8] Current Loss: 5.9420\n",
            "[Batch 9] Current Loss: 6.1590\n",
            "[Batch 0] Current Loss: 6.4006\n",
            "[Batch 1] Current Loss: 6.0156\n",
            "[Batch 2] Current Loss: 6.4474\n",
            "[Batch 3] Current Loss: 6.6181\n",
            "[Batch 4] Current Loss: 5.9159\n",
            "[Batch 5] Current Loss: 5.5925\n",
            "[Batch 6] Current Loss: 5.7510\n",
            "[Batch 7] Current Loss: 6.4135\n",
            "[Batch 8] Current Loss: 6.5239\n",
            "[Batch 9] Current Loss: 5.9926\n",
            "Ep 1 (Step 001440): Train loss 5.829, Val loss 6.167\n",
            "[Batch 0] Current Loss: 6.3318\n",
            "[Batch 1] Current Loss: 6.2899\n",
            "[Batch 2] Current Loss: 6.3102\n",
            "[Batch 3] Current Loss: 5.5722\n",
            "[Batch 4] Current Loss: 6.0964\n",
            "[Batch 5] Current Loss: 5.8290\n",
            "[Batch 6] Current Loss: 6.0933\n",
            "[Batch 7] Current Loss: 5.5395\n",
            "[Batch 8] Current Loss: 5.5019\n",
            "[Batch 9] Current Loss: 5.9904\n",
            "[Batch 0] Current Loss: 5.9659\n",
            "[Batch 1] Current Loss: 6.5769\n",
            "[Batch 2] Current Loss: 6.1138\n",
            "[Batch 3] Current Loss: 5.9199\n",
            "[Batch 4] Current Loss: 6.0511\n",
            "[Batch 5] Current Loss: 6.1872\n",
            "[Batch 6] Current Loss: 6.0119\n",
            "[Batch 7] Current Loss: 5.9904\n",
            "[Batch 8] Current Loss: 6.0465\n",
            "[Batch 9] Current Loss: 6.0350\n",
            "Ep 1 (Step 001460): Train loss 5.955, Val loss 6.090\n",
            "[Batch 0] Current Loss: 5.4571\n",
            "[Batch 1] Current Loss: 5.2101\n",
            "[Batch 2] Current Loss: 5.9954\n",
            "[Batch 3] Current Loss: 5.9619\n",
            "[Batch 4] Current Loss: 6.1976\n",
            "[Batch 5] Current Loss: 6.2470\n",
            "[Batch 6] Current Loss: 6.4693\n",
            "[Batch 7] Current Loss: 6.1615\n",
            "[Batch 8] Current Loss: 5.6339\n",
            "[Batch 9] Current Loss: 5.3221\n",
            "[Batch 0] Current Loss: 5.9719\n",
            "[Batch 1] Current Loss: 5.8636\n",
            "[Batch 2] Current Loss: 5.9626\n",
            "[Batch 3] Current Loss: 5.7378\n",
            "[Batch 4] Current Loss: 6.7271\n",
            "[Batch 5] Current Loss: 6.5181\n",
            "[Batch 6] Current Loss: 6.1801\n",
            "[Batch 7] Current Loss: 6.1190\n",
            "[Batch 8] Current Loss: 5.9782\n",
            "[Batch 9] Current Loss: 6.5292\n",
            "Ep 1 (Step 001480): Train loss 5.866, Val loss 6.159\n",
            "[Batch 0] Current Loss: 5.8499\n",
            "[Batch 1] Current Loss: 5.4844\n",
            "[Batch 2] Current Loss: 5.9033\n",
            "[Batch 3] Current Loss: 5.7985\n",
            "[Batch 4] Current Loss: 5.5038\n",
            "[Batch 5] Current Loss: 5.8009\n",
            "[Batch 6] Current Loss: 5.9964\n",
            "[Batch 7] Current Loss: 6.3603\n",
            "[Batch 8] Current Loss: 5.8719\n",
            "[Batch 9] Current Loss: 6.5932\n",
            "[Batch 0] Current Loss: 6.6785\n",
            "[Batch 1] Current Loss: 6.5060\n",
            "[Batch 2] Current Loss: 6.1312\n",
            "[Batch 3] Current Loss: 5.3968\n",
            "[Batch 4] Current Loss: 6.0205\n",
            "[Batch 5] Current Loss: 6.1267\n",
            "[Batch 6] Current Loss: 5.9234\n",
            "[Batch 7] Current Loss: 6.5579\n",
            "[Batch 8] Current Loss: 6.1637\n",
            "[Batch 9] Current Loss: 6.2634\n",
            "Ep 1 (Step 001500): Train loss 5.916, Val loss 6.177\n",
            "[Batch 0] Current Loss: 5.9292\n",
            "[Batch 1] Current Loss: 6.3302\n",
            "[Batch 2] Current Loss: 6.2051\n",
            "[Batch 3] Current Loss: 6.1483\n",
            "[Batch 4] Current Loss: 5.2156\n",
            "[Batch 5] Current Loss: 6.3267\n",
            "[Batch 6] Current Loss: 5.9069\n",
            "[Batch 7] Current Loss: 6.1967\n",
            "[Batch 8] Current Loss: 6.1859\n",
            "[Batch 9] Current Loss: 6.0638\n",
            "[Batch 0] Current Loss: 5.4856\n",
            "[Batch 1] Current Loss: 5.5348\n",
            "[Batch 2] Current Loss: 6.3388\n",
            "[Batch 3] Current Loss: 6.3353\n",
            "[Batch 4] Current Loss: 5.9607\n",
            "[Batch 5] Current Loss: 6.5526\n",
            "[Batch 6] Current Loss: 5.6504\n",
            "[Batch 7] Current Loss: 6.0027\n",
            "[Batch 8] Current Loss: 5.2215\n",
            "[Batch 9] Current Loss: 6.1772\n",
            "Ep 1 (Step 001520): Train loss 6.051, Val loss 5.926\n",
            "[Batch 0] Current Loss: 6.0930\n",
            "[Batch 1] Current Loss: 5.7821\n",
            "[Batch 2] Current Loss: 6.0906\n",
            "[Batch 3] Current Loss: 5.8646\n",
            "[Batch 4] Current Loss: 6.4906\n",
            "[Batch 5] Current Loss: 5.9095\n",
            "[Batch 6] Current Loss: 5.7462\n",
            "[Batch 7] Current Loss: 5.7070\n",
            "[Batch 8] Current Loss: 5.8922\n",
            "[Batch 9] Current Loss: 6.2637\n",
            "[Batch 0] Current Loss: 5.5988\n",
            "[Batch 1] Current Loss: 5.6687\n",
            "[Batch 2] Current Loss: 6.1940\n",
            "[Batch 3] Current Loss: 6.0656\n",
            "[Batch 4] Current Loss: 5.5861\n",
            "[Batch 5] Current Loss: 6.3802\n",
            "[Batch 6] Current Loss: 5.9100\n",
            "[Batch 7] Current Loss: 5.6039\n",
            "[Batch 8] Current Loss: 6.0875\n",
            "[Batch 9] Current Loss: 6.0061\n",
            "Ep 1 (Step 001540): Train loss 5.984, Val loss 5.910\n",
            "[Batch 0] Current Loss: 6.1361\n",
            "[Batch 1] Current Loss: 6.3239\n",
            "[Batch 2] Current Loss: 6.1300\n",
            "[Batch 3] Current Loss: 6.1081\n",
            "[Batch 4] Current Loss: 5.8912\n",
            "[Batch 5] Current Loss: 6.0317\n",
            "[Batch 6] Current Loss: 6.3170\n",
            "[Batch 7] Current Loss: 5.6279\n",
            "[Batch 8] Current Loss: 5.4523\n",
            "[Batch 9] Current Loss: 5.3121\n",
            "[Batch 0] Current Loss: 6.0683\n",
            "[Batch 1] Current Loss: 5.7071\n",
            "[Batch 2] Current Loss: 6.1512\n",
            "[Batch 3] Current Loss: 6.0770\n",
            "[Batch 4] Current Loss: 5.7299\n",
            "[Batch 5] Current Loss: 6.5273\n",
            "[Batch 6] Current Loss: 6.0348\n",
            "[Batch 7] Current Loss: 5.9256\n",
            "[Batch 8] Current Loss: 5.7509\n",
            "[Batch 9] Current Loss: 5.8434\n",
            "Ep 1 (Step 001560): Train loss 5.933, Val loss 5.982\n",
            "[Batch 0] Current Loss: 5.5929\n",
            "[Batch 1] Current Loss: 6.1104\n",
            "[Batch 2] Current Loss: 5.8398\n",
            "[Batch 3] Current Loss: 5.5931\n",
            "[Batch 4] Current Loss: 5.3830\n",
            "[Batch 5] Current Loss: 5.7847\n",
            "[Batch 6] Current Loss: 5.8629\n",
            "[Batch 7] Current Loss: 5.9300\n",
            "[Batch 8] Current Loss: 6.1204\n",
            "[Batch 9] Current Loss: 5.8689\n",
            "[Batch 0] Current Loss: 5.9200\n",
            "[Batch 1] Current Loss: 5.5957\n",
            "[Batch 2] Current Loss: 6.5039\n",
            "[Batch 3] Current Loss: 6.0756\n",
            "[Batch 4] Current Loss: 5.7383\n",
            "[Batch 5] Current Loss: 6.3259\n",
            "[Batch 6] Current Loss: 5.9373\n",
            "[Batch 7] Current Loss: 6.1370\n",
            "[Batch 8] Current Loss: 6.1767\n",
            "[Batch 9] Current Loss: 5.2242\n",
            "Ep 1 (Step 001580): Train loss 5.809, Val loss 5.963\n",
            "[Batch 0] Current Loss: 6.0207\n",
            "[Batch 1] Current Loss: 5.5697\n",
            "[Batch 2] Current Loss: 6.2091\n",
            "[Batch 3] Current Loss: 5.8311\n",
            "[Batch 4] Current Loss: 5.5315\n",
            "[Batch 5] Current Loss: 5.4666\n",
            "[Batch 6] Current Loss: 5.3643\n",
            "[Batch 7] Current Loss: 5.7794\n",
            "[Batch 8] Current Loss: 6.2040\n",
            "[Batch 9] Current Loss: 6.1514\n",
            "[Batch 0] Current Loss: 6.1713\n",
            "[Batch 1] Current Loss: 6.0695\n",
            "[Batch 2] Current Loss: 6.1524\n",
            "[Batch 3] Current Loss: 6.1560\n",
            "[Batch 4] Current Loss: 5.6952\n",
            "[Batch 5] Current Loss: 5.6730\n",
            "[Batch 6] Current Loss: 5.8624\n",
            "[Batch 7] Current Loss: 6.0449\n",
            "[Batch 8] Current Loss: 5.8323\n",
            "[Batch 9] Current Loss: 6.0850\n",
            "Ep 1 (Step 001600): Train loss 5.813, Val loss 5.974\n",
            "[Batch 0] Current Loss: 6.3656\n",
            "[Batch 1] Current Loss: 5.5196\n",
            "[Batch 2] Current Loss: 6.0111\n",
            "[Batch 3] Current Loss: 5.2288\n",
            "[Batch 4] Current Loss: 5.7394\n",
            "[Batch 5] Current Loss: 6.0313\n",
            "[Batch 6] Current Loss: 6.1577\n",
            "[Batch 7] Current Loss: 6.3057\n",
            "[Batch 8] Current Loss: 6.0034\n",
            "[Batch 9] Current Loss: 6.1380\n",
            "[Batch 0] Current Loss: 6.1821\n",
            "[Batch 1] Current Loss: 5.9433\n",
            "[Batch 2] Current Loss: 5.6451\n",
            "[Batch 3] Current Loss: 5.8425\n",
            "[Batch 4] Current Loss: 6.2360\n",
            "[Batch 5] Current Loss: 5.6557\n",
            "[Batch 6] Current Loss: 5.2518\n",
            "[Batch 7] Current Loss: 6.1900\n",
            "[Batch 8] Current Loss: 5.3409\n",
            "[Batch 9] Current Loss: 6.2765\n",
            "Ep 1 (Step 001620): Train loss 5.950, Val loss 5.856\n",
            "[Batch 0] Current Loss: 6.2578\n",
            "[Batch 1] Current Loss: 5.7569\n",
            "[Batch 2] Current Loss: 6.1947\n",
            "[Batch 3] Current Loss: 5.7944\n",
            "[Batch 4] Current Loss: 5.9025\n",
            "[Batch 5] Current Loss: 5.6859\n",
            "[Batch 6] Current Loss: 6.0394\n",
            "[Batch 7] Current Loss: 5.9273\n",
            "[Batch 8] Current Loss: 5.7661\n",
            "[Batch 9] Current Loss: 5.6756\n",
            "[Batch 0] Current Loss: 5.7132\n",
            "[Batch 1] Current Loss: 6.1268\n",
            "[Batch 2] Current Loss: 6.2284\n",
            "[Batch 3] Current Loss: 5.7994\n",
            "[Batch 4] Current Loss: 6.2697\n",
            "[Batch 5] Current Loss: 5.6457\n",
            "[Batch 6] Current Loss: 5.7040\n",
            "[Batch 7] Current Loss: 5.8069\n",
            "[Batch 8] Current Loss: 5.9690\n",
            "[Batch 9] Current Loss: 6.3767\n",
            "Ep 1 (Step 001640): Train loss 5.900, Val loss 5.964\n",
            "[Batch 0] Current Loss: 5.7515\n",
            "[Batch 1] Current Loss: 6.0767\n",
            "[Batch 2] Current Loss: 5.7054\n",
            "[Batch 3] Current Loss: 6.2634\n",
            "[Batch 4] Current Loss: 5.8191\n",
            "[Batch 5] Current Loss: 6.2396\n",
            "[Batch 6] Current Loss: 5.4773\n",
            "[Batch 7] Current Loss: 6.1082\n",
            "[Batch 8] Current Loss: 5.3794\n",
            "[Batch 9] Current Loss: 6.0934\n",
            "[Batch 0] Current Loss: 5.6294\n",
            "[Batch 1] Current Loss: 6.3128\n",
            "[Batch 2] Current Loss: 5.9665\n",
            "[Batch 3] Current Loss: 5.7588\n",
            "[Batch 4] Current Loss: 5.8716\n",
            "[Batch 5] Current Loss: 6.0833\n",
            "[Batch 6] Current Loss: 5.8351\n",
            "[Batch 7] Current Loss: 6.1414\n",
            "[Batch 8] Current Loss: 6.3602\n",
            "[Batch 9] Current Loss: 5.9136\n",
            "Ep 1 (Step 001660): Train loss 5.891, Val loss 5.987\n",
            "[Batch 0] Current Loss: 6.2209\n",
            "[Batch 1] Current Loss: 5.7893\n",
            "[Batch 2] Current Loss: 5.6183\n",
            "[Batch 3] Current Loss: 5.3782\n",
            "[Batch 4] Current Loss: 5.5250\n",
            "[Batch 5] Current Loss: 5.8805\n",
            "[Batch 6] Current Loss: 5.7743\n",
            "[Batch 7] Current Loss: 5.4420\n",
            "[Batch 8] Current Loss: 6.2050\n",
            "[Batch 9] Current Loss: 5.4968\n",
            "[Batch 0] Current Loss: 5.8163\n",
            "[Batch 1] Current Loss: 6.1845\n",
            "[Batch 2] Current Loss: 5.9464\n",
            "[Batch 3] Current Loss: 6.2580\n",
            "[Batch 4] Current Loss: 5.8865\n",
            "[Batch 5] Current Loss: 5.4134\n",
            "[Batch 6] Current Loss: 5.0486\n",
            "[Batch 7] Current Loss: 5.7514\n",
            "[Batch 8] Current Loss: 5.8171\n",
            "[Batch 9] Current Loss: 5.8299\n",
            "Ep 1 (Step 001680): Train loss 5.733, Val loss 5.795\n",
            "[Batch 0] Current Loss: 6.0415\n",
            "[Batch 1] Current Loss: 5.3679\n",
            "[Batch 2] Current Loss: 5.9321\n",
            "[Batch 3] Current Loss: 6.2387\n",
            "[Batch 4] Current Loss: 5.4764\n",
            "[Batch 5] Current Loss: 6.0956\n",
            "[Batch 6] Current Loss: 5.5942\n",
            "[Batch 7] Current Loss: 5.8775\n",
            "[Batch 8] Current Loss: 5.4528\n",
            "[Batch 9] Current Loss: 5.5293\n",
            "[Batch 0] Current Loss: 6.3075\n",
            "[Batch 1] Current Loss: 5.6861\n",
            "[Batch 2] Current Loss: 6.1905\n",
            "[Batch 3] Current Loss: 5.9419\n",
            "[Batch 4] Current Loss: 5.8315\n",
            "[Batch 5] Current Loss: 6.0004\n",
            "[Batch 6] Current Loss: 6.4645\n",
            "[Batch 7] Current Loss: 6.1919\n",
            "[Batch 8] Current Loss: 6.0545\n",
            "[Batch 9] Current Loss: 5.9709\n",
            "Ep 1 (Step 001700): Train loss 5.761, Val loss 6.064\n",
            "[Batch 0] Current Loss: 5.9392\n",
            "[Batch 1] Current Loss: 6.3256\n",
            "[Batch 2] Current Loss: 6.1839\n",
            "[Batch 3] Current Loss: 5.5517\n",
            "[Batch 4] Current Loss: 5.9484\n",
            "[Batch 5] Current Loss: 5.7664\n",
            "[Batch 6] Current Loss: 5.2673\n",
            "[Batch 7] Current Loss: 5.9746\n",
            "[Batch 8] Current Loss: 5.6738\n",
            "[Batch 9] Current Loss: 5.8553\n",
            "[Batch 0] Current Loss: 5.8171\n",
            "[Batch 1] Current Loss: 6.0963\n",
            "[Batch 2] Current Loss: 5.0983\n",
            "[Batch 3] Current Loss: 6.0202\n",
            "[Batch 4] Current Loss: 5.5144\n",
            "[Batch 5] Current Loss: 5.6650\n",
            "[Batch 6] Current Loss: 6.0775\n",
            "[Batch 7] Current Loss: 6.0077\n",
            "[Batch 8] Current Loss: 6.1683\n",
            "[Batch 9] Current Loss: 5.5116\n",
            "Ep 1 (Step 001720): Train loss 5.849, Val loss 5.798\n",
            "[Batch 0] Current Loss: 5.9546\n",
            "[Batch 1] Current Loss: 5.6675\n",
            "[Batch 2] Current Loss: 5.6337\n",
            "[Batch 3] Current Loss: 5.2523\n",
            "[Batch 4] Current Loss: 5.5925\n",
            "[Batch 5] Current Loss: 5.4617\n",
            "[Batch 6] Current Loss: 5.7828\n",
            "[Batch 7] Current Loss: 5.4519\n",
            "[Batch 8] Current Loss: 5.4294\n",
            "[Batch 9] Current Loss: 5.9064\n",
            "[Batch 0] Current Loss: 5.9416\n",
            "[Batch 1] Current Loss: 6.3113\n",
            "[Batch 2] Current Loss: 5.7090\n",
            "[Batch 3] Current Loss: 6.1178\n",
            "[Batch 4] Current Loss: 5.8952\n",
            "[Batch 5] Current Loss: 6.0211\n",
            "[Batch 6] Current Loss: 5.8548\n",
            "[Batch 7] Current Loss: 5.7716\n",
            "[Batch 8] Current Loss: 6.2452\n",
            "[Batch 9] Current Loss: 6.2398\n",
            "Ep 1 (Step 001740): Train loss 5.613, Val loss 6.011\n",
            "[Batch 0] Current Loss: 5.8750\n",
            "[Batch 1] Current Loss: 5.7647\n",
            "[Batch 2] Current Loss: 5.8736\n",
            "[Batch 3] Current Loss: 5.7270\n",
            "[Batch 4] Current Loss: 5.7753\n",
            "[Batch 5] Current Loss: 6.1585\n",
            "[Batch 6] Current Loss: 6.0325\n",
            "[Batch 7] Current Loss: 5.9059\n",
            "[Batch 8] Current Loss: 5.5563\n",
            "[Batch 9] Current Loss: 5.8777\n",
            "[Batch 0] Current Loss: 6.1334\n",
            "[Batch 1] Current Loss: 5.6022\n",
            "[Batch 2] Current Loss: 5.3472\n",
            "[Batch 3] Current Loss: 5.9085\n",
            "[Batch 4] Current Loss: 5.7324\n",
            "[Batch 5] Current Loss: 5.5677\n",
            "[Batch 6] Current Loss: 5.6672\n",
            "[Batch 7] Current Loss: 5.9760\n",
            "[Batch 8] Current Loss: 5.5516\n",
            "[Batch 9] Current Loss: 5.7342\n",
            "Ep 1 (Step 001760): Train loss 5.855, Val loss 5.722\n",
            "[Batch 0] Current Loss: 6.1308\n",
            "[Batch 1] Current Loss: 6.3849\n",
            "[Batch 2] Current Loss: 5.7095\n",
            "[Batch 3] Current Loss: 6.0825\n",
            "[Batch 4] Current Loss: 5.6066\n",
            "[Batch 5] Current Loss: 6.2782\n",
            "[Batch 6] Current Loss: 6.4688\n",
            "[Batch 7] Current Loss: 6.1871\n",
            "[Batch 8] Current Loss: 6.0750\n",
            "[Batch 9] Current Loss: 5.9502\n",
            "[Batch 0] Current Loss: 5.8422\n",
            "[Batch 1] Current Loss: 5.9937\n",
            "[Batch 2] Current Loss: 6.0067\n",
            "[Batch 3] Current Loss: 6.2239\n",
            "[Batch 4] Current Loss: 5.6523\n",
            "[Batch 5] Current Loss: 6.0472\n",
            "[Batch 6] Current Loss: 5.9812\n",
            "[Batch 7] Current Loss: 5.7491\n",
            "[Batch 8] Current Loss: 5.9680\n",
            "[Batch 9] Current Loss: 5.6078\n",
            "Ep 1 (Step 001780): Train loss 6.087, Val loss 5.907\n",
            "[Batch 0] Current Loss: 6.3249\n",
            "[Batch 1] Current Loss: 6.1420\n",
            "[Batch 2] Current Loss: 6.2230\n",
            "[Batch 3] Current Loss: 5.3568\n",
            "[Batch 4] Current Loss: 5.6202\n",
            "[Batch 5] Current Loss: 5.3491\n",
            "[Batch 6] Current Loss: 5.8172\n",
            "[Batch 7] Current Loss: 6.1635\n",
            "[Batch 8] Current Loss: 5.4335\n",
            "[Batch 9] Current Loss: 5.4654\n",
            "[Batch 0] Current Loss: 6.0392\n",
            "[Batch 1] Current Loss: 6.3196\n",
            "[Batch 2] Current Loss: 6.4377\n",
            "[Batch 3] Current Loss: 5.8334\n",
            "[Batch 4] Current Loss: 6.2747\n",
            "[Batch 5] Current Loss: 5.7874\n",
            "[Batch 6] Current Loss: 5.7610\n",
            "[Batch 7] Current Loss: 5.3457\n",
            "[Batch 8] Current Loss: 6.2129\n",
            "[Batch 9] Current Loss: 6.0479\n",
            "Ep 1 (Step 001800): Train loss 5.790, Val loss 6.006\n",
            "[Batch 0] Current Loss: 5.6951\n",
            "[Batch 1] Current Loss: 5.8101\n",
            "[Batch 2] Current Loss: 5.9538\n",
            "[Batch 3] Current Loss: 6.2235\n",
            "[Batch 4] Current Loss: 6.4846\n",
            "[Batch 5] Current Loss: 5.9224\n",
            "[Batch 6] Current Loss: 6.0802\n",
            "[Batch 7] Current Loss: 5.9582\n",
            "[Batch 8] Current Loss: 5.9295\n",
            "[Batch 9] Current Loss: 6.0410\n",
            "[Batch 0] Current Loss: 6.3088\n",
            "[Batch 1] Current Loss: 5.8378\n",
            "[Batch 2] Current Loss: 5.5606\n",
            "[Batch 3] Current Loss: 6.1564\n",
            "[Batch 4] Current Loss: 6.0624\n",
            "[Batch 5] Current Loss: 6.5469\n",
            "[Batch 6] Current Loss: 6.2595\n",
            "[Batch 7] Current Loss: 5.9299\n",
            "[Batch 8] Current Loss: 5.7309\n",
            "[Batch 9] Current Loss: 6.2146\n",
            "Ep 1 (Step 001820): Train loss 6.010, Val loss 6.061\n",
            "[Batch 0] Current Loss: 5.6985\n",
            "[Batch 1] Current Loss: 5.9654\n",
            "[Batch 2] Current Loss: 6.1944\n",
            "[Batch 3] Current Loss: 5.7558\n",
            "[Batch 4] Current Loss: 5.5215\n",
            "[Batch 5] Current Loss: 5.7499\n",
            "[Batch 6] Current Loss: 5.6464\n",
            "[Batch 7] Current Loss: 5.9107\n",
            "[Batch 8] Current Loss: 5.5255\n",
            "[Batch 9] Current Loss: 5.3775\n",
            "[Batch 0] Current Loss: 6.1021\n",
            "[Batch 1] Current Loss: 5.9213\n",
            "[Batch 2] Current Loss: 6.1147\n",
            "[Batch 3] Current Loss: 6.0553\n",
            "[Batch 4] Current Loss: 6.0347\n",
            "[Batch 5] Current Loss: 5.9013\n",
            "[Batch 6] Current Loss: 6.2498\n",
            "[Batch 7] Current Loss: 5.9917\n",
            "[Batch 8] Current Loss: 5.9904\n",
            "[Batch 9] Current Loss: 5.8971\n",
            "Ep 1 (Step 001840): Train loss 5.735, Val loss 6.026\n",
            "[Batch 0] Current Loss: 5.5359\n",
            "[Batch 1] Current Loss: 5.3157\n",
            "[Batch 2] Current Loss: 5.5561\n",
            "[Batch 3] Current Loss: 5.9141\n",
            "[Batch 4] Current Loss: 5.8633\n",
            "[Batch 5] Current Loss: 6.4212\n",
            "[Batch 6] Current Loss: 5.5878\n",
            "[Batch 7] Current Loss: 5.7166\n",
            "[Batch 8] Current Loss: 5.4328\n",
            "[Batch 9] Current Loss: 5.4615\n",
            "[Batch 0] Current Loss: 5.7599\n",
            "[Batch 1] Current Loss: 6.0762\n",
            "[Batch 2] Current Loss: 5.5843\n",
            "[Batch 3] Current Loss: 5.5693\n",
            "[Batch 4] Current Loss: 5.8722\n",
            "[Batch 5] Current Loss: 5.8961\n",
            "[Batch 6] Current Loss: 6.4673\n",
            "[Batch 7] Current Loss: 5.9998\n",
            "[Batch 8] Current Loss: 5.7200\n",
            "[Batch 9] Current Loss: 5.9031\n",
            "Ep 1 (Step 001860): Train loss 5.681, Val loss 5.885\n",
            "[Batch 0] Current Loss: 5.8300\n",
            "[Batch 1] Current Loss: 6.3485\n",
            "[Batch 2] Current Loss: 5.9661\n",
            "[Batch 3] Current Loss: 5.9215\n",
            "[Batch 4] Current Loss: 5.2785\n",
            "[Batch 5] Current Loss: 5.7504\n",
            "[Batch 6] Current Loss: 5.5802\n",
            "[Batch 7] Current Loss: 5.8141\n",
            "[Batch 8] Current Loss: 5.8306\n",
            "[Batch 9] Current Loss: 5.7826\n",
            "[Batch 0] Current Loss: 6.0434\n",
            "[Batch 1] Current Loss: 5.9311\n",
            "[Batch 2] Current Loss: 5.9863\n",
            "[Batch 3] Current Loss: 5.4244\n",
            "[Batch 4] Current Loss: 5.7706\n",
            "[Batch 5] Current Loss: 5.9127\n",
            "[Batch 6] Current Loss: 5.9615\n",
            "[Batch 7] Current Loss: 5.7316\n",
            "[Batch 8] Current Loss: 5.9155\n",
            "[Batch 9] Current Loss: 6.0834\n",
            "Ep 1 (Step 001880): Train loss 5.810, Val loss 5.876\n",
            "[Batch 0] Current Loss: 5.6750\n",
            "[Batch 1] Current Loss: 5.8086\n",
            "[Batch 2] Current Loss: 5.5469\n",
            "[Batch 3] Current Loss: 6.0150\n",
            "[Batch 4] Current Loss: 6.0112\n",
            "[Batch 5] Current Loss: 5.7891\n",
            "[Batch 6] Current Loss: 5.9085\n",
            "[Batch 7] Current Loss: 6.6034\n",
            "[Batch 8] Current Loss: 5.8126\n",
            "[Batch 9] Current Loss: 4.8925\n",
            "[Batch 0] Current Loss: 6.3978\n",
            "[Batch 1] Current Loss: 5.8346\n",
            "[Batch 2] Current Loss: 5.8632\n",
            "[Batch 3] Current Loss: 5.4664\n",
            "[Batch 4] Current Loss: 6.2544\n",
            "[Batch 5] Current Loss: 5.9212\n",
            "[Batch 6] Current Loss: 6.3625\n",
            "[Batch 7] Current Loss: 6.0590\n",
            "[Batch 8] Current Loss: 5.7364\n",
            "[Batch 9] Current Loss: 5.5449\n",
            "Ep 1 (Step 001900): Train loss 5.806, Val loss 5.944\n",
            "[Batch 0] Current Loss: 5.9469\n",
            "[Batch 1] Current Loss: 5.4972\n",
            "[Batch 2] Current Loss: 6.1294\n",
            "[Batch 3] Current Loss: 5.5867\n",
            "[Batch 4] Current Loss: 5.7491\n",
            "[Batch 5] Current Loss: 5.9338\n",
            "[Batch 6] Current Loss: 5.5536\n",
            "[Batch 7] Current Loss: 5.5079\n",
            "[Batch 8] Current Loss: 5.7776\n",
            "[Batch 9] Current Loss: 5.8907\n",
            "[Batch 0] Current Loss: 6.2634\n",
            "[Batch 1] Current Loss: 5.9716\n",
            "[Batch 2] Current Loss: 6.2743\n",
            "[Batch 3] Current Loss: 6.0211\n",
            "[Batch 4] Current Loss: 5.7830\n",
            "[Batch 5] Current Loss: 5.8947\n",
            "[Batch 6] Current Loss: 6.0574\n",
            "[Batch 7] Current Loss: 6.0487\n",
            "[Batch 8] Current Loss: 6.0737\n",
            "[Batch 9] Current Loss: 5.8954\n",
            "Ep 1 (Step 001920): Train loss 5.757, Val loss 6.028\n",
            "[Batch 0] Current Loss: 6.0172\n",
            "[Batch 1] Current Loss: 5.7096\n",
            "[Batch 2] Current Loss: 5.7338\n",
            "[Batch 3] Current Loss: 5.6283\n",
            "[Batch 4] Current Loss: 5.1594\n",
            "[Batch 5] Current Loss: 5.9289\n",
            "[Batch 6] Current Loss: 6.1991\n",
            "[Batch 7] Current Loss: 5.6663\n",
            "[Batch 8] Current Loss: 5.5892\n",
            "[Batch 9] Current Loss: 5.2307\n",
            "[Batch 0] Current Loss: 5.9420\n",
            "[Batch 1] Current Loss: 5.4821\n",
            "[Batch 2] Current Loss: 5.6326\n",
            "[Batch 3] Current Loss: 5.5149\n",
            "[Batch 4] Current Loss: 6.3092\n",
            "[Batch 5] Current Loss: 5.7397\n",
            "[Batch 6] Current Loss: 6.0138\n",
            "[Batch 7] Current Loss: 5.9462\n",
            "[Batch 8] Current Loss: 6.4986\n",
            "[Batch 9] Current Loss: 5.5165\n",
            "Ep 1 (Step 001940): Train loss 5.686, Val loss 5.860\n",
            "[Batch 0] Current Loss: 5.2166\n",
            "[Batch 1] Current Loss: 6.1282\n",
            "[Batch 2] Current Loss: 5.7990\n",
            "[Batch 3] Current Loss: 5.8598\n",
            "[Batch 4] Current Loss: 5.6398\n",
            "[Batch 5] Current Loss: 5.8407\n",
            "[Batch 6] Current Loss: 5.6546\n",
            "[Batch 7] Current Loss: 5.6360\n",
            "[Batch 8] Current Loss: 5.3473\n",
            "[Batch 9] Current Loss: 5.2775\n",
            "[Batch 0] Current Loss: 6.3082\n",
            "[Batch 1] Current Loss: 6.2461\n",
            "[Batch 2] Current Loss: 5.8548\n",
            "[Batch 3] Current Loss: 4.8816\n",
            "[Batch 4] Current Loss: 5.8008\n",
            "[Batch 5] Current Loss: 6.2928\n",
            "[Batch 6] Current Loss: 6.1812\n",
            "[Batch 7] Current Loss: 6.4190\n",
            "[Batch 8] Current Loss: 6.0732\n",
            "[Batch 9] Current Loss: 5.2952\n",
            "Ep 1 (Step 001960): Train loss 5.640, Val loss 5.935\n",
            "[Batch 0] Current Loss: 6.2024\n",
            "[Batch 1] Current Loss: 5.9095\n",
            "[Batch 2] Current Loss: 5.7680\n",
            "[Batch 3] Current Loss: 5.2753\n",
            "[Batch 4] Current Loss: 5.7878\n",
            "[Batch 5] Current Loss: 6.0201\n",
            "[Batch 6] Current Loss: 6.4404\n",
            "[Batch 7] Current Loss: 5.9292\n",
            "[Batch 8] Current Loss: 5.7711\n",
            "[Batch 9] Current Loss: 5.4859\n",
            "[Batch 0] Current Loss: 5.9231\n",
            "[Batch 1] Current Loss: 6.2567\n",
            "[Batch 2] Current Loss: 6.3705\n",
            "[Batch 3] Current Loss: 5.7149\n",
            "[Batch 4] Current Loss: 5.7691\n",
            "[Batch 5] Current Loss: 6.0452\n",
            "[Batch 6] Current Loss: 6.0652\n",
            "[Batch 7] Current Loss: 5.3258\n",
            "[Batch 8] Current Loss: 5.7550\n",
            "[Batch 9] Current Loss: 5.2975\n",
            "Ep 1 (Step 001980): Train loss 5.859, Val loss 5.852\n",
            "[Batch 0] Current Loss: 5.7629\n",
            "[Batch 1] Current Loss: 5.1432\n",
            "[Batch 2] Current Loss: 5.4783\n",
            "[Batch 3] Current Loss: 5.5217\n",
            "[Batch 4] Current Loss: 5.6836\n",
            "[Batch 5] Current Loss: 6.1532\n",
            "[Batch 6] Current Loss: 5.4312\n",
            "[Batch 7] Current Loss: 6.2097\n",
            "[Batch 8] Current Loss: 5.3436\n",
            "[Batch 9] Current Loss: 5.7291\n",
            "[Batch 0] Current Loss: 5.9937\n",
            "[Batch 1] Current Loss: 5.8601\n",
            "[Batch 2] Current Loss: 5.7560\n",
            "[Batch 3] Current Loss: 5.6485\n",
            "[Batch 4] Current Loss: 5.7178\n",
            "[Batch 5] Current Loss: 5.7038\n",
            "[Batch 6] Current Loss: 5.5455\n",
            "[Batch 7] Current Loss: 5.0778\n",
            "[Batch 8] Current Loss: 6.6555\n",
            "[Batch 9] Current Loss: 5.9330\n",
            "Ep 1 (Step 002000): Train loss 5.646, Val loss 5.789\n",
            "[Batch 0] Current Loss: 5.9228\n",
            "[Batch 1] Current Loss: 6.4186\n",
            "[Batch 2] Current Loss: 6.1467\n",
            "[Batch 3] Current Loss: 5.9949\n",
            "[Batch 4] Current Loss: 6.1460\n",
            "[Batch 5] Current Loss: 6.1612\n",
            "[Batch 6] Current Loss: 5.9056\n",
            "[Batch 7] Current Loss: 5.1554\n",
            "[Batch 8] Current Loss: 5.6806\n",
            "[Batch 9] Current Loss: 6.0080\n",
            "[Batch 0] Current Loss: 5.9762\n",
            "[Batch 1] Current Loss: 5.9057\n",
            "[Batch 2] Current Loss: 5.9767\n",
            "[Batch 3] Current Loss: 5.9037\n",
            "[Batch 4] Current Loss: 6.2440\n",
            "[Batch 5] Current Loss: 6.3204\n",
            "[Batch 6] Current Loss: 5.2781\n",
            "[Batch 7] Current Loss: 6.1164\n",
            "[Batch 8] Current Loss: 5.9593\n",
            "[Batch 9] Current Loss: 6.6395\n",
            "Ep 1 (Step 002020): Train loss 5.954, Val loss 6.032\n",
            "[Batch 0] Current Loss: 5.5044\n",
            "[Batch 1] Current Loss: 5.4715\n",
            "[Batch 2] Current Loss: 5.3677\n",
            "[Batch 3] Current Loss: 5.6971\n",
            "[Batch 4] Current Loss: 5.5802\n",
            "[Batch 5] Current Loss: 5.3109\n",
            "[Batch 6] Current Loss: 5.9189\n",
            "[Batch 7] Current Loss: 5.6408\n",
            "[Batch 8] Current Loss: 5.8909\n",
            "[Batch 9] Current Loss: 5.6017\n",
            "[Batch 0] Current Loss: 6.2673\n",
            "[Batch 1] Current Loss: 5.7363\n",
            "[Batch 2] Current Loss: 5.6734\n",
            "[Batch 3] Current Loss: 5.5441\n",
            "[Batch 4] Current Loss: 6.2975\n",
            "[Batch 5] Current Loss: 5.7709\n",
            "[Batch 6] Current Loss: 5.8323\n",
            "[Batch 7] Current Loss: 5.9751\n",
            "[Batch 8] Current Loss: 5.5151\n",
            "[Batch 9] Current Loss: 5.3174\n",
            "Ep 1 (Step 002040): Train loss 5.598, Val loss 5.793\n",
            "[Batch 0] Current Loss: 5.3180\n",
            "[Batch 1] Current Loss: 5.6614\n",
            "[Batch 2] Current Loss: 6.2014\n",
            "[Batch 3] Current Loss: 5.8485\n",
            "[Batch 4] Current Loss: 5.7462\n",
            "[Batch 5] Current Loss: 5.8541\n",
            "[Batch 6] Current Loss: 5.8327\n",
            "[Batch 7] Current Loss: 5.6249\n",
            "[Batch 8] Current Loss: 5.7789\n",
            "[Batch 9] Current Loss: 5.3751\n",
            "[Batch 0] Current Loss: 6.0026\n",
            "[Batch 1] Current Loss: 5.8559\n",
            "[Batch 2] Current Loss: 5.2796\n",
            "[Batch 3] Current Loss: 5.7103\n",
            "[Batch 4] Current Loss: 5.8829\n",
            "[Batch 5] Current Loss: 6.0381\n",
            "[Batch 6] Current Loss: 6.0457\n",
            "[Batch 7] Current Loss: 5.9362\n",
            "[Batch 8] Current Loss: 6.3332\n",
            "[Batch 9] Current Loss: 6.3656\n",
            "Ep 1 (Step 002060): Train loss 5.724, Val loss 5.945\n",
            "[Batch 0] Current Loss: 5.5149\n",
            "[Batch 1] Current Loss: 5.2646\n",
            "[Batch 2] Current Loss: 6.3458\n",
            "[Batch 3] Current Loss: 5.7336\n",
            "[Batch 4] Current Loss: 6.1630\n",
            "[Batch 5] Current Loss: 5.5496\n",
            "[Batch 6] Current Loss: 5.4057\n",
            "[Batch 7] Current Loss: 6.1008\n",
            "[Batch 8] Current Loss: 5.5245\n",
            "[Batch 9] Current Loss: 5.5106\n",
            "[Batch 0] Current Loss: 6.6363\n",
            "[Batch 1] Current Loss: 5.8762\n",
            "[Batch 2] Current Loss: 5.7557\n",
            "[Batch 3] Current Loss: 5.4065\n",
            "[Batch 4] Current Loss: 5.8868\n",
            "[Batch 5] Current Loss: 5.5056\n",
            "[Batch 6] Current Loss: 5.9138\n",
            "[Batch 7] Current Loss: 5.4562\n",
            "[Batch 8] Current Loss: 5.3697\n",
            "[Batch 9] Current Loss: 5.7170\n",
            "Ep 1 (Step 002080): Train loss 5.711, Val loss 5.752\n",
            "[Batch 0] Current Loss: 5.6239\n",
            "[Batch 1] Current Loss: 5.3029\n",
            "[Batch 2] Current Loss: 5.7899\n",
            "[Batch 3] Current Loss: 5.2233\n",
            "[Batch 4] Current Loss: 6.0166\n",
            "[Batch 5] Current Loss: 5.7721\n",
            "[Batch 6] Current Loss: 5.5577\n",
            "[Batch 7] Current Loss: 6.0981\n",
            "[Batch 8] Current Loss: 5.7782\n",
            "[Batch 9] Current Loss: 5.5787\n",
            "[Batch 0] Current Loss: 5.7577\n",
            "[Batch 1] Current Loss: 5.6796\n",
            "[Batch 2] Current Loss: 6.1443\n",
            "[Batch 3] Current Loss: 5.4815\n",
            "[Batch 4] Current Loss: 6.7862\n",
            "[Batch 5] Current Loss: 5.7840\n",
            "[Batch 6] Current Loss: 6.1879\n",
            "[Batch 7] Current Loss: 6.3653\n",
            "[Batch 8] Current Loss: 6.0778\n",
            "[Batch 9] Current Loss: 6.2519\n",
            "Ep 1 (Step 002100): Train loss 5.674, Val loss 6.052\n",
            "[Batch 0] Current Loss: 5.6997\n",
            "[Batch 1] Current Loss: 5.9552\n",
            "[Batch 2] Current Loss: 5.9410\n",
            "[Batch 3] Current Loss: 5.4023\n",
            "[Batch 4] Current Loss: 5.1681\n",
            "[Batch 5] Current Loss: 6.0108\n",
            "[Batch 6] Current Loss: 5.6530\n",
            "[Batch 7] Current Loss: 5.9104\n",
            "[Batch 8] Current Loss: 5.9473\n",
            "[Batch 9] Current Loss: 6.1735\n",
            "[Batch 0] Current Loss: 5.2978\n",
            "[Batch 1] Current Loss: 5.5928\n",
            "[Batch 2] Current Loss: 6.4826\n",
            "[Batch 3] Current Loss: 5.6946\n",
            "[Batch 4] Current Loss: 5.8876\n",
            "[Batch 5] Current Loss: 5.9794\n",
            "[Batch 6] Current Loss: 5.4457\n",
            "[Batch 7] Current Loss: 6.0775\n",
            "[Batch 8] Current Loss: 6.1658\n",
            "[Batch 9] Current Loss: 5.9510\n",
            "Ep 1 (Step 002120): Train loss 5.786, Val loss 5.857\n",
            "[Batch 0] Current Loss: 5.9049\n",
            "[Batch 1] Current Loss: 5.6608\n",
            "[Batch 2] Current Loss: 5.7294\n",
            "[Batch 3] Current Loss: 5.7804\n",
            "[Batch 4] Current Loss: 5.8534\n",
            "[Batch 5] Current Loss: 5.6377\n",
            "[Batch 6] Current Loss: 5.9038\n",
            "[Batch 7] Current Loss: 5.8194\n",
            "[Batch 8] Current Loss: 6.2867\n",
            "[Batch 9] Current Loss: 5.6504\n",
            "[Batch 0] Current Loss: 6.0250\n",
            "[Batch 1] Current Loss: 6.0369\n",
            "[Batch 2] Current Loss: 5.3945\n",
            "[Batch 3] Current Loss: 5.4420\n",
            "[Batch 4] Current Loss: 5.7106\n",
            "[Batch 5] Current Loss: 5.2429\n",
            "[Batch 6] Current Loss: 5.8735\n",
            "[Batch 7] Current Loss: 5.9086\n",
            "[Batch 8] Current Loss: 5.7870\n",
            "[Batch 9] Current Loss: 5.3442\n",
            "Ep 1 (Step 002140): Train loss 5.823, Val loss 5.677\n",
            "[Batch 0] Current Loss: 6.0748\n",
            "[Batch 1] Current Loss: 5.5643\n",
            "[Batch 2] Current Loss: 5.8551\n",
            "[Batch 3] Current Loss: 5.3979\n",
            "[Batch 4] Current Loss: 5.3121\n",
            "[Batch 5] Current Loss: 6.0187\n",
            "[Batch 6] Current Loss: 5.6187\n",
            "[Batch 7] Current Loss: 5.9391\n",
            "[Batch 8] Current Loss: 5.2013\n",
            "[Batch 9] Current Loss: 5.9670\n",
            "[Batch 0] Current Loss: 5.9289\n",
            "[Batch 1] Current Loss: 6.0748\n",
            "[Batch 2] Current Loss: 6.1203\n",
            "[Batch 3] Current Loss: 5.9755\n",
            "[Batch 4] Current Loss: 5.8567\n",
            "[Batch 5] Current Loss: 6.4289\n",
            "[Batch 6] Current Loss: 5.7862\n",
            "[Batch 7] Current Loss: 5.7051\n",
            "[Batch 8] Current Loss: 5.9453\n",
            "[Batch 9] Current Loss: 5.4018\n",
            "Ep 1 (Step 002160): Train loss 5.695, Val loss 5.922\n",
            "[Batch 0] Current Loss: 5.3005\n",
            "[Batch 1] Current Loss: 5.2951\n",
            "[Batch 2] Current Loss: 5.2967\n",
            "[Batch 3] Current Loss: 5.8798\n",
            "[Batch 4] Current Loss: 5.7781\n",
            "[Batch 5] Current Loss: 5.6384\n",
            "[Batch 6] Current Loss: 6.0192\n",
            "[Batch 7] Current Loss: 5.4776\n",
            "[Batch 8] Current Loss: 5.7130\n",
            "[Batch 9] Current Loss: 5.4308\n",
            "[Batch 0] Current Loss: 5.1929\n",
            "[Batch 1] Current Loss: 6.1213\n",
            "[Batch 2] Current Loss: 5.4138\n",
            "[Batch 3] Current Loss: 5.1881\n",
            "[Batch 4] Current Loss: 6.4209\n",
            "[Batch 5] Current Loss: 5.9074\n",
            "[Batch 6] Current Loss: 5.8452\n",
            "[Batch 7] Current Loss: 5.8596\n",
            "[Batch 8] Current Loss: 5.5516\n",
            "[Batch 9] Current Loss: 5.7257\n",
            "Ep 1 (Step 002180): Train loss 5.583, Val loss 5.723\n",
            "[Batch 0] Current Loss: 5.4942\n",
            "[Batch 1] Current Loss: 6.0491\n",
            "[Batch 2] Current Loss: 5.8296\n",
            "[Batch 3] Current Loss: 5.6346\n",
            "[Batch 4] Current Loss: 5.8895\n",
            "[Batch 5] Current Loss: 6.0820\n",
            "[Batch 6] Current Loss: 5.8648\n",
            "[Batch 7] Current Loss: 5.3643\n",
            "[Batch 8] Current Loss: 5.3491\n",
            "[Batch 9] Current Loss: 5.8856\n",
            "[Batch 0] Current Loss: 5.7982\n",
            "[Batch 1] Current Loss: 5.7975\n",
            "[Batch 2] Current Loss: 5.8269\n",
            "[Batch 3] Current Loss: 5.9499\n",
            "[Batch 4] Current Loss: 6.3441\n",
            "[Batch 5] Current Loss: 6.2677\n",
            "[Batch 6] Current Loss: 5.6769\n",
            "[Batch 7] Current Loss: 6.3107\n",
            "[Batch 8] Current Loss: 5.0221\n",
            "[Batch 9] Current Loss: 5.8151\n",
            "Ep 1 (Step 002200): Train loss 5.744, Val loss 5.881\n",
            "[Batch 0] Current Loss: 5.5903\n",
            "[Batch 1] Current Loss: 5.3852\n",
            "[Batch 2] Current Loss: 5.7914\n",
            "[Batch 3] Current Loss: 5.5934\n",
            "[Batch 4] Current Loss: 5.6524\n",
            "[Batch 5] Current Loss: 5.5573\n",
            "[Batch 6] Current Loss: 6.1183\n",
            "[Batch 7] Current Loss: 5.4593\n",
            "[Batch 8] Current Loss: 5.4237\n",
            "[Batch 9] Current Loss: 6.3035\n",
            "[Batch 0] Current Loss: 5.3109\n",
            "[Batch 1] Current Loss: 6.0001\n",
            "[Batch 2] Current Loss: 5.6552\n",
            "[Batch 3] Current Loss: 5.6478\n",
            "[Batch 4] Current Loss: 6.1180\n",
            "[Batch 5] Current Loss: 6.2139\n",
            "[Batch 6] Current Loss: 6.4226\n",
            "[Batch 7] Current Loss: 6.0218\n",
            "[Batch 8] Current Loss: 5.8511\n",
            "[Batch 9] Current Loss: 5.7774\n",
            "Ep 1 (Step 002220): Train loss 5.687, Val loss 5.902\n",
            "[Batch 0] Current Loss: 5.7788\n",
            "[Batch 1] Current Loss: 5.3789\n",
            "[Batch 2] Current Loss: 5.7807\n",
            "[Batch 3] Current Loss: 5.9465\n",
            "[Batch 4] Current Loss: 5.8445\n",
            "[Batch 5] Current Loss: 5.7251\n",
            "[Batch 6] Current Loss: 5.7470\n",
            "[Batch 7] Current Loss: 6.0430\n",
            "[Batch 8] Current Loss: 5.4003\n",
            "[Batch 9] Current Loss: 5.1908\n",
            "[Batch 0] Current Loss: 5.8851\n",
            "[Batch 1] Current Loss: 5.4614\n",
            "[Batch 2] Current Loss: 5.6589\n",
            "[Batch 3] Current Loss: 5.5822\n",
            "[Batch 4] Current Loss: 5.7883\n",
            "[Batch 5] Current Loss: 5.6245\n",
            "[Batch 6] Current Loss: 5.7555\n",
            "[Batch 7] Current Loss: 5.8018\n",
            "[Batch 8] Current Loss: 5.6478\n",
            "[Batch 9] Current Loss: 6.1380\n",
            "Ep 1 (Step 002240): Train loss 5.684, Val loss 5.734\n",
            "[Batch 0] Current Loss: 5.0297\n",
            "[Batch 1] Current Loss: 5.4380\n",
            "[Batch 2] Current Loss: 5.5491\n",
            "[Batch 3] Current Loss: 5.7448\n",
            "[Batch 4] Current Loss: 6.0553\n",
            "[Batch 5] Current Loss: 5.4240\n",
            "[Batch 6] Current Loss: 6.2781\n",
            "[Batch 7] Current Loss: 5.0917\n",
            "[Batch 8] Current Loss: 5.8302\n",
            "[Batch 9] Current Loss: 5.4515\n",
            "[Batch 0] Current Loss: 6.0901\n",
            "[Batch 1] Current Loss: 5.8787\n",
            "[Batch 2] Current Loss: 5.4002\n",
            "[Batch 3] Current Loss: 5.9565\n",
            "[Batch 4] Current Loss: 5.1524\n",
            "[Batch 5] Current Loss: 6.1003\n",
            "[Batch 6] Current Loss: 6.1214\n",
            "[Batch 7] Current Loss: 6.1214\n",
            "[Batch 8] Current Loss: 5.7672\n",
            "[Batch 9] Current Loss: 6.1899\n",
            "Ep 1 (Step 002260): Train loss 5.589, Val loss 5.878\n",
            "[Batch 0] Current Loss: 5.7127\n",
            "[Batch 1] Current Loss: 6.2844\n",
            "[Batch 2] Current Loss: 5.8941\n",
            "[Batch 3] Current Loss: 5.5025\n",
            "[Batch 4] Current Loss: 5.5796\n",
            "[Batch 5] Current Loss: 5.4987\n",
            "[Batch 6] Current Loss: 5.5794\n",
            "[Batch 7] Current Loss: 5.5708\n",
            "[Batch 8] Current Loss: 5.4908\n",
            "[Batch 9] Current Loss: 5.5903\n",
            "[Batch 0] Current Loss: 5.9699\n",
            "[Batch 1] Current Loss: 5.9570\n",
            "[Batch 2] Current Loss: 5.8481\n",
            "[Batch 3] Current Loss: 5.9396\n",
            "[Batch 4] Current Loss: 5.8939\n",
            "[Batch 5] Current Loss: 5.4990\n",
            "[Batch 6] Current Loss: 6.1650\n",
            "[Batch 7] Current Loss: 5.6932\n",
            "[Batch 8] Current Loss: 5.4246\n",
            "[Batch 9] Current Loss: 6.3958\n",
            "Ep 1 (Step 002280): Train loss 5.670, Val loss 5.879\n",
            "[Batch 0] Current Loss: 5.9634\n",
            "[Batch 1] Current Loss: 5.7869\n",
            "[Batch 2] Current Loss: 6.2998\n",
            "[Batch 3] Current Loss: 5.7065\n",
            "[Batch 4] Current Loss: 5.5093\n",
            "[Batch 5] Current Loss: 6.0457\n",
            "[Batch 6] Current Loss: 5.8559\n",
            "[Batch 7] Current Loss: 5.0330\n",
            "[Batch 8] Current Loss: 5.5622\n",
            "[Batch 9] Current Loss: 5.6209\n",
            "[Batch 0] Current Loss: 5.5742\n",
            "[Batch 1] Current Loss: 5.4049\n",
            "[Batch 2] Current Loss: 6.0159\n",
            "[Batch 3] Current Loss: 5.1434\n",
            "[Batch 4] Current Loss: 5.7620\n",
            "[Batch 5] Current Loss: 6.2095\n",
            "[Batch 6] Current Loss: 6.0179\n",
            "[Batch 7] Current Loss: 6.3477\n",
            "[Batch 8] Current Loss: 5.8299\n",
            "[Batch 9] Current Loss: 5.9098\n",
            "Ep 1 (Step 002300): Train loss 5.738, Val loss 5.822\n",
            "[Batch 0] Current Loss: 5.6189\n",
            "[Batch 1] Current Loss: 6.0705\n",
            "[Batch 2] Current Loss: 5.6293\n",
            "[Batch 3] Current Loss: 5.6786\n",
            "[Batch 4] Current Loss: 5.5018\n",
            "[Batch 5] Current Loss: 5.4654\n",
            "[Batch 6] Current Loss: 6.2038\n",
            "[Batch 7] Current Loss: 5.9457\n",
            "[Batch 8] Current Loss: 5.7192\n",
            "[Batch 9] Current Loss: 6.0708\n",
            "[Batch 0] Current Loss: 6.0888\n",
            "[Batch 1] Current Loss: 5.0639\n",
            "[Batch 2] Current Loss: 5.6204\n",
            "[Batch 3] Current Loss: 5.3513\n",
            "[Batch 4] Current Loss: 5.6772\n",
            "[Batch 5] Current Loss: 5.5592\n",
            "[Batch 6] Current Loss: 6.0909\n",
            "[Batch 7] Current Loss: 6.0848\n",
            "[Batch 8] Current Loss: 5.7733\n",
            "[Batch 9] Current Loss: 6.1014\n",
            "Ep 1 (Step 002320): Train loss 5.790, Val loss 5.741\n",
            "[Batch 0] Current Loss: 5.8802\n",
            "[Batch 1] Current Loss: 6.0402\n",
            "[Batch 2] Current Loss: 6.1308\n",
            "[Batch 3] Current Loss: 5.6103\n",
            "[Batch 4] Current Loss: 5.3915\n",
            "[Batch 5] Current Loss: 5.4502\n",
            "[Batch 6] Current Loss: 5.7521\n",
            "[Batch 7] Current Loss: 5.1879\n",
            "[Batch 8] Current Loss: 5.7204\n",
            "[Batch 9] Current Loss: 5.3936\n",
            "[Batch 0] Current Loss: 6.0671\n",
            "[Batch 1] Current Loss: 5.1127\n",
            "[Batch 2] Current Loss: 5.7418\n",
            "[Batch 3] Current Loss: 5.7503\n",
            "[Batch 4] Current Loss: 5.2121\n",
            "[Batch 5] Current Loss: 6.1455\n",
            "[Batch 6] Current Loss: 5.8324\n",
            "[Batch 7] Current Loss: 5.9481\n",
            "[Batch 8] Current Loss: 5.8105\n",
            "[Batch 9] Current Loss: 5.7410\n",
            "Ep 1 (Step 002340): Train loss 5.656, Val loss 5.736\n",
            "[Batch 0] Current Loss: 5.0239\n",
            "[Batch 1] Current Loss: 5.9326\n",
            "[Batch 2] Current Loss: 5.9358\n",
            "[Batch 3] Current Loss: 5.5488\n",
            "[Batch 4] Current Loss: 6.0123\n",
            "[Batch 5] Current Loss: 5.7764\n",
            "[Batch 6] Current Loss: 5.3090\n",
            "[Batch 7] Current Loss: 6.0814\n",
            "[Batch 8] Current Loss: 5.9604\n",
            "[Batch 9] Current Loss: 5.3743\n",
            "[Batch 0] Current Loss: 6.1538\n",
            "[Batch 1] Current Loss: 5.7072\n",
            "[Batch 2] Current Loss: 6.0909\n",
            "[Batch 3] Current Loss: 6.2370\n",
            "[Batch 4] Current Loss: 5.9140\n",
            "[Batch 5] Current Loss: 5.4860\n",
            "[Batch 6] Current Loss: 5.9702\n",
            "[Batch 7] Current Loss: 5.4015\n",
            "[Batch 8] Current Loss: 5.8832\n",
            "[Batch 9] Current Loss: 6.0871\n",
            "Ep 1 (Step 002360): Train loss 5.696, Val loss 5.893\n",
            "[Batch 0] Current Loss: 5.9394\n",
            "[Batch 1] Current Loss: 5.5479\n",
            "[Batch 2] Current Loss: 5.2491\n",
            "[Batch 3] Current Loss: 5.5736\n",
            "[Batch 4] Current Loss: 5.4319\n",
            "[Batch 5] Current Loss: 5.2948\n",
            "[Batch 6] Current Loss: 5.6457\n",
            "[Batch 7] Current Loss: 5.3402\n",
            "[Batch 8] Current Loss: 5.2817\n",
            "[Batch 9] Current Loss: 5.4993\n",
            "[Batch 0] Current Loss: 6.5744\n",
            "[Batch 1] Current Loss: 6.2883\n",
            "[Batch 2] Current Loss: 5.6545\n",
            "[Batch 3] Current Loss: 6.3473\n",
            "[Batch 4] Current Loss: 6.4519\n",
            "[Batch 5] Current Loss: 5.9276\n",
            "[Batch 6] Current Loss: 5.9965\n",
            "[Batch 7] Current Loss: 5.8071\n",
            "[Batch 8] Current Loss: 5.9400\n",
            "[Batch 9] Current Loss: 5.6603\n",
            "Ep 1 (Step 002380): Train loss 5.480, Val loss 6.065\n",
            "[Batch 0] Current Loss: 6.2036\n",
            "[Batch 1] Current Loss: 5.1890\n",
            "[Batch 2] Current Loss: 5.0562\n",
            "[Batch 3] Current Loss: 5.4806\n",
            "[Batch 4] Current Loss: 5.4904\n",
            "[Batch 5] Current Loss: 5.6324\n",
            "[Batch 6] Current Loss: 5.3239\n",
            "[Batch 7] Current Loss: 5.8852\n",
            "[Batch 8] Current Loss: 5.6112\n",
            "[Batch 9] Current Loss: 5.9555\n",
            "[Batch 0] Current Loss: 5.5638\n",
            "[Batch 1] Current Loss: 6.5913\n",
            "[Batch 2] Current Loss: 5.1516\n",
            "[Batch 3] Current Loss: 5.6166\n",
            "[Batch 4] Current Loss: 5.8502\n",
            "[Batch 5] Current Loss: 6.3102\n",
            "[Batch 6] Current Loss: 5.4954\n",
            "[Batch 7] Current Loss: 5.8775\n",
            "[Batch 8] Current Loss: 5.8261\n",
            "[Batch 9] Current Loss: 5.5950\n",
            "Ep 1 (Step 002400): Train loss 5.583, Val loss 5.788\n",
            "[Batch 0] Current Loss: 5.9859\n",
            "[Batch 1] Current Loss: 5.8419\n",
            "[Batch 2] Current Loss: 5.8170\n",
            "[Batch 3] Current Loss: 5.5609\n",
            "[Batch 4] Current Loss: 5.6885\n",
            "[Batch 5] Current Loss: 6.0500\n",
            "[Batch 6] Current Loss: 5.7049\n",
            "[Batch 7] Current Loss: 5.4641\n",
            "[Batch 8] Current Loss: 6.0745\n",
            "[Batch 9] Current Loss: 5.7946\n",
            "[Batch 0] Current Loss: 6.0140\n",
            "[Batch 1] Current Loss: 6.4973\n",
            "[Batch 2] Current Loss: 5.8235\n",
            "[Batch 3] Current Loss: 5.8451\n",
            "[Batch 4] Current Loss: 5.3774\n",
            "[Batch 5] Current Loss: 5.2204\n",
            "[Batch 6] Current Loss: 5.7619\n",
            "[Batch 7] Current Loss: 5.1984\n",
            "[Batch 8] Current Loss: 5.9083\n",
            "[Batch 9] Current Loss: 5.7470\n",
            "Ep 1 (Step 002420): Train loss 5.798, Val loss 5.739\n",
            "[Batch 0] Current Loss: 5.5497\n",
            "[Batch 1] Current Loss: 6.1175\n",
            "[Batch 2] Current Loss: 5.6912\n",
            "[Batch 3] Current Loss: 5.7223\n",
            "[Batch 4] Current Loss: 5.7473\n",
            "[Batch 5] Current Loss: 5.9893\n",
            "[Batch 6] Current Loss: 5.1224\n",
            "[Batch 7] Current Loss: 5.4417\n",
            "[Batch 8] Current Loss: 5.6929\n",
            "[Batch 9] Current Loss: 5.1159\n",
            "[Batch 0] Current Loss: 6.3212\n",
            "[Batch 1] Current Loss: 6.0911\n",
            "[Batch 2] Current Loss: 6.0031\n",
            "[Batch 3] Current Loss: 5.2902\n",
            "[Batch 4] Current Loss: 5.8368\n",
            "[Batch 5] Current Loss: 5.7644\n",
            "[Batch 6] Current Loss: 5.4563\n",
            "[Batch 7] Current Loss: 5.7995\n",
            "[Batch 8] Current Loss: 5.8278\n",
            "[Batch 9] Current Loss: 5.4829\n",
            "Ep 1 (Step 002440): Train loss 5.619, Val loss 5.787\n",
            "[Batch 0] Current Loss: 5.6541\n",
            "[Batch 1] Current Loss: 5.2803\n",
            "[Batch 2] Current Loss: 5.6065\n",
            "[Batch 3] Current Loss: 5.4521\n",
            "[Batch 4] Current Loss: 5.6094\n",
            "[Batch 5] Current Loss: 5.9402\n",
            "[Batch 6] Current Loss: 5.9888\n",
            "[Batch 7] Current Loss: 5.3958\n",
            "[Batch 8] Current Loss: 5.5128\n",
            "[Batch 9] Current Loss: 6.0302\n",
            "[Batch 0] Current Loss: 5.5675\n",
            "[Batch 1] Current Loss: 6.3283\n",
            "[Batch 2] Current Loss: 5.5616\n",
            "[Batch 3] Current Loss: 5.4521\n",
            "[Batch 4] Current Loss: 5.5075\n",
            "[Batch 5] Current Loss: 5.9576\n",
            "[Batch 6] Current Loss: 6.1475\n",
            "[Batch 7] Current Loss: 6.1490\n",
            "[Batch 8] Current Loss: 5.9168\n",
            "[Batch 9] Current Loss: 5.8650\n",
            "Ep 1 (Step 002460): Train loss 5.647, Val loss 5.845\n",
            "[Batch 0] Current Loss: 5.3836\n",
            "[Batch 1] Current Loss: 5.0527\n",
            "[Batch 2] Current Loss: 4.7971\n",
            "[Batch 3] Current Loss: 5.9553\n",
            "[Batch 4] Current Loss: 5.6215\n",
            "[Batch 5] Current Loss: 5.9701\n",
            "[Batch 6] Current Loss: 5.2088\n",
            "[Batch 7] Current Loss: 5.8799\n",
            "[Batch 8] Current Loss: 5.6923\n",
            "[Batch 9] Current Loss: 5.7203\n",
            "[Batch 0] Current Loss: 5.9459\n",
            "[Batch 1] Current Loss: 6.0657\n",
            "[Batch 2] Current Loss: 5.7925\n",
            "[Batch 3] Current Loss: 5.6866\n",
            "[Batch 4] Current Loss: 5.4599\n",
            "[Batch 5] Current Loss: 5.9033\n",
            "[Batch 6] Current Loss: 5.3587\n",
            "[Batch 7] Current Loss: 5.7224\n",
            "[Batch 8] Current Loss: 6.0172\n",
            "[Batch 9] Current Loss: 5.7208\n",
            "Ep 1 (Step 002480): Train loss 5.528, Val loss 5.767\n",
            "[Batch 0] Current Loss: 5.2726\n",
            "[Batch 1] Current Loss: 5.1129\n",
            "[Batch 2] Current Loss: 6.1263\n",
            "[Batch 3] Current Loss: 6.0592\n",
            "[Batch 4] Current Loss: 5.9809\n",
            "[Batch 5] Current Loss: 5.6260\n",
            "[Batch 6] Current Loss: 5.4783\n",
            "[Batch 7] Current Loss: 5.7360\n",
            "[Batch 8] Current Loss: 5.4316\n",
            "[Batch 9] Current Loss: 5.6491\n",
            "[Batch 0] Current Loss: 5.9405\n",
            "[Batch 1] Current Loss: 6.0510\n",
            "[Batch 2] Current Loss: 6.2471\n",
            "[Batch 3] Current Loss: 5.3492\n",
            "[Batch 4] Current Loss: 5.8940\n",
            "[Batch 5] Current Loss: 6.1555\n",
            "[Batch 6] Current Loss: 5.6460\n",
            "[Batch 7] Current Loss: 5.5077\n",
            "[Batch 8] Current Loss: 5.8232\n",
            "[Batch 9] Current Loss: 5.9170\n",
            "Ep 1 (Step 002500): Train loss 5.647, Val loss 5.853\n",
            "[Batch 0] Current Loss: 5.4265\n",
            "[Batch 1] Current Loss: 5.8946\n",
            "[Batch 2] Current Loss: 5.6833\n",
            "[Batch 3] Current Loss: 6.1770\n",
            "[Batch 4] Current Loss: 5.8867\n",
            "[Batch 5] Current Loss: 6.0598\n",
            "[Batch 6] Current Loss: 5.1649\n",
            "[Batch 7] Current Loss: 5.9030\n",
            "[Batch 8] Current Loss: 5.6726\n",
            "[Batch 9] Current Loss: 5.5656\n",
            "[Batch 0] Current Loss: 5.3576\n",
            "[Batch 1] Current Loss: 5.3566\n",
            "[Batch 2] Current Loss: 5.8819\n",
            "[Batch 3] Current Loss: 5.5866\n",
            "[Batch 4] Current Loss: 5.4888\n",
            "[Batch 5] Current Loss: 6.3410\n",
            "[Batch 6] Current Loss: 6.1269\n",
            "[Batch 7] Current Loss: 5.9541\n",
            "[Batch 8] Current Loss: 5.9558\n",
            "[Batch 9] Current Loss: 5.7692\n",
            "Ep 1 (Step 002520): Train loss 5.743, Val loss 5.782\n",
            "[Batch 0] Current Loss: 6.2107\n",
            "[Batch 1] Current Loss: 5.8511\n",
            "[Batch 2] Current Loss: 4.9085\n",
            "[Batch 3] Current Loss: 5.3200\n",
            "[Batch 4] Current Loss: 5.1903\n",
            "[Batch 5] Current Loss: 5.7583\n",
            "[Batch 6] Current Loss: 5.2881\n",
            "[Batch 7] Current Loss: 5.5292\n",
            "[Batch 8] Current Loss: 4.9296\n",
            "[Batch 9] Current Loss: 5.4543\n",
            "[Batch 0] Current Loss: 5.6795\n",
            "[Batch 1] Current Loss: 6.3801\n",
            "[Batch 2] Current Loss: 5.2814\n",
            "[Batch 3] Current Loss: 5.6157\n",
            "[Batch 4] Current Loss: 5.5252\n",
            "[Batch 5] Current Loss: 6.3200\n",
            "[Batch 6] Current Loss: 5.8649\n",
            "[Batch 7] Current Loss: 5.4751\n",
            "[Batch 8] Current Loss: 5.4228\n",
            "[Batch 9] Current Loss: 6.1911\n",
            "Ep 1 (Step 002540): Train loss 5.444, Val loss 5.776\n",
            "[Batch 0] Current Loss: 5.4720\n",
            "[Batch 1] Current Loss: 5.9391\n",
            "[Batch 2] Current Loss: 5.3770\n",
            "[Batch 3] Current Loss: 5.4374\n",
            "[Batch 4] Current Loss: 5.6033\n",
            "[Batch 5] Current Loss: 4.9822\n",
            "[Batch 6] Current Loss: 5.8232\n",
            "[Batch 7] Current Loss: 5.5375\n",
            "[Batch 8] Current Loss: 5.1670\n",
            "[Batch 9] Current Loss: 5.9223\n",
            "[Batch 0] Current Loss: 6.2042\n",
            "[Batch 1] Current Loss: 5.5891\n",
            "[Batch 2] Current Loss: 5.6773\n",
            "[Batch 3] Current Loss: 5.6362\n",
            "[Batch 4] Current Loss: 5.7074\n",
            "[Batch 5] Current Loss: 5.5724\n",
            "[Batch 6] Current Loss: 5.5236\n",
            "[Batch 7] Current Loss: 5.7759\n",
            "[Batch 8] Current Loss: 5.4068\n",
            "[Batch 9] Current Loss: 5.4715\n",
            "Ep 1 (Step 002560): Train loss 5.526, Val loss 5.656\n",
            "[Batch 0] Current Loss: 5.6581\n",
            "[Batch 1] Current Loss: 5.6528\n",
            "[Batch 2] Current Loss: 5.7245\n",
            "[Batch 3] Current Loss: 5.7676\n",
            "[Batch 4] Current Loss: 5.6870\n",
            "[Batch 5] Current Loss: 5.3679\n",
            "[Batch 6] Current Loss: 5.3324\n",
            "[Batch 7] Current Loss: 5.7186\n",
            "[Batch 8] Current Loss: 5.8975\n",
            "[Batch 9] Current Loss: 5.7173\n",
            "[Batch 0] Current Loss: 6.0289\n",
            "[Batch 1] Current Loss: 6.0652\n",
            "[Batch 2] Current Loss: 5.3536\n",
            "[Batch 3] Current Loss: 5.4033\n",
            "[Batch 4] Current Loss: 5.6251\n",
            "[Batch 5] Current Loss: 5.8996\n",
            "[Batch 6] Current Loss: 5.7432\n",
            "[Batch 7] Current Loss: 5.6176\n",
            "[Batch 8] Current Loss: 5.8692\n",
            "[Batch 9] Current Loss: 5.3086\n",
            "Ep 1 (Step 002580): Train loss 5.652, Val loss 5.691\n",
            "[Batch 0] Current Loss: 5.2693\n",
            "[Batch 1] Current Loss: 5.4716\n",
            "[Batch 2] Current Loss: 5.8679\n",
            "[Batch 3] Current Loss: 5.4975\n",
            "[Batch 4] Current Loss: 5.6779\n",
            "[Batch 5] Current Loss: 5.5888\n",
            "[Batch 6] Current Loss: 5.7332\n",
            "[Batch 7] Current Loss: 5.5872\n",
            "[Batch 8] Current Loss: 5.3083\n",
            "[Batch 9] Current Loss: 5.5803\n",
            "[Batch 0] Current Loss: 6.1519\n",
            "[Batch 1] Current Loss: 6.1934\n",
            "[Batch 2] Current Loss: 5.9075\n",
            "[Batch 3] Current Loss: 5.8779\n",
            "[Batch 4] Current Loss: 6.0088\n",
            "[Batch 5] Current Loss: 6.2263\n",
            "[Batch 6] Current Loss: 5.5531\n",
            "[Batch 7] Current Loss: 5.8606\n",
            "[Batch 8] Current Loss: 5.7349\n",
            "[Batch 9] Current Loss: 6.0666\n",
            "Ep 1 (Step 002600): Train loss 5.558, Val loss 5.958\n",
            "[Batch 0] Current Loss: 5.6736\n",
            "[Batch 1] Current Loss: 5.2205\n",
            "[Batch 2] Current Loss: 5.1352\n",
            "[Batch 3] Current Loss: 6.0058\n",
            "[Batch 4] Current Loss: 5.6591\n",
            "[Batch 5] Current Loss: 5.7380\n",
            "[Batch 6] Current Loss: 5.7160\n",
            "[Batch 7] Current Loss: 5.6519\n",
            "[Batch 8] Current Loss: 5.8345\n",
            "[Batch 9] Current Loss: 5.5683\n",
            "[Batch 0] Current Loss: 5.9260\n",
            "[Batch 1] Current Loss: 5.7519\n",
            "[Batch 2] Current Loss: 6.0632\n",
            "[Batch 3] Current Loss: 5.6604\n",
            "[Batch 4] Current Loss: 5.2981\n",
            "[Batch 5] Current Loss: 6.2201\n",
            "[Batch 6] Current Loss: 6.0118\n",
            "[Batch 7] Current Loss: 5.0862\n",
            "[Batch 8] Current Loss: 5.4735\n",
            "[Batch 9] Current Loss: 5.5357\n",
            "Ep 1 (Step 002620): Train loss 5.620, Val loss 5.703\n",
            "[Batch 0] Current Loss: 5.9824\n",
            "[Batch 1] Current Loss: 5.3098\n",
            "[Batch 2] Current Loss: 5.3862\n",
            "[Batch 3] Current Loss: 5.3657\n",
            "[Batch 4] Current Loss: 6.0036\n",
            "[Batch 5] Current Loss: 5.5668\n",
            "[Batch 6] Current Loss: 5.6034\n",
            "[Batch 7] Current Loss: 5.8162\n",
            "[Batch 8] Current Loss: 5.3855\n",
            "[Batch 9] Current Loss: 5.3949\n",
            "[Batch 0] Current Loss: 5.7734\n",
            "[Batch 1] Current Loss: 5.0745\n",
            "[Batch 2] Current Loss: 5.7227\n",
            "[Batch 3] Current Loss: 5.5581\n",
            "[Batch 4] Current Loss: 5.4960\n",
            "[Batch 5] Current Loss: 5.7020\n",
            "[Batch 6] Current Loss: 5.1800\n",
            "[Batch 7] Current Loss: 5.2124\n",
            "[Batch 8] Current Loss: 5.6162\n",
            "[Batch 9] Current Loss: 5.3017\n",
            "Ep 1 (Step 002640): Train loss 5.581, Val loss 5.464\n",
            "[Batch 0] Current Loss: 5.2712\n",
            "[Batch 1] Current Loss: 5.9091\n",
            "[Batch 2] Current Loss: 6.1291\n",
            "[Batch 3] Current Loss: 5.6811\n",
            "[Batch 4] Current Loss: 5.3961\n",
            "[Batch 5] Current Loss: 5.3039\n",
            "[Batch 6] Current Loss: 5.5071\n",
            "[Batch 7] Current Loss: 5.3516\n",
            "[Batch 8] Current Loss: 5.8629\n",
            "[Batch 9] Current Loss: 5.4299\n",
            "[Batch 0] Current Loss: 5.5344\n",
            "[Batch 1] Current Loss: 5.7616\n",
            "[Batch 2] Current Loss: 5.4814\n",
            "[Batch 3] Current Loss: 6.3372\n",
            "[Batch 4] Current Loss: 6.0962\n",
            "[Batch 5] Current Loss: 5.8760\n",
            "[Batch 6] Current Loss: 5.9142\n",
            "[Batch 7] Current Loss: 6.0988\n",
            "[Batch 8] Current Loss: 5.6936\n",
            "[Batch 9] Current Loss: 5.5637\n",
            "Ep 1 (Step 002660): Train loss 5.584, Val loss 5.836\n",
            "[Batch 0] Current Loss: 5.9146\n",
            "[Batch 1] Current Loss: 5.4780\n",
            "[Batch 2] Current Loss: 5.4130\n",
            "[Batch 3] Current Loss: 6.1848\n",
            "[Batch 4] Current Loss: 5.0544\n",
            "[Batch 5] Current Loss: 5.2865\n",
            "[Batch 6] Current Loss: 6.1332\n",
            "[Batch 7] Current Loss: 5.1661\n",
            "[Batch 8] Current Loss: 5.0041\n",
            "[Batch 9] Current Loss: 5.8557\n",
            "[Batch 0] Current Loss: 5.8371\n",
            "[Batch 1] Current Loss: 6.1707\n",
            "[Batch 2] Current Loss: 5.8229\n",
            "[Batch 3] Current Loss: 5.4239\n",
            "[Batch 4] Current Loss: 5.6807\n",
            "[Batch 5] Current Loss: 6.0484\n",
            "[Batch 6] Current Loss: 5.1171\n",
            "[Batch 7] Current Loss: 5.5140\n",
            "[Batch 8] Current Loss: 5.7800\n",
            "[Batch 9] Current Loss: 5.4399\n",
            "Ep 1 (Step 002680): Train loss 5.549, Val loss 5.683\n",
            "[Batch 0] Current Loss: 6.1399\n",
            "[Batch 1] Current Loss: 5.4408\n",
            "[Batch 2] Current Loss: 5.7943\n",
            "[Batch 3] Current Loss: 6.0274\n",
            "[Batch 4] Current Loss: 5.5006\n",
            "[Batch 5] Current Loss: 5.8295\n",
            "[Batch 6] Current Loss: 5.5433\n",
            "[Batch 7] Current Loss: 5.6865\n",
            "[Batch 8] Current Loss: 5.6884\n",
            "[Batch 9] Current Loss: 5.2463\n",
            "[Batch 0] Current Loss: 5.5342\n",
            "[Batch 1] Current Loss: 5.3355\n",
            "[Batch 2] Current Loss: 5.6449\n",
            "[Batch 3] Current Loss: 5.5703\n",
            "[Batch 4] Current Loss: 6.2712\n",
            "[Batch 5] Current Loss: 5.4934\n",
            "[Batch 6] Current Loss: 5.7242\n",
            "[Batch 7] Current Loss: 5.6667\n",
            "[Batch 8] Current Loss: 6.0313\n",
            "[Batch 9] Current Loss: 5.7365\n",
            "Ep 1 (Step 002700): Train loss 5.690, Val loss 5.701\n",
            "[Batch 0] Current Loss: 5.5605\n",
            "[Batch 1] Current Loss: 5.5445\n",
            "[Batch 2] Current Loss: 5.4597\n",
            "[Batch 3] Current Loss: 5.5920\n",
            "[Batch 4] Current Loss: 5.5204\n",
            "[Batch 5] Current Loss: 5.6136\n",
            "[Batch 6] Current Loss: 5.5594\n",
            "[Batch 7] Current Loss: 5.1716\n",
            "[Batch 8] Current Loss: 5.4163\n",
            "[Batch 9] Current Loss: 5.3918\n",
            "[Batch 0] Current Loss: 5.6970\n",
            "[Batch 1] Current Loss: 5.3576\n",
            "[Batch 2] Current Loss: 5.7155\n",
            "[Batch 3] Current Loss: 6.2469\n",
            "[Batch 4] Current Loss: 5.7555\n",
            "[Batch 5] Current Loss: 5.5486\n",
            "[Batch 6] Current Loss: 5.5363\n",
            "[Batch 7] Current Loss: 6.1410\n",
            "[Batch 8] Current Loss: 6.1220\n",
            "[Batch 9] Current Loss: 5.6378\n",
            "Ep 1 (Step 002720): Train loss 5.483, Val loss 5.776\n",
            "[Batch 0] Current Loss: 5.1343\n",
            "[Batch 1] Current Loss: 5.1733\n",
            "[Batch 2] Current Loss: 5.6500\n",
            "[Batch 3] Current Loss: 6.1178\n",
            "[Batch 4] Current Loss: 5.8404\n",
            "[Batch 5] Current Loss: 5.1422\n",
            "[Batch 6] Current Loss: 5.3250\n",
            "[Batch 7] Current Loss: 5.7145\n",
            "[Batch 8] Current Loss: 5.2165\n",
            "[Batch 9] Current Loss: 5.8551\n",
            "[Batch 0] Current Loss: 5.5791\n",
            "[Batch 1] Current Loss: 5.3504\n",
            "[Batch 2] Current Loss: 5.3035\n",
            "[Batch 3] Current Loss: 5.9636\n",
            "[Batch 4] Current Loss: 5.1632\n",
            "[Batch 5] Current Loss: 5.6451\n",
            "[Batch 6] Current Loss: 6.1517\n",
            "[Batch 7] Current Loss: 5.8027\n",
            "[Batch 8] Current Loss: 5.0912\n",
            "[Batch 9] Current Loss: 5.8187\n",
            "Ep 1 (Step 002740): Train loss 5.517, Val loss 5.587\n",
            "[Batch 0] Current Loss: 5.7431\n",
            "[Batch 1] Current Loss: 5.6541\n",
            "[Batch 2] Current Loss: 5.4560\n",
            "[Batch 3] Current Loss: 4.7418\n",
            "[Batch 4] Current Loss: 5.7885\n",
            "[Batch 5] Current Loss: 5.9773\n",
            "[Batch 6] Current Loss: 5.6383\n",
            "[Batch 7] Current Loss: 5.2990\n",
            "[Batch 8] Current Loss: 4.8375\n",
            "[Batch 9] Current Loss: 5.2088\n",
            "[Batch 0] Current Loss: 6.0391\n",
            "[Batch 1] Current Loss: 5.5807\n",
            "[Batch 2] Current Loss: 5.6626\n",
            "[Batch 3] Current Loss: 5.8174\n",
            "[Batch 4] Current Loss: 5.7404\n",
            "[Batch 5] Current Loss: 5.7739\n",
            "[Batch 6] Current Loss: 5.6429\n",
            "[Batch 7] Current Loss: 5.6257\n",
            "[Batch 8] Current Loss: 5.5401\n",
            "[Batch 9] Current Loss: 5.3228\n",
            "Ep 1 (Step 002760): Train loss 5.434, Val loss 5.675\n",
            "[Batch 0] Current Loss: 5.7303\n",
            "[Batch 1] Current Loss: 5.2893\n",
            "[Batch 2] Current Loss: 5.7737\n",
            "[Batch 3] Current Loss: 5.4510\n",
            "[Batch 4] Current Loss: 5.2462\n",
            "[Batch 5] Current Loss: 5.5202\n",
            "[Batch 6] Current Loss: 4.9803\n",
            "[Batch 7] Current Loss: 5.8147\n",
            "[Batch 8] Current Loss: 5.6432\n",
            "[Batch 9] Current Loss: 5.3938\n",
            "[Batch 0] Current Loss: 5.9623\n",
            "[Batch 1] Current Loss: 5.9014\n",
            "[Batch 2] Current Loss: 5.5674\n",
            "[Batch 3] Current Loss: 6.3159\n",
            "[Batch 4] Current Loss: 5.6125\n",
            "[Batch 5] Current Loss: 5.7167\n",
            "[Batch 6] Current Loss: 5.7674\n",
            "[Batch 7] Current Loss: 6.1245\n",
            "[Batch 8] Current Loss: 5.9351\n",
            "[Batch 9] Current Loss: 5.8495\n",
            "Ep 1 (Step 002780): Train loss 5.484, Val loss 5.875\n",
            "[Batch 0] Current Loss: 4.8839\n",
            "[Batch 1] Current Loss: 5.8079\n",
            "[Batch 2] Current Loss: 5.7603\n",
            "[Batch 3] Current Loss: 4.9961\n",
            "[Batch 4] Current Loss: 5.7265\n",
            "[Batch 5] Current Loss: 5.9566\n",
            "[Batch 6] Current Loss: 5.5754\n",
            "[Batch 7] Current Loss: 5.6669\n",
            "[Batch 8] Current Loss: 5.6685\n",
            "[Batch 9] Current Loss: 5.3766\n",
            "[Batch 0] Current Loss: 5.6465\n",
            "[Batch 1] Current Loss: 5.4514\n",
            "[Batch 2] Current Loss: 5.5258\n",
            "[Batch 3] Current Loss: 5.9873\n",
            "[Batch 4] Current Loss: 5.7687\n",
            "[Batch 5] Current Loss: 6.5128\n",
            "[Batch 6] Current Loss: 6.0435\n",
            "[Batch 7] Current Loss: 5.7589\n",
            "[Batch 8] Current Loss: 5.6026\n",
            "[Batch 9] Current Loss: 6.1176\n",
            "Ep 1 (Step 002800): Train loss 5.542, Val loss 5.842\n",
            "[Batch 0] Current Loss: 5.3441\n",
            "[Batch 1] Current Loss: 5.1564\n",
            "[Batch 2] Current Loss: 5.3375\n",
            "[Batch 3] Current Loss: 5.1824\n",
            "[Batch 4] Current Loss: 5.9663\n",
            "[Batch 5] Current Loss: 5.1367\n",
            "[Batch 6] Current Loss: 5.8180\n",
            "[Batch 7] Current Loss: 5.6607\n",
            "[Batch 8] Current Loss: 5.6287\n",
            "[Batch 9] Current Loss: 5.5664\n",
            "[Batch 0] Current Loss: 6.0852\n",
            "[Batch 1] Current Loss: 6.1070\n",
            "[Batch 2] Current Loss: 5.9169\n",
            "[Batch 3] Current Loss: 6.1398\n",
            "[Batch 4] Current Loss: 5.3656\n",
            "[Batch 5] Current Loss: 6.1695\n",
            "[Batch 6] Current Loss: 5.7630\n",
            "[Batch 7] Current Loss: 6.1414\n",
            "[Batch 8] Current Loss: 5.6104\n",
            "[Batch 9] Current Loss: 5.9073\n",
            "Ep 1 (Step 002820): Train loss 5.480, Val loss 5.921\n",
            "[Batch 0] Current Loss: 5.3242\n",
            "[Batch 1] Current Loss: 5.9049\n",
            "[Batch 2] Current Loss: 5.4776\n",
            "[Batch 3] Current Loss: 5.0978\n",
            "[Batch 4] Current Loss: 5.1804\n",
            "[Batch 5] Current Loss: 5.3090\n",
            "[Batch 6] Current Loss: 5.1026\n",
            "[Batch 7] Current Loss: 5.3740\n",
            "[Batch 8] Current Loss: 5.7414\n",
            "[Batch 9] Current Loss: 5.6465\n",
            "[Batch 0] Current Loss: 6.0779\n",
            "[Batch 1] Current Loss: 5.6198\n",
            "[Batch 2] Current Loss: 5.7730\n",
            "[Batch 3] Current Loss: 5.6887\n",
            "[Batch 4] Current Loss: 6.0373\n",
            "[Batch 5] Current Loss: 5.2119\n",
            "[Batch 6] Current Loss: 5.3104\n",
            "[Batch 7] Current Loss: 5.7313\n",
            "[Batch 8] Current Loss: 5.3184\n",
            "[Batch 9] Current Loss: 5.7712\n",
            "Ep 1 (Step 002840): Train loss 5.416, Val loss 5.654\n",
            "[Batch 0] Current Loss: 5.0070\n",
            "[Batch 1] Current Loss: 5.4790\n",
            "[Batch 2] Current Loss: 5.4452\n",
            "[Batch 3] Current Loss: 5.8057\n",
            "[Batch 4] Current Loss: 5.5954\n",
            "[Batch 5] Current Loss: 6.0164\n",
            "[Batch 6] Current Loss: 5.1707\n",
            "[Batch 7] Current Loss: 5.1164\n",
            "[Batch 8] Current Loss: 5.5721\n",
            "[Batch 9] Current Loss: 5.1416\n",
            "[Batch 0] Current Loss: 6.2111\n",
            "[Batch 1] Current Loss: 5.8757\n",
            "[Batch 2] Current Loss: 5.5393\n",
            "[Batch 3] Current Loss: 5.8489\n",
            "[Batch 4] Current Loss: 5.7103\n",
            "[Batch 5] Current Loss: 6.2768\n",
            "[Batch 6] Current Loss: 5.7451\n",
            "[Batch 7] Current Loss: 6.2768\n",
            "[Batch 8] Current Loss: 5.6689\n",
            "[Batch 9] Current Loss: 6.0360\n",
            "Ep 1 (Step 002860): Train loss 5.435, Val loss 5.919\n",
            "[Batch 0] Current Loss: 5.8012\n",
            "[Batch 1] Current Loss: 5.8337\n",
            "[Batch 2] Current Loss: 5.5305\n",
            "[Batch 3] Current Loss: 5.5167\n",
            "[Batch 4] Current Loss: 5.5013\n",
            "[Batch 5] Current Loss: 5.4579\n",
            "[Batch 6] Current Loss: 5.7758\n",
            "[Batch 7] Current Loss: 5.8068\n",
            "[Batch 8] Current Loss: 5.6073\n",
            "[Batch 9] Current Loss: 5.6772\n",
            "[Batch 0] Current Loss: 5.8734\n",
            "[Batch 1] Current Loss: 6.1188\n",
            "[Batch 2] Current Loss: 5.2906\n",
            "[Batch 3] Current Loss: 5.1557\n",
            "[Batch 4] Current Loss: 5.5193\n",
            "[Batch 5] Current Loss: 6.1711\n",
            "[Batch 6] Current Loss: 5.3882\n",
            "[Batch 7] Current Loss: 5.8296\n",
            "[Batch 8] Current Loss: 5.9397\n",
            "[Batch 9] Current Loss: 5.8681\n",
            "Ep 1 (Step 002880): Train loss 5.651, Val loss 5.715\n",
            "[Batch 0] Current Loss: 5.2528\n",
            "[Batch 1] Current Loss: 5.5251\n",
            "[Batch 2] Current Loss: 5.0734\n",
            "[Batch 3] Current Loss: 5.3591\n",
            "[Batch 4] Current Loss: 5.7694\n",
            "[Batch 5] Current Loss: 5.6038\n",
            "[Batch 6] Current Loss: 5.6776\n",
            "[Batch 7] Current Loss: 5.6403\n",
            "[Batch 8] Current Loss: 5.7180\n",
            "[Batch 9] Current Loss: 5.5182\n",
            "[Batch 0] Current Loss: 5.9189\n",
            "[Batch 1] Current Loss: 5.5525\n",
            "[Batch 2] Current Loss: 6.2204\n",
            "[Batch 3] Current Loss: 5.7537\n",
            "[Batch 4] Current Loss: 6.1100\n",
            "[Batch 5] Current Loss: 6.1988\n",
            "[Batch 6] Current Loss: 5.7066\n",
            "[Batch 7] Current Loss: 5.3093\n",
            "[Batch 8] Current Loss: 5.5862\n",
            "[Batch 9] Current Loss: 6.0490\n",
            "Ep 1 (Step 002900): Train loss 5.514, Val loss 5.841\n",
            "[Batch 0] Current Loss: 5.5954\n",
            "[Batch 1] Current Loss: 5.7526\n",
            "[Batch 2] Current Loss: 5.7652\n",
            "[Batch 3] Current Loss: 5.9367\n",
            "[Batch 4] Current Loss: 5.7382\n",
            "[Batch 5] Current Loss: 5.4960\n",
            "[Batch 6] Current Loss: 5.5630\n",
            "[Batch 7] Current Loss: 5.3408\n",
            "[Batch 8] Current Loss: 5.4762\n",
            "[Batch 9] Current Loss: 5.5074\n",
            "[Batch 0] Current Loss: 5.7585\n",
            "[Batch 1] Current Loss: 5.6542\n",
            "[Batch 2] Current Loss: 5.4812\n",
            "[Batch 3] Current Loss: 5.9994\n",
            "[Batch 4] Current Loss: 5.3538\n",
            "[Batch 5] Current Loss: 5.5479\n",
            "[Batch 6] Current Loss: 5.9473\n",
            "[Batch 7] Current Loss: 5.9606\n",
            "[Batch 8] Current Loss: 5.9776\n",
            "[Batch 9] Current Loss: 5.7805\n",
            "Ep 1 (Step 002920): Train loss 5.617, Val loss 5.746\n",
            "[Batch 0] Current Loss: 5.3473\n",
            "[Batch 1] Current Loss: 5.7660\n",
            "[Batch 2] Current Loss: 5.4668\n",
            "[Batch 3] Current Loss: 5.3777\n",
            "[Batch 4] Current Loss: 5.4073\n",
            "[Batch 5] Current Loss: 5.7058\n",
            "[Batch 6] Current Loss: 5.5127\n",
            "[Batch 7] Current Loss: 5.6691\n",
            "[Batch 8] Current Loss: 5.8819\n",
            "[Batch 9] Current Loss: 6.0337\n",
            "[Batch 0] Current Loss: 5.2592\n",
            "[Batch 1] Current Loss: 5.3505\n",
            "[Batch 2] Current Loss: 5.2286\n",
            "[Batch 3] Current Loss: 5.8603\n",
            "[Batch 4] Current Loss: 5.7772\n",
            "[Batch 5] Current Loss: 6.2670\n",
            "[Batch 6] Current Loss: 6.0785\n",
            "[Batch 7] Current Loss: 5.6876\n",
            "[Batch 8] Current Loss: 5.2731\n",
            "[Batch 9] Current Loss: 5.4563\n",
            "Ep 1 (Step 002940): Train loss 5.617, Val loss 5.624\n",
            "[Batch 0] Current Loss: 5.9927\n",
            "[Batch 1] Current Loss: 5.5524\n",
            "[Batch 2] Current Loss: 5.3953\n",
            "[Batch 3] Current Loss: 4.8857\n",
            "[Batch 4] Current Loss: 5.3029\n",
            "[Batch 5] Current Loss: 5.1015\n",
            "[Batch 6] Current Loss: 5.9308\n",
            "[Batch 7] Current Loss: 5.3111\n",
            "[Batch 8] Current Loss: 5.4645\n",
            "[Batch 9] Current Loss: 5.4984\n",
            "[Batch 0] Current Loss: 5.5264\n",
            "[Batch 1] Current Loss: 5.6495\n",
            "[Batch 2] Current Loss: 5.0878\n",
            "[Batch 3] Current Loss: 5.7919\n",
            "[Batch 4] Current Loss: 5.7178\n",
            "[Batch 5] Current Loss: 5.9121\n",
            "[Batch 6] Current Loss: 5.6116\n",
            "[Batch 7] Current Loss: 5.7773\n",
            "[Batch 8] Current Loss: 5.8973\n",
            "[Batch 9] Current Loss: 5.7479\n",
            "Ep 1 (Step 002960): Train loss 5.444, Val loss 5.672\n",
            "[Batch 0] Current Loss: 5.4097\n",
            "[Batch 1] Current Loss: 5.6850\n",
            "[Batch 2] Current Loss: 5.4176\n",
            "[Batch 3] Current Loss: 5.4665\n",
            "[Batch 4] Current Loss: 5.3994\n",
            "[Batch 5] Current Loss: 5.2636\n",
            "[Batch 6] Current Loss: 6.2764\n",
            "[Batch 7] Current Loss: 6.0845\n",
            "[Batch 8] Current Loss: 5.2891\n",
            "[Batch 9] Current Loss: 5.1702\n",
            "[Batch 0] Current Loss: 5.3245\n",
            "[Batch 1] Current Loss: 5.5805\n",
            "[Batch 2] Current Loss: 5.4964\n",
            "[Batch 3] Current Loss: 5.8369\n",
            "[Batch 4] Current Loss: 5.2541\n",
            "[Batch 5] Current Loss: 6.1627\n",
            "[Batch 6] Current Loss: 5.7169\n",
            "[Batch 7] Current Loss: 5.6330\n",
            "[Batch 8] Current Loss: 5.9428\n",
            "[Batch 9] Current Loss: 6.2862\n",
            "Ep 1 (Step 002980): Train loss 5.546, Val loss 5.723\n",
            "[Batch 0] Current Loss: 5.8266\n",
            "[Batch 1] Current Loss: 5.8372\n",
            "[Batch 2] Current Loss: 5.1420\n",
            "[Batch 3] Current Loss: 5.3781\n",
            "[Batch 4] Current Loss: 5.7130\n",
            "[Batch 5] Current Loss: 5.6392\n",
            "[Batch 6] Current Loss: 5.7169\n",
            "[Batch 7] Current Loss: 5.1345\n",
            "[Batch 8] Current Loss: 5.8504\n",
            "[Batch 9] Current Loss: 5.3014\n",
            "[Batch 0] Current Loss: 5.3139\n",
            "[Batch 1] Current Loss: 5.7216\n",
            "[Batch 2] Current Loss: 5.8652\n",
            "[Batch 3] Current Loss: 5.8635\n",
            "[Batch 4] Current Loss: 5.8790\n",
            "[Batch 5] Current Loss: 6.0510\n",
            "[Batch 6] Current Loss: 6.3465\n",
            "[Batch 7] Current Loss: 5.1315\n",
            "[Batch 8] Current Loss: 5.5494\n",
            "[Batch 9] Current Loss: 6.0316\n",
            "Ep 1 (Step 003000): Train loss 5.554, Val loss 5.775\n",
            "[Batch 0] Current Loss: 5.3965\n",
            "[Batch 1] Current Loss: 5.7847\n",
            "[Batch 2] Current Loss: 5.3509\n",
            "[Batch 3] Current Loss: 5.6561\n",
            "[Batch 4] Current Loss: 5.2275\n",
            "[Batch 5] Current Loss: 5.6343\n",
            "[Batch 6] Current Loss: 5.6910\n",
            "[Batch 7] Current Loss: 5.1595\n",
            "[Batch 8] Current Loss: 4.8271\n",
            "[Batch 9] Current Loss: 5.5820\n",
            "[Batch 0] Current Loss: 6.2078\n",
            "[Batch 1] Current Loss: 5.7310\n",
            "[Batch 2] Current Loss: 5.8628\n",
            "[Batch 3] Current Loss: 5.8047\n",
            "[Batch 4] Current Loss: 5.4469\n",
            "[Batch 5] Current Loss: 5.7683\n",
            "[Batch 6] Current Loss: 5.4505\n",
            "[Batch 7] Current Loss: 5.2628\n",
            "[Batch 8] Current Loss: 5.4486\n",
            "[Batch 9] Current Loss: 5.1498\n",
            "Ep 1 (Step 003020): Train loss 5.431, Val loss 5.613\n",
            "[Batch 0] Current Loss: 5.2580\n",
            "[Batch 1] Current Loss: 5.5421\n",
            "[Batch 2] Current Loss: 5.5224\n",
            "[Batch 3] Current Loss: 5.3112\n",
            "[Batch 4] Current Loss: 5.4568\n",
            "[Batch 5] Current Loss: 4.9572\n",
            "[Batch 6] Current Loss: 5.6824\n",
            "[Batch 7] Current Loss: 5.5873\n",
            "[Batch 8] Current Loss: 5.3425\n",
            "[Batch 9] Current Loss: 5.5843\n",
            "[Batch 0] Current Loss: 5.4879\n",
            "[Batch 1] Current Loss: 5.9713\n",
            "[Batch 2] Current Loss: 5.9960\n",
            "[Batch 3] Current Loss: 5.9583\n",
            "[Batch 4] Current Loss: 5.8152\n",
            "[Batch 5] Current Loss: 5.9416\n",
            "[Batch 6] Current Loss: 5.8149\n",
            "[Batch 7] Current Loss: 5.6883\n",
            "[Batch 8] Current Loss: 5.5301\n",
            "[Batch 9] Current Loss: 5.6619\n",
            "Ep 1 (Step 003040): Train loss 5.424, Val loss 5.787\n",
            "[Batch 0] Current Loss: 4.9584\n",
            "[Batch 1] Current Loss: 5.6308\n",
            "[Batch 2] Current Loss: 5.6497\n",
            "[Batch 3] Current Loss: 6.1904\n",
            "[Batch 4] Current Loss: 5.5035\n",
            "[Batch 5] Current Loss: 5.7208\n",
            "[Batch 6] Current Loss: 4.9040\n",
            "[Batch 7] Current Loss: 5.1705\n",
            "[Batch 8] Current Loss: 5.1823\n",
            "[Batch 9] Current Loss: 5.4781\n",
            "[Batch 0] Current Loss: 5.9775\n",
            "[Batch 1] Current Loss: 5.9331\n",
            "[Batch 2] Current Loss: 5.3177\n",
            "[Batch 3] Current Loss: 5.3001\n",
            "[Batch 4] Current Loss: 5.8142\n",
            "[Batch 5] Current Loss: 6.0168\n",
            "[Batch 6] Current Loss: 5.3341\n",
            "[Batch 7] Current Loss: 5.4535\n",
            "[Batch 8] Current Loss: 5.7801\n",
            "[Batch 9] Current Loss: 5.0707\n",
            "Ep 1 (Step 003060): Train loss 5.439, Val loss 5.600\n",
            "[Batch 0] Current Loss: 5.5721\n",
            "[Batch 1] Current Loss: 5.4798\n",
            "[Batch 2] Current Loss: 4.7834\n",
            "[Batch 3] Current Loss: 5.9568\n",
            "[Batch 4] Current Loss: 5.7365\n",
            "[Batch 5] Current Loss: 5.1045\n",
            "[Batch 6] Current Loss: 5.3250\n",
            "[Batch 7] Current Loss: 5.3780\n",
            "[Batch 8] Current Loss: 5.5236\n",
            "[Batch 9] Current Loss: 5.2042\n",
            "[Batch 0] Current Loss: 5.9336\n",
            "[Batch 1] Current Loss: 5.2041\n",
            "[Batch 2] Current Loss: 5.9115\n",
            "[Batch 3] Current Loss: 5.9979\n",
            "[Batch 4] Current Loss: 5.6462\n",
            "[Batch 5] Current Loss: 6.2825\n",
            "[Batch 6] Current Loss: 6.2567\n",
            "[Batch 7] Current Loss: 5.5242\n",
            "[Batch 8] Current Loss: 5.8938\n",
            "[Batch 9] Current Loss: 5.7160\n",
            "Ep 1 (Step 003080): Train loss 5.406, Val loss 5.837\n",
            "[Batch 0] Current Loss: 5.5857\n",
            "[Batch 1] Current Loss: 4.8471\n",
            "[Batch 2] Current Loss: 5.7453\n",
            "[Batch 3] Current Loss: 5.2472\n",
            "[Batch 4] Current Loss: 5.8030\n",
            "[Batch 5] Current Loss: 5.4892\n",
            "[Batch 6] Current Loss: 5.6409\n",
            "[Batch 7] Current Loss: 5.6960\n",
            "[Batch 8] Current Loss: 5.7042\n",
            "[Batch 9] Current Loss: 5.5101\n",
            "[Batch 0] Current Loss: 5.7977\n",
            "[Batch 1] Current Loss: 5.7644\n",
            "[Batch 2] Current Loss: 5.4903\n",
            "[Batch 3] Current Loss: 5.6247\n",
            "[Batch 4] Current Loss: 5.4174\n",
            "[Batch 5] Current Loss: 5.9862\n",
            "[Batch 6] Current Loss: 5.4353\n",
            "[Batch 7] Current Loss: 5.5798\n",
            "[Batch 8] Current Loss: 5.9902\n",
            "[Batch 9] Current Loss: 6.0179\n",
            "Ep 1 (Step 003100): Train loss 5.527, Val loss 5.710\n",
            "[Batch 0] Current Loss: 5.4639\n",
            "[Batch 1] Current Loss: 5.0160\n",
            "[Batch 2] Current Loss: 5.4917\n",
            "[Batch 3] Current Loss: 5.5072\n",
            "[Batch 4] Current Loss: 5.5636\n",
            "[Batch 5] Current Loss: 4.7560\n",
            "[Batch 6] Current Loss: 5.6592\n",
            "[Batch 7] Current Loss: 5.3534\n",
            "[Batch 8] Current Loss: 5.3444\n",
            "[Batch 9] Current Loss: 5.5988\n",
            "[Batch 0] Current Loss: 5.7997\n",
            "[Batch 1] Current Loss: 5.9995\n",
            "[Batch 2] Current Loss: 6.4214\n",
            "[Batch 3] Current Loss: 5.3354\n",
            "[Batch 4] Current Loss: 5.1455\n",
            "[Batch 5] Current Loss: 5.2153\n",
            "[Batch 6] Current Loss: 5.9179\n",
            "[Batch 7] Current Loss: 5.5962\n",
            "[Batch 8] Current Loss: 5.7046\n",
            "[Batch 9] Current Loss: 6.0360\n",
            "Ep 1 (Step 003120): Train loss 5.375, Val loss 5.717\n",
            "[Batch 0] Current Loss: 5.5411\n",
            "[Batch 1] Current Loss: 5.7987\n",
            "[Batch 2] Current Loss: 5.8067\n",
            "[Batch 3] Current Loss: 4.9338\n",
            "[Batch 4] Current Loss: 4.9143\n",
            "[Batch 5] Current Loss: 4.9668\n",
            "[Batch 6] Current Loss: 4.9404\n",
            "[Batch 7] Current Loss: 5.7800\n",
            "[Batch 8] Current Loss: 6.0123\n",
            "[Batch 9] Current Loss: 5.7828\n",
            "[Batch 0] Current Loss: 5.5167\n",
            "[Batch 1] Current Loss: 5.4737\n",
            "[Batch 2] Current Loss: 5.5242\n",
            "[Batch 3] Current Loss: 5.0466\n",
            "[Batch 4] Current Loss: 5.5909\n",
            "[Batch 5] Current Loss: 6.1807\n",
            "[Batch 6] Current Loss: 5.7607\n",
            "[Batch 7] Current Loss: 5.6000\n",
            "[Batch 8] Current Loss: 5.8692\n",
            "[Batch 9] Current Loss: 5.7394\n",
            "Ep 1 (Step 003140): Train loss 5.448, Val loss 5.630\n",
            "[Batch 0] Current Loss: 4.9596\n",
            "[Batch 1] Current Loss: 4.9979\n",
            "[Batch 2] Current Loss: 5.0822\n",
            "[Batch 3] Current Loss: 5.4919\n",
            "[Batch 4] Current Loss: 5.2434\n",
            "[Batch 5] Current Loss: 5.9609\n",
            "[Batch 6] Current Loss: 5.2454\n",
            "[Batch 7] Current Loss: 5.1821\n",
            "[Batch 8] Current Loss: 5.3909\n",
            "[Batch 9] Current Loss: 5.4815\n",
            "[Batch 0] Current Loss: 6.1651\n",
            "[Batch 1] Current Loss: 5.9581\n",
            "[Batch 2] Current Loss: 4.7844\n",
            "[Batch 3] Current Loss: 5.7263\n",
            "[Batch 4] Current Loss: 5.4939\n",
            "[Batch 5] Current Loss: 5.9604\n",
            "[Batch 6] Current Loss: 5.5115\n",
            "[Batch 7] Current Loss: 5.9567\n",
            "[Batch 8] Current Loss: 5.6855\n",
            "[Batch 9] Current Loss: 6.2724\n",
            "Ep 1 (Step 003160): Train loss 5.304, Val loss 5.751\n",
            "[Batch 0] Current Loss: 5.6566\n",
            "[Batch 1] Current Loss: 5.8150\n",
            "[Batch 2] Current Loss: 5.1686\n",
            "[Batch 3] Current Loss: 5.9349\n",
            "[Batch 4] Current Loss: 5.4284\n",
            "[Batch 5] Current Loss: 5.3852\n",
            "[Batch 6] Current Loss: 5.8321\n",
            "[Batch 7] Current Loss: 5.8002\n",
            "[Batch 8] Current Loss: 4.8936\n",
            "[Batch 9] Current Loss: 5.2324\n",
            "[Batch 0] Current Loss: 5.5876\n",
            "[Batch 1] Current Loss: 6.0854\n",
            "[Batch 2] Current Loss: 5.2489\n",
            "[Batch 3] Current Loss: 5.8306\n",
            "[Batch 4] Current Loss: 6.0361\n",
            "[Batch 5] Current Loss: 5.5177\n",
            "[Batch 6] Current Loss: 5.3550\n",
            "[Batch 7] Current Loss: 5.4621\n",
            "[Batch 8] Current Loss: 6.2384\n",
            "[Batch 9] Current Loss: 5.7579\n",
            "Ep 1 (Step 003180): Train loss 5.515, Val loss 5.712\n",
            "[Batch 0] Current Loss: 4.9594\n",
            "[Batch 1] Current Loss: 5.3598\n",
            "[Batch 2] Current Loss: 4.8808\n",
            "[Batch 3] Current Loss: 5.0202\n",
            "[Batch 4] Current Loss: 5.2467\n",
            "[Batch 5] Current Loss: 5.9854\n",
            "[Batch 6] Current Loss: 5.4825\n",
            "[Batch 7] Current Loss: 5.3083\n",
            "[Batch 8] Current Loss: 5.6637\n",
            "[Batch 9] Current Loss: 5.3264\n",
            "[Batch 0] Current Loss: 5.1712\n",
            "[Batch 1] Current Loss: 5.7432\n",
            "[Batch 2] Current Loss: 5.3984\n",
            "[Batch 3] Current Loss: 5.4610\n",
            "[Batch 4] Current Loss: 5.2434\n",
            "[Batch 5] Current Loss: 6.0552\n",
            "[Batch 6] Current Loss: 5.2964\n",
            "[Batch 7] Current Loss: 5.2284\n",
            "[Batch 8] Current Loss: 5.9578\n",
            "[Batch 9] Current Loss: 6.2335\n",
            "Ep 1 (Step 003200): Train loss 5.323, Val loss 5.579\n",
            "[Batch 0] Current Loss: 5.7803\n",
            "[Batch 1] Current Loss: 5.0007\n",
            "[Batch 2] Current Loss: 5.9525\n",
            "[Batch 3] Current Loss: 5.1827\n",
            "[Batch 4] Current Loss: 5.1784\n",
            "[Batch 5] Current Loss: 5.4199\n",
            "[Batch 6] Current Loss: 5.0505\n",
            "[Batch 7] Current Loss: 5.8445\n",
            "[Batch 8] Current Loss: 5.5525\n",
            "[Batch 9] Current Loss: 5.0916\n",
            "[Batch 0] Current Loss: 5.7055\n",
            "[Batch 1] Current Loss: 5.9662\n",
            "[Batch 2] Current Loss: 5.9234\n",
            "[Batch 3] Current Loss: 6.0043\n",
            "[Batch 4] Current Loss: 5.7501\n",
            "[Batch 5] Current Loss: 4.9912\n",
            "[Batch 6] Current Loss: 6.0069\n",
            "[Batch 7] Current Loss: 5.2029\n",
            "[Batch 8] Current Loss: 5.3285\n",
            "[Batch 9] Current Loss: 5.3589\n",
            "Ep 1 (Step 003220): Train loss 5.405, Val loss 5.624\n",
            "[Batch 0] Current Loss: 5.5031\n",
            "[Batch 1] Current Loss: 5.3905\n",
            "[Batch 2] Current Loss: 4.5446\n",
            "[Batch 3] Current Loss: 5.9014\n",
            "[Batch 4] Current Loss: 5.6151\n",
            "[Batch 5] Current Loss: 5.9499\n",
            "[Batch 6] Current Loss: 5.8459\n",
            "[Batch 7] Current Loss: 5.3392\n",
            "[Batch 8] Current Loss: 5.6662\n",
            "[Batch 9] Current Loss: 4.7253\n",
            "[Batch 0] Current Loss: 5.4596\n",
            "[Batch 1] Current Loss: 5.7861\n",
            "[Batch 2] Current Loss: 5.3399\n",
            "[Batch 3] Current Loss: 5.8480\n",
            "[Batch 4] Current Loss: 5.4737\n",
            "[Batch 5] Current Loss: 5.2012\n",
            "[Batch 6] Current Loss: 5.6593\n",
            "[Batch 7] Current Loss: 5.2856\n",
            "[Batch 8] Current Loss: 5.5686\n",
            "[Batch 9] Current Loss: 5.5841\n",
            "Ep 1 (Step 003240): Train loss 5.448, Val loss 5.521\n",
            "[Batch 0] Current Loss: 5.6415\n",
            "[Batch 1] Current Loss: 5.6665\n",
            "[Batch 2] Current Loss: 5.8470\n",
            "[Batch 3] Current Loss: 6.1594\n",
            "[Batch 4] Current Loss: 5.6076\n",
            "[Batch 5] Current Loss: 5.8391\n",
            "[Batch 6] Current Loss: 5.5489\n",
            "[Batch 7] Current Loss: 5.7842\n",
            "[Batch 8] Current Loss: 4.9677\n",
            "[Batch 9] Current Loss: 5.2218\n",
            "[Batch 0] Current Loss: 5.1195\n",
            "[Batch 1] Current Loss: 5.9453\n",
            "[Batch 2] Current Loss: 5.8999\n",
            "[Batch 3] Current Loss: 5.7283\n",
            "[Batch 4] Current Loss: 5.6858\n",
            "[Batch 5] Current Loss: 5.9867\n",
            "[Batch 6] Current Loss: 5.5408\n",
            "[Batch 7] Current Loss: 5.4095\n",
            "[Batch 8] Current Loss: 5.8075\n",
            "[Batch 9] Current Loss: 6.2423\n",
            "Ep 1 (Step 003260): Train loss 5.628, Val loss 5.737\n",
            "[Batch 0] Current Loss: 5.5244\n",
            "[Batch 1] Current Loss: 5.3790\n",
            "[Batch 2] Current Loss: 4.9895\n",
            "[Batch 3] Current Loss: 5.0916\n",
            "[Batch 4] Current Loss: 5.8866\n",
            "[Batch 5] Current Loss: 5.0675\n",
            "[Batch 6] Current Loss: 5.4640\n",
            "[Batch 7] Current Loss: 5.2063\n",
            "[Batch 8] Current Loss: 5.6544\n",
            "[Batch 9] Current Loss: 5.3179\n",
            "[Batch 0] Current Loss: 6.3899\n",
            "[Batch 1] Current Loss: 4.8864\n",
            "[Batch 2] Current Loss: 4.7714\n",
            "[Batch 3] Current Loss: 6.0466\n",
            "[Batch 4] Current Loss: 5.8536\n",
            "[Batch 5] Current Loss: 5.3501\n",
            "[Batch 6] Current Loss: 5.0786\n",
            "[Batch 7] Current Loss: 5.8651\n",
            "[Batch 8] Current Loss: 5.2078\n",
            "[Batch 9] Current Loss: 5.6779\n",
            "Ep 1 (Step 003280): Train loss 5.358, Val loss 5.513\n",
            "[Batch 0] Current Loss: 5.8058\n",
            "[Batch 1] Current Loss: 5.2876\n",
            "[Batch 2] Current Loss: 5.3191\n",
            "[Batch 3] Current Loss: 5.4897\n",
            "[Batch 4] Current Loss: 5.6309\n",
            "[Batch 5] Current Loss: 5.7650\n",
            "[Batch 6] Current Loss: 5.4082\n",
            "[Batch 7] Current Loss: 5.1404\n",
            "[Batch 8] Current Loss: 4.9561\n",
            "[Batch 9] Current Loss: 5.0885\n",
            "[Batch 0] Current Loss: 5.5812\n",
            "[Batch 1] Current Loss: 5.3628\n",
            "[Batch 2] Current Loss: 6.1433\n",
            "[Batch 3] Current Loss: 5.6590\n",
            "[Batch 4] Current Loss: 5.8556\n",
            "[Batch 5] Current Loss: 6.0179\n",
            "[Batch 6] Current Loss: 5.9257\n",
            "[Batch 7] Current Loss: 6.1632\n",
            "[Batch 8] Current Loss: 5.5308\n",
            "[Batch 9] Current Loss: 4.6110\n",
            "Ep 1 (Step 003300): Train loss 5.389, Val loss 5.685\n",
            "[Batch 0] Current Loss: 5.1029\n",
            "[Batch 1] Current Loss: 5.2932\n",
            "[Batch 2] Current Loss: 5.6000\n",
            "[Batch 3] Current Loss: 5.6034\n",
            "[Batch 4] Current Loss: 5.2686\n",
            "[Batch 5] Current Loss: 5.0677\n",
            "[Batch 6] Current Loss: 5.2541\n",
            "[Batch 7] Current Loss: 5.5037\n",
            "[Batch 8] Current Loss: 5.2791\n",
            "[Batch 9] Current Loss: 5.1484\n",
            "[Batch 0] Current Loss: 5.6525\n",
            "[Batch 1] Current Loss: 5.3906\n",
            "[Batch 2] Current Loss: 5.4933\n",
            "[Batch 3] Current Loss: 5.7745\n",
            "[Batch 4] Current Loss: 5.8427\n",
            "[Batch 5] Current Loss: 5.7660\n",
            "[Batch 6] Current Loss: 5.3375\n",
            "[Batch 7] Current Loss: 5.5266\n",
            "[Batch 8] Current Loss: 5.4186\n",
            "[Batch 9] Current Loss: 5.4593\n",
            "Ep 1 (Step 003320): Train loss 5.312, Val loss 5.566\n",
            "[Batch 0] Current Loss: 5.5611\n",
            "[Batch 1] Current Loss: 5.3202\n",
            "[Batch 2] Current Loss: 5.2797\n",
            "[Batch 3] Current Loss: 5.0879\n",
            "[Batch 4] Current Loss: 5.0878\n",
            "[Batch 5] Current Loss: 5.6121\n",
            "[Batch 6] Current Loss: 5.6425\n",
            "[Batch 7] Current Loss: 5.5973\n",
            "[Batch 8] Current Loss: 5.6327\n",
            "[Batch 9] Current Loss: 5.1072\n",
            "[Batch 0] Current Loss: 5.6592\n",
            "[Batch 1] Current Loss: 5.9496\n",
            "[Batch 2] Current Loss: 5.9718\n",
            "[Batch 3] Current Loss: 5.9085\n",
            "[Batch 4] Current Loss: 5.5772\n",
            "[Batch 5] Current Loss: 5.8076\n",
            "[Batch 6] Current Loss: 5.1126\n",
            "[Batch 7] Current Loss: 5.9370\n",
            "[Batch 8] Current Loss: 6.0396\n",
            "[Batch 9] Current Loss: 5.8120\n",
            "Ep 1 (Step 003340): Train loss 5.393, Val loss 5.778\n",
            "[Batch 0] Current Loss: 4.9376\n",
            "[Batch 1] Current Loss: 5.4230\n",
            "[Batch 2] Current Loss: 5.6901\n",
            "[Batch 3] Current Loss: 4.9686\n",
            "[Batch 4] Current Loss: 5.7255\n",
            "[Batch 5] Current Loss: 5.3920\n",
            "[Batch 6] Current Loss: 5.1089\n",
            "[Batch 7] Current Loss: 5.5997\n",
            "[Batch 8] Current Loss: 5.1711\n",
            "[Batch 9] Current Loss: 5.8022\n",
            "[Batch 0] Current Loss: 5.4207\n",
            "[Batch 1] Current Loss: 5.4427\n",
            "[Batch 2] Current Loss: 5.6346\n",
            "[Batch 3] Current Loss: 5.5782\n",
            "[Batch 4] Current Loss: 5.7600\n",
            "[Batch 5] Current Loss: 6.0564\n",
            "[Batch 6] Current Loss: 5.5813\n",
            "[Batch 7] Current Loss: 6.1775\n",
            "[Batch 8] Current Loss: 5.6396\n",
            "[Batch 9] Current Loss: 5.9472\n",
            "Ep 1 (Step 003360): Train loss 5.382, Val loss 5.724\n",
            "[Batch 0] Current Loss: 5.1711\n",
            "[Batch 1] Current Loss: 5.8584\n",
            "[Batch 2] Current Loss: 4.8749\n",
            "[Batch 3] Current Loss: 5.3689\n",
            "[Batch 4] Current Loss: 5.5973\n",
            "[Batch 5] Current Loss: 5.3442\n",
            "[Batch 6] Current Loss: 5.2303\n",
            "[Batch 7] Current Loss: 5.5463\n",
            "[Batch 8] Current Loss: 5.6272\n",
            "[Batch 9] Current Loss: 5.3863\n",
            "[Batch 0] Current Loss: 5.9346\n",
            "[Batch 1] Current Loss: 5.6623\n",
            "[Batch 2] Current Loss: 5.5262\n",
            "[Batch 3] Current Loss: 5.4920\n",
            "[Batch 4] Current Loss: 6.0367\n",
            "[Batch 5] Current Loss: 5.9446\n",
            "[Batch 6] Current Loss: 5.8540\n",
            "[Batch 7] Current Loss: 5.1898\n",
            "[Batch 8] Current Loss: 5.5732\n",
            "[Batch 9] Current Loss: 5.7896\n",
            "Ep 1 (Step 003380): Train loss 5.400, Val loss 5.700\n",
            "[Batch 0] Current Loss: 5.7707\n",
            "[Batch 1] Current Loss: 5.6111\n",
            "[Batch 2] Current Loss: 4.9867\n",
            "[Batch 3] Current Loss: 5.8483\n",
            "[Batch 4] Current Loss: 5.1264\n",
            "[Batch 5] Current Loss: 5.3292\n",
            "[Batch 6] Current Loss: 5.9694\n",
            "[Batch 7] Current Loss: 6.1283\n",
            "[Batch 8] Current Loss: 5.4993\n",
            "[Batch 9] Current Loss: 5.5047\n",
            "[Batch 0] Current Loss: 5.1988\n",
            "[Batch 1] Current Loss: 5.2734\n",
            "[Batch 2] Current Loss: 5.3093\n",
            "[Batch 3] Current Loss: 5.5752\n",
            "[Batch 4] Current Loss: 5.6617\n",
            "[Batch 5] Current Loss: 6.0599\n",
            "[Batch 6] Current Loss: 6.1027\n",
            "[Batch 7] Current Loss: 5.6336\n",
            "[Batch 8] Current Loss: 5.2732\n",
            "[Batch 9] Current Loss: 5.1393\n",
            "Ep 1 (Step 003400): Train loss 5.577, Val loss 5.523\n",
            "[Batch 0] Current Loss: 5.2439\n",
            "[Batch 1] Current Loss: 4.9792\n",
            "[Batch 2] Current Loss: 5.3176\n",
            "[Batch 3] Current Loss: 5.0897\n",
            "[Batch 4] Current Loss: 5.3659\n",
            "[Batch 5] Current Loss: 5.3890\n",
            "[Batch 6] Current Loss: 5.4689\n",
            "[Batch 7] Current Loss: 5.6806\n",
            "[Batch 8] Current Loss: 5.6330\n",
            "[Batch 9] Current Loss: 5.1776\n",
            "[Batch 0] Current Loss: 5.9832\n",
            "[Batch 1] Current Loss: 5.5617\n",
            "[Batch 2] Current Loss: 5.4706\n",
            "[Batch 3] Current Loss: 5.7984\n",
            "[Batch 4] Current Loss: 5.2983\n",
            "[Batch 5] Current Loss: 4.8901\n",
            "[Batch 6] Current Loss: 6.3006\n",
            "[Batch 7] Current Loss: 5.6359\n",
            "[Batch 8] Current Loss: 5.2751\n",
            "[Batch 9] Current Loss: 5.8281\n",
            "Ep 1 (Step 003420): Train loss 5.335, Val loss 5.604\n",
            "[Batch 0] Current Loss: 5.1825\n",
            "[Batch 1] Current Loss: 5.2909\n",
            "[Batch 2] Current Loss: 5.0928\n",
            "[Batch 3] Current Loss: 5.6491\n",
            "[Batch 4] Current Loss: 5.7930\n",
            "[Batch 5] Current Loss: 5.1305\n",
            "[Batch 6] Current Loss: 5.3255\n",
            "[Batch 7] Current Loss: 5.4435\n",
            "[Batch 8] Current Loss: 5.2166\n",
            "[Batch 9] Current Loss: 5.6473\n",
            "[Batch 0] Current Loss: 5.4296\n",
            "[Batch 1] Current Loss: 5.7304\n",
            "[Batch 2] Current Loss: 5.7580\n",
            "[Batch 3] Current Loss: 5.8242\n",
            "[Batch 4] Current Loss: 6.0325\n",
            "[Batch 5] Current Loss: 5.4321\n",
            "[Batch 6] Current Loss: 5.4390\n",
            "[Batch 7] Current Loss: 5.9170\n",
            "[Batch 8] Current Loss: 5.7502\n",
            "[Batch 9] Current Loss: 5.4034\n",
            "Ep 1 (Step 003440): Train loss 5.377, Val loss 5.672\n",
            "[Batch 0] Current Loss: 5.6828\n",
            "[Batch 1] Current Loss: 5.2728\n",
            "[Batch 2] Current Loss: 5.4135\n",
            "[Batch 3] Current Loss: 5.3906\n",
            "[Batch 4] Current Loss: 5.7063\n",
            "[Batch 5] Current Loss: 5.6726\n",
            "[Batch 6] Current Loss: 4.7341\n",
            "[Batch 7] Current Loss: 5.4329\n",
            "[Batch 8] Current Loss: 5.1209\n",
            "[Batch 9] Current Loss: 5.3983\n",
            "[Batch 0] Current Loss: 5.6793\n",
            "[Batch 1] Current Loss: 5.2567\n",
            "[Batch 2] Current Loss: 6.0819\n",
            "[Batch 3] Current Loss: 5.7011\n",
            "[Batch 4] Current Loss: 5.6875\n",
            "[Batch 5] Current Loss: 5.6037\n",
            "[Batch 6] Current Loss: 5.3126\n",
            "[Batch 7] Current Loss: 5.1741\n",
            "[Batch 8] Current Loss: 5.6124\n",
            "[Batch 9] Current Loss: 5.4628\n",
            "Ep 1 (Step 003460): Train loss 5.382, Val loss 5.557\n",
            "[Batch 0] Current Loss: 5.4680\n",
            "[Batch 1] Current Loss: 5.5470\n",
            "[Batch 2] Current Loss: 5.1106\n",
            "[Batch 3] Current Loss: 5.2837\n",
            "[Batch 4] Current Loss: 5.1267\n",
            "[Batch 5] Current Loss: 5.3595\n",
            "[Batch 6] Current Loss: 4.9014\n",
            "[Batch 7] Current Loss: 5.4318\n",
            "[Batch 8] Current Loss: 5.7361\n",
            "[Batch 9] Current Loss: 5.4542\n",
            "[Batch 0] Current Loss: 5.7049\n",
            "[Batch 1] Current Loss: 5.7198\n",
            "[Batch 2] Current Loss: 6.1619\n",
            "[Batch 3] Current Loss: 5.3831\n",
            "[Batch 4] Current Loss: 6.1985\n",
            "[Batch 5] Current Loss: 5.9464\n",
            "[Batch 6] Current Loss: 5.5885\n",
            "[Batch 7] Current Loss: 5.7511\n",
            "[Batch 8] Current Loss: 5.7978\n",
            "[Batch 9] Current Loss: 5.8996\n",
            "Ep 1 (Step 003480): Train loss 5.342, Val loss 5.815\n",
            "[Batch 0] Current Loss: 4.9946\n",
            "[Batch 1] Current Loss: 5.4781\n",
            "[Batch 2] Current Loss: 4.9541\n",
            "[Batch 3] Current Loss: 5.2292\n",
            "[Batch 4] Current Loss: 5.4178\n",
            "[Batch 5] Current Loss: 5.1421\n",
            "[Batch 6] Current Loss: 5.5021\n",
            "[Batch 7] Current Loss: 5.2285\n",
            "[Batch 8] Current Loss: 5.3386\n",
            "[Batch 9] Current Loss: 4.9243\n",
            "[Batch 0] Current Loss: 5.9231\n",
            "[Batch 1] Current Loss: 5.4013\n",
            "[Batch 2] Current Loss: 6.0978\n",
            "[Batch 3] Current Loss: 6.1140\n",
            "[Batch 4] Current Loss: 6.0828\n",
            "[Batch 5] Current Loss: 5.3037\n",
            "[Batch 6] Current Loss: 5.7234\n",
            "[Batch 7] Current Loss: 5.4096\n",
            "[Batch 8] Current Loss: 5.5163\n",
            "[Batch 9] Current Loss: 5.8820\n",
            "Ep 1 (Step 003500): Train loss 5.221, Val loss 5.745\n",
            "[Batch 0] Current Loss: 5.5756\n",
            "[Batch 1] Current Loss: 5.1242\n",
            "[Batch 2] Current Loss: 6.0829\n",
            "[Batch 3] Current Loss: 4.3760\n",
            "[Batch 4] Current Loss: 4.7431\n",
            "[Batch 5] Current Loss: 6.2595\n",
            "[Batch 6] Current Loss: 4.5657\n",
            "[Batch 7] Current Loss: 4.8175\n",
            "[Batch 8] Current Loss: 5.7278\n",
            "[Batch 9] Current Loss: 5.4980\n",
            "[Batch 0] Current Loss: 5.3218\n",
            "[Batch 1] Current Loss: 6.3036\n",
            "[Batch 2] Current Loss: 5.8876\n",
            "[Batch 3] Current Loss: 5.3337\n",
            "[Batch 4] Current Loss: 5.5709\n",
            "[Batch 5] Current Loss: 5.4559\n",
            "[Batch 6] Current Loss: 6.4578\n",
            "[Batch 7] Current Loss: 5.7295\n",
            "[Batch 8] Current Loss: 5.4504\n",
            "[Batch 9] Current Loss: 5.1935\n",
            "Ep 1 (Step 003520): Train loss 5.277, Val loss 5.670\n",
            "[Batch 0] Current Loss: 3.8314\n",
            "[Batch 1] Current Loss: 5.4768\n",
            "[Batch 2] Current Loss: 5.5310\n",
            "[Batch 3] Current Loss: 5.3648\n",
            "[Batch 4] Current Loss: 5.4048\n",
            "[Batch 5] Current Loss: 5.0291\n",
            "[Batch 6] Current Loss: 6.0661\n",
            "[Batch 7] Current Loss: 5.2161\n",
            "[Batch 8] Current Loss: 4.7392\n",
            "[Batch 9] Current Loss: 5.4580\n",
            "[Batch 0] Current Loss: 5.7681\n",
            "[Batch 1] Current Loss: 5.6797\n",
            "[Batch 2] Current Loss: 5.6679\n",
            "[Batch 3] Current Loss: 5.9006\n",
            "[Batch 4] Current Loss: 5.6021\n",
            "[Batch 5] Current Loss: 5.1113\n",
            "[Batch 6] Current Loss: 6.1576\n",
            "[Batch 7] Current Loss: 5.2338\n",
            "[Batch 8] Current Loss: 5.7694\n",
            "[Batch 9] Current Loss: 5.6734\n",
            "Ep 1 (Step 003540): Train loss 5.212, Val loss 5.656\n",
            "[Batch 0] Current Loss: 5.3475\n",
            "[Batch 1] Current Loss: 4.9365\n",
            "[Batch 2] Current Loss: 5.2508\n",
            "[Batch 3] Current Loss: 5.7158\n",
            "[Batch 4] Current Loss: 5.6815\n",
            "[Batch 5] Current Loss: 5.5422\n",
            "[Batch 6] Current Loss: 4.8954\n",
            "[Batch 7] Current Loss: 5.1184\n",
            "[Batch 8] Current Loss: 5.1973\n",
            "[Batch 9] Current Loss: 5.5460\n",
            "[Batch 0] Current Loss: 5.3232\n",
            "[Batch 1] Current Loss: 5.6610\n",
            "[Batch 2] Current Loss: 5.4266\n",
            "[Batch 3] Current Loss: 5.1207\n",
            "[Batch 4] Current Loss: 6.0441\n",
            "[Batch 5] Current Loss: 5.8377\n",
            "[Batch 6] Current Loss: 5.9261\n",
            "[Batch 7] Current Loss: 5.4031\n",
            "[Batch 8] Current Loss: 5.5474\n",
            "[Batch 9] Current Loss: 5.6825\n",
            "Ep 1 (Step 003560): Train loss 5.323, Val loss 5.597\n",
            "[Batch 0] Current Loss: 5.4177\n",
            "[Batch 1] Current Loss: 5.4943\n",
            "[Batch 2] Current Loss: 5.5317\n",
            "[Batch 3] Current Loss: 5.4825\n",
            "[Batch 4] Current Loss: 5.5324\n",
            "[Batch 5] Current Loss: 4.9029\n",
            "[Batch 6] Current Loss: 5.7588\n",
            "[Batch 7] Current Loss: 4.9359\n",
            "[Batch 8] Current Loss: 5.9804\n",
            "[Batch 9] Current Loss: 6.0184\n",
            "[Batch 0] Current Loss: 5.5911\n",
            "[Batch 1] Current Loss: 6.0430\n",
            "[Batch 2] Current Loss: 5.0616\n",
            "[Batch 3] Current Loss: 5.5959\n",
            "[Batch 4] Current Loss: 5.8653\n",
            "[Batch 5] Current Loss: 5.6620\n",
            "[Batch 6] Current Loss: 5.5014\n",
            "[Batch 7] Current Loss: 5.4901\n",
            "[Batch 8] Current Loss: 6.0469\n",
            "[Batch 9] Current Loss: 5.4104\n",
            "Ep 1 (Step 003580): Train loss 5.505, Val loss 5.627\n",
            "[Batch 0] Current Loss: 5.1507\n",
            "[Batch 1] Current Loss: 5.4269\n",
            "[Batch 2] Current Loss: 5.1368\n",
            "[Batch 3] Current Loss: 5.3367\n",
            "[Batch 4] Current Loss: 4.5875\n",
            "[Batch 5] Current Loss: 5.4743\n",
            "[Batch 6] Current Loss: 4.8673\n",
            "[Batch 7] Current Loss: 5.2619\n",
            "[Batch 8] Current Loss: 5.2514\n",
            "[Batch 9] Current Loss: 5.8820\n",
            "[Batch 0] Current Loss: 5.6419\n",
            "[Batch 1] Current Loss: 5.9448\n",
            "[Batch 2] Current Loss: 4.9417\n",
            "[Batch 3] Current Loss: 5.7519\n",
            "[Batch 4] Current Loss: 5.7400\n",
            "[Batch 5] Current Loss: 5.0387\n",
            "[Batch 6] Current Loss: 5.4327\n",
            "[Batch 7] Current Loss: 5.9506\n",
            "[Batch 8] Current Loss: 5.1512\n",
            "[Batch 9] Current Loss: 5.8254\n",
            "Ep 1 (Step 003600): Train loss 5.238, Val loss 5.542\n",
            "[Batch 0] Current Loss: 5.0843\n",
            "[Batch 1] Current Loss: 5.6276\n",
            "[Batch 2] Current Loss: 5.1780\n",
            "[Batch 3] Current Loss: 5.0802\n",
            "[Batch 4] Current Loss: 4.7177\n",
            "[Batch 5] Current Loss: 5.1247\n",
            "[Batch 6] Current Loss: 5.5411\n",
            "[Batch 7] Current Loss: 5.1009\n",
            "[Batch 8] Current Loss: 5.0414\n",
            "[Batch 9] Current Loss: 4.8552\n",
            "[Batch 0] Current Loss: 5.8205\n",
            "[Batch 1] Current Loss: 6.1927\n",
            "[Batch 2] Current Loss: 5.2695\n",
            "[Batch 3] Current Loss: 5.0268\n",
            "[Batch 4] Current Loss: 5.4296\n",
            "[Batch 5] Current Loss: 5.9560\n",
            "[Batch 6] Current Loss: 5.6668\n",
            "[Batch 7] Current Loss: 5.5835\n",
            "[Batch 8] Current Loss: 5.6045\n",
            "[Batch 9] Current Loss: 6.3792\n",
            "Ep 1 (Step 003620): Train loss 5.135, Val loss 5.693\n",
            "[Batch 0] Current Loss: 4.6528\n",
            "[Batch 1] Current Loss: 5.4718\n",
            "[Batch 2] Current Loss: 5.3439\n",
            "[Batch 3] Current Loss: 5.9651\n",
            "[Batch 4] Current Loss: 4.8300\n",
            "[Batch 5] Current Loss: 5.3835\n",
            "[Batch 6] Current Loss: 5.2017\n",
            "[Batch 7] Current Loss: 5.4123\n",
            "[Batch 8] Current Loss: 5.5923\n",
            "[Batch 9] Current Loss: 5.0020\n",
            "[Batch 0] Current Loss: 5.7474\n",
            "[Batch 1] Current Loss: 5.4516\n",
            "[Batch 2] Current Loss: 5.6704\n",
            "[Batch 3] Current Loss: 4.7513\n",
            "[Batch 4] Current Loss: 5.0900\n",
            "[Batch 5] Current Loss: 5.5081\n",
            "[Batch 6] Current Loss: 5.4728\n",
            "[Batch 7] Current Loss: 5.2561\n",
            "[Batch 8] Current Loss: 5.5537\n",
            "[Batch 9] Current Loss: 5.6839\n",
            "Ep 1 (Step 003640): Train loss 5.286, Val loss 5.419\n",
            "[Batch 0] Current Loss: 5.5957\n",
            "[Batch 1] Current Loss: 5.1317\n",
            "[Batch 2] Current Loss: 5.4361\n",
            "[Batch 3] Current Loss: 5.4423\n",
            "[Batch 4] Current Loss: 5.5305\n",
            "[Batch 5] Current Loss: 5.4938\n",
            "[Batch 6] Current Loss: 5.2098\n",
            "[Batch 7] Current Loss: 5.2617\n",
            "[Batch 8] Current Loss: 5.1225\n",
            "[Batch 9] Current Loss: 5.3309\n",
            "[Batch 0] Current Loss: 5.7773\n",
            "[Batch 1] Current Loss: 5.1463\n",
            "[Batch 2] Current Loss: 4.9764\n",
            "[Batch 3] Current Loss: 5.7136\n",
            "[Batch 4] Current Loss: 5.7329\n",
            "[Batch 5] Current Loss: 5.1596\n",
            "[Batch 6] Current Loss: 6.0354\n",
            "[Batch 7] Current Loss: 6.3310\n",
            "[Batch 8] Current Loss: 5.2008\n",
            "[Batch 9] Current Loss: 5.1147\n",
            "Ep 1 (Step 003660): Train loss 5.356, Val loss 5.519\n",
            "[Batch 0] Current Loss: 5.0695\n",
            "[Batch 1] Current Loss: 6.0569\n",
            "[Batch 2] Current Loss: 5.2850\n",
            "[Batch 3] Current Loss: 5.1356\n",
            "[Batch 4] Current Loss: 5.3458\n",
            "[Batch 5] Current Loss: 5.0041\n",
            "[Batch 6] Current Loss: 5.4792\n",
            "[Batch 7] Current Loss: 5.6819\n",
            "[Batch 8] Current Loss: 5.3900\n",
            "[Batch 9] Current Loss: 5.1681\n",
            "[Batch 0] Current Loss: 5.7127\n",
            "[Batch 1] Current Loss: 5.8768\n",
            "[Batch 2] Current Loss: 6.0797\n",
            "[Batch 3] Current Loss: 5.7072\n",
            "[Batch 4] Current Loss: 5.6245\n",
            "[Batch 5] Current Loss: 5.8023\n",
            "[Batch 6] Current Loss: 5.4682\n",
            "[Batch 7] Current Loss: 5.4538\n",
            "[Batch 8] Current Loss: 5.6390\n",
            "[Batch 9] Current Loss: 5.9251\n",
            "Ep 1 (Step 003680): Train loss 5.362, Val loss 5.729\n",
            "[Batch 0] Current Loss: 5.3521\n",
            "[Batch 1] Current Loss: 5.1290\n",
            "[Batch 2] Current Loss: 5.2691\n",
            "[Batch 3] Current Loss: 5.5075\n",
            "[Batch 4] Current Loss: 5.0889\n",
            "[Batch 5] Current Loss: 5.2043\n",
            "[Batch 6] Current Loss: 4.8978\n",
            "[Batch 7] Current Loss: 4.7263\n",
            "[Batch 8] Current Loss: 5.0657\n",
            "[Batch 9] Current Loss: 5.2093\n",
            "[Batch 0] Current Loss: 5.4603\n",
            "[Batch 1] Current Loss: 5.5931\n",
            "[Batch 2] Current Loss: 5.8314\n",
            "[Batch 3] Current Loss: 5.7720\n",
            "[Batch 4] Current Loss: 5.9093\n",
            "[Batch 5] Current Loss: 5.5766\n",
            "[Batch 6] Current Loss: 5.5468\n",
            "[Batch 7] Current Loss: 5.2226\n",
            "[Batch 8] Current Loss: 5.7401\n",
            "[Batch 9] Current Loss: 6.0847\n",
            "Ep 1 (Step 003700): Train loss 5.145, Val loss 5.674\n",
            "[Batch 0] Current Loss: 5.9085\n",
            "[Batch 1] Current Loss: 5.0784\n",
            "[Batch 2] Current Loss: 5.5870\n",
            "[Batch 3] Current Loss: 5.1356\n",
            "[Batch 4] Current Loss: 5.7003\n",
            "[Batch 5] Current Loss: 4.9937\n",
            "[Batch 6] Current Loss: 5.4608\n",
            "[Batch 7] Current Loss: 5.3391\n",
            "[Batch 8] Current Loss: 4.8205\n",
            "[Batch 9] Current Loss: 5.6798\n",
            "[Batch 0] Current Loss: 5.4731\n",
            "[Batch 1] Current Loss: 6.2807\n",
            "[Batch 2] Current Loss: 5.2374\n",
            "[Batch 3] Current Loss: 5.8826\n",
            "[Batch 4] Current Loss: 5.1665\n",
            "[Batch 5] Current Loss: 6.4306\n",
            "[Batch 6] Current Loss: 5.8582\n",
            "[Batch 7] Current Loss: 5.7932\n",
            "[Batch 8] Current Loss: 5.9258\n",
            "[Batch 9] Current Loss: 5.4926\n",
            "Ep 1 (Step 003720): Train loss 5.370, Val loss 5.754\n",
            "[Batch 0] Current Loss: 5.2952\n",
            "[Batch 1] Current Loss: 5.4762\n",
            "[Batch 2] Current Loss: 5.0415\n",
            "[Batch 3] Current Loss: 5.1165\n",
            "[Batch 4] Current Loss: 6.1552\n",
            "[Batch 5] Current Loss: 5.2513\n",
            "[Batch 6] Current Loss: 5.5014\n",
            "[Batch 7] Current Loss: 5.5027\n",
            "[Batch 8] Current Loss: 4.9055\n",
            "[Batch 9] Current Loss: 5.8137\n",
            "[Batch 0] Current Loss: 5.6218\n",
            "[Batch 1] Current Loss: 5.5992\n",
            "[Batch 2] Current Loss: 5.4012\n",
            "[Batch 3] Current Loss: 5.8620\n",
            "[Batch 4] Current Loss: 5.9389\n",
            "[Batch 5] Current Loss: 5.4485\n",
            "[Batch 6] Current Loss: 5.6475\n",
            "[Batch 7] Current Loss: 5.4539\n",
            "[Batch 8] Current Loss: 6.0480\n",
            "[Batch 9] Current Loss: 5.9286\n",
            "Ep 1 (Step 003740): Train loss 5.406, Val loss 5.695\n",
            "[Batch 0] Current Loss: 5.4922\n",
            "[Batch 1] Current Loss: 5.3532\n",
            "[Batch 2] Current Loss: 4.9189\n",
            "[Batch 3] Current Loss: 5.6387\n",
            "[Batch 4] Current Loss: 5.4095\n",
            "[Batch 5] Current Loss: 4.8113\n",
            "[Batch 6] Current Loss: 4.2155\n",
            "[Batch 7] Current Loss: 5.0247\n",
            "[Batch 8] Current Loss: 5.4905\n",
            "[Batch 9] Current Loss: 5.3064\n",
            "[Batch 0] Current Loss: 4.8388\n",
            "[Batch 1] Current Loss: 4.9849\n",
            "[Batch 2] Current Loss: 5.4185\n",
            "[Batch 3] Current Loss: 5.0410\n",
            "[Batch 4] Current Loss: 5.7653\n",
            "[Batch 5] Current Loss: 5.3561\n",
            "[Batch 6] Current Loss: 5.7048\n",
            "[Batch 7] Current Loss: 5.7391\n",
            "[Batch 8] Current Loss: 5.5576\n",
            "[Batch 9] Current Loss: 6.0428\n",
            "Ep 1 (Step 003760): Train loss 5.166, Val loss 5.445\n",
            "[Batch 0] Current Loss: 5.5084\n",
            "[Batch 1] Current Loss: 4.5551\n",
            "[Batch 2] Current Loss: 5.7454\n",
            "[Batch 3] Current Loss: 5.6173\n",
            "[Batch 4] Current Loss: 4.7356\n",
            "[Batch 5] Current Loss: 5.4887\n",
            "[Batch 6] Current Loss: 4.9909\n",
            "[Batch 7] Current Loss: 4.3801\n",
            "[Batch 8] Current Loss: 5.4067\n",
            "[Batch 9] Current Loss: 5.7334\n",
            "[Batch 0] Current Loss: 5.5842\n",
            "[Batch 1] Current Loss: 5.3993\n",
            "[Batch 2] Current Loss: 5.8041\n",
            "[Batch 3] Current Loss: 6.0809\n",
            "[Batch 4] Current Loss: 5.6081\n",
            "[Batch 5] Current Loss: 5.6693\n",
            "[Batch 6] Current Loss: 6.0574\n",
            "[Batch 7] Current Loss: 5.6966\n",
            "[Batch 8] Current Loss: 5.7185\n",
            "[Batch 9] Current Loss: 4.9117\n",
            "Ep 1 (Step 003780): Train loss 5.216, Val loss 5.653\n",
            "[Batch 0] Current Loss: 4.6941\n",
            "[Batch 1] Current Loss: 5.5007\n",
            "[Batch 2] Current Loss: 5.3843\n",
            "[Batch 3] Current Loss: 5.5483\n",
            "[Batch 4] Current Loss: 5.2983\n",
            "[Batch 5] Current Loss: 5.4485\n",
            "[Batch 6] Current Loss: 5.6202\n",
            "[Batch 7] Current Loss: 4.7376\n",
            "[Batch 8] Current Loss: 5.2172\n",
            "[Batch 9] Current Loss: 5.5686\n",
            "[Batch 0] Current Loss: 5.6878\n",
            "[Batch 1] Current Loss: 5.9358\n",
            "[Batch 2] Current Loss: 5.2396\n",
            "[Batch 3] Current Loss: 5.4967\n",
            "[Batch 4] Current Loss: 5.2336\n",
            "[Batch 5] Current Loss: 5.5951\n",
            "[Batch 6] Current Loss: 5.7582\n",
            "[Batch 7] Current Loss: 5.7925\n",
            "[Batch 8] Current Loss: 5.7277\n",
            "[Batch 9] Current Loss: 5.7258\n",
            "Ep 1 (Step 003800): Train loss 5.302, Val loss 5.619\n",
            "[Batch 0] Current Loss: 5.6018\n",
            "[Batch 1] Current Loss: 5.0731\n",
            "[Batch 2] Current Loss: 5.5234\n",
            "[Batch 3] Current Loss: 5.1451\n",
            "[Batch 4] Current Loss: 5.7180\n",
            "[Batch 5] Current Loss: 5.3959\n",
            "[Batch 6] Current Loss: 5.1225\n",
            "[Batch 7] Current Loss: 5.4981\n",
            "[Batch 8] Current Loss: 5.4432\n",
            "[Batch 9] Current Loss: 5.5154\n",
            "[Batch 0] Current Loss: 5.5703\n",
            "[Batch 1] Current Loss: 5.0750\n",
            "[Batch 2] Current Loss: 5.7475\n",
            "[Batch 3] Current Loss: 5.0219\n",
            "[Batch 4] Current Loss: 5.7373\n",
            "[Batch 5] Current Loss: 5.6789\n",
            "[Batch 6] Current Loss: 5.6876\n",
            "[Batch 7] Current Loss: 5.5861\n",
            "[Batch 8] Current Loss: 5.8739\n",
            "[Batch 9] Current Loss: 5.6138\n",
            "Ep 1 (Step 003820): Train loss 5.404, Val loss 5.559\n",
            "[Batch 0] Current Loss: 5.3532\n",
            "[Batch 1] Current Loss: 5.7990\n",
            "[Batch 2] Current Loss: 5.5350\n",
            "[Batch 3] Current Loss: 5.1144\n",
            "[Batch 4] Current Loss: 4.9466\n",
            "[Batch 5] Current Loss: 5.1947\n",
            "[Batch 6] Current Loss: 5.1007\n",
            "[Batch 7] Current Loss: 5.1426\n",
            "[Batch 8] Current Loss: 5.0672\n",
            "[Batch 9] Current Loss: 5.6837\n",
            "[Batch 0] Current Loss: 5.6850\n",
            "[Batch 1] Current Loss: 5.4019\n",
            "[Batch 2] Current Loss: 5.6661\n",
            "[Batch 3] Current Loss: 5.7981\n",
            "[Batch 4] Current Loss: 5.8816\n",
            "[Batch 5] Current Loss: 6.7234\n",
            "[Batch 6] Current Loss: 6.0519\n",
            "[Batch 7] Current Loss: 6.2428\n",
            "[Batch 8] Current Loss: 5.4963\n",
            "[Batch 9] Current Loss: 5.6015\n",
            "Ep 1 (Step 003840): Train loss 5.294, Val loss 5.855\n",
            "[Batch 0] Current Loss: 5.7887\n",
            "[Batch 1] Current Loss: 4.8929\n",
            "[Batch 2] Current Loss: 5.8066\n",
            "[Batch 3] Current Loss: 5.6726\n",
            "[Batch 4] Current Loss: 5.7387\n",
            "[Batch 5] Current Loss: 4.9679\n",
            "[Batch 6] Current Loss: 4.8095\n",
            "[Batch 7] Current Loss: 5.2195\n",
            "[Batch 8] Current Loss: 5.3283\n",
            "[Batch 9] Current Loss: 4.9373\n",
            "[Batch 0] Current Loss: 5.5033\n",
            "[Batch 1] Current Loss: 5.4362\n",
            "[Batch 2] Current Loss: 5.3284\n",
            "[Batch 3] Current Loss: 5.3756\n",
            "[Batch 4] Current Loss: 5.3333\n",
            "[Batch 5] Current Loss: 5.4129\n",
            "[Batch 6] Current Loss: 5.5270\n",
            "[Batch 7] Current Loss: 5.1635\n",
            "[Batch 8] Current Loss: 5.7952\n",
            "[Batch 9] Current Loss: 5.1817\n",
            "Ep 1 (Step 003860): Train loss 5.316, Val loss 5.406\n",
            "[Batch 0] Current Loss: 5.7109\n",
            "[Batch 1] Current Loss: 5.3676\n",
            "[Batch 2] Current Loss: 5.3059\n",
            "[Batch 3] Current Loss: 5.1765\n",
            "[Batch 4] Current Loss: 5.4551\n",
            "[Batch 5] Current Loss: 5.0504\n",
            "[Batch 6] Current Loss: 5.5097\n",
            "[Batch 7] Current Loss: 5.5570\n",
            "[Batch 8] Current Loss: 4.9009\n",
            "[Batch 9] Current Loss: 5.3570\n",
            "[Batch 0] Current Loss: 6.0171\n",
            "[Batch 1] Current Loss: 5.2459\n",
            "[Batch 2] Current Loss: 5.2729\n",
            "[Batch 3] Current Loss: 5.7343\n",
            "[Batch 4] Current Loss: 5.4137\n",
            "[Batch 5] Current Loss: 5.5374\n",
            "[Batch 6] Current Loss: 5.8010\n",
            "[Batch 7] Current Loss: 6.4839\n",
            "[Batch 8] Current Loss: 4.9965\n",
            "[Batch 9] Current Loss: 5.8522\n",
            "Ep 1 (Step 003880): Train loss 5.339, Val loss 5.635\n",
            "[Batch 0] Current Loss: 4.9790\n",
            "[Batch 1] Current Loss: 5.0227\n",
            "[Batch 2] Current Loss: 5.6522\n",
            "[Batch 3] Current Loss: 5.6326\n",
            "[Batch 4] Current Loss: 5.2251\n",
            "[Batch 5] Current Loss: 5.0834\n",
            "[Batch 6] Current Loss: 4.9857\n",
            "[Batch 7] Current Loss: 5.1353\n",
            "[Batch 8] Current Loss: 5.4131\n",
            "[Batch 9] Current Loss: 4.4699\n",
            "[Batch 0] Current Loss: 6.0434\n",
            "[Batch 1] Current Loss: 5.7792\n",
            "[Batch 2] Current Loss: 5.4705\n",
            "[Batch 3] Current Loss: 4.9859\n",
            "[Batch 4] Current Loss: 5.4126\n",
            "[Batch 5] Current Loss: 6.0443\n",
            "[Batch 6] Current Loss: 5.5828\n",
            "[Batch 7] Current Loss: 5.8551\n",
            "[Batch 8] Current Loss: 4.8481\n",
            "[Batch 9] Current Loss: 5.6895\n",
            "Ep 1 (Step 003900): Train loss 5.160, Val loss 5.571\n",
            "[Batch 0] Current Loss: 5.3300\n",
            "[Batch 1] Current Loss: 5.3698\n",
            "[Batch 2] Current Loss: 5.5316\n",
            "[Batch 3] Current Loss: 5.2591\n",
            "[Batch 4] Current Loss: 5.3646\n",
            "[Batch 5] Current Loss: 5.7666\n",
            "[Batch 6] Current Loss: 5.1190\n",
            "[Batch 7] Current Loss: 5.3644\n",
            "[Batch 8] Current Loss: 5.2717\n",
            "[Batch 9] Current Loss: 5.4098\n",
            "[Batch 0] Current Loss: 5.3976\n",
            "[Batch 1] Current Loss: 5.3521\n",
            "[Batch 2] Current Loss: 5.3525\n",
            "[Batch 3] Current Loss: 4.8301\n",
            "[Batch 4] Current Loss: 5.8344\n",
            "[Batch 5] Current Loss: 5.4915\n",
            "[Batch 6] Current Loss: 5.5992\n",
            "[Batch 7] Current Loss: 5.6961\n",
            "[Batch 8] Current Loss: 5.8708\n",
            "[Batch 9] Current Loss: 5.6101\n",
            "Ep 1 (Step 003920): Train loss 5.379, Val loss 5.503\n",
            "[Batch 0] Current Loss: 4.8329\n",
            "[Batch 1] Current Loss: 5.6289\n",
            "[Batch 2] Current Loss: 5.1283\n",
            "[Batch 3] Current Loss: 5.6387\n",
            "[Batch 4] Current Loss: 5.2744\n",
            "[Batch 5] Current Loss: 5.4114\n",
            "[Batch 6] Current Loss: 4.8791\n",
            "[Batch 7] Current Loss: 5.4385\n",
            "[Batch 8] Current Loss: 4.9162\n",
            "[Batch 9] Current Loss: 5.2070\n",
            "[Batch 0] Current Loss: 6.0131\n",
            "[Batch 1] Current Loss: 5.8095\n",
            "[Batch 2] Current Loss: 5.4004\n",
            "[Batch 3] Current Loss: 5.4559\n",
            "[Batch 4] Current Loss: 5.6956\n",
            "[Batch 5] Current Loss: 5.3842\n",
            "[Batch 6] Current Loss: 5.8499\n",
            "[Batch 7] Current Loss: 5.7599\n",
            "[Batch 8] Current Loss: 5.3679\n",
            "[Batch 9] Current Loss: 5.4681\n",
            "Ep 1 (Step 003940): Train loss 5.236, Val loss 5.620\n",
            "[Batch 0] Current Loss: 5.1474\n",
            "[Batch 1] Current Loss: 4.8973\n",
            "[Batch 2] Current Loss: 5.5186\n",
            "[Batch 3] Current Loss: 4.8135\n",
            "[Batch 4] Current Loss: 5.3700\n",
            "[Batch 5] Current Loss: 5.3872\n",
            "[Batch 6] Current Loss: 5.6017\n",
            "[Batch 7] Current Loss: 5.8960\n",
            "[Batch 8] Current Loss: 5.1477\n",
            "[Batch 9] Current Loss: 5.4340\n",
            "[Batch 0] Current Loss: 5.7963\n",
            "[Batch 1] Current Loss: 5.6621\n",
            "[Batch 2] Current Loss: 5.4157\n",
            "[Batch 3] Current Loss: 5.2638\n",
            "[Batch 4] Current Loss: 5.6488\n",
            "[Batch 5] Current Loss: 6.3573\n",
            "[Batch 6] Current Loss: 5.4548\n",
            "[Batch 7] Current Loss: 5.4143\n",
            "[Batch 8] Current Loss: 5.1264\n",
            "[Batch 9] Current Loss: 5.3816\n",
            "Ep 1 (Step 003960): Train loss 5.321, Val loss 5.552\n",
            "[Batch 0] Current Loss: 5.6318\n",
            "[Batch 1] Current Loss: 5.6096\n",
            "[Batch 2] Current Loss: 5.8922\n",
            "[Batch 3] Current Loss: 5.0770\n",
            "[Batch 4] Current Loss: 5.5497\n",
            "[Batch 5] Current Loss: 5.0148\n",
            "[Batch 6] Current Loss: 5.5613\n",
            "[Batch 7] Current Loss: 5.2858\n",
            "[Batch 8] Current Loss: 5.1692\n",
            "[Batch 9] Current Loss: 5.1269\n",
            "[Batch 0] Current Loss: 5.3673\n",
            "[Batch 1] Current Loss: 5.8132\n",
            "[Batch 2] Current Loss: 5.7783\n",
            "[Batch 3] Current Loss: 6.1359\n",
            "[Batch 4] Current Loss: 5.4020\n",
            "[Batch 5] Current Loss: 5.4808\n",
            "[Batch 6] Current Loss: 5.4401\n",
            "[Batch 7] Current Loss: 5.8872\n",
            "[Batch 8] Current Loss: 5.3760\n",
            "[Batch 9] Current Loss: 5.7027\n",
            "Ep 1 (Step 003980): Train loss 5.392, Val loss 5.638\n",
            "[Batch 0] Current Loss: 4.8587\n",
            "[Batch 1] Current Loss: 5.5453\n",
            "[Batch 2] Current Loss: 5.2326\n",
            "[Batch 3] Current Loss: 5.1739\n",
            "[Batch 4] Current Loss: 5.5530\n",
            "[Batch 5] Current Loss: 5.6121\n",
            "[Batch 6] Current Loss: 5.4862\n",
            "[Batch 7] Current Loss: 5.4760\n",
            "[Batch 8] Current Loss: 5.1888\n",
            "[Batch 9] Current Loss: 4.9721\n",
            "[Batch 0] Current Loss: 5.9008\n",
            "[Batch 1] Current Loss: 5.9310\n",
            "[Batch 2] Current Loss: 5.0939\n",
            "[Batch 3] Current Loss: 5.5897\n",
            "[Batch 4] Current Loss: 5.8792\n",
            "[Batch 5] Current Loss: 6.0373\n",
            "[Batch 6] Current Loss: 6.1499\n",
            "[Batch 7] Current Loss: 6.1164\n",
            "[Batch 8] Current Loss: 5.1088\n",
            "[Batch 9] Current Loss: 6.1843\n",
            "Ep 1 (Step 004000): Train loss 5.310, Val loss 5.799\n",
            "[Batch 0] Current Loss: 4.7075\n",
            "[Batch 1] Current Loss: 4.9325\n",
            "[Batch 2] Current Loss: 5.0072\n",
            "[Batch 3] Current Loss: 5.4607\n",
            "[Batch 4] Current Loss: 5.3074\n",
            "[Batch 5] Current Loss: 5.3492\n",
            "[Batch 6] Current Loss: 5.1705\n",
            "[Batch 7] Current Loss: 4.7300\n",
            "[Batch 8] Current Loss: 5.4449\n",
            "[Batch 9] Current Loss: 5.3721\n",
            "[Batch 0] Current Loss: 5.9513\n",
            "[Batch 1] Current Loss: 6.2703\n",
            "[Batch 2] Current Loss: 5.1650\n",
            "[Batch 3] Current Loss: 5.4192\n",
            "[Batch 4] Current Loss: 5.5161\n",
            "[Batch 5] Current Loss: 4.8747\n",
            "[Batch 6] Current Loss: 5.8746\n",
            "[Batch 7] Current Loss: 5.6511\n",
            "[Batch 8] Current Loss: 5.8340\n",
            "[Batch 9] Current Loss: 6.3825\n",
            "Ep 1 (Step 004020): Train loss 5.148, Val loss 5.694\n",
            "[Batch 0] Current Loss: 5.0272\n",
            "[Batch 1] Current Loss: 5.6529\n",
            "[Batch 2] Current Loss: 5.4571\n",
            "[Batch 3] Current Loss: 5.0916\n",
            "[Batch 4] Current Loss: 4.9035\n",
            "[Batch 5] Current Loss: 5.6627\n",
            "[Batch 6] Current Loss: 5.2429\n",
            "[Batch 7] Current Loss: 4.7221\n",
            "[Batch 8] Current Loss: 5.4948\n",
            "[Batch 9] Current Loss: 5.3274\n",
            "[Batch 0] Current Loss: 5.5648\n",
            "[Batch 1] Current Loss: 5.4450\n",
            "[Batch 2] Current Loss: 4.8707\n",
            "[Batch 3] Current Loss: 5.6780\n",
            "[Batch 4] Current Loss: 5.2488\n",
            "[Batch 5] Current Loss: 5.8422\n",
            "[Batch 6] Current Loss: 5.9801\n",
            "[Batch 7] Current Loss: 5.5121\n",
            "[Batch 8] Current Loss: 5.0567\n",
            "[Batch 9] Current Loss: 5.1777\n",
            "Ep 1 (Step 004040): Train loss 5.258, Val loss 5.438\n",
            "[Batch 0] Current Loss: 5.2412\n",
            "[Batch 1] Current Loss: 5.2471\n",
            "[Batch 2] Current Loss: 5.3217\n",
            "[Batch 3] Current Loss: 5.2354\n",
            "[Batch 4] Current Loss: 5.1034\n",
            "[Batch 5] Current Loss: 5.5221\n",
            "[Batch 6] Current Loss: 5.3557\n",
            "[Batch 7] Current Loss: 4.5448\n",
            "[Batch 8] Current Loss: 4.7929\n",
            "[Batch 9] Current Loss: 4.5361\n",
            "[Batch 0] Current Loss: 5.4216\n",
            "[Batch 1] Current Loss: 5.7434\n",
            "[Batch 2] Current Loss: 5.2393\n",
            "[Batch 3] Current Loss: 5.6438\n",
            "[Batch 4] Current Loss: 5.5903\n",
            "[Batch 5] Current Loss: 5.6023\n",
            "[Batch 6] Current Loss: 5.3934\n",
            "[Batch 7] Current Loss: 5.9039\n",
            "[Batch 8] Current Loss: 5.6686\n",
            "[Batch 9] Current Loss: 5.9619\n",
            "Ep 1 (Step 004060): Train loss 5.090, Val loss 5.617\n",
            "[Batch 0] Current Loss: 5.1926\n",
            "[Batch 1] Current Loss: 4.3662\n",
            "[Batch 2] Current Loss: 5.2744\n",
            "[Batch 3] Current Loss: 5.5530\n",
            "[Batch 4] Current Loss: 4.6136\n",
            "[Batch 5] Current Loss: 5.0522\n",
            "[Batch 6] Current Loss: 5.6633\n",
            "[Batch 7] Current Loss: 5.0619\n",
            "[Batch 8] Current Loss: 4.7868\n",
            "[Batch 9] Current Loss: 5.0475\n",
            "[Batch 0] Current Loss: 5.9303\n",
            "[Batch 1] Current Loss: 5.5441\n",
            "[Batch 2] Current Loss: 5.3806\n",
            "[Batch 3] Current Loss: 5.6097\n",
            "[Batch 4] Current Loss: 6.1380\n",
            "[Batch 5] Current Loss: 5.6328\n",
            "[Batch 6] Current Loss: 5.9175\n",
            "[Batch 7] Current Loss: 5.7231\n",
            "[Batch 8] Current Loss: 5.5041\n",
            "[Batch 9] Current Loss: 5.5226\n",
            "Ep 1 (Step 004080): Train loss 5.061, Val loss 5.690\n",
            "[Batch 0] Current Loss: 5.0302\n",
            "[Batch 1] Current Loss: 5.4263\n",
            "[Batch 2] Current Loss: 4.9811\n",
            "[Batch 3] Current Loss: 4.7321\n",
            "[Batch 4] Current Loss: 5.5222\n",
            "[Batch 5] Current Loss: 5.1258\n",
            "[Batch 6] Current Loss: 5.1870\n",
            "[Batch 7] Current Loss: 5.3560\n",
            "[Batch 8] Current Loss: 5.5643\n",
            "[Batch 9] Current Loss: 5.4770\n",
            "[Batch 0] Current Loss: 4.8884\n",
            "[Batch 1] Current Loss: 5.9374\n",
            "[Batch 2] Current Loss: 6.0599\n",
            "[Batch 3] Current Loss: 5.2773\n",
            "[Batch 4] Current Loss: 5.2774\n",
            "[Batch 5] Current Loss: 5.4176\n",
            "[Batch 6] Current Loss: 5.7213\n",
            "[Batch 7] Current Loss: 5.6502\n",
            "[Batch 8] Current Loss: 5.4237\n",
            "[Batch 9] Current Loss: 6.0896\n",
            "Ep 1 (Step 004100): Train loss 5.240, Val loss 5.574\n",
            "[Batch 0] Current Loss: 5.4443\n",
            "[Batch 1] Current Loss: 5.5683\n",
            "[Batch 2] Current Loss: 4.6074\n",
            "[Batch 3] Current Loss: 5.3837\n",
            "[Batch 4] Current Loss: 5.2689\n",
            "[Batch 5] Current Loss: 5.1396\n",
            "[Batch 6] Current Loss: 5.2018\n",
            "[Batch 7] Current Loss: 4.5939\n",
            "[Batch 8] Current Loss: 5.6745\n",
            "[Batch 9] Current Loss: 5.2474\n",
            "[Batch 0] Current Loss: 5.6266\n",
            "[Batch 1] Current Loss: 5.5665\n",
            "[Batch 2] Current Loss: 4.7224\n",
            "[Batch 3] Current Loss: 5.5365\n",
            "[Batch 4] Current Loss: 5.4106\n",
            "[Batch 5] Current Loss: 5.7364\n",
            "[Batch 6] Current Loss: 5.6864\n",
            "[Batch 7] Current Loss: 4.9834\n",
            "[Batch 8] Current Loss: 5.9456\n",
            "[Batch 9] Current Loss: 5.1908\n",
            "Ep 1 (Step 004120): Train loss 5.213, Val loss 5.441\n",
            "[Batch 0] Current Loss: 5.2689\n",
            "[Batch 1] Current Loss: 5.5911\n",
            "[Batch 2] Current Loss: 5.2234\n",
            "[Batch 3] Current Loss: 5.2472\n",
            "[Batch 4] Current Loss: 5.4707\n",
            "[Batch 5] Current Loss: 4.8147\n",
            "[Batch 6] Current Loss: 5.0040\n",
            "[Batch 7] Current Loss: 5.1439\n",
            "[Batch 8] Current Loss: 5.7099\n",
            "[Batch 9] Current Loss: 4.6845\n",
            "[Batch 0] Current Loss: 5.4247\n",
            "[Batch 1] Current Loss: 5.9655\n",
            "[Batch 2] Current Loss: 5.6501\n",
            "[Batch 3] Current Loss: 5.4379\n",
            "[Batch 4] Current Loss: 5.9654\n",
            "[Batch 5] Current Loss: 4.9576\n",
            "[Batch 6] Current Loss: 5.9502\n",
            "[Batch 7] Current Loss: 5.1854\n",
            "[Batch 8] Current Loss: 5.4581\n",
            "[Batch 9] Current Loss: 6.2859\n",
            "Ep 1 (Step 004140): Train loss 5.216, Val loss 5.628\n",
            "[Batch 0] Current Loss: 5.6504\n",
            "[Batch 1] Current Loss: 5.4303\n",
            "[Batch 2] Current Loss: 5.3559\n",
            "[Batch 3] Current Loss: 5.2643\n",
            "[Batch 4] Current Loss: 5.3989\n",
            "[Batch 5] Current Loss: 4.9797\n",
            "[Batch 6] Current Loss: 5.0767\n",
            "[Batch 7] Current Loss: 4.7404\n",
            "[Batch 8] Current Loss: 5.5487\n",
            "[Batch 9] Current Loss: 5.0159\n",
            "[Batch 0] Current Loss: 5.8871\n",
            "[Batch 1] Current Loss: 5.9007\n",
            "[Batch 2] Current Loss: 5.2525\n",
            "[Batch 3] Current Loss: 5.8984\n",
            "[Batch 4] Current Loss: 5.3693\n",
            "[Batch 5] Current Loss: 5.6120\n",
            "[Batch 6] Current Loss: 4.7426\n",
            "[Batch 7] Current Loss: 6.0160\n",
            "[Batch 8] Current Loss: 5.6848\n",
            "[Batch 9] Current Loss: 5.5325\n",
            "Ep 1 (Step 004160): Train loss 5.246, Val loss 5.590\n",
            "[Batch 0] Current Loss: 5.2222\n",
            "[Batch 1] Current Loss: 5.4648\n",
            "[Batch 2] Current Loss: 5.2770\n",
            "[Batch 3] Current Loss: 5.2570\n",
            "[Batch 4] Current Loss: 4.5579\n",
            "[Batch 5] Current Loss: 5.1674\n",
            "[Batch 6] Current Loss: 5.1771\n",
            "[Batch 7] Current Loss: 5.3419\n",
            "[Batch 8] Current Loss: 5.1789\n",
            "[Batch 9] Current Loss: 5.1390\n",
            "[Batch 0] Current Loss: 5.6087\n",
            "[Batch 1] Current Loss: 6.0912\n",
            "[Batch 2] Current Loss: 5.5137\n",
            "[Batch 3] Current Loss: 6.2901\n",
            "[Batch 4] Current Loss: 6.1529\n",
            "[Batch 5] Current Loss: 5.5753\n",
            "[Batch 6] Current Loss: 5.5053\n",
            "[Batch 7] Current Loss: 5.7844\n",
            "[Batch 8] Current Loss: 6.4169\n",
            "[Batch 9] Current Loss: 5.8836\n",
            "Ep 1 (Step 004180): Train loss 5.178, Val loss 5.882\n",
            "[Batch 0] Current Loss: 5.0176\n",
            "[Batch 1] Current Loss: 5.4533\n",
            "[Batch 2] Current Loss: 5.5560\n",
            "[Batch 3] Current Loss: 4.7727\n",
            "[Batch 4] Current Loss: 4.8301\n",
            "[Batch 5] Current Loss: 5.0476\n",
            "[Batch 6] Current Loss: 5.2004\n",
            "[Batch 7] Current Loss: 5.2042\n",
            "[Batch 8] Current Loss: 5.1837\n",
            "[Batch 9] Current Loss: 4.4056\n",
            "[Batch 0] Current Loss: 5.5071\n",
            "[Batch 1] Current Loss: 5.5362\n",
            "[Batch 2] Current Loss: 5.6846\n",
            "[Batch 3] Current Loss: 5.1959\n",
            "[Batch 4] Current Loss: 5.7049\n",
            "[Batch 5] Current Loss: 5.5379\n",
            "[Batch 6] Current Loss: 5.9551\n",
            "[Batch 7] Current Loss: 5.5368\n",
            "[Batch 8] Current Loss: 5.5563\n",
            "[Batch 9] Current Loss: 6.2461\n",
            "Ep 1 (Step 004200): Train loss 5.067, Val loss 5.646\n",
            "[Batch 0] Current Loss: 5.4020\n",
            "[Batch 1] Current Loss: 5.1883\n",
            "[Batch 2] Current Loss: 5.4589\n",
            "[Batch 3] Current Loss: 5.6145\n",
            "[Batch 4] Current Loss: 5.2750\n",
            "[Batch 5] Current Loss: 5.4576\n",
            "[Batch 6] Current Loss: 6.1797\n",
            "[Batch 7] Current Loss: 5.2509\n",
            "[Batch 8] Current Loss: 5.4248\n",
            "[Batch 9] Current Loss: 5.4997\n",
            "[Batch 0] Current Loss: 5.4133\n",
            "[Batch 1] Current Loss: 5.8355\n",
            "[Batch 2] Current Loss: 5.0452\n",
            "[Batch 3] Current Loss: 5.9040\n",
            "[Batch 4] Current Loss: 5.4777\n",
            "[Batch 5] Current Loss: 5.7281\n",
            "[Batch 6] Current Loss: 6.1532\n",
            "[Batch 7] Current Loss: 5.3575\n",
            "[Batch 8] Current Loss: 5.9353\n",
            "[Batch 9] Current Loss: 5.1346\n",
            "Ep 1 (Step 004220): Train loss 5.475, Val loss 5.598\n",
            "[Batch 0] Current Loss: 5.5748\n",
            "[Batch 1] Current Loss: 4.7942\n",
            "[Batch 2] Current Loss: 5.1878\n",
            "[Batch 3] Current Loss: 5.0100\n",
            "[Batch 4] Current Loss: 5.0884\n",
            "[Batch 5] Current Loss: 4.9183\n",
            "[Batch 6] Current Loss: 5.2481\n",
            "[Batch 7] Current Loss: 5.1059\n",
            "[Batch 8] Current Loss: 4.7463\n",
            "[Batch 9] Current Loss: 5.5949\n",
            "[Batch 0] Current Loss: 5.7171\n",
            "[Batch 1] Current Loss: 6.0326\n",
            "[Batch 2] Current Loss: 5.3631\n",
            "[Batch 3] Current Loss: 5.6365\n",
            "[Batch 4] Current Loss: 5.4075\n",
            "[Batch 5] Current Loss: 5.5160\n",
            "[Batch 6] Current Loss: 6.0498\n",
            "[Batch 7] Current Loss: 5.7301\n",
            "[Batch 8] Current Loss: 5.4896\n",
            "[Batch 9] Current Loss: 5.3404\n",
            "Ep 1 (Step 004240): Train loss 5.127, Val loss 5.628\n",
            "[Batch 0] Current Loss: 5.4627\n",
            "[Batch 1] Current Loss: 5.4605\n",
            "[Batch 2] Current Loss: 5.4848\n",
            "[Batch 3] Current Loss: 5.0441\n",
            "[Batch 4] Current Loss: 5.2265\n",
            "[Batch 5] Current Loss: 5.1248\n",
            "[Batch 6] Current Loss: 4.4145\n",
            "[Batch 7] Current Loss: 4.6001\n",
            "[Batch 8] Current Loss: 5.3603\n",
            "[Batch 9] Current Loss: 4.8484\n",
            "[Batch 0] Current Loss: 5.7007\n",
            "[Batch 1] Current Loss: 4.9171\n",
            "[Batch 2] Current Loss: 4.8146\n",
            "[Batch 3] Current Loss: 6.0113\n",
            "[Batch 4] Current Loss: 5.9099\n",
            "[Batch 5] Current Loss: 5.9006\n",
            "[Batch 6] Current Loss: 5.4571\n",
            "[Batch 7] Current Loss: 6.0472\n",
            "[Batch 8] Current Loss: 5.8121\n",
            "[Batch 9] Current Loss: 5.5035\n",
            "Ep 1 (Step 004260): Train loss 5.103, Val loss 5.607\n",
            "[Batch 0] Current Loss: 5.6792\n",
            "[Batch 1] Current Loss: 5.2528\n",
            "[Batch 2] Current Loss: 5.3640\n",
            "[Batch 3] Current Loss: 5.3024\n",
            "[Batch 4] Current Loss: 5.2727\n",
            "[Batch 5] Current Loss: 5.2407\n",
            "[Batch 6] Current Loss: 5.4990\n",
            "[Batch 7] Current Loss: 4.6108\n",
            "[Batch 8] Current Loss: 5.2734\n",
            "[Batch 9] Current Loss: 5.0948\n",
            "[Batch 0] Current Loss: 6.0143\n",
            "[Batch 1] Current Loss: 5.5405\n",
            "[Batch 2] Current Loss: 5.9791\n",
            "[Batch 3] Current Loss: 5.5516\n",
            "[Batch 4] Current Loss: 5.2465\n",
            "[Batch 5] Current Loss: 6.2407\n",
            "[Batch 6] Current Loss: 5.2161\n",
            "[Batch 7] Current Loss: 5.4582\n",
            "[Batch 8] Current Loss: 5.5949\n",
            "[Batch 9] Current Loss: 6.1119\n",
            "Ep 1 (Step 004280): Train loss 5.259, Val loss 5.695\n",
            "[Batch 0] Current Loss: 5.2321\n",
            "[Batch 1] Current Loss: 5.4494\n",
            "[Batch 2] Current Loss: 5.0953\n",
            "[Batch 3] Current Loss: 4.7247\n",
            "[Batch 4] Current Loss: 5.3214\n",
            "[Batch 5] Current Loss: 5.6447\n",
            "[Batch 6] Current Loss: 5.3785\n",
            "[Batch 7] Current Loss: 4.7988\n",
            "[Batch 8] Current Loss: 5.0887\n",
            "[Batch 9] Current Loss: 5.3254\n",
            "[Batch 0] Current Loss: 5.5441\n",
            "[Batch 1] Current Loss: 5.4010\n",
            "[Batch 2] Current Loss: 5.5254\n",
            "[Batch 3] Current Loss: 5.6273\n",
            "[Batch 4] Current Loss: 5.8838\n",
            "[Batch 5] Current Loss: 5.5266\n",
            "[Batch 6] Current Loss: 5.2924\n",
            "[Batch 7] Current Loss: 5.4606\n",
            "[Batch 8] Current Loss: 5.6607\n",
            "[Batch 9] Current Loss: 5.2233\n",
            "Ep 1 (Step 004300): Train loss 5.206, Val loss 5.515\n",
            "[Batch 0] Current Loss: 4.9775\n",
            "[Batch 1] Current Loss: 5.6428\n",
            "[Batch 2] Current Loss: 4.9935\n",
            "[Batch 3] Current Loss: 5.5601\n",
            "[Batch 4] Current Loss: 5.4618\n",
            "[Batch 5] Current Loss: 5.0383\n",
            "[Batch 6] Current Loss: 4.5409\n",
            "[Batch 7] Current Loss: 5.2497\n",
            "[Batch 8] Current Loss: 5.0269\n",
            "[Batch 9] Current Loss: 4.9298\n",
            "[Batch 0] Current Loss: 5.0078\n",
            "[Batch 1] Current Loss: 5.6873\n",
            "[Batch 2] Current Loss: 5.4502\n",
            "[Batch 3] Current Loss: 5.4319\n",
            "[Batch 4] Current Loss: 5.2264\n",
            "[Batch 5] Current Loss: 5.9842\n",
            "[Batch 6] Current Loss: 5.1425\n",
            "[Batch 7] Current Loss: 5.5803\n",
            "[Batch 8] Current Loss: 5.5479\n",
            "[Batch 9] Current Loss: 5.8500\n",
            "Ep 1 (Step 004320): Train loss 5.142, Val loss 5.491\n",
            "[Batch 0] Current Loss: 4.3744\n",
            "[Batch 1] Current Loss: 5.5842\n",
            "[Batch 2] Current Loss: 5.2319\n",
            "[Batch 3] Current Loss: 5.2532\n",
            "[Batch 4] Current Loss: 6.1457\n",
            "[Batch 5] Current Loss: 4.9822\n",
            "[Batch 6] Current Loss: 5.3668\n",
            "[Batch 7] Current Loss: 5.2578\n",
            "[Batch 8] Current Loss: 5.1692\n",
            "[Batch 9] Current Loss: 4.9298\n",
            "[Batch 0] Current Loss: 5.1904\n",
            "[Batch 1] Current Loss: 5.8679\n",
            "[Batch 2] Current Loss: 5.6767\n",
            "[Batch 3] Current Loss: 5.0794\n",
            "[Batch 4] Current Loss: 5.3974\n",
            "[Batch 5] Current Loss: 5.5317\n",
            "[Batch 6] Current Loss: 5.5188\n",
            "[Batch 7] Current Loss: 5.8740\n",
            "[Batch 8] Current Loss: 5.3170\n",
            "[Batch 9] Current Loss: 5.0994\n",
            "Ep 1 (Step 004340): Train loss 5.230, Val loss 5.455\n",
            "[Batch 0] Current Loss: 5.0265\n",
            "[Batch 1] Current Loss: 5.0990\n",
            "[Batch 2] Current Loss: 5.2806\n",
            "[Batch 3] Current Loss: 5.3609\n",
            "[Batch 4] Current Loss: 5.3387\n",
            "[Batch 5] Current Loss: 4.9486\n",
            "[Batch 6] Current Loss: 4.9833\n",
            "[Batch 7] Current Loss: 5.1236\n",
            "[Batch 8] Current Loss: 4.9813\n",
            "[Batch 9] Current Loss: 4.9200\n",
            "[Batch 0] Current Loss: 5.6577\n",
            "[Batch 1] Current Loss: 5.7808\n",
            "[Batch 2] Current Loss: 5.8916\n",
            "[Batch 3] Current Loss: 5.6022\n",
            "[Batch 4] Current Loss: 5.5163\n",
            "[Batch 5] Current Loss: 6.2293\n",
            "[Batch 6] Current Loss: 5.8349\n",
            "[Batch 7] Current Loss: 5.5050\n",
            "[Batch 8] Current Loss: 5.3546\n",
            "[Batch 9] Current Loss: 5.5238\n",
            "Ep 1 (Step 004360): Train loss 5.106, Val loss 5.690\n",
            "[Batch 0] Current Loss: 5.2772\n",
            "[Batch 1] Current Loss: 4.8190\n",
            "[Batch 2] Current Loss: 5.4251\n",
            "[Batch 3] Current Loss: 5.1966\n",
            "[Batch 4] Current Loss: 5.4171\n",
            "[Batch 5] Current Loss: 5.4634\n",
            "[Batch 6] Current Loss: 5.0468\n",
            "[Batch 7] Current Loss: 5.1738\n",
            "[Batch 8] Current Loss: 5.5167\n",
            "[Batch 9] Current Loss: 4.8170\n",
            "[Batch 0] Current Loss: 5.6717\n",
            "[Batch 1] Current Loss: 5.8823\n",
            "[Batch 2] Current Loss: 5.8227\n",
            "[Batch 3] Current Loss: 5.6322\n",
            "[Batch 4] Current Loss: 5.4920\n",
            "[Batch 5] Current Loss: 5.8085\n",
            "[Batch 6] Current Loss: 5.7958\n",
            "[Batch 7] Current Loss: 5.4099\n",
            "[Batch 8] Current Loss: 6.4624\n",
            "[Batch 9] Current Loss: 5.4458\n",
            "Ep 1 (Step 004380): Train loss 5.215, Val loss 5.742\n",
            "[Batch 0] Current Loss: 5.4565\n",
            "[Batch 1] Current Loss: 5.4152\n",
            "[Batch 2] Current Loss: 5.3785\n",
            "[Batch 3] Current Loss: 4.7684\n",
            "[Batch 4] Current Loss: 5.2984\n",
            "[Batch 5] Current Loss: 4.5813\n",
            "[Batch 6] Current Loss: 5.0129\n",
            "[Batch 7] Current Loss: 4.8769\n",
            "[Batch 8] Current Loss: 5.6976\n",
            "[Batch 9] Current Loss: 5.1358\n",
            "[Batch 0] Current Loss: 5.3423\n",
            "[Batch 1] Current Loss: 5.4333\n",
            "[Batch 2] Current Loss: 5.3547\n",
            "[Batch 3] Current Loss: 5.3896\n",
            "[Batch 4] Current Loss: 5.1493\n",
            "[Batch 5] Current Loss: 5.5043\n",
            "[Batch 6] Current Loss: 5.2666\n",
            "[Batch 7] Current Loss: 5.5707\n",
            "[Batch 8] Current Loss: 5.4473\n",
            "[Batch 9] Current Loss: 5.6015\n",
            "Ep 1 (Step 004400): Train loss 5.162, Val loss 5.406\n",
            "[Batch 0] Current Loss: 5.4521\n",
            "[Batch 1] Current Loss: 4.9093\n",
            "[Batch 2] Current Loss: 5.0185\n",
            "[Batch 3] Current Loss: 5.5904\n",
            "[Batch 4] Current Loss: 5.2571\n",
            "[Batch 5] Current Loss: 5.3399\n",
            "[Batch 6] Current Loss: 4.9041\n",
            "[Batch 7] Current Loss: 5.0614\n",
            "[Batch 8] Current Loss: 5.6022\n",
            "[Batch 9] Current Loss: 4.8781\n",
            "[Batch 0] Current Loss: 4.7126\n",
            "[Batch 1] Current Loss: 6.3839\n",
            "[Batch 2] Current Loss: 5.4431\n",
            "[Batch 3] Current Loss: 5.4834\n",
            "[Batch 4] Current Loss: 5.8650\n",
            "[Batch 5] Current Loss: 4.9941\n",
            "[Batch 6] Current Loss: 5.4950\n",
            "[Batch 7] Current Loss: 5.8409\n",
            "[Batch 8] Current Loss: 5.7885\n",
            "[Batch 9] Current Loss: 5.6499\n",
            "Ep 1 (Step 004420): Train loss 5.201, Val loss 5.566\n",
            "[Batch 0] Current Loss: 4.9733\n",
            "[Batch 1] Current Loss: 4.7130\n",
            "[Batch 2] Current Loss: 4.8487\n",
            "[Batch 3] Current Loss: 5.1356\n",
            "[Batch 4] Current Loss: 4.7165\n",
            "[Batch 5] Current Loss: 5.6064\n",
            "[Batch 6] Current Loss: 4.9531\n",
            "[Batch 7] Current Loss: 5.2693\n",
            "[Batch 8] Current Loss: 5.1582\n",
            "[Batch 9] Current Loss: 4.7046\n",
            "[Batch 0] Current Loss: 5.5266\n",
            "[Batch 1] Current Loss: 5.2242\n",
            "[Batch 2] Current Loss: 5.7587\n",
            "[Batch 3] Current Loss: 5.3318\n",
            "[Batch 4] Current Loss: 4.8554\n",
            "[Batch 5] Current Loss: 6.1434\n",
            "[Batch 6] Current Loss: 5.4377\n",
            "[Batch 7] Current Loss: 5.1065\n",
            "[Batch 8] Current Loss: 5.6188\n",
            "[Batch 9] Current Loss: 5.5739\n",
            "Ep 1 (Step 004440): Train loss 5.008, Val loss 5.458\n",
            "[Batch 0] Current Loss: 5.3852\n",
            "[Batch 1] Current Loss: 5.0736\n",
            "[Batch 2] Current Loss: 5.2006\n",
            "[Batch 3] Current Loss: 5.0187\n",
            "[Batch 4] Current Loss: 5.1840\n",
            "[Batch 5] Current Loss: 5.1707\n",
            "[Batch 6] Current Loss: 4.9680\n",
            "[Batch 7] Current Loss: 5.0991\n",
            "[Batch 8] Current Loss: 5.5285\n",
            "[Batch 9] Current Loss: 4.6686\n",
            "[Batch 0] Current Loss: 6.2743\n",
            "[Batch 1] Current Loss: 5.7197\n",
            "[Batch 2] Current Loss: 5.7457\n",
            "[Batch 3] Current Loss: 5.5522\n",
            "[Batch 4] Current Loss: 5.4183\n",
            "[Batch 5] Current Loss: 5.7270\n",
            "[Batch 6] Current Loss: 5.6329\n",
            "[Batch 7] Current Loss: 5.1870\n",
            "[Batch 8] Current Loss: 5.1869\n",
            "[Batch 9] Current Loss: 5.1014\n",
            "Ep 1 (Step 004460): Train loss 5.130, Val loss 5.555\n",
            "[Batch 0] Current Loss: 5.5526\n",
            "[Batch 1] Current Loss: 5.6161\n",
            "[Batch 2] Current Loss: 5.2496\n",
            "[Batch 3] Current Loss: 5.2646\n",
            "[Batch 4] Current Loss: 5.6265\n",
            "[Batch 5] Current Loss: 4.8910\n",
            "[Batch 6] Current Loss: 4.8912\n",
            "[Batch 7] Current Loss: 5.3443\n",
            "[Batch 8] Current Loss: 5.0041\n",
            "[Batch 9] Current Loss: 5.3362\n",
            "[Batch 0] Current Loss: 5.9171\n",
            "[Batch 1] Current Loss: 5.5549\n",
            "[Batch 2] Current Loss: 5.0523\n",
            "[Batch 3] Current Loss: 5.7925\n",
            "[Batch 4] Current Loss: 4.7093\n",
            "[Batch 5] Current Loss: 5.1049\n",
            "[Batch 6] Current Loss: 5.7464\n",
            "[Batch 7] Current Loss: 5.7896\n",
            "[Batch 8] Current Loss: 5.2667\n",
            "[Batch 9] Current Loss: 5.5794\n",
            "Ep 1 (Step 004480): Train loss 5.278, Val loss 5.451\n",
            "[Batch 0] Current Loss: 5.0211\n",
            "[Batch 1] Current Loss: 5.6308\n",
            "[Batch 2] Current Loss: 4.9240\n",
            "[Batch 3] Current Loss: 4.5515\n",
            "[Batch 4] Current Loss: 4.6420\n",
            "[Batch 5] Current Loss: 5.2443\n",
            "[Batch 6] Current Loss: 5.2299\n",
            "[Batch 7] Current Loss: 4.9927\n",
            "[Batch 8] Current Loss: 4.6539\n",
            "[Batch 9] Current Loss: 5.3720\n",
            "[Batch 0] Current Loss: 5.1068\n",
            "[Batch 1] Current Loss: 5.1316\n",
            "[Batch 2] Current Loss: 5.5426\n",
            "[Batch 3] Current Loss: 5.8229\n",
            "[Batch 4] Current Loss: 5.0005\n",
            "[Batch 5] Current Loss: 5.6113\n",
            "[Batch 6] Current Loss: 5.5411\n",
            "[Batch 7] Current Loss: 5.2695\n",
            "[Batch 8] Current Loss: 5.5036\n",
            "[Batch 9] Current Loss: 5.4567\n",
            "Ep 1 (Step 004500): Train loss 5.026, Val loss 5.399\n",
            "[Batch 0] Current Loss: 5.0732\n",
            "[Batch 1] Current Loss: 4.9817\n",
            "[Batch 2] Current Loss: 5.2369\n",
            "[Batch 3] Current Loss: 5.0847\n",
            "[Batch 4] Current Loss: 4.9543\n",
            "[Batch 5] Current Loss: 5.4383\n",
            "[Batch 6] Current Loss: 4.7604\n",
            "[Batch 7] Current Loss: 4.8969\n",
            "[Batch 8] Current Loss: 4.8034\n",
            "[Batch 9] Current Loss: 5.4373\n",
            "[Batch 0] Current Loss: 4.7620\n",
            "[Batch 1] Current Loss: 5.3916\n",
            "[Batch 2] Current Loss: 5.6120\n",
            "[Batch 3] Current Loss: 5.8880\n",
            "[Batch 4] Current Loss: 5.6372\n",
            "[Batch 5] Current Loss: 5.3671\n",
            "[Batch 6] Current Loss: 6.1513\n",
            "[Batch 7] Current Loss: 5.0785\n",
            "[Batch 8] Current Loss: 5.4680\n",
            "[Batch 9] Current Loss: 5.0600\n",
            "Ep 1 (Step 004520): Train loss 5.067, Val loss 5.442\n",
            "[Batch 0] Current Loss: 5.5216\n",
            "[Batch 1] Current Loss: 5.7168\n",
            "[Batch 2] Current Loss: 5.1602\n",
            "[Batch 3] Current Loss: 5.3300\n",
            "[Batch 4] Current Loss: 4.7312\n",
            "[Batch 5] Current Loss: 5.4629\n",
            "[Batch 6] Current Loss: 5.1475\n",
            "[Batch 7] Current Loss: 5.0446\n",
            "[Batch 8] Current Loss: 5.3158\n",
            "[Batch 9] Current Loss: 4.9798\n",
            "[Batch 0] Current Loss: 5.4807\n",
            "[Batch 1] Current Loss: 5.8496\n",
            "[Batch 2] Current Loss: 5.0803\n",
            "[Batch 3] Current Loss: 6.0189\n",
            "[Batch 4] Current Loss: 5.1783\n",
            "[Batch 5] Current Loss: 5.3510\n",
            "[Batch 6] Current Loss: 6.2317\n",
            "[Batch 7] Current Loss: 5.6579\n",
            "[Batch 8] Current Loss: 5.4170\n",
            "[Batch 9] Current Loss: 5.0415\n",
            "Ep 1 (Step 004540): Train loss 5.241, Val loss 5.531\n",
            "[Batch 0] Current Loss: 4.9835\n",
            "[Batch 1] Current Loss: 4.9650\n",
            "[Batch 2] Current Loss: 4.8796\n",
            "[Batch 3] Current Loss: 5.1681\n",
            "[Batch 4] Current Loss: 5.1549\n",
            "[Batch 5] Current Loss: 5.0673\n",
            "[Batch 6] Current Loss: 5.0377\n",
            "[Batch 7] Current Loss: 5.1618\n",
            "[Batch 8] Current Loss: 5.2408\n",
            "[Batch 9] Current Loss: 5.5127\n",
            "[Batch 0] Current Loss: 5.3742\n",
            "[Batch 1] Current Loss: 5.6813\n",
            "[Batch 2] Current Loss: 5.4089\n",
            "[Batch 3] Current Loss: 5.5072\n",
            "[Batch 4] Current Loss: 5.4894\n",
            "[Batch 5] Current Loss: 5.5812\n",
            "[Batch 6] Current Loss: 5.4929\n",
            "[Batch 7] Current Loss: 6.1030\n",
            "[Batch 8] Current Loss: 5.0790\n",
            "[Batch 9] Current Loss: 5.5438\n",
            "Ep 1 (Step 004560): Train loss 5.117, Val loss 5.526\n",
            "[Batch 0] Current Loss: 5.0674\n",
            "[Batch 1] Current Loss: 5.2632\n",
            "[Batch 2] Current Loss: 4.5121\n",
            "[Batch 3] Current Loss: 4.5316\n",
            "[Batch 4] Current Loss: 4.7909\n",
            "[Batch 5] Current Loss: 5.2673\n",
            "[Batch 6] Current Loss: 5.1203\n",
            "[Batch 7] Current Loss: 4.6857\n",
            "[Batch 8] Current Loss: 5.0409\n",
            "[Batch 9] Current Loss: 5.4338\n",
            "[Batch 0] Current Loss: 5.3153\n",
            "[Batch 1] Current Loss: 5.2673\n",
            "[Batch 2] Current Loss: 5.4602\n",
            "[Batch 3] Current Loss: 5.0823\n",
            "[Batch 4] Current Loss: 5.2551\n",
            "[Batch 5] Current Loss: 5.4910\n",
            "[Batch 6] Current Loss: 5.1661\n",
            "[Batch 7] Current Loss: 4.9456\n",
            "[Batch 8] Current Loss: 5.4563\n",
            "[Batch 9] Current Loss: 4.9007\n",
            "Ep 1 (Step 004580): Train loss 4.971, Val loss 5.234\n",
            "[Batch 0] Current Loss: 6.0355\n",
            "[Batch 1] Current Loss: 5.4319\n",
            "[Batch 2] Current Loss: 4.8885\n",
            "[Batch 3] Current Loss: 5.1848\n",
            "[Batch 4] Current Loss: 5.0785\n",
            "[Batch 5] Current Loss: 5.2472\n",
            "[Batch 6] Current Loss: 4.8084\n",
            "[Batch 7] Current Loss: 4.9477\n",
            "[Batch 8] Current Loss: 5.7261\n",
            "[Batch 9] Current Loss: 5.0192\n",
            "[Batch 0] Current Loss: 5.1273\n",
            "[Batch 1] Current Loss: 5.7936\n",
            "[Batch 2] Current Loss: 5.9755\n",
            "[Batch 3] Current Loss: 5.6792\n",
            "[Batch 4] Current Loss: 5.9021\n",
            "[Batch 5] Current Loss: 5.5237\n",
            "[Batch 6] Current Loss: 6.2599\n",
            "[Batch 7] Current Loss: 5.6309\n",
            "[Batch 8] Current Loss: 4.6933\n",
            "[Batch 9] Current Loss: 5.1995\n",
            "Ep 1 (Step 004600): Train loss 5.237, Val loss 5.578\n",
            "[Batch 0] Current Loss: 4.7808\n",
            "[Batch 1] Current Loss: 5.0774\n",
            "[Batch 2] Current Loss: 5.4436\n",
            "[Batch 3] Current Loss: 5.1574\n",
            "[Batch 4] Current Loss: 5.1174\n",
            "[Batch 5] Current Loss: 5.0806\n",
            "[Batch 6] Current Loss: 5.0249\n",
            "[Batch 7] Current Loss: 4.5212\n",
            "[Batch 8] Current Loss: 5.4738\n",
            "[Batch 9] Current Loss: 5.0175\n",
            "[Batch 0] Current Loss: 5.8468\n",
            "[Batch 1] Current Loss: 5.5910\n",
            "[Batch 2] Current Loss: 5.1762\n",
            "[Batch 3] Current Loss: 5.7763\n",
            "[Batch 4] Current Loss: 5.1971\n",
            "[Batch 5] Current Loss: 5.2334\n",
            "[Batch 6] Current Loss: 5.7364\n",
            "[Batch 7] Current Loss: 5.6451\n",
            "[Batch 8] Current Loss: 5.4064\n",
            "[Batch 9] Current Loss: 5.5693\n",
            "Ep 1 (Step 004620): Train loss 5.069, Val loss 5.518\n",
            "[Batch 0] Current Loss: 5.5064\n",
            "[Batch 1] Current Loss: 5.1787\n",
            "[Batch 2] Current Loss: 4.8889\n",
            "[Batch 3] Current Loss: 4.6491\n",
            "[Batch 4] Current Loss: 5.5609\n",
            "[Batch 5] Current Loss: 5.2549\n",
            "[Batch 6] Current Loss: 5.4227\n",
            "[Batch 7] Current Loss: 4.9738\n",
            "[Batch 8] Current Loss: 5.4579\n",
            "[Batch 9] Current Loss: 5.1486\n",
            "[Batch 0] Current Loss: 5.8817\n",
            "[Batch 1] Current Loss: 5.4091\n",
            "[Batch 2] Current Loss: 5.3561\n",
            "[Batch 3] Current Loss: 5.2969\n",
            "[Batch 4] Current Loss: 4.9761\n",
            "[Batch 5] Current Loss: 5.8374\n",
            "[Batch 6] Current Loss: 5.7094\n",
            "[Batch 7] Current Loss: 5.3219\n",
            "[Batch 8] Current Loss: 5.6260\n",
            "[Batch 9] Current Loss: 5.5974\n",
            "Ep 1 (Step 004640): Train loss 5.204, Val loss 5.501\n",
            "[Batch 0] Current Loss: 4.4342\n",
            "[Batch 1] Current Loss: 4.7106\n",
            "[Batch 2] Current Loss: 4.8162\n",
            "[Batch 3] Current Loss: 5.6052\n",
            "[Batch 4] Current Loss: 4.8135\n",
            "[Batch 5] Current Loss: 5.2415\n",
            "[Batch 6] Current Loss: 4.9377\n",
            "[Batch 7] Current Loss: 5.2784\n",
            "[Batch 8] Current Loss: 5.0388\n",
            "[Batch 9] Current Loss: 4.9204\n",
            "[Batch 0] Current Loss: 5.6560\n",
            "[Batch 1] Current Loss: 5.8631\n",
            "[Batch 2] Current Loss: 5.5510\n",
            "[Batch 3] Current Loss: 5.8385\n",
            "[Batch 4] Current Loss: 5.5446\n",
            "[Batch 5] Current Loss: 5.7733\n",
            "[Batch 6] Current Loss: 5.3098\n",
            "[Batch 7] Current Loss: 5.3236\n",
            "[Batch 8] Current Loss: 5.3911\n",
            "[Batch 9] Current Loss: 5.8155\n",
            "Ep 1 (Step 004660): Train loss 4.980, Val loss 5.607\n",
            "[Batch 0] Current Loss: 5.4541\n",
            "[Batch 1] Current Loss: 5.5437\n",
            "[Batch 2] Current Loss: 5.3753\n",
            "[Batch 3] Current Loss: 4.9203\n",
            "[Batch 4] Current Loss: 5.1964\n",
            "[Batch 5] Current Loss: 5.4212\n",
            "[Batch 6] Current Loss: 5.6855\n",
            "[Batch 7] Current Loss: 5.4180\n",
            "[Batch 8] Current Loss: 5.0711\n",
            "[Batch 9] Current Loss: 4.9384\n",
            "[Batch 0] Current Loss: 5.7705\n",
            "[Batch 1] Current Loss: 5.2077\n",
            "[Batch 2] Current Loss: 5.6649\n",
            "[Batch 3] Current Loss: 5.7000\n",
            "[Batch 4] Current Loss: 5.5658\n",
            "[Batch 5] Current Loss: 5.2774\n",
            "[Batch 6] Current Loss: 5.3689\n",
            "[Batch 7] Current Loss: 5.2480\n",
            "[Batch 8] Current Loss: 5.1725\n",
            "[Batch 9] Current Loss: 5.4780\n",
            "Ep 1 (Step 004680): Train loss 5.302, Val loss 5.445\n",
            "[Batch 0] Current Loss: 5.4063\n",
            "[Batch 1] Current Loss: 5.2788\n",
            "[Batch 2] Current Loss: 5.2618\n",
            "[Batch 3] Current Loss: 4.9070\n",
            "[Batch 4] Current Loss: 5.5184\n",
            "[Batch 5] Current Loss: 4.7629\n",
            "[Batch 6] Current Loss: 5.0204\n",
            "[Batch 7] Current Loss: 5.3667\n",
            "[Batch 8] Current Loss: 5.1312\n",
            "[Batch 9] Current Loss: 4.6817\n",
            "[Batch 0] Current Loss: 5.7371\n",
            "[Batch 1] Current Loss: 5.4900\n",
            "[Batch 2] Current Loss: 5.0867\n",
            "[Batch 3] Current Loss: 5.1921\n",
            "[Batch 4] Current Loss: 5.9565\n",
            "[Batch 5] Current Loss: 5.7654\n",
            "[Batch 6] Current Loss: 6.0115\n",
            "[Batch 7] Current Loss: 5.9965\n",
            "[Batch 8] Current Loss: 5.0083\n",
            "[Batch 9] Current Loss: 5.7382\n",
            "Ep 1 (Step 004700): Train loss 5.134, Val loss 5.598\n",
            "[Batch 0] Current Loss: 5.1541\n",
            "[Batch 1] Current Loss: 4.3380\n",
            "[Batch 2] Current Loss: 5.0211\n",
            "[Batch 3] Current Loss: 5.2552\n",
            "[Batch 4] Current Loss: 4.9614\n",
            "[Batch 5] Current Loss: 5.6921\n",
            "[Batch 6] Current Loss: 5.3883\n",
            "[Batch 7] Current Loss: 5.3037\n",
            "[Batch 8] Current Loss: 5.2158\n",
            "[Batch 9] Current Loss: 5.1722\n",
            "[Batch 0] Current Loss: 5.9993\n",
            "[Batch 1] Current Loss: 4.8869\n",
            "[Batch 2] Current Loss: 5.5627\n",
            "[Batch 3] Current Loss: 5.0514\n",
            "[Batch 4] Current Loss: 5.9853\n",
            "[Batch 5] Current Loss: 5.6423\n",
            "[Batch 6] Current Loss: 5.5116\n",
            "[Batch 7] Current Loss: 5.6578\n",
            "[Batch 8] Current Loss: 5.8439\n",
            "[Batch 9] Current Loss: 5.7472\n",
            "Ep 1 (Step 004720): Train loss 5.150, Val loss 5.589\n",
            "[Batch 0] Current Loss: 5.0499\n",
            "[Batch 1] Current Loss: 5.2540\n",
            "[Batch 2] Current Loss: 5.0935\n",
            "[Batch 3] Current Loss: 5.1470\n",
            "[Batch 4] Current Loss: 5.0425\n",
            "[Batch 5] Current Loss: 4.4639\n",
            "[Batch 6] Current Loss: 5.2407\n",
            "[Batch 7] Current Loss: 4.9737\n",
            "[Batch 8] Current Loss: 5.3148\n",
            "[Batch 9] Current Loss: 4.2752\n",
            "[Batch 0] Current Loss: 5.6960\n",
            "[Batch 1] Current Loss: 5.4720\n",
            "[Batch 2] Current Loss: 5.9591\n",
            "[Batch 3] Current Loss: 5.1649\n",
            "[Batch 4] Current Loss: 5.0628\n",
            "[Batch 5] Current Loss: 5.1018\n",
            "[Batch 6] Current Loss: 5.4304\n",
            "[Batch 7] Current Loss: 5.7099\n",
            "[Batch 8] Current Loss: 5.5572\n",
            "[Batch 9] Current Loss: 5.7022\n",
            "Ep 1 (Step 004740): Train loss 4.986, Val loss 5.486\n",
            "[Batch 0] Current Loss: 5.1937\n",
            "[Batch 1] Current Loss: 5.6495\n",
            "[Batch 2] Current Loss: 4.4312\n",
            "[Batch 3] Current Loss: 5.0099\n",
            "[Batch 4] Current Loss: 5.2393\n",
            "[Batch 5] Current Loss: 4.9781\n",
            "[Batch 6] Current Loss: 4.6990\n",
            "[Batch 7] Current Loss: 4.6054\n",
            "[Batch 8] Current Loss: 4.6837\n",
            "[Batch 9] Current Loss: 5.1447\n",
            "[Batch 0] Current Loss: 5.7803\n",
            "[Batch 1] Current Loss: 5.6798\n",
            "[Batch 2] Current Loss: 5.6881\n",
            "[Batch 3] Current Loss: 5.6392\n",
            "[Batch 4] Current Loss: 5.4332\n",
            "[Batch 5] Current Loss: 5.4260\n",
            "[Batch 6] Current Loss: 5.6862\n",
            "[Batch 7] Current Loss: 6.1774\n",
            "[Batch 8] Current Loss: 5.9379\n",
            "[Batch 9] Current Loss: 5.4358\n",
            "Ep 1 (Step 004760): Train loss 4.963, Val loss 5.688\n",
            "[Batch 0] Current Loss: 5.2240\n",
            "[Batch 1] Current Loss: 5.0411\n",
            "[Batch 2] Current Loss: 4.9276\n",
            "[Batch 3] Current Loss: 4.9999\n",
            "[Batch 4] Current Loss: 5.1005\n",
            "[Batch 5] Current Loss: 5.2811\n",
            "[Batch 6] Current Loss: 4.6440\n",
            "[Batch 7] Current Loss: 5.4985\n",
            "[Batch 8] Current Loss: 5.0395\n",
            "[Batch 9] Current Loss: 5.1393\n",
            "[Batch 0] Current Loss: 5.8562\n",
            "[Batch 1] Current Loss: 5.4830\n",
            "[Batch 2] Current Loss: 5.2088\n",
            "[Batch 3] Current Loss: 5.5903\n",
            "[Batch 4] Current Loss: 5.8556\n",
            "[Batch 5] Current Loss: 5.9114\n",
            "[Batch 6] Current Loss: 5.9757\n",
            "[Batch 7] Current Loss: 5.2821\n",
            "[Batch 8] Current Loss: 4.5551\n",
            "[Batch 9] Current Loss: 5.8065\n",
            "Ep 1 (Step 004780): Train loss 5.090, Val loss 5.552\n",
            "[Batch 0] Current Loss: 5.2898\n",
            "[Batch 1] Current Loss: 5.4611\n",
            "[Batch 2] Current Loss: 5.2183\n",
            "[Batch 3] Current Loss: 4.7408\n",
            "[Batch 4] Current Loss: 4.8152\n",
            "[Batch 5] Current Loss: 5.3946\n",
            "[Batch 6] Current Loss: 5.2124\n",
            "[Batch 7] Current Loss: 4.9054\n",
            "[Batch 8] Current Loss: 4.8484\n",
            "[Batch 9] Current Loss: 5.1186\n",
            "[Batch 0] Current Loss: 5.5567\n",
            "[Batch 1] Current Loss: 5.7448\n",
            "[Batch 2] Current Loss: 5.3670\n",
            "[Batch 3] Current Loss: 5.0798\n",
            "[Batch 4] Current Loss: 5.5338\n",
            "[Batch 5] Current Loss: 5.7284\n",
            "[Batch 6] Current Loss: 6.5795\n",
            "[Batch 7] Current Loss: 5.5295\n",
            "[Batch 8] Current Loss: 5.9529\n",
            "[Batch 9] Current Loss: 5.6468\n",
            "Ep 1 (Step 004800): Train loss 5.100, Val loss 5.672\n",
            "[Batch 0] Current Loss: 4.9564\n",
            "[Batch 1] Current Loss: 5.3728\n",
            "[Batch 2] Current Loss: 5.1001\n",
            "[Batch 3] Current Loss: 4.9975\n",
            "[Batch 4] Current Loss: 5.2598\n",
            "[Batch 5] Current Loss: 5.1691\n",
            "[Batch 6] Current Loss: 5.3693\n",
            "[Batch 7] Current Loss: 5.0524\n",
            "[Batch 8] Current Loss: 5.3987\n",
            "[Batch 9] Current Loss: 4.5118\n",
            "[Batch 0] Current Loss: 5.8838\n",
            "[Batch 1] Current Loss: 5.3647\n",
            "[Batch 2] Current Loss: 5.7995\n",
            "[Batch 3] Current Loss: 5.7890\n",
            "[Batch 4] Current Loss: 6.0303\n",
            "[Batch 5] Current Loss: 5.6243\n",
            "[Batch 6] Current Loss: 5.5404\n",
            "[Batch 7] Current Loss: 5.8629\n",
            "[Batch 8] Current Loss: 5.8231\n",
            "[Batch 9] Current Loss: 5.2319\n",
            "Ep 1 (Step 004820): Train loss 5.119, Val loss 5.695\n",
            "[Batch 0] Current Loss: 4.6141\n",
            "[Batch 1] Current Loss: 5.1317\n",
            "[Batch 2] Current Loss: 5.6273\n",
            "[Batch 3] Current Loss: 5.1068\n",
            "[Batch 4] Current Loss: 4.6291\n",
            "[Batch 5] Current Loss: 4.9973\n",
            "[Batch 6] Current Loss: 4.2174\n",
            "[Batch 7] Current Loss: 5.4228\n",
            "[Batch 8] Current Loss: 5.5713\n",
            "[Batch 9] Current Loss: 5.0832\n",
            "[Batch 0] Current Loss: 5.4286\n",
            "[Batch 1] Current Loss: 5.6109\n",
            "[Batch 2] Current Loss: 5.9247\n",
            "[Batch 3] Current Loss: 5.6098\n",
            "[Batch 4] Current Loss: 5.8060\n",
            "[Batch 5] Current Loss: 5.8127\n",
            "[Batch 6] Current Loss: 5.0442\n",
            "[Batch 7] Current Loss: 6.2242\n",
            "[Batch 8] Current Loss: 5.8061\n",
            "[Batch 9] Current Loss: 5.6152\n",
            "Ep 1 (Step 004840): Train loss 5.040, Val loss 5.688\n",
            "[Batch 0] Current Loss: 4.8385\n",
            "[Batch 1] Current Loss: 5.0936\n",
            "[Batch 2] Current Loss: 5.3433\n",
            "[Batch 3] Current Loss: 4.6067\n",
            "[Batch 4] Current Loss: 5.2188\n",
            "[Batch 5] Current Loss: 4.6353\n",
            "[Batch 6] Current Loss: 4.9273\n",
            "[Batch 7] Current Loss: 4.7445\n",
            "[Batch 8] Current Loss: 5.2530\n",
            "[Batch 9] Current Loss: 5.1646\n",
            "[Batch 0] Current Loss: 5.1467\n",
            "[Batch 1] Current Loss: 5.0131\n",
            "[Batch 2] Current Loss: 5.6627\n",
            "[Batch 3] Current Loss: 5.7476\n",
            "[Batch 4] Current Loss: 5.2133\n",
            "[Batch 5] Current Loss: 5.5959\n",
            "[Batch 6] Current Loss: 5.6805\n",
            "[Batch 7] Current Loss: 6.0427\n",
            "[Batch 8] Current Loss: 5.5449\n",
            "[Batch 9] Current Loss: 5.2425\n",
            "Ep 1 (Step 004860): Train loss 4.983, Val loss 5.489\n",
            "[Batch 0] Current Loss: 5.4245\n",
            "[Batch 1] Current Loss: 5.2107\n",
            "[Batch 2] Current Loss: 5.1391\n",
            "[Batch 3] Current Loss: 5.2650\n",
            "[Batch 4] Current Loss: 4.8189\n",
            "[Batch 5] Current Loss: 5.0049\n",
            "[Batch 6] Current Loss: 4.8963\n",
            "[Batch 7] Current Loss: 5.0756\n",
            "[Batch 8] Current Loss: 4.3531\n",
            "[Batch 9] Current Loss: 5.2134\n",
            "[Batch 0] Current Loss: 5.4342\n",
            "[Batch 1] Current Loss: 5.6605\n",
            "[Batch 2] Current Loss: 6.1064\n",
            "[Batch 3] Current Loss: 5.5437\n",
            "[Batch 4] Current Loss: 5.7447\n",
            "[Batch 5] Current Loss: 5.2840\n",
            "[Batch 6] Current Loss: 5.8915\n",
            "[Batch 7] Current Loss: 5.6155\n",
            "[Batch 8] Current Loss: 5.0532\n",
            "[Batch 9] Current Loss: 5.3986\n",
            "Ep 1 (Step 004880): Train loss 5.040, Val loss 5.573\n",
            "[Batch 0] Current Loss: 5.3297\n",
            "[Batch 1] Current Loss: 5.2852\n",
            "[Batch 2] Current Loss: 5.1944\n",
            "[Batch 3] Current Loss: 5.2954\n",
            "[Batch 4] Current Loss: 4.5705\n",
            "[Batch 5] Current Loss: 5.5398\n",
            "[Batch 6] Current Loss: 5.0893\n",
            "[Batch 7] Current Loss: 4.7195\n",
            "[Batch 8] Current Loss: 4.8157\n",
            "[Batch 9] Current Loss: 5.2465\n",
            "[Batch 0] Current Loss: 5.7284\n",
            "[Batch 1] Current Loss: 5.5872\n",
            "[Batch 2] Current Loss: 5.3205\n",
            "[Batch 3] Current Loss: 4.8533\n",
            "[Batch 4] Current Loss: 6.0200\n",
            "[Batch 5] Current Loss: 6.0074\n",
            "[Batch 6] Current Loss: 5.4195\n",
            "[Batch 7] Current Loss: 5.8399\n",
            "[Batch 8] Current Loss: 6.1172\n",
            "[Batch 9] Current Loss: 5.3316\n",
            "Ep 1 (Step 004900): Train loss 5.109, Val loss 5.623\n",
            "[Batch 0] Current Loss: 4.9910\n",
            "[Batch 1] Current Loss: 5.4765\n",
            "[Batch 2] Current Loss: 5.0453\n",
            "[Batch 3] Current Loss: 5.0422\n",
            "[Batch 4] Current Loss: 5.0724\n",
            "[Batch 5] Current Loss: 5.1613\n",
            "[Batch 6] Current Loss: 5.3335\n",
            "[Batch 7] Current Loss: 5.1720\n",
            "[Batch 8] Current Loss: 5.6159\n",
            "[Batch 9] Current Loss: 4.9817\n",
            "[Batch 0] Current Loss: 5.5550\n",
            "[Batch 1] Current Loss: 5.4367\n",
            "[Batch 2] Current Loss: 5.5317\n",
            "[Batch 3] Current Loss: 5.5525\n",
            "[Batch 4] Current Loss: 6.1852\n",
            "[Batch 5] Current Loss: 5.6428\n",
            "[Batch 6] Current Loss: 5.4587\n",
            "[Batch 7] Current Loss: 5.7102\n",
            "[Batch 8] Current Loss: 5.4606\n",
            "[Batch 9] Current Loss: 5.5331\n",
            "Ep 1 (Step 004920): Train loss 5.189, Val loss 5.607\n",
            "[Batch 0] Current Loss: 5.6553\n",
            "[Batch 1] Current Loss: 5.3215\n",
            "[Batch 2] Current Loss: 5.3076\n",
            "[Batch 3] Current Loss: 5.2402\n",
            "[Batch 4] Current Loss: 5.5125\n",
            "[Batch 5] Current Loss: 5.3730\n",
            "[Batch 6] Current Loss: 5.4730\n",
            "[Batch 7] Current Loss: 5.0347\n",
            "[Batch 8] Current Loss: 5.3810\n",
            "[Batch 9] Current Loss: 4.3217\n",
            "[Batch 0] Current Loss: 5.9322\n",
            "[Batch 1] Current Loss: 5.3635\n",
            "[Batch 2] Current Loss: 5.8242\n",
            "[Batch 3] Current Loss: 5.4541\n",
            "[Batch 4] Current Loss: 5.9058\n",
            "[Batch 5] Current Loss: 5.6966\n",
            "[Batch 6] Current Loss: 5.3677\n",
            "[Batch 7] Current Loss: 5.0009\n",
            "[Batch 8] Current Loss: 4.7671\n",
            "[Batch 9] Current Loss: 5.3989\n",
            "Ep 1 (Step 004940): Train loss 5.262, Val loss 5.471\n",
            "[Batch 0] Current Loss: 5.1583\n",
            "[Batch 1] Current Loss: 5.3352\n",
            "[Batch 2] Current Loss: 4.7732\n",
            "[Batch 3] Current Loss: 5.1474\n",
            "[Batch 4] Current Loss: 5.1718\n",
            "[Batch 5] Current Loss: 4.8389\n",
            "[Batch 6] Current Loss: 5.1519\n",
            "[Batch 7] Current Loss: 4.5294\n",
            "[Batch 8] Current Loss: 5.0131\n",
            "[Batch 9] Current Loss: 4.6384\n",
            "[Batch 0] Current Loss: 5.0398\n",
            "[Batch 1] Current Loss: 5.6436\n",
            "[Batch 2] Current Loss: 5.5718\n",
            "[Batch 3] Current Loss: 5.5060\n",
            "[Batch 4] Current Loss: 5.2727\n",
            "[Batch 5] Current Loss: 5.5618\n",
            "[Batch 6] Current Loss: 5.5396\n",
            "[Batch 7] Current Loss: 5.8090\n",
            "[Batch 8] Current Loss: 5.2669\n",
            "[Batch 9] Current Loss: 5.4199\n",
            "Ep 1 (Step 004960): Train loss 4.976, Val loss 5.463\n",
            "[Batch 0] Current Loss: 5.6071\n",
            "[Batch 1] Current Loss: 5.1095\n",
            "[Batch 2] Current Loss: 4.7794\n",
            "[Batch 3] Current Loss: 4.8323\n",
            "[Batch 4] Current Loss: 4.8834\n",
            "[Batch 5] Current Loss: 4.6256\n",
            "[Batch 6] Current Loss: 4.5608\n",
            "[Batch 7] Current Loss: 5.0576\n",
            "[Batch 8] Current Loss: 4.6810\n",
            "[Batch 9] Current Loss: 5.6808\n",
            "[Batch 0] Current Loss: 5.3549\n",
            "[Batch 1] Current Loss: 5.2812\n",
            "[Batch 2] Current Loss: 5.4307\n",
            "[Batch 3] Current Loss: 5.3637\n",
            "[Batch 4] Current Loss: 5.8661\n",
            "[Batch 5] Current Loss: 5.7385\n",
            "[Batch 6] Current Loss: 5.4473\n",
            "[Batch 7] Current Loss: 5.7013\n",
            "[Batch 8] Current Loss: 5.8273\n",
            "[Batch 9] Current Loss: 5.4308\n",
            "Ep 1 (Step 004980): Train loss 4.982, Val loss 5.544\n",
            "[Batch 0] Current Loss: 5.0673\n",
            "[Batch 1] Current Loss: 5.7246\n",
            "[Batch 2] Current Loss: 4.9367\n",
            "[Batch 3] Current Loss: 5.0701\n",
            "[Batch 4] Current Loss: 4.9316\n",
            "[Batch 5] Current Loss: 5.0956\n",
            "[Batch 6] Current Loss: 4.7155\n",
            "[Batch 7] Current Loss: 4.8819\n",
            "[Batch 8] Current Loss: 4.9510\n",
            "[Batch 9] Current Loss: 5.4014\n",
            "[Batch 0] Current Loss: 5.3281\n",
            "[Batch 1] Current Loss: 5.3016\n",
            "[Batch 2] Current Loss: 5.8532\n",
            "[Batch 3] Current Loss: 5.7041\n",
            "[Batch 4] Current Loss: 5.0664\n",
            "[Batch 5] Current Loss: 4.8982\n",
            "[Batch 6] Current Loss: 5.8889\n",
            "[Batch 7] Current Loss: 5.6229\n",
            "[Batch 8] Current Loss: 5.2607\n",
            "[Batch 9] Current Loss: 5.5361\n",
            "Ep 1 (Step 005000): Train loss 5.078, Val loss 5.446\n",
            "[Batch 0] Current Loss: 5.0255\n",
            "[Batch 1] Current Loss: 5.0516\n",
            "[Batch 2] Current Loss: 4.8576\n",
            "[Batch 3] Current Loss: 4.8685\n",
            "[Batch 4] Current Loss: 5.0147\n",
            "[Batch 5] Current Loss: 4.7650\n",
            "[Batch 6] Current Loss: 5.3637\n",
            "[Batch 7] Current Loss: 4.9391\n",
            "[Batch 8] Current Loss: 4.9788\n",
            "[Batch 9] Current Loss: 4.8341\n",
            "[Batch 0] Current Loss: 5.6604\n",
            "[Batch 1] Current Loss: 5.4693\n",
            "[Batch 2] Current Loss: 5.7942\n",
            "[Batch 3] Current Loss: 5.2320\n",
            "[Batch 4] Current Loss: 5.6323\n",
            "[Batch 5] Current Loss: 5.4743\n",
            "[Batch 6] Current Loss: 5.6685\n",
            "[Batch 7] Current Loss: 5.0190\n",
            "[Batch 8] Current Loss: 5.7812\n",
            "[Batch 9] Current Loss: 5.2397\n",
            "Ep 1 (Step 005020): Train loss 4.970, Val loss 5.497\n",
            "[Batch 0] Current Loss: 4.9075\n",
            "[Batch 1] Current Loss: 5.3823\n",
            "[Batch 2] Current Loss: 5.6944\n",
            "[Batch 3] Current Loss: 5.2547\n",
            "[Batch 4] Current Loss: 4.5310\n",
            "[Batch 5] Current Loss: 4.2117\n",
            "[Batch 6] Current Loss: 5.6829\n",
            "[Batch 7] Current Loss: 5.2404\n",
            "[Batch 8] Current Loss: 5.5102\n",
            "[Batch 9] Current Loss: 4.9700\n",
            "[Batch 0] Current Loss: 5.5380\n",
            "[Batch 1] Current Loss: 5.1720\n",
            "[Batch 2] Current Loss: 5.9570\n",
            "[Batch 3] Current Loss: 4.9997\n",
            "[Batch 4] Current Loss: 5.3954\n",
            "[Batch 5] Current Loss: 4.9778\n",
            "[Batch 6] Current Loss: 5.6347\n",
            "[Batch 7] Current Loss: 5.5205\n",
            "[Batch 8] Current Loss: 5.6900\n",
            "[Batch 9] Current Loss: 5.9306\n",
            "Ep 1 (Step 005040): Train loss 5.138, Val loss 5.482\n",
            "[Batch 0] Current Loss: 4.9003\n",
            "[Batch 1] Current Loss: 4.9765\n",
            "[Batch 2] Current Loss: 4.9893\n",
            "[Batch 3] Current Loss: 4.7506\n",
            "[Batch 4] Current Loss: 4.9366\n",
            "[Batch 5] Current Loss: 5.3612\n",
            "[Batch 6] Current Loss: 4.5925\n",
            "[Batch 7] Current Loss: 5.1971\n",
            "[Batch 8] Current Loss: 4.6689\n",
            "[Batch 9] Current Loss: 5.3126\n",
            "[Batch 0] Current Loss: 5.4099\n",
            "[Batch 1] Current Loss: 5.1977\n",
            "[Batch 2] Current Loss: 5.5629\n",
            "[Batch 3] Current Loss: 5.4378\n",
            "[Batch 4] Current Loss: 5.7779\n",
            "[Batch 5] Current Loss: 5.4643\n",
            "[Batch 6] Current Loss: 5.5282\n",
            "[Batch 7] Current Loss: 5.6150\n",
            "[Batch 8] Current Loss: 5.4071\n",
            "[Batch 9] Current Loss: 5.0147\n",
            "Ep 1 (Step 005060): Train loss 4.969, Val loss 5.442\n",
            "[Batch 0] Current Loss: 4.8967\n",
            "[Batch 1] Current Loss: 4.9188\n",
            "[Batch 2] Current Loss: 5.0130\n",
            "[Batch 3] Current Loss: 4.9762\n",
            "[Batch 4] Current Loss: 5.1360\n",
            "[Batch 5] Current Loss: 5.0789\n",
            "[Batch 6] Current Loss: 4.8134\n",
            "[Batch 7] Current Loss: 5.1454\n",
            "[Batch 8] Current Loss: 5.3114\n",
            "[Batch 9] Current Loss: 5.3247\n",
            "[Batch 0] Current Loss: 5.7638\n",
            "[Batch 1] Current Loss: 5.5414\n",
            "[Batch 2] Current Loss: 5.9793\n",
            "[Batch 3] Current Loss: 5.4009\n",
            "[Batch 4] Current Loss: 5.7923\n",
            "[Batch 5] Current Loss: 5.6356\n",
            "[Batch 6] Current Loss: 5.9639\n",
            "[Batch 7] Current Loss: 5.5033\n",
            "[Batch 8] Current Loss: 4.9892\n",
            "[Batch 9] Current Loss: 5.7719\n",
            "Ep 1 (Step 005080): Train loss 5.061, Val loss 5.634\n",
            "[Batch 0] Current Loss: 5.0611\n",
            "[Batch 1] Current Loss: 5.3738\n",
            "[Batch 2] Current Loss: 5.1569\n",
            "[Batch 3] Current Loss: 4.7871\n",
            "[Batch 4] Current Loss: 4.7460\n",
            "[Batch 5] Current Loss: 4.2957\n",
            "[Batch 6] Current Loss: 5.5621\n",
            "[Batch 7] Current Loss: 5.2534\n",
            "[Batch 8] Current Loss: 4.9648\n",
            "[Batch 9] Current Loss: 4.9682\n",
            "[Batch 0] Current Loss: 5.4080\n",
            "[Batch 1] Current Loss: 5.6605\n",
            "[Batch 2] Current Loss: 5.8054\n",
            "[Batch 3] Current Loss: 5.8205\n",
            "[Batch 4] Current Loss: 5.3017\n",
            "[Batch 5] Current Loss: 5.8037\n",
            "[Batch 6] Current Loss: 5.0706\n",
            "[Batch 7] Current Loss: 5.0730\n",
            "[Batch 8] Current Loss: 5.5774\n",
            "[Batch 9] Current Loss: 5.5269\n",
            "Ep 1 (Step 005100): Train loss 5.017, Val loss 5.505\n",
            "[Batch 0] Current Loss: 5.3076\n",
            "[Batch 1] Current Loss: 5.1185\n",
            "[Batch 2] Current Loss: 5.0012\n",
            "[Batch 3] Current Loss: 5.1074\n",
            "[Batch 4] Current Loss: 4.3831\n",
            "[Batch 5] Current Loss: 4.8655\n",
            "[Batch 6] Current Loss: 4.9418\n",
            "[Batch 7] Current Loss: 4.7816\n",
            "[Batch 8] Current Loss: 4.5897\n",
            "[Batch 9] Current Loss: 4.9693\n",
            "[Batch 0] Current Loss: 5.5961\n",
            "[Batch 1] Current Loss: 5.5556\n",
            "[Batch 2] Current Loss: 5.3668\n",
            "[Batch 3] Current Loss: 5.0490\n",
            "[Batch 4] Current Loss: 5.6205\n",
            "[Batch 5] Current Loss: 5.6389\n",
            "[Batch 6] Current Loss: 5.7757\n",
            "[Batch 7] Current Loss: 5.4891\n",
            "[Batch 8] Current Loss: 5.5357\n",
            "[Batch 9] Current Loss: 5.5605\n",
            "Ep 1 (Step 005120): Train loss 4.907, Val loss 5.519\n",
            "[Batch 0] Current Loss: 4.8498\n",
            "[Batch 1] Current Loss: 4.9888\n",
            "[Batch 2] Current Loss: 5.2925\n",
            "[Batch 3] Current Loss: 4.9079\n",
            "[Batch 4] Current Loss: 4.7217\n",
            "[Batch 5] Current Loss: 5.3610\n",
            "[Batch 6] Current Loss: 4.8909\n",
            "[Batch 7] Current Loss: 4.9348\n",
            "[Batch 8] Current Loss: 4.8316\n",
            "[Batch 9] Current Loss: 4.5802\n",
            "[Batch 0] Current Loss: 5.2478\n",
            "[Batch 1] Current Loss: 5.3680\n",
            "[Batch 2] Current Loss: 6.0731\n",
            "[Batch 3] Current Loss: 5.4489\n",
            "[Batch 4] Current Loss: 5.5066\n",
            "[Batch 5] Current Loss: 5.2617\n",
            "[Batch 6] Current Loss: 5.7528\n",
            "[Batch 7] Current Loss: 5.2529\n",
            "[Batch 8] Current Loss: 5.1461\n",
            "[Batch 9] Current Loss: 5.6098\n",
            "Ep 1 (Step 005140): Train loss 4.936, Val loss 5.467\n",
            "[Batch 0] Current Loss: 5.0517\n",
            "[Batch 1] Current Loss: 4.5980\n",
            "[Batch 2] Current Loss: 5.1789\n",
            "[Batch 3] Current Loss: 5.4839\n",
            "[Batch 4] Current Loss: 4.6239\n",
            "[Batch 5] Current Loss: 5.0385\n",
            "[Batch 6] Current Loss: 4.9069\n",
            "[Batch 7] Current Loss: 5.0754\n",
            "[Batch 8] Current Loss: 4.7758\n",
            "[Batch 9] Current Loss: 5.0800\n",
            "[Batch 0] Current Loss: 5.0522\n",
            "[Batch 1] Current Loss: 5.7062\n",
            "[Batch 2] Current Loss: 5.3352\n",
            "[Batch 3] Current Loss: 5.2032\n",
            "[Batch 4] Current Loss: 5.2793\n",
            "[Batch 5] Current Loss: 5.0734\n",
            "[Batch 6] Current Loss: 5.6895\n",
            "[Batch 7] Current Loss: 5.5107\n",
            "[Batch 8] Current Loss: 5.9239\n",
            "[Batch 9] Current Loss: 5.5962\n",
            "Ep 1 (Step 005160): Train loss 4.981, Val loss 5.437\n",
            "[Batch 0] Current Loss: 5.2415\n",
            "[Batch 1] Current Loss: 4.9774\n",
            "[Batch 2] Current Loss: 4.8150\n",
            "[Batch 3] Current Loss: 5.0238\n",
            "[Batch 4] Current Loss: 4.7434\n",
            "[Batch 5] Current Loss: 5.0470\n",
            "[Batch 6] Current Loss: 5.4106\n",
            "[Batch 7] Current Loss: 4.7190\n",
            "[Batch 8] Current Loss: 5.2567\n",
            "[Batch 9] Current Loss: 5.2739\n",
            "[Batch 0] Current Loss: 5.9537\n",
            "[Batch 1] Current Loss: 4.9835\n",
            "[Batch 2] Current Loss: 5.4153\n",
            "[Batch 3] Current Loss: 5.7280\n",
            "[Batch 4] Current Loss: 5.1797\n",
            "[Batch 5] Current Loss: 5.4272\n",
            "[Batch 6] Current Loss: 4.9663\n",
            "[Batch 7] Current Loss: 5.4633\n",
            "[Batch 8] Current Loss: 5.2277\n",
            "[Batch 9] Current Loss: 5.4991\n",
            "Ep 1 (Step 005180): Train loss 5.051, Val loss 5.384\n",
            "[Batch 0] Current Loss: 4.8416\n",
            "[Batch 1] Current Loss: 5.2044\n",
            "[Batch 2] Current Loss: 5.3642\n",
            "[Batch 3] Current Loss: 4.9599\n",
            "[Batch 4] Current Loss: 4.7493\n",
            "[Batch 5] Current Loss: 5.6910\n",
            "[Batch 6] Current Loss: 4.9453\n",
            "[Batch 7] Current Loss: 4.5962\n",
            "[Batch 8] Current Loss: 4.8979\n",
            "[Batch 9] Current Loss: 5.1140\n",
            "[Batch 0] Current Loss: 5.7200\n",
            "[Batch 1] Current Loss: 4.8681\n",
            "[Batch 2] Current Loss: 5.5340\n",
            "[Batch 3] Current Loss: 6.0809\n",
            "[Batch 4] Current Loss: 5.6166\n",
            "[Batch 5] Current Loss: 5.3259\n",
            "[Batch 6] Current Loss: 5.6460\n",
            "[Batch 7] Current Loss: 5.0816\n",
            "[Batch 8] Current Loss: 5.7013\n",
            "[Batch 9] Current Loss: 5.5340\n",
            "Ep 1 (Step 005200): Train loss 5.036, Val loss 5.511\n",
            "[Batch 0] Current Loss: 5.1833\n",
            "[Batch 1] Current Loss: 4.8887\n",
            "[Batch 2] Current Loss: 5.9047\n",
            "[Batch 3] Current Loss: 4.8841\n",
            "[Batch 4] Current Loss: 5.1272\n",
            "[Batch 5] Current Loss: 4.8424\n",
            "[Batch 6] Current Loss: 5.1089\n",
            "[Batch 7] Current Loss: 5.2077\n",
            "[Batch 8] Current Loss: 4.1298\n",
            "[Batch 9] Current Loss: 4.5409\n",
            "[Batch 0] Current Loss: 5.2011\n",
            "[Batch 1] Current Loss: 5.3460\n",
            "[Batch 2] Current Loss: 5.6050\n",
            "[Batch 3] Current Loss: 5.3906\n",
            "[Batch 4] Current Loss: 5.7253\n",
            "[Batch 5] Current Loss: 5.2031\n",
            "[Batch 6] Current Loss: 5.3927\n",
            "[Batch 7] Current Loss: 5.0780\n",
            "[Batch 8] Current Loss: 5.2200\n",
            "[Batch 9] Current Loss: 5.5133\n",
            "Ep 1 (Step 005220): Train loss 4.982, Val loss 5.367\n",
            "[Batch 0] Current Loss: 5.1995\n",
            "[Batch 1] Current Loss: 5.0144\n",
            "[Batch 2] Current Loss: 5.3547\n",
            "[Batch 3] Current Loss: 5.0956\n",
            "[Batch 4] Current Loss: 4.9813\n",
            "[Batch 5] Current Loss: 4.7023\n",
            "[Batch 6] Current Loss: 5.3798\n",
            "[Batch 7] Current Loss: 5.0567\n",
            "[Batch 8] Current Loss: 5.0387\n",
            "[Batch 9] Current Loss: 4.7292\n",
            "[Batch 0] Current Loss: 5.3984\n",
            "[Batch 1] Current Loss: 4.3543\n",
            "[Batch 2] Current Loss: 5.3987\n",
            "[Batch 3] Current Loss: 5.6916\n",
            "[Batch 4] Current Loss: 5.6042\n",
            "[Batch 5] Current Loss: 5.8764\n",
            "[Batch 6] Current Loss: 5.8110\n",
            "[Batch 7] Current Loss: 5.7284\n",
            "[Batch 8] Current Loss: 5.2129\n",
            "[Batch 9] Current Loss: 5.7270\n",
            "Ep 1 (Step 005240): Train loss 5.055, Val loss 5.480\n",
            "[Batch 0] Current Loss: 5.2656\n",
            "[Batch 1] Current Loss: 5.2359\n",
            "[Batch 2] Current Loss: 5.0087\n",
            "[Batch 3] Current Loss: 5.1416\n",
            "[Batch 4] Current Loss: 5.0464\n",
            "[Batch 5] Current Loss: 4.9520\n",
            "[Batch 6] Current Loss: 4.4132\n",
            "[Batch 7] Current Loss: 4.9406\n",
            "[Batch 8] Current Loss: 5.0913\n",
            "[Batch 9] Current Loss: 4.6535\n",
            "[Batch 0] Current Loss: 5.1787\n",
            "[Batch 1] Current Loss: 5.7786\n",
            "[Batch 2] Current Loss: 5.6672\n",
            "[Batch 3] Current Loss: 5.7101\n",
            "[Batch 4] Current Loss: 5.4903\n",
            "[Batch 5] Current Loss: 5.2497\n",
            "[Batch 6] Current Loss: 5.3173\n",
            "[Batch 7] Current Loss: 5.4171\n",
            "[Batch 8] Current Loss: 5.8971\n",
            "[Batch 9] Current Loss: 5.7515\n",
            "Ep 1 (Step 005260): Train loss 4.975, Val loss 5.546\n",
            "[Batch 0] Current Loss: 4.8635\n",
            "[Batch 1] Current Loss: 4.3634\n",
            "[Batch 2] Current Loss: 4.6908\n",
            "[Batch 3] Current Loss: 5.1500\n",
            "[Batch 4] Current Loss: 4.8604\n",
            "[Batch 5] Current Loss: 5.0356\n",
            "[Batch 6] Current Loss: 4.9033\n",
            "[Batch 7] Current Loss: 5.0231\n",
            "[Batch 8] Current Loss: 5.1477\n",
            "[Batch 9] Current Loss: 5.3142\n",
            "[Batch 0] Current Loss: 5.1286\n",
            "[Batch 1] Current Loss: 5.4372\n",
            "[Batch 2] Current Loss: 5.6626\n",
            "[Batch 3] Current Loss: 5.9190\n",
            "[Batch 4] Current Loss: 5.2240\n",
            "[Batch 5] Current Loss: 5.8460\n",
            "[Batch 6] Current Loss: 6.1557\n",
            "[Batch 7] Current Loss: 5.2657\n",
            "[Batch 8] Current Loss: 4.8904\n",
            "[Batch 9] Current Loss: 5.5134\n",
            "Ep 1 (Step 005280): Train loss 4.935, Val loss 5.504\n",
            "[Batch 0] Current Loss: 5.1241\n",
            "[Batch 1] Current Loss: 5.4302\n",
            "[Batch 2] Current Loss: 4.6949\n",
            "[Batch 3] Current Loss: 5.0163\n",
            "[Batch 4] Current Loss: 4.5250\n",
            "[Batch 5] Current Loss: 4.6847\n",
            "[Batch 6] Current Loss: 5.1711\n",
            "[Batch 7] Current Loss: 4.8645\n",
            "[Batch 8] Current Loss: 4.8554\n",
            "[Batch 9] Current Loss: 5.2073\n",
            "[Batch 0] Current Loss: 5.6553\n",
            "[Batch 1] Current Loss: 5.4878\n",
            "[Batch 2] Current Loss: 5.3024\n",
            "[Batch 3] Current Loss: 5.6521\n",
            "[Batch 4] Current Loss: 5.4787\n",
            "[Batch 5] Current Loss: 5.2877\n",
            "[Batch 6] Current Loss: 5.3004\n",
            "[Batch 7] Current Loss: 5.6714\n",
            "[Batch 8] Current Loss: 5.4722\n",
            "[Batch 9] Current Loss: 5.2169\n",
            "Ep 1 (Step 005300): Train loss 4.957, Val loss 5.452\n",
            "[Batch 0] Current Loss: 5.1753\n",
            "[Batch 1] Current Loss: 4.8917\n",
            "[Batch 2] Current Loss: 4.9309\n",
            "[Batch 3] Current Loss: 5.3716\n",
            "[Batch 4] Current Loss: 4.6891\n",
            "[Batch 5] Current Loss: 4.8832\n",
            "[Batch 6] Current Loss: 5.1464\n",
            "[Batch 7] Current Loss: 4.7610\n",
            "[Batch 8] Current Loss: 4.6755\n",
            "[Batch 9] Current Loss: 5.2941\n",
            "[Batch 0] Current Loss: 5.7717\n",
            "[Batch 1] Current Loss: 5.7117\n",
            "[Batch 2] Current Loss: 5.4413\n",
            "[Batch 3] Current Loss: 5.2274\n",
            "[Batch 4] Current Loss: 5.3443\n",
            "[Batch 5] Current Loss: 5.1175\n",
            "[Batch 6] Current Loss: 5.6300\n",
            "[Batch 7] Current Loss: 5.2306\n",
            "[Batch 8] Current Loss: 5.7003\n",
            "[Batch 9] Current Loss: 4.9071\n",
            "Ep 1 (Step 005320): Train loss 4.982, Val loss 5.408\n",
            "[Batch 0] Current Loss: 5.2179\n",
            "[Batch 1] Current Loss: 5.2499\n",
            "[Batch 2] Current Loss: 4.6502\n",
            "[Batch 3] Current Loss: 4.9122\n",
            "[Batch 4] Current Loss: 4.9257\n",
            "[Batch 5] Current Loss: 4.8411\n",
            "[Batch 6] Current Loss: 4.5387\n",
            "[Batch 7] Current Loss: 4.4858\n",
            "[Batch 8] Current Loss: 4.7004\n",
            "[Batch 9] Current Loss: 4.6626\n",
            "[Batch 0] Current Loss: 5.7430\n",
            "[Batch 1] Current Loss: 5.4038\n",
            "[Batch 2] Current Loss: 4.6682\n",
            "[Batch 3] Current Loss: 5.1999\n",
            "[Batch 4] Current Loss: 5.6431\n",
            "[Batch 5] Current Loss: 5.1196\n",
            "[Batch 6] Current Loss: 5.6513\n",
            "[Batch 7] Current Loss: 5.2036\n",
            "[Batch 8] Current Loss: 5.1820\n",
            "[Batch 9] Current Loss: 5.5743\n",
            "Ep 1 (Step 005340): Train loss 4.818, Val loss 5.339\n",
            "[Batch 0] Current Loss: 4.6370\n",
            "[Batch 1] Current Loss: 5.1601\n",
            "[Batch 2] Current Loss: 4.8279\n",
            "[Batch 3] Current Loss: 5.4508\n",
            "[Batch 4] Current Loss: 5.1831\n",
            "[Batch 5] Current Loss: 4.9103\n",
            "[Batch 6] Current Loss: 5.2378\n",
            "[Batch 7] Current Loss: 5.1864\n",
            "[Batch 8] Current Loss: 5.3968\n",
            "[Batch 9] Current Loss: 5.0655\n",
            "[Batch 0] Current Loss: 5.6831\n",
            "[Batch 1] Current Loss: 5.8701\n",
            "[Batch 2] Current Loss: 4.9748\n",
            "[Batch 3] Current Loss: 5.3435\n",
            "[Batch 4] Current Loss: 4.8450\n",
            "[Batch 5] Current Loss: 5.9992\n",
            "[Batch 6] Current Loss: 5.3926\n",
            "[Batch 7] Current Loss: 5.0672\n",
            "[Batch 8] Current Loss: 5.2378\n",
            "[Batch 9] Current Loss: 5.4322\n",
            "Ep 1 (Step 005360): Train loss 5.106, Val loss 5.385\n",
            "[Batch 0] Current Loss: 4.9348\n",
            "[Batch 1] Current Loss: 4.9679\n",
            "[Batch 2] Current Loss: 5.7234\n",
            "[Batch 3] Current Loss: 4.6706\n",
            "[Batch 4] Current Loss: 5.1384\n",
            "[Batch 5] Current Loss: 4.8098\n",
            "[Batch 6] Current Loss: 4.9536\n",
            "[Batch 7] Current Loss: 4.7397\n",
            "[Batch 8] Current Loss: 5.3710\n",
            "[Batch 9] Current Loss: 5.1469\n",
            "[Batch 0] Current Loss: 4.7724\n",
            "[Batch 1] Current Loss: 5.4443\n",
            "[Batch 2] Current Loss: 5.4625\n",
            "[Batch 3] Current Loss: 4.9707\n",
            "[Batch 4] Current Loss: 5.5753\n",
            "[Batch 5] Current Loss: 5.4468\n",
            "[Batch 6] Current Loss: 5.4859\n",
            "[Batch 7] Current Loss: 5.1675\n",
            "[Batch 8] Current Loss: 5.7467\n",
            "[Batch 9] Current Loss: 5.2857\n",
            "Ep 1 (Step 005380): Train loss 5.046, Val loss 5.336\n",
            "[Batch 0] Current Loss: 4.4569\n",
            "[Batch 1] Current Loss: 5.0291\n",
            "[Batch 2] Current Loss: 5.4752\n",
            "[Batch 3] Current Loss: 5.0427\n",
            "[Batch 4] Current Loss: 4.5431\n",
            "[Batch 5] Current Loss: 5.4895\n",
            "[Batch 6] Current Loss: 4.1818\n",
            "[Batch 7] Current Loss: 5.1214\n",
            "[Batch 8] Current Loss: 5.0037\n",
            "[Batch 9] Current Loss: 5.3991\n",
            "[Batch 0] Current Loss: 5.2724\n",
            "[Batch 1] Current Loss: 5.3732\n",
            "[Batch 2] Current Loss: 5.6813\n",
            "[Batch 3] Current Loss: 5.7281\n",
            "[Batch 4] Current Loss: 4.6104\n",
            "[Batch 5] Current Loss: 5.5635\n",
            "[Batch 6] Current Loss: 5.6739\n",
            "[Batch 7] Current Loss: 5.3015\n",
            "[Batch 8] Current Loss: 5.7905\n",
            "[Batch 9] Current Loss: 5.4985\n",
            "Ep 1 (Step 005400): Train loss 4.974, Val loss 5.449\n",
            "[Batch 0] Current Loss: 4.9564\n",
            "[Batch 1] Current Loss: 4.9313\n",
            "[Batch 2] Current Loss: 4.8805\n",
            "[Batch 3] Current Loss: 4.6636\n",
            "[Batch 4] Current Loss: 4.4833\n",
            "[Batch 5] Current Loss: 5.1449\n",
            "[Batch 6] Current Loss: 4.9980\n",
            "[Batch 7] Current Loss: 5.3453\n",
            "[Batch 8] Current Loss: 4.7356\n",
            "[Batch 9] Current Loss: 5.2028\n",
            "[Batch 0] Current Loss: 5.3963\n",
            "[Batch 1] Current Loss: 5.9582\n",
            "[Batch 2] Current Loss: 5.8624\n",
            "[Batch 3] Current Loss: 5.5755\n",
            "[Batch 4] Current Loss: 5.5924\n",
            "[Batch 5] Current Loss: 6.1549\n",
            "[Batch 6] Current Loss: 5.0017\n",
            "[Batch 7] Current Loss: 5.1097\n",
            "[Batch 8] Current Loss: 5.1443\n",
            "[Batch 9] Current Loss: 4.8840\n",
            "Ep 1 (Step 005420): Train loss 4.934, Val loss 5.468\n",
            "[Batch 0] Current Loss: 4.6619\n",
            "[Batch 1] Current Loss: 4.7840\n",
            "[Batch 2] Current Loss: 4.9909\n",
            "[Batch 3] Current Loss: 4.9162\n",
            "[Batch 4] Current Loss: 4.8338\n",
            "[Batch 5] Current Loss: 5.0567\n",
            "[Batch 6] Current Loss: 4.6954\n",
            "[Batch 7] Current Loss: 5.3342\n",
            "[Batch 8] Current Loss: 4.7585\n",
            "[Batch 9] Current Loss: 4.2211\n",
            "[Batch 0] Current Loss: 5.6959\n",
            "[Batch 1] Current Loss: 5.2651\n",
            "[Batch 2] Current Loss: 5.2864\n",
            "[Batch 3] Current Loss: 5.3691\n",
            "[Batch 4] Current Loss: 5.3442\n",
            "[Batch 5] Current Loss: 5.2796\n",
            "[Batch 6] Current Loss: 5.3532\n",
            "[Batch 7] Current Loss: 5.4879\n",
            "[Batch 8] Current Loss: 4.9254\n",
            "[Batch 9] Current Loss: 5.7377\n",
            "Ep 1 (Step 005440): Train loss 4.825, Val loss 5.374\n",
            "[Batch 0] Current Loss: 4.6197\n",
            "[Batch 1] Current Loss: 5.6084\n",
            "[Batch 2] Current Loss: 5.7681\n",
            "[Batch 3] Current Loss: 4.7821\n",
            "[Batch 4] Current Loss: 4.2400\n",
            "[Batch 5] Current Loss: 5.2874\n",
            "[Batch 6] Current Loss: 4.8423\n",
            "[Batch 7] Current Loss: 4.8781\n",
            "[Batch 8] Current Loss: 4.8291\n",
            "[Batch 9] Current Loss: 4.9563\n",
            "[Batch 0] Current Loss: 5.2143\n",
            "[Batch 1] Current Loss: 5.3930\n",
            "[Batch 2] Current Loss: 5.8057\n",
            "[Batch 3] Current Loss: 5.5792\n",
            "[Batch 4] Current Loss: 5.6612\n",
            "[Batch 5] Current Loss: 6.0774\n",
            "[Batch 6] Current Loss: 5.1225\n",
            "[Batch 7] Current Loss: 5.9139\n",
            "[Batch 8] Current Loss: 5.2561\n",
            "[Batch 9] Current Loss: 5.6007\n",
            "Ep 1 (Step 005460): Train loss 4.981, Val loss 5.562\n",
            "[Batch 0] Current Loss: 5.3576\n",
            "[Batch 1] Current Loss: 5.4018\n",
            "[Batch 2] Current Loss: 4.5964\n",
            "[Batch 3] Current Loss: 5.1946\n",
            "[Batch 4] Current Loss: 4.8386\n",
            "[Batch 5] Current Loss: 5.0046\n",
            "[Batch 6] Current Loss: 5.4924\n",
            "[Batch 7] Current Loss: 4.9600\n",
            "[Batch 8] Current Loss: 5.1552\n",
            "[Batch 9] Current Loss: 4.7101\n",
            "[Batch 0] Current Loss: 5.5588\n",
            "[Batch 1] Current Loss: 5.6689\n",
            "[Batch 2] Current Loss: 5.8555\n",
            "[Batch 3] Current Loss: 5.2586\n",
            "[Batch 4] Current Loss: 5.9356\n",
            "[Batch 5] Current Loss: 5.3789\n",
            "[Batch 6] Current Loss: 5.8317\n",
            "[Batch 7] Current Loss: 5.2023\n",
            "[Batch 8] Current Loss: 4.7856\n",
            "[Batch 9] Current Loss: 5.7747\n",
            "Ep 1 (Step 005480): Train loss 5.071, Val loss 5.525\n",
            "[Batch 0] Current Loss: 4.9103\n",
            "[Batch 1] Current Loss: 4.7077\n",
            "[Batch 2] Current Loss: 5.2546\n",
            "[Batch 3] Current Loss: 5.2128\n",
            "[Batch 4] Current Loss: 4.5768\n",
            "[Batch 5] Current Loss: 4.6715\n",
            "[Batch 6] Current Loss: 5.0594\n",
            "[Batch 7] Current Loss: 4.9459\n",
            "[Batch 8] Current Loss: 4.7572\n",
            "[Batch 9] Current Loss: 5.0876\n",
            "[Batch 0] Current Loss: 5.6281\n",
            "[Batch 1] Current Loss: 5.2222\n",
            "[Batch 2] Current Loss: 5.5419\n",
            "[Batch 3] Current Loss: 5.4725\n",
            "[Batch 4] Current Loss: 4.7317\n",
            "[Batch 5] Current Loss: 5.3444\n",
            "[Batch 6] Current Loss: 5.3564\n",
            "[Batch 7] Current Loss: 5.0194\n",
            "[Batch 8] Current Loss: 5.6381\n",
            "[Batch 9] Current Loss: 5.1093\n",
            "Ep 1 (Step 005500): Train loss 4.918, Val loss 5.306\n",
            "[Batch 0] Current Loss: 4.7245\n",
            "[Batch 1] Current Loss: 5.6606\n",
            "[Batch 2] Current Loss: 5.2950\n",
            "[Batch 3] Current Loss: 4.5759\n",
            "[Batch 4] Current Loss: 5.0696\n",
            "[Batch 5] Current Loss: 5.0420\n",
            "[Batch 6] Current Loss: 4.8522\n",
            "[Batch 7] Current Loss: 5.2537\n",
            "[Batch 8] Current Loss: 5.5970\n",
            "[Batch 9] Current Loss: 5.2238\n",
            "[Batch 0] Current Loss: 5.5984\n",
            "[Batch 1] Current Loss: 4.6938\n",
            "[Batch 2] Current Loss: 5.2135\n",
            "[Batch 3] Current Loss: 5.2708\n",
            "[Batch 4] Current Loss: 5.3376\n",
            "[Batch 5] Current Loss: 6.0343\n",
            "[Batch 6] Current Loss: 6.1624\n",
            "[Batch 7] Current Loss: 4.9856\n",
            "[Batch 8] Current Loss: 5.4861\n",
            "[Batch 9] Current Loss: 5.5894\n",
            "Ep 1 (Step 005520): Train loss 5.129, Val loss 5.437\n",
            "[Batch 0] Current Loss: 5.3235\n",
            "[Batch 1] Current Loss: 5.6319\n",
            "[Batch 2] Current Loss: 4.9849\n",
            "[Batch 3] Current Loss: 4.6041\n",
            "[Batch 4] Current Loss: 4.2753\n",
            "[Batch 5] Current Loss: 5.2855\n",
            "[Batch 6] Current Loss: 4.9818\n",
            "[Batch 7] Current Loss: 5.5088\n",
            "[Batch 8] Current Loss: 4.8441\n",
            "[Batch 9] Current Loss: 4.5600\n",
            "[Batch 0] Current Loss: 5.5678\n",
            "[Batch 1] Current Loss: 5.5275\n",
            "[Batch 2] Current Loss: 4.9752\n",
            "[Batch 3] Current Loss: 5.5571\n",
            "[Batch 4] Current Loss: 5.6912\n",
            "[Batch 5] Current Loss: 5.6290\n",
            "[Batch 6] Current Loss: 6.2299\n",
            "[Batch 7] Current Loss: 5.0528\n",
            "[Batch 8] Current Loss: 5.9331\n",
            "[Batch 9] Current Loss: 5.5516\n",
            "Ep 1 (Step 005540): Train loss 5.000, Val loss 5.572\n",
            "[Batch 0] Current Loss: 5.2556\n",
            "[Batch 1] Current Loss: 5.0788\n",
            "[Batch 2] Current Loss: 4.9406\n",
            "[Batch 3] Current Loss: 4.8078\n",
            "[Batch 4] Current Loss: 4.7912\n",
            "[Batch 5] Current Loss: 4.8845\n",
            "[Batch 6] Current Loss: 5.1640\n",
            "[Batch 7] Current Loss: 5.7620\n",
            "[Batch 8] Current Loss: 5.1044\n",
            "[Batch 9] Current Loss: 4.6036\n",
            "[Batch 0] Current Loss: 5.5973\n",
            "[Batch 1] Current Loss: 5.5135\n",
            "[Batch 2] Current Loss: 6.3181\n",
            "[Batch 3] Current Loss: 5.7308\n",
            "[Batch 4] Current Loss: 5.0611\n",
            "[Batch 5] Current Loss: 5.2496\n",
            "[Batch 6] Current Loss: 5.7481\n",
            "[Batch 7] Current Loss: 5.7692\n",
            "[Batch 8] Current Loss: 6.0684\n",
            "[Batch 9] Current Loss: 5.8371\n",
            "Ep 1 (Step 005560): Train loss 5.039, Val loss 5.689\n",
            "[Batch 0] Current Loss: 5.0426\n",
            "[Batch 1] Current Loss: 4.5360\n",
            "[Batch 2] Current Loss: 4.5427\n",
            "[Batch 3] Current Loss: 5.3095\n",
            "[Batch 4] Current Loss: 5.1465\n",
            "[Batch 5] Current Loss: 4.9777\n",
            "[Batch 6] Current Loss: 5.1496\n",
            "[Batch 7] Current Loss: 4.8319\n",
            "[Batch 8] Current Loss: 5.3348\n",
            "[Batch 9] Current Loss: 4.7081\n",
            "[Batch 0] Current Loss: 5.4770\n",
            "[Batch 1] Current Loss: 4.8677\n",
            "[Batch 2] Current Loss: 5.7628\n",
            "[Batch 3] Current Loss: 5.9056\n",
            "[Batch 4] Current Loss: 5.4656\n",
            "[Batch 5] Current Loss: 5.0608\n",
            "[Batch 6] Current Loss: 5.4420\n",
            "[Batch 7] Current Loss: 5.2716\n",
            "[Batch 8] Current Loss: 5.5892\n",
            "[Batch 9] Current Loss: 5.2782\n",
            "Ep 1 (Step 005580): Train loss 4.958, Val loss 5.412\n",
            "[Batch 0] Current Loss: 4.9656\n",
            "[Batch 1] Current Loss: 4.7700\n",
            "[Batch 2] Current Loss: 5.1116\n",
            "[Batch 3] Current Loss: 4.9462\n",
            "[Batch 4] Current Loss: 5.1095\n",
            "[Batch 5] Current Loss: 5.1198\n",
            "[Batch 6] Current Loss: 5.3862\n",
            "[Batch 7] Current Loss: 5.1576\n",
            "[Batch 8] Current Loss: 5.3750\n",
            "[Batch 9] Current Loss: 4.5557\n",
            "[Batch 0] Current Loss: 5.3798\n",
            "[Batch 1] Current Loss: 5.6860\n",
            "[Batch 2] Current Loss: 5.7968\n",
            "[Batch 3] Current Loss: 5.3098\n",
            "[Batch 4] Current Loss: 4.8725\n",
            "[Batch 5] Current Loss: 5.5332\n",
            "[Batch 6] Current Loss: 5.6784\n",
            "[Batch 7] Current Loss: 5.0711\n",
            "[Batch 8] Current Loss: 5.4288\n",
            "[Batch 9] Current Loss: 5.7663\n",
            "Ep 1 (Step 005600): Train loss 5.050, Val loss 5.452\n",
            "[Batch 0] Current Loss: 5.0289\n",
            "[Batch 1] Current Loss: 4.8311\n",
            "[Batch 2] Current Loss: 4.9631\n",
            "[Batch 3] Current Loss: 4.2883\n",
            "[Batch 4] Current Loss: 5.1072\n",
            "[Batch 5] Current Loss: 5.4244\n",
            "[Batch 6] Current Loss: 4.5031\n",
            "[Batch 7] Current Loss: 5.6994\n",
            "[Batch 8] Current Loss: 4.5587\n",
            "[Batch 9] Current Loss: 4.4456\n",
            "[Batch 0] Current Loss: 5.6001\n",
            "[Batch 1] Current Loss: 5.6361\n",
            "[Batch 2] Current Loss: 4.8900\n",
            "[Batch 3] Current Loss: 5.4779\n",
            "[Batch 4] Current Loss: 5.7146\n",
            "[Batch 5] Current Loss: 6.0075\n",
            "[Batch 6] Current Loss: 5.5301\n",
            "[Batch 7] Current Loss: 5.5823\n",
            "[Batch 8] Current Loss: 5.1588\n",
            "[Batch 9] Current Loss: 4.4895\n",
            "Ep 1 (Step 005620): Train loss 4.885, Val loss 5.409\n",
            "[Batch 0] Current Loss: 5.1943\n",
            "[Batch 1] Current Loss: 4.7596\n",
            "[Batch 2] Current Loss: 4.5605\n",
            "[Batch 3] Current Loss: 4.9347\n",
            "[Batch 4] Current Loss: 4.7555\n",
            "[Batch 5] Current Loss: 5.4660\n",
            "[Batch 6] Current Loss: 5.2703\n",
            "[Batch 7] Current Loss: 4.7521\n",
            "[Batch 8] Current Loss: 4.7460\n",
            "[Batch 9] Current Loss: 5.1945\n",
            "[Batch 0] Current Loss: 5.3523\n",
            "[Batch 1] Current Loss: 5.0490\n",
            "[Batch 2] Current Loss: 4.9765\n",
            "[Batch 3] Current Loss: 5.4612\n",
            "[Batch 4] Current Loss: 5.3391\n",
            "[Batch 5] Current Loss: 5.8454\n",
            "[Batch 6] Current Loss: 5.8169\n",
            "[Batch 7] Current Loss: 6.0933\n",
            "[Batch 8] Current Loss: 5.3725\n",
            "[Batch 9] Current Loss: 5.7548\n",
            "Ep 1 (Step 005640): Train loss 4.963, Val loss 5.506\n",
            "[Batch 0] Current Loss: 5.1979\n",
            "[Batch 1] Current Loss: 4.5672\n",
            "[Batch 2] Current Loss: 4.6337\n",
            "[Batch 3] Current Loss: 5.4946\n",
            "[Batch 4] Current Loss: 4.8712\n",
            "[Batch 5] Current Loss: 5.1194\n",
            "[Batch 6] Current Loss: 5.0040\n",
            "[Batch 7] Current Loss: 5.5526\n",
            "[Batch 8] Current Loss: 5.0205\n",
            "[Batch 9] Current Loss: 5.0871\n",
            "[Batch 0] Current Loss: 5.3381\n",
            "[Batch 1] Current Loss: 5.5189\n",
            "[Batch 2] Current Loss: 5.4178\n",
            "[Batch 3] Current Loss: 5.2618\n",
            "[Batch 4] Current Loss: 5.7868\n",
            "[Batch 5] Current Loss: 5.3777\n",
            "[Batch 6] Current Loss: 5.9096\n",
            "[Batch 7] Current Loss: 5.5522\n",
            "[Batch 8] Current Loss: 5.4087\n",
            "[Batch 9] Current Loss: 6.2757\n",
            "Ep 1 (Step 005660): Train loss 5.055, Val loss 5.585\n",
            "[Batch 0] Current Loss: 5.0103\n",
            "[Batch 1] Current Loss: 4.3766\n",
            "[Batch 2] Current Loss: 5.2635\n",
            "[Batch 3] Current Loss: 5.1417\n",
            "[Batch 4] Current Loss: 4.3732\n",
            "[Batch 5] Current Loss: 5.1928\n",
            "[Batch 6] Current Loss: 4.9451\n",
            "[Batch 7] Current Loss: 5.1559\n",
            "[Batch 8] Current Loss: 4.9221\n",
            "[Batch 9] Current Loss: 4.8289\n",
            "[Batch 0] Current Loss: 5.6585\n",
            "[Batch 1] Current Loss: 5.5089\n",
            "[Batch 2] Current Loss: 5.5040\n",
            "[Batch 3] Current Loss: 5.9140\n",
            "[Batch 4] Current Loss: 5.1010\n",
            "[Batch 5] Current Loss: 4.9118\n",
            "[Batch 6] Current Loss: 5.8939\n",
            "[Batch 7] Current Loss: 4.5027\n",
            "[Batch 8] Current Loss: 5.8336\n",
            "[Batch 9] Current Loss: 5.1961\n",
            "Ep 1 (Step 005680): Train loss 4.921, Val loss 5.402\n",
            "[Batch 0] Current Loss: 5.2916\n",
            "[Batch 1] Current Loss: 5.5213\n",
            "[Batch 2] Current Loss: 5.2344\n",
            "[Batch 3] Current Loss: 4.8081\n",
            "[Batch 4] Current Loss: 4.9603\n",
            "[Batch 5] Current Loss: 4.6559\n",
            "[Batch 6] Current Loss: 4.8085\n",
            "[Batch 7] Current Loss: 5.4687\n",
            "[Batch 8] Current Loss: 4.5825\n",
            "[Batch 9] Current Loss: 4.7074\n",
            "[Batch 0] Current Loss: 5.7298\n",
            "[Batch 1] Current Loss: 4.9002\n",
            "[Batch 2] Current Loss: 6.5041\n",
            "[Batch 3] Current Loss: 5.8667\n",
            "[Batch 4] Current Loss: 4.4622\n",
            "[Batch 5] Current Loss: 5.5601\n",
            "[Batch 6] Current Loss: 5.5466\n",
            "[Batch 7] Current Loss: 5.2644\n",
            "[Batch 8] Current Loss: 5.5698\n",
            "[Batch 9] Current Loss: 6.1014\n",
            "Ep 1 (Step 005700): Train loss 5.004, Val loss 5.551\n",
            "[Batch 0] Current Loss: 4.3728\n",
            "[Batch 1] Current Loss: 5.2829\n",
            "[Batch 2] Current Loss: 4.9576\n",
            "[Batch 3] Current Loss: 4.8835\n",
            "[Batch 4] Current Loss: 4.5817\n",
            "[Batch 5] Current Loss: 5.2058\n",
            "[Batch 6] Current Loss: 4.4489\n",
            "[Batch 7] Current Loss: 4.7460\n",
            "[Batch 8] Current Loss: 5.0117\n",
            "[Batch 9] Current Loss: 5.0512\n",
            "[Batch 0] Current Loss: 5.5754\n",
            "[Batch 1] Current Loss: 5.2393\n",
            "[Batch 2] Current Loss: 5.4535\n",
            "[Batch 3] Current Loss: 5.4418\n",
            "[Batch 4] Current Loss: 5.5058\n",
            "[Batch 5] Current Loss: 4.9948\n",
            "[Batch 6] Current Loss: 5.5797\n",
            "[Batch 7] Current Loss: 5.6193\n",
            "[Batch 8] Current Loss: 5.3280\n",
            "[Batch 9] Current Loss: 5.6846\n",
            "Ep 1 (Step 005720): Train loss 4.854, Val loss 5.442\n",
            "[Batch 0] Current Loss: 4.5402\n",
            "[Batch 1] Current Loss: 5.1182\n",
            "[Batch 2] Current Loss: 5.1629\n",
            "[Batch 3] Current Loss: 5.2139\n",
            "[Batch 4] Current Loss: 4.7347\n",
            "[Batch 5] Current Loss: 5.1855\n",
            "[Batch 6] Current Loss: 4.8941\n",
            "[Batch 7] Current Loss: 5.1632\n",
            "[Batch 8] Current Loss: 4.1759\n",
            "[Batch 9] Current Loss: 4.8449\n",
            "[Batch 0] Current Loss: 5.9081\n",
            "[Batch 1] Current Loss: 5.0467\n",
            "[Batch 2] Current Loss: 5.3297\n",
            "[Batch 3] Current Loss: 5.2273\n",
            "[Batch 4] Current Loss: 4.9662\n",
            "[Batch 5] Current Loss: 5.5055\n",
            "[Batch 6] Current Loss: 5.7016\n",
            "[Batch 7] Current Loss: 5.1466\n",
            "[Batch 8] Current Loss: 5.6304\n",
            "[Batch 9] Current Loss: 4.8457\n",
            "Ep 1 (Step 005740): Train loss 4.903, Val loss 5.331\n",
            "[Batch 0] Current Loss: 5.0281\n",
            "[Batch 1] Current Loss: 5.0103\n",
            "[Batch 2] Current Loss: 4.9050\n",
            "[Batch 3] Current Loss: 4.9620\n",
            "[Batch 4] Current Loss: 4.9972\n",
            "[Batch 5] Current Loss: 4.7203\n",
            "[Batch 6] Current Loss: 5.1078\n",
            "[Batch 7] Current Loss: 4.3679\n",
            "[Batch 8] Current Loss: 4.6021\n",
            "[Batch 9] Current Loss: 4.8219\n",
            "[Batch 0] Current Loss: 5.6711\n",
            "[Batch 1] Current Loss: 6.2221\n",
            "[Batch 2] Current Loss: 5.3931\n",
            "[Batch 3] Current Loss: 5.1359\n",
            "[Batch 4] Current Loss: 5.7165\n",
            "[Batch 5] Current Loss: 5.7510\n",
            "[Batch 6] Current Loss: 5.4762\n",
            "[Batch 7] Current Loss: 6.0080\n",
            "[Batch 8] Current Loss: 5.2768\n",
            "[Batch 9] Current Loss: 4.7855\n",
            "Ep 1 (Step 005760): Train loss 4.852, Val loss 5.544\n",
            "[Batch 0] Current Loss: 4.3129\n",
            "[Batch 1] Current Loss: 4.7358\n",
            "[Batch 2] Current Loss: 5.0420\n",
            "[Batch 3] Current Loss: 5.1409\n",
            "[Batch 4] Current Loss: 4.9872\n",
            "[Batch 5] Current Loss: 4.7782\n",
            "[Batch 6] Current Loss: 5.5681\n",
            "[Batch 7] Current Loss: 4.6197\n",
            "[Batch 8] Current Loss: 4.7451\n",
            "[Batch 9] Current Loss: 5.3964\n",
            "[Batch 0] Current Loss: 5.4640\n",
            "[Batch 1] Current Loss: 5.7462\n",
            "[Batch 2] Current Loss: 5.2367\n",
            "[Batch 3] Current Loss: 5.2092\n",
            "[Batch 4] Current Loss: 5.4630\n",
            "[Batch 5] Current Loss: 5.3908\n",
            "[Batch 6] Current Loss: 6.0157\n",
            "[Batch 7] Current Loss: 5.9971\n",
            "[Batch 8] Current Loss: 5.3353\n",
            "[Batch 9] Current Loss: 4.9316\n",
            "Ep 1 (Step 005780): Train loss 4.933, Val loss 5.479\n",
            "[Batch 0] Current Loss: 5.2361\n",
            "[Batch 1] Current Loss: 4.6248\n",
            "[Batch 2] Current Loss: 4.7296\n",
            "[Batch 3] Current Loss: 5.3320\n",
            "[Batch 4] Current Loss: 5.2077\n",
            "[Batch 5] Current Loss: 5.3080\n",
            "[Batch 6] Current Loss: 5.2599\n",
            "[Batch 7] Current Loss: 4.9761\n",
            "[Batch 8] Current Loss: 4.9564\n",
            "[Batch 9] Current Loss: 5.2520\n",
            "[Batch 0] Current Loss: 5.1692\n",
            "[Batch 1] Current Loss: 5.5745\n",
            "[Batch 2] Current Loss: 5.3739\n",
            "[Batch 3] Current Loss: 5.5461\n",
            "[Batch 4] Current Loss: 5.4698\n",
            "[Batch 5] Current Loss: 5.1153\n",
            "[Batch 6] Current Loss: 5.3119\n",
            "[Batch 7] Current Loss: 4.9702\n",
            "[Batch 8] Current Loss: 5.5959\n",
            "[Batch 9] Current Loss: 5.4865\n",
            "Ep 1 (Step 005800): Train loss 5.088, Val loss 5.361\n",
            "[Batch 0] Current Loss: 5.2200\n",
            "[Batch 1] Current Loss: 5.0466\n",
            "[Batch 2] Current Loss: 4.8416\n",
            "[Batch 3] Current Loss: 4.4557\n",
            "[Batch 4] Current Loss: 4.7344\n",
            "[Batch 5] Current Loss: 4.6899\n",
            "[Batch 6] Current Loss: 5.2620\n",
            "[Batch 7] Current Loss: 4.8380\n",
            "[Batch 8] Current Loss: 4.7707\n",
            "[Batch 9] Current Loss: 4.6551\n",
            "[Batch 0] Current Loss: 5.6089\n",
            "[Batch 1] Current Loss: 5.8836\n",
            "[Batch 2] Current Loss: 5.3468\n",
            "[Batch 3] Current Loss: 5.4016\n",
            "[Batch 4] Current Loss: 5.2848\n",
            "[Batch 5] Current Loss: 5.1253\n",
            "[Batch 6] Current Loss: 5.9578\n",
            "[Batch 7] Current Loss: 5.8376\n",
            "[Batch 8] Current Loss: 5.4530\n",
            "[Batch 9] Current Loss: 5.4676\n",
            "Ep 1 (Step 005820): Train loss 4.851, Val loss 5.537\n",
            "[Batch 0] Current Loss: 4.4533\n",
            "[Batch 1] Current Loss: 5.1138\n",
            "[Batch 2] Current Loss: 5.0255\n",
            "[Batch 3] Current Loss: 4.9406\n",
            "[Batch 4] Current Loss: 5.3879\n",
            "[Batch 5] Current Loss: 4.8888\n",
            "[Batch 6] Current Loss: 4.8768\n",
            "[Batch 7] Current Loss: 4.4317\n",
            "[Batch 8] Current Loss: 5.6152\n",
            "[Batch 9] Current Loss: 4.7872\n",
            "[Batch 0] Current Loss: 5.6568\n",
            "[Batch 1] Current Loss: 5.0924\n",
            "[Batch 2] Current Loss: 5.6479\n",
            "[Batch 3] Current Loss: 6.1229\n",
            "[Batch 4] Current Loss: 5.0904\n",
            "[Batch 5] Current Loss: 5.2101\n",
            "[Batch 6] Current Loss: 5.6703\n",
            "[Batch 7] Current Loss: 5.4995\n",
            "[Batch 8] Current Loss: 5.6962\n",
            "[Batch 9] Current Loss: 6.0059\n",
            "Ep 1 (Step 005840): Train loss 4.952, Val loss 5.569\n",
            "[Batch 0] Current Loss: 5.0231\n",
            "[Batch 1] Current Loss: 5.6515\n",
            "[Batch 2] Current Loss: 4.9790\n",
            "[Batch 3] Current Loss: 4.8869\n",
            "[Batch 4] Current Loss: 4.8210\n",
            "[Batch 5] Current Loss: 4.8622\n",
            "[Batch 6] Current Loss: 5.4490\n",
            "[Batch 7] Current Loss: 4.9963\n",
            "[Batch 8] Current Loss: 4.8598\n",
            "[Batch 9] Current Loss: 5.1877\n",
            "[Batch 0] Current Loss: 5.8348\n",
            "[Batch 1] Current Loss: 5.3461\n",
            "[Batch 2] Current Loss: 5.6394\n",
            "[Batch 3] Current Loss: 5.8232\n",
            "[Batch 4] Current Loss: 5.0396\n",
            "[Batch 5] Current Loss: 5.1612\n",
            "[Batch 6] Current Loss: 5.3848\n",
            "[Batch 7] Current Loss: 6.4016\n",
            "[Batch 8] Current Loss: 5.1951\n",
            "[Batch 9] Current Loss: 5.3740\n",
            "Ep 1 (Step 005860): Train loss 5.072, Val loss 5.520\n",
            "[Batch 0] Current Loss: 4.5604\n",
            "[Batch 1] Current Loss: 5.1811\n",
            "[Batch 2] Current Loss: 5.1819\n",
            "[Batch 3] Current Loss: 5.1303\n",
            "[Batch 4] Current Loss: 4.6919\n",
            "[Batch 5] Current Loss: 4.9215\n",
            "[Batch 6] Current Loss: 5.2607\n",
            "[Batch 7] Current Loss: 5.0292\n",
            "[Batch 8] Current Loss: 4.4264\n",
            "[Batch 9] Current Loss: 4.2844\n",
            "[Batch 0] Current Loss: 5.3415\n",
            "[Batch 1] Current Loss: 5.5650\n",
            "[Batch 2] Current Loss: 5.5627\n",
            "[Batch 3] Current Loss: 5.8516\n",
            "[Batch 4] Current Loss: 5.5109\n",
            "[Batch 5] Current Loss: 5.1223\n",
            "[Batch 6] Current Loss: 5.5517\n",
            "[Batch 7] Current Loss: 5.6132\n",
            "[Batch 8] Current Loss: 5.2827\n",
            "[Batch 9] Current Loss: 5.5067\n",
            "Ep 1 (Step 005880): Train loss 4.867, Val loss 5.491\n",
            "[Batch 0] Current Loss: 5.0146\n",
            "[Batch 1] Current Loss: 5.4213\n",
            "[Batch 2] Current Loss: 5.2041\n",
            "[Batch 3] Current Loss: 5.4356\n",
            "[Batch 4] Current Loss: 3.9782\n",
            "[Batch 5] Current Loss: 4.3667\n",
            "[Batch 6] Current Loss: 5.0128\n",
            "[Batch 7] Current Loss: 5.2589\n",
            "[Batch 8] Current Loss: 4.2764\n",
            "[Batch 9] Current Loss: 4.4155\n",
            "[Batch 0] Current Loss: 5.0242\n",
            "[Batch 1] Current Loss: 4.9859\n",
            "[Batch 2] Current Loss: 4.6090\n",
            "[Batch 3] Current Loss: 5.5953\n",
            "[Batch 4] Current Loss: 5.3502\n",
            "[Batch 5] Current Loss: 5.7925\n",
            "[Batch 6] Current Loss: 5.8142\n",
            "[Batch 7] Current Loss: 5.5637\n",
            "[Batch 8] Current Loss: 4.9967\n",
            "[Batch 9] Current Loss: 5.8690\n",
            "Ep 1 (Step 005900): Train loss 4.838, Val loss 5.360\n",
            "[Batch 0] Current Loss: 4.3044\n",
            "[Batch 1] Current Loss: 4.1788\n",
            "[Batch 2] Current Loss: 5.3052\n",
            "[Batch 3] Current Loss: 4.7196\n",
            "[Batch 4] Current Loss: 5.2282\n",
            "[Batch 5] Current Loss: 5.1512\n",
            "[Batch 6] Current Loss: 5.4780\n",
            "[Batch 7] Current Loss: 5.0619\n",
            "[Batch 8] Current Loss: 4.3592\n",
            "[Batch 9] Current Loss: 5.1755\n",
            "[Batch 0] Current Loss: 5.8454\n",
            "[Batch 1] Current Loss: 5.4910\n",
            "[Batch 2] Current Loss: 5.5930\n",
            "[Batch 3] Current Loss: 5.3903\n",
            "[Batch 4] Current Loss: 5.1788\n",
            "[Batch 5] Current Loss: 5.9171\n",
            "[Batch 6] Current Loss: 5.5457\n",
            "[Batch 7] Current Loss: 5.0804\n",
            "[Batch 8] Current Loss: 5.5514\n",
            "[Batch 9] Current Loss: 4.9309\n",
            "Ep 1 (Step 005920): Train loss 4.896, Val loss 5.452\n",
            "[Batch 0] Current Loss: 5.0825\n",
            "[Batch 1] Current Loss: 4.7740\n",
            "[Batch 2] Current Loss: 4.8742\n",
            "[Batch 3] Current Loss: 4.9571\n",
            "[Batch 4] Current Loss: 4.7907\n",
            "[Batch 5] Current Loss: 3.7921\n",
            "[Batch 6] Current Loss: 4.3160\n",
            "[Batch 7] Current Loss: 5.4698\n",
            "[Batch 8] Current Loss: 4.9840\n",
            "[Batch 9] Current Loss: 5.4316\n",
            "[Batch 0] Current Loss: 4.8071\n",
            "[Batch 1] Current Loss: 5.4012\n",
            "[Batch 2] Current Loss: 4.8327\n",
            "[Batch 3] Current Loss: 5.0074\n",
            "[Batch 4] Current Loss: 5.3886\n",
            "[Batch 5] Current Loss: 5.2481\n",
            "[Batch 6] Current Loss: 5.3416\n",
            "[Batch 7] Current Loss: 5.3407\n",
            "[Batch 8] Current Loss: 4.9347\n",
            "[Batch 9] Current Loss: 4.8282\n",
            "Ep 1 (Step 005940): Train loss 4.847, Val loss 5.113\n",
            "[Batch 0] Current Loss: 4.1788\n",
            "[Batch 1] Current Loss: 4.6860\n",
            "[Batch 2] Current Loss: 5.1004\n",
            "[Batch 3] Current Loss: 5.0761\n",
            "[Batch 4] Current Loss: 4.4873\n",
            "[Batch 5] Current Loss: 4.7914\n",
            "[Batch 6] Current Loss: 4.7102\n",
            "[Batch 7] Current Loss: 4.6524\n",
            "[Batch 8] Current Loss: 5.2052\n",
            "[Batch 9] Current Loss: 5.3684\n",
            "[Batch 0] Current Loss: 5.7108\n",
            "[Batch 1] Current Loss: 5.0012\n",
            "[Batch 2] Current Loss: 4.9904\n",
            "[Batch 3] Current Loss: 5.5301\n",
            "[Batch 4] Current Loss: 5.8171\n",
            "[Batch 5] Current Loss: 5.8696\n",
            "[Batch 6] Current Loss: 5.7554\n",
            "[Batch 7] Current Loss: 5.2182\n",
            "[Batch 8] Current Loss: 5.0997\n",
            "[Batch 9] Current Loss: 5.1284\n",
            "Ep 1 (Step 005960): Train loss 4.826, Val loss 5.412\n",
            "[Batch 0] Current Loss: 4.9852\n",
            "[Batch 1] Current Loss: 4.9647\n",
            "[Batch 2] Current Loss: 4.6945\n",
            "[Batch 3] Current Loss: 4.6697\n",
            "[Batch 4] Current Loss: 4.8016\n",
            "[Batch 5] Current Loss: 5.0911\n",
            "[Batch 6] Current Loss: 5.1121\n",
            "[Batch 7] Current Loss: 5.2539\n",
            "[Batch 8] Current Loss: 4.9581\n",
            "[Batch 9] Current Loss: 4.9144\n",
            "[Batch 0] Current Loss: 5.7624\n",
            "[Batch 1] Current Loss: 5.4258\n",
            "[Batch 2] Current Loss: 5.1845\n",
            "[Batch 3] Current Loss: 5.5661\n",
            "[Batch 4] Current Loss: 5.9383\n",
            "[Batch 5] Current Loss: 5.6922\n",
            "[Batch 6] Current Loss: 5.4089\n",
            "[Batch 7] Current Loss: 5.2572\n",
            "[Batch 8] Current Loss: 5.5023\n",
            "[Batch 9] Current Loss: 5.9931\n",
            "Ep 1 (Step 005980): Train loss 4.945, Val loss 5.573\n",
            "[Batch 0] Current Loss: 5.1227\n",
            "[Batch 1] Current Loss: 5.0109\n",
            "[Batch 2] Current Loss: 4.4573\n",
            "[Batch 3] Current Loss: 5.1722\n",
            "[Batch 4] Current Loss: 4.5907\n",
            "[Batch 5] Current Loss: 5.1128\n",
            "[Batch 6] Current Loss: 4.4239\n",
            "[Batch 7] Current Loss: 4.8196\n",
            "[Batch 8] Current Loss: 4.5393\n",
            "[Batch 9] Current Loss: 5.3436\n",
            "[Batch 0] Current Loss: 5.8339\n",
            "[Batch 1] Current Loss: 5.8739\n",
            "[Batch 2] Current Loss: 5.8608\n",
            "[Batch 3] Current Loss: 5.7380\n",
            "[Batch 4] Current Loss: 4.7374\n",
            "[Batch 5] Current Loss: 5.5090\n",
            "[Batch 6] Current Loss: 5.6303\n",
            "[Batch 7] Current Loss: 5.4130\n",
            "[Batch 8] Current Loss: 5.3758\n",
            "[Batch 9] Current Loss: 5.5621\n",
            "Ep 1 (Step 006000): Train loss 4.859, Val loss 5.553\n",
            "[Batch 0] Current Loss: 4.3691\n",
            "[Batch 1] Current Loss: 4.8955\n",
            "[Batch 2] Current Loss: 4.2026\n",
            "[Batch 3] Current Loss: 5.0551\n",
            "[Batch 4] Current Loss: 5.1971\n",
            "[Batch 5] Current Loss: 4.4955\n",
            "[Batch 6] Current Loss: 4.3791\n",
            "[Batch 7] Current Loss: 5.3144\n",
            "[Batch 8] Current Loss: 4.5699\n",
            "[Batch 9] Current Loss: 5.0525\n",
            "[Batch 0] Current Loss: 5.2280\n",
            "[Batch 1] Current Loss: 5.4425\n",
            "[Batch 2] Current Loss: 5.0179\n",
            "[Batch 3] Current Loss: 5.6898\n",
            "[Batch 4] Current Loss: 4.9828\n",
            "[Batch 5] Current Loss: 5.9033\n",
            "[Batch 6] Current Loss: 5.0974\n",
            "[Batch 7] Current Loss: 5.9165\n",
            "[Batch 8] Current Loss: 5.3781\n",
            "[Batch 9] Current Loss: 5.7512\n",
            "Ep 1 (Step 006020): Train loss 4.753, Val loss 5.441\n",
            "[Batch 0] Current Loss: 5.3274\n",
            "[Batch 1] Current Loss: 4.7611\n",
            "[Batch 2] Current Loss: 5.1147\n",
            "[Batch 3] Current Loss: 4.8300\n",
            "[Batch 4] Current Loss: 4.6376\n",
            "[Batch 5] Current Loss: 5.4154\n",
            "[Batch 6] Current Loss: 4.8031\n",
            "[Batch 7] Current Loss: 4.4017\n",
            "[Batch 8] Current Loss: 5.1705\n",
            "[Batch 9] Current Loss: 4.6408\n",
            "[Batch 0] Current Loss: 5.1833\n",
            "[Batch 1] Current Loss: 5.3284\n",
            "[Batch 2] Current Loss: 5.4391\n",
            "[Batch 3] Current Loss: 5.2918\n",
            "[Batch 4] Current Loss: 5.5427\n",
            "[Batch 5] Current Loss: 5.4882\n",
            "[Batch 6] Current Loss: 5.5618\n",
            "[Batch 7] Current Loss: 5.7380\n",
            "[Batch 8] Current Loss: 5.0677\n",
            "[Batch 9] Current Loss: 5.4069\n",
            "Ep 1 (Step 006040): Train loss 4.910, Val loss 5.405\n",
            "[Batch 0] Current Loss: 4.2519\n",
            "[Batch 1] Current Loss: 4.9874\n",
            "[Batch 2] Current Loss: 4.7402\n",
            "[Batch 3] Current Loss: 4.5824\n",
            "[Batch 4] Current Loss: 4.6423\n",
            "[Batch 5] Current Loss: 4.5312\n",
            "[Batch 6] Current Loss: 4.1848\n",
            "[Batch 7] Current Loss: 4.5005\n",
            "[Batch 8] Current Loss: 4.8005\n",
            "[Batch 9] Current Loss: 5.1109\n",
            "[Batch 0] Current Loss: 5.0506\n",
            "[Batch 1] Current Loss: 5.2496\n",
            "[Batch 2] Current Loss: 5.1389\n",
            "[Batch 3] Current Loss: 5.4908\n",
            "[Batch 4] Current Loss: 4.9279\n",
            "[Batch 5] Current Loss: 5.0437\n",
            "[Batch 6] Current Loss: 5.3537\n",
            "[Batch 7] Current Loss: 4.9801\n",
            "[Batch 8] Current Loss: 5.2824\n",
            "[Batch 9] Current Loss: 5.1585\n",
            "Ep 1 (Step 006060): Train loss 4.633, Val loss 5.168\n",
            "[Batch 0] Current Loss: 4.7375\n",
            "[Batch 1] Current Loss: 5.0215\n",
            "[Batch 2] Current Loss: 4.6215\n",
            "[Batch 3] Current Loss: 4.8220\n",
            "[Batch 4] Current Loss: 4.7915\n",
            "[Batch 5] Current Loss: 4.9722\n",
            "[Batch 6] Current Loss: 5.1436\n",
            "[Batch 7] Current Loss: 5.0132\n",
            "[Batch 8] Current Loss: 5.1659\n",
            "[Batch 9] Current Loss: 4.7732\n",
            "[Batch 0] Current Loss: 5.6619\n",
            "[Batch 1] Current Loss: 4.7863\n",
            "[Batch 2] Current Loss: 5.8005\n",
            "[Batch 3] Current Loss: 4.9916\n",
            "[Batch 4] Current Loss: 5.8949\n",
            "[Batch 5] Current Loss: 5.5091\n",
            "[Batch 6] Current Loss: 4.9730\n",
            "[Batch 7] Current Loss: 4.8629\n",
            "[Batch 8] Current Loss: 4.7355\n",
            "[Batch 9] Current Loss: 5.6474\n",
            "Ep 1 (Step 006080): Train loss 4.906, Val loss 5.286\n",
            "[Batch 0] Current Loss: 5.4482\n",
            "[Batch 1] Current Loss: 5.1049\n",
            "[Batch 2] Current Loss: 4.3053\n",
            "[Batch 3] Current Loss: 4.4745\n",
            "[Batch 4] Current Loss: 4.8093\n",
            "[Batch 5] Current Loss: 4.7312\n",
            "[Batch 6] Current Loss: 4.9988\n",
            "[Batch 7] Current Loss: 4.5920\n",
            "[Batch 8] Current Loss: 4.8224\n",
            "[Batch 9] Current Loss: 5.0981\n",
            "[Batch 0] Current Loss: 5.3525\n",
            "[Batch 1] Current Loss: 5.5185\n",
            "[Batch 2] Current Loss: 5.6804\n",
            "[Batch 3] Current Loss: 5.8490\n",
            "[Batch 4] Current Loss: 5.2710\n",
            "[Batch 5] Current Loss: 6.1024\n",
            "[Batch 6] Current Loss: 5.6007\n",
            "[Batch 7] Current Loss: 5.5679\n",
            "[Batch 8] Current Loss: 5.5888\n",
            "[Batch 9] Current Loss: 5.3607\n",
            "Ep 1 (Step 006100): Train loss 4.838, Val loss 5.589\n",
            "[Batch 0] Current Loss: 4.6798\n",
            "[Batch 1] Current Loss: 4.4784\n",
            "[Batch 2] Current Loss: 4.7332\n",
            "[Batch 3] Current Loss: 4.5343\n",
            "[Batch 4] Current Loss: 5.0432\n",
            "[Batch 5] Current Loss: 4.8020\n",
            "[Batch 6] Current Loss: 4.5359\n",
            "[Batch 7] Current Loss: 5.1044\n",
            "[Batch 8] Current Loss: 4.5656\n",
            "[Batch 9] Current Loss: 4.1545\n",
            "[Batch 0] Current Loss: 4.9641\n",
            "[Batch 1] Current Loss: 4.9695\n",
            "[Batch 2] Current Loss: 6.0520\n",
            "[Batch 3] Current Loss: 5.1633\n",
            "[Batch 4] Current Loss: 5.3847\n",
            "[Batch 5] Current Loss: 5.1773\n",
            "[Batch 6] Current Loss: 5.1026\n",
            "[Batch 7] Current Loss: 5.6510\n",
            "[Batch 8] Current Loss: 5.6087\n",
            "[Batch 9] Current Loss: 4.5017\n",
            "Ep 1 (Step 006120): Train loss 4.663, Val loss 5.257\n",
            "[Batch 0] Current Loss: 4.3811\n",
            "[Batch 1] Current Loss: 4.8493\n",
            "[Batch 2] Current Loss: 4.2291\n",
            "[Batch 3] Current Loss: 4.5443\n",
            "[Batch 4] Current Loss: 4.3636\n",
            "[Batch 5] Current Loss: 4.6801\n",
            "[Batch 6] Current Loss: 4.8303\n",
            "[Batch 7] Current Loss: 4.8191\n",
            "[Batch 8] Current Loss: 4.9425\n",
            "[Batch 9] Current Loss: 5.1489\n",
            "[Batch 0] Current Loss: 5.6325\n",
            "[Batch 1] Current Loss: 5.4751\n",
            "[Batch 2] Current Loss: 5.2769\n",
            "[Batch 3] Current Loss: 5.6263\n",
            "[Batch 4] Current Loss: 5.0949\n",
            "[Batch 5] Current Loss: 5.0385\n",
            "[Batch 6] Current Loss: 5.7013\n",
            "[Batch 7] Current Loss: 4.9390\n",
            "[Batch 8] Current Loss: 5.2617\n",
            "[Batch 9] Current Loss: 5.2858\n",
            "Ep 1 (Step 006140): Train loss 4.679, Val loss 5.333\n",
            "[Batch 0] Current Loss: 4.4850\n",
            "[Batch 1] Current Loss: 4.9541\n",
            "[Batch 2] Current Loss: 4.6524\n",
            "[Batch 3] Current Loss: 4.6723\n",
            "[Batch 4] Current Loss: 4.3326\n",
            "[Batch 5] Current Loss: 4.8141\n",
            "[Batch 6] Current Loss: 4.6929\n",
            "[Batch 7] Current Loss: 4.8141\n",
            "[Batch 8] Current Loss: 5.0554\n",
            "[Batch 9] Current Loss: 5.1817\n",
            "[Batch 0] Current Loss: 5.4617\n",
            "[Batch 1] Current Loss: 5.5281\n",
            "[Batch 2] Current Loss: 5.7054\n",
            "[Batch 3] Current Loss: 6.0543\n",
            "[Batch 4] Current Loss: 5.8101\n",
            "[Batch 5] Current Loss: 5.4863\n",
            "[Batch 6] Current Loss: 5.6619\n",
            "[Batch 7] Current Loss: 4.9657\n",
            "[Batch 8] Current Loss: 5.9748\n",
            "[Batch 9] Current Loss: 5.4992\n",
            "Ep 1 (Step 006160): Train loss 4.765, Val loss 5.615\n",
            "[Batch 0] Current Loss: 4.9243\n",
            "[Batch 1] Current Loss: 4.9511\n",
            "[Batch 2] Current Loss: 5.2622\n",
            "[Batch 3] Current Loss: 5.3595\n",
            "[Batch 4] Current Loss: 4.0520\n",
            "[Batch 5] Current Loss: 4.9270\n",
            "[Batch 6] Current Loss: 4.2531\n",
            "[Batch 7] Current Loss: 4.9703\n",
            "[Batch 8] Current Loss: 4.8414\n",
            "[Batch 9] Current Loss: 4.6496\n",
            "[Batch 0] Current Loss: 5.7292\n",
            "[Batch 1] Current Loss: 5.2389\n",
            "[Batch 2] Current Loss: 5.2819\n",
            "[Batch 3] Current Loss: 5.4183\n",
            "[Batch 4] Current Loss: 4.7488\n",
            "[Batch 5] Current Loss: 5.2299\n",
            "[Batch 6] Current Loss: 6.1865\n",
            "[Batch 7] Current Loss: 5.2348\n",
            "[Batch 8] Current Loss: 5.9770\n",
            "[Batch 9] Current Loss: 5.5544\n",
            "Ep 1 (Step 006180): Train loss 4.819, Val loss 5.460\n",
            "[Batch 0] Current Loss: 4.6192\n",
            "[Batch 1] Current Loss: 4.6225\n",
            "[Batch 2] Current Loss: 5.1552\n",
            "[Batch 3] Current Loss: 4.9765\n",
            "[Batch 4] Current Loss: 4.6191\n",
            "[Batch 5] Current Loss: 4.7229\n",
            "[Batch 6] Current Loss: 5.2459\n",
            "[Batch 7] Current Loss: 5.1481\n",
            "[Batch 8] Current Loss: 4.6121\n",
            "[Batch 9] Current Loss: 5.1910\n",
            "[Batch 0] Current Loss: 5.6660\n",
            "[Batch 1] Current Loss: 5.7758\n",
            "[Batch 2] Current Loss: 5.5687\n",
            "[Batch 3] Current Loss: 5.5521\n",
            "[Batch 4] Current Loss: 5.2950\n",
            "[Batch 5] Current Loss: 5.3136\n",
            "[Batch 6] Current Loss: 5.1301\n",
            "[Batch 7] Current Loss: 4.8987\n",
            "[Batch 8] Current Loss: 5.5831\n",
            "[Batch 9] Current Loss: 5.6431\n",
            "Ep 1 (Step 006200): Train loss 4.891, Val loss 5.443\n",
            "[Batch 0] Current Loss: 4.9751\n",
            "[Batch 1] Current Loss: 5.0964\n",
            "[Batch 2] Current Loss: 5.1091\n",
            "[Batch 3] Current Loss: 4.8909\n",
            "[Batch 4] Current Loss: 5.0180\n",
            "[Batch 5] Current Loss: 4.9219\n",
            "[Batch 6] Current Loss: 4.8675\n",
            "[Batch 7] Current Loss: 5.0343\n",
            "[Batch 8] Current Loss: 4.9863\n",
            "[Batch 9] Current Loss: 4.5620\n",
            "[Batch 0] Current Loss: 5.4617\n",
            "[Batch 1] Current Loss: 4.9578\n",
            "[Batch 2] Current Loss: 5.7415\n",
            "[Batch 3] Current Loss: 5.8539\n",
            "[Batch 4] Current Loss: 5.7807\n",
            "[Batch 5] Current Loss: 5.8490\n",
            "[Batch 6] Current Loss: 5.2034\n",
            "[Batch 7] Current Loss: 5.3718\n",
            "[Batch 8] Current Loss: 5.2468\n",
            "[Batch 9] Current Loss: 5.5520\n",
            "Ep 1 (Step 006220): Train loss 4.946, Val loss 5.502\n",
            "[Batch 0] Current Loss: 4.9090\n",
            "[Batch 1] Current Loss: 4.7813\n",
            "[Batch 2] Current Loss: 4.7927\n",
            "[Batch 3] Current Loss: 4.7569\n",
            "[Batch 4] Current Loss: 5.3744\n",
            "[Batch 5] Current Loss: 4.5230\n",
            "[Batch 6] Current Loss: 4.7030\n",
            "[Batch 7] Current Loss: 5.6257\n",
            "[Batch 8] Current Loss: 4.7026\n",
            "[Batch 9] Current Loss: 5.0063\n",
            "[Batch 0] Current Loss: 4.8490\n",
            "[Batch 1] Current Loss: 5.3155\n",
            "[Batch 2] Current Loss: 5.0663\n",
            "[Batch 3] Current Loss: 5.6906\n",
            "[Batch 4] Current Loss: 5.2972\n",
            "[Batch 5] Current Loss: 5.8112\n",
            "[Batch 6] Current Loss: 5.7655\n",
            "[Batch 7] Current Loss: 5.0150\n",
            "[Batch 8] Current Loss: 5.0550\n",
            "[Batch 9] Current Loss: 5.1431\n",
            "Ep 1 (Step 006240): Train loss 4.917, Val loss 5.301\n",
            "[Batch 0] Current Loss: 4.9632\n",
            "[Batch 1] Current Loss: 4.7607\n",
            "[Batch 2] Current Loss: 4.3521\n",
            "[Batch 3] Current Loss: 5.4292\n",
            "[Batch 4] Current Loss: 3.7442\n",
            "[Batch 5] Current Loss: 5.2048\n",
            "[Batch 6] Current Loss: 4.6824\n",
            "[Batch 7] Current Loss: 5.3962\n",
            "[Batch 8] Current Loss: 5.1628\n",
            "[Batch 9] Current Loss: 4.2996\n",
            "[Batch 0] Current Loss: 5.2439\n",
            "[Batch 1] Current Loss: 4.9769\n",
            "[Batch 2] Current Loss: 5.4626\n",
            "[Batch 3] Current Loss: 4.9120\n",
            "[Batch 4] Current Loss: 5.2184\n",
            "[Batch 5] Current Loss: 5.0057\n",
            "[Batch 6] Current Loss: 4.7099\n",
            "[Batch 7] Current Loss: 5.6387\n",
            "[Batch 8] Current Loss: 4.9430\n",
            "[Batch 9] Current Loss: 5.6210\n",
            "Ep 1 (Step 006260): Train loss 4.800, Val loss 5.173\n",
            "[Batch 0] Current Loss: 5.0067\n",
            "[Batch 1] Current Loss: 4.7195\n",
            "[Batch 2] Current Loss: 5.0561\n",
            "[Batch 3] Current Loss: 4.9263\n",
            "[Batch 4] Current Loss: 4.9882\n",
            "[Batch 5] Current Loss: 4.7349\n",
            "[Batch 6] Current Loss: 4.6692\n",
            "[Batch 7] Current Loss: 4.8526\n",
            "[Batch 8] Current Loss: 5.0542\n",
            "[Batch 9] Current Loss: 5.2369\n",
            "[Batch 0] Current Loss: 5.4970\n",
            "[Batch 1] Current Loss: 5.3534\n",
            "[Batch 2] Current Loss: 5.6170\n",
            "[Batch 3] Current Loss: 5.7734\n",
            "[Batch 4] Current Loss: 5.5365\n",
            "[Batch 5] Current Loss: 5.7139\n",
            "[Batch 6] Current Loss: 5.2572\n",
            "[Batch 7] Current Loss: 6.1975\n",
            "[Batch 8] Current Loss: 6.3378\n",
            "[Batch 9] Current Loss: 5.7944\n",
            "Ep 1 (Step 006280): Train loss 4.924, Val loss 5.708\n",
            "[Batch 0] Current Loss: 4.5463\n",
            "[Batch 1] Current Loss: 5.4263\n",
            "[Batch 2] Current Loss: 4.6024\n",
            "[Batch 3] Current Loss: 4.4182\n",
            "[Batch 4] Current Loss: 4.7158\n",
            "[Batch 5] Current Loss: 4.7698\n",
            "[Batch 6] Current Loss: 4.7767\n",
            "[Batch 7] Current Loss: 4.8945\n",
            "[Batch 8] Current Loss: 4.7102\n",
            "[Batch 9] Current Loss: 4.2385\n",
            "[Batch 0] Current Loss: 5.4096\n",
            "[Batch 1] Current Loss: 5.7200\n",
            "[Batch 2] Current Loss: 4.8927\n",
            "[Batch 3] Current Loss: 5.2165\n",
            "[Batch 4] Current Loss: 5.3538\n",
            "[Batch 5] Current Loss: 6.1605\n",
            "[Batch 6] Current Loss: 5.3397\n",
            "[Batch 7] Current Loss: 5.8024\n",
            "[Batch 8] Current Loss: 5.5263\n",
            "[Batch 9] Current Loss: 5.9274\n",
            "Ep 1 (Step 006300): Train loss 4.710, Val loss 5.535\n",
            "[Batch 0] Current Loss: 3.8212\n",
            "[Batch 1] Current Loss: 4.8915\n",
            "[Batch 2] Current Loss: 5.1741\n",
            "[Batch 3] Current Loss: 4.9720\n",
            "[Batch 4] Current Loss: 4.1221\n",
            "[Batch 5] Current Loss: 4.9249\n",
            "[Batch 6] Current Loss: 4.9898\n",
            "[Batch 7] Current Loss: 4.5084\n",
            "[Batch 8] Current Loss: 4.5655\n",
            "[Batch 9] Current Loss: 5.1264\n",
            "[Batch 0] Current Loss: 5.6400\n",
            "[Batch 1] Current Loss: 5.6927\n",
            "[Batch 2] Current Loss: 5.3094\n",
            "[Batch 3] Current Loss: 5.3791\n",
            "[Batch 4] Current Loss: 5.6725\n",
            "[Batch 5] Current Loss: 5.5602\n",
            "[Batch 6] Current Loss: 5.4377\n",
            "[Batch 7] Current Loss: 5.0251\n",
            "[Batch 8] Current Loss: 5.1471\n",
            "[Batch 9] Current Loss: 5.9905\n",
            "Ep 1 (Step 006320): Train loss 4.710, Val loss 5.485\n",
            "[Batch 0] Current Loss: 4.8881\n",
            "[Batch 1] Current Loss: 4.2851\n",
            "[Batch 2] Current Loss: 4.4326\n",
            "[Batch 3] Current Loss: 4.3498\n",
            "[Batch 4] Current Loss: 4.8128\n",
            "[Batch 5] Current Loss: 5.0624\n",
            "[Batch 6] Current Loss: 5.1711\n",
            "[Batch 7] Current Loss: 4.3045\n",
            "[Batch 8] Current Loss: 4.8322\n",
            "[Batch 9] Current Loss: 4.9024\n",
            "[Batch 0] Current Loss: 5.3289\n",
            "[Batch 1] Current Loss: 5.0779\n",
            "[Batch 2] Current Loss: 5.3041\n",
            "[Batch 3] Current Loss: 5.3323\n",
            "[Batch 4] Current Loss: 5.8482\n",
            "[Batch 5] Current Loss: 5.3156\n",
            "[Batch 6] Current Loss: 6.1488\n",
            "[Batch 7] Current Loss: 5.2556\n",
            "[Batch 8] Current Loss: 5.5709\n",
            "[Batch 9] Current Loss: 5.7080\n",
            "Ep 1 (Step 006340): Train loss 4.704, Val loss 5.489\n",
            "[Batch 0] Current Loss: 4.4798\n",
            "[Batch 1] Current Loss: 4.9153\n",
            "[Batch 2] Current Loss: 4.3155\n",
            "[Batch 3] Current Loss: 3.9571\n",
            "[Batch 4] Current Loss: 4.9497\n",
            "[Batch 5] Current Loss: 4.8370\n",
            "[Batch 6] Current Loss: 4.9505\n",
            "[Batch 7] Current Loss: 4.8150\n",
            "[Batch 8] Current Loss: 4.7957\n",
            "[Batch 9] Current Loss: 4.7510\n",
            "[Batch 0] Current Loss: 5.8649\n",
            "[Batch 1] Current Loss: 5.1574\n",
            "[Batch 2] Current Loss: 5.1196\n",
            "[Batch 3] Current Loss: 5.8272\n",
            "[Batch 4] Current Loss: 5.5154\n",
            "[Batch 5] Current Loss: 5.2050\n",
            "[Batch 6] Current Loss: 4.8582\n",
            "[Batch 7] Current Loss: 5.4323\n",
            "[Batch 8] Current Loss: 5.0732\n",
            "[Batch 9] Current Loss: 5.7365\n",
            "Ep 1 (Step 006360): Train loss 4.677, Val loss 5.379\n",
            "[Batch 0] Current Loss: 4.9551\n",
            "[Batch 1] Current Loss: 3.7704\n",
            "[Batch 2] Current Loss: 4.0874\n",
            "[Batch 3] Current Loss: 4.8577\n",
            "[Batch 4] Current Loss: 5.1616\n",
            "[Batch 5] Current Loss: 4.3876\n",
            "[Batch 6] Current Loss: 4.3649\n",
            "[Batch 7] Current Loss: 4.3570\n",
            "[Batch 8] Current Loss: 5.0279\n",
            "[Batch 9] Current Loss: 4.9077\n",
            "[Batch 0] Current Loss: 6.0273\n",
            "[Batch 1] Current Loss: 5.3299\n",
            "[Batch 2] Current Loss: 5.2536\n",
            "[Batch 3] Current Loss: 5.3172\n",
            "[Batch 4] Current Loss: 5.9107\n",
            "[Batch 5] Current Loss: 5.6925\n",
            "[Batch 6] Current Loss: 5.4451\n",
            "[Batch 7] Current Loss: 5.1211\n",
            "[Batch 8] Current Loss: 5.2509\n",
            "[Batch 9] Current Loss: 5.2252\n",
            "Ep 1 (Step 006380): Train loss 4.588, Val loss 5.457\n",
            "[Batch 0] Current Loss: 5.2348\n",
            "[Batch 1] Current Loss: 4.9396\n",
            "[Batch 2] Current Loss: 4.7266\n",
            "[Batch 3] Current Loss: 5.0186\n",
            "[Batch 4] Current Loss: 4.8074\n",
            "[Batch 5] Current Loss: 4.2666\n",
            "[Batch 6] Current Loss: 4.5164\n",
            "[Batch 7] Current Loss: 4.8033\n",
            "[Batch 8] Current Loss: 5.0079\n",
            "[Batch 9] Current Loss: 4.7699\n",
            "[Batch 0] Current Loss: 5.5782\n",
            "[Batch 1] Current Loss: 4.4812\n",
            "[Batch 2] Current Loss: 5.6173\n",
            "[Batch 3] Current Loss: 5.3975\n",
            "[Batch 4] Current Loss: 5.7290\n",
            "[Batch 5] Current Loss: 6.0018\n",
            "[Batch 6] Current Loss: 5.1366\n",
            "[Batch 7] Current Loss: 5.4182\n",
            "[Batch 8] Current Loss: 5.5875\n",
            "[Batch 9] Current Loss: 5.2232\n",
            "Ep 1 (Step 006400): Train loss 4.809, Val loss 5.417\n",
            "[Batch 0] Current Loss: 5.0739\n",
            "[Batch 1] Current Loss: 4.5628\n",
            "[Batch 2] Current Loss: 4.5549\n",
            "[Batch 3] Current Loss: 4.5929\n",
            "[Batch 4] Current Loss: 4.4425\n",
            "[Batch 5] Current Loss: 4.7921\n",
            "[Batch 6] Current Loss: 5.1031\n",
            "[Batch 7] Current Loss: 4.6475\n",
            "[Batch 8] Current Loss: 5.1622\n",
            "[Batch 9] Current Loss: 4.2185\n",
            "[Batch 0] Current Loss: 5.4423\n",
            "[Batch 1] Current Loss: 5.5804\n",
            "[Batch 2] Current Loss: 5.8694\n",
            "[Batch 3] Current Loss: 5.3244\n",
            "[Batch 4] Current Loss: 4.9809\n",
            "[Batch 5] Current Loss: 5.2743\n",
            "[Batch 6] Current Loss: 5.8374\n",
            "[Batch 7] Current Loss: 5.2639\n",
            "[Batch 8] Current Loss: 5.5846\n",
            "[Batch 9] Current Loss: 5.4078\n",
            "Ep 1 (Step 006420): Train loss 4.715, Val loss 5.457\n",
            "[Batch 0] Current Loss: 4.7173\n",
            "[Batch 1] Current Loss: 4.7718\n",
            "[Batch 2] Current Loss: 4.7335\n",
            "[Batch 3] Current Loss: 4.4443\n",
            "[Batch 4] Current Loss: 4.5068\n",
            "[Batch 5] Current Loss: 5.4003\n",
            "[Batch 6] Current Loss: 4.7261\n",
            "[Batch 7] Current Loss: 4.6363\n",
            "[Batch 8] Current Loss: 4.9307\n",
            "[Batch 9] Current Loss: 4.9834\n",
            "[Batch 0] Current Loss: 5.4092\n",
            "[Batch 1] Current Loss: 5.1524\n",
            "[Batch 2] Current Loss: 5.7606\n",
            "[Batch 3] Current Loss: 5.0808\n",
            "[Batch 4] Current Loss: 5.3656\n",
            "[Batch 5] Current Loss: 5.1913\n",
            "[Batch 6] Current Loss: 4.7690\n",
            "[Batch 7] Current Loss: 5.5589\n",
            "[Batch 8] Current Loss: 4.8127\n",
            "[Batch 9] Current Loss: 5.3984\n",
            "Ep 1 (Step 006440): Train loss 4.785, Val loss 5.250\n",
            "[Batch 0] Current Loss: 4.9413\n",
            "[Batch 1] Current Loss: 4.5454\n",
            "[Batch 2] Current Loss: 4.1941\n",
            "[Batch 3] Current Loss: 4.5592\n",
            "[Batch 4] Current Loss: 4.7671\n",
            "[Batch 5] Current Loss: 4.5960\n",
            "[Batch 6] Current Loss: 4.8334\n",
            "[Batch 7] Current Loss: 4.1550\n",
            "[Batch 8] Current Loss: 4.5492\n",
            "[Batch 9] Current Loss: 3.9014\n",
            "[Batch 0] Current Loss: 5.2886\n",
            "[Batch 1] Current Loss: 5.2590\n",
            "[Batch 2] Current Loss: 5.8577\n",
            "[Batch 3] Current Loss: 5.0497\n",
            "[Batch 4] Current Loss: 5.6045\n",
            "[Batch 5] Current Loss: 5.2877\n",
            "[Batch 6] Current Loss: 5.7267\n",
            "[Batch 7] Current Loss: 4.9278\n",
            "[Batch 8] Current Loss: 5.3533\n",
            "[Batch 9] Current Loss: 5.1814\n",
            "Ep 1 (Step 006460): Train loss 4.504, Val loss 5.354\n",
            "[Batch 0] Current Loss: 4.8292\n",
            "[Batch 1] Current Loss: 5.0237\n",
            "[Batch 2] Current Loss: 4.2506\n",
            "[Batch 3] Current Loss: 5.0156\n",
            "[Batch 4] Current Loss: 5.0892\n",
            "[Batch 5] Current Loss: 4.5655\n",
            "[Batch 6] Current Loss: 4.9029\n",
            "[Batch 7] Current Loss: 5.1036\n",
            "[Batch 8] Current Loss: 4.6074\n",
            "[Batch 9] Current Loss: 4.3190\n",
            "[Batch 0] Current Loss: 4.9818\n",
            "[Batch 1] Current Loss: 5.1571\n",
            "[Batch 2] Current Loss: 5.6697\n",
            "[Batch 3] Current Loss: 5.4629\n",
            "[Batch 4] Current Loss: 5.4130\n",
            "[Batch 5] Current Loss: 5.1667\n",
            "[Batch 6] Current Loss: 5.5166\n",
            "[Batch 7] Current Loss: 5.7932\n",
            "[Batch 8] Current Loss: 4.9504\n",
            "[Batch 9] Current Loss: 5.5078\n",
            "Ep 1 (Step 006480): Train loss 4.771, Val loss 5.362\n",
            "[Batch 0] Current Loss: 4.7336\n",
            "[Batch 1] Current Loss: 4.3761\n",
            "[Batch 2] Current Loss: 4.9606\n",
            "[Batch 3] Current Loss: 4.9737\n",
            "[Batch 4] Current Loss: 4.2508\n",
            "[Batch 5] Current Loss: 5.0634\n",
            "[Batch 6] Current Loss: 5.1677\n",
            "[Batch 7] Current Loss: 4.5907\n",
            "[Batch 8] Current Loss: 4.9415\n",
            "[Batch 9] Current Loss: 4.6820\n",
            "[Batch 0] Current Loss: 4.9139\n",
            "[Batch 1] Current Loss: 4.9723\n",
            "[Batch 2] Current Loss: 5.5790\n",
            "[Batch 3] Current Loss: 5.5967\n",
            "[Batch 4] Current Loss: 5.2396\n",
            "[Batch 5] Current Loss: 4.9415\n",
            "[Batch 6] Current Loss: 5.2244\n",
            "[Batch 7] Current Loss: 5.4592\n",
            "[Batch 8] Current Loss: 4.6339\n",
            "[Batch 9] Current Loss: 5.6073\n",
            "Ep 1 (Step 006500): Train loss 4.774, Val loss 5.217\n",
            "[Batch 0] Current Loss: 5.1815\n",
            "[Batch 1] Current Loss: 4.9111\n",
            "[Batch 2] Current Loss: 4.5110\n",
            "[Batch 3] Current Loss: 4.6208\n",
            "[Batch 4] Current Loss: 4.5867\n",
            "[Batch 5] Current Loss: 4.2323\n",
            "[Batch 6] Current Loss: 4.8620\n",
            "[Batch 7] Current Loss: 5.0105\n",
            "[Batch 8] Current Loss: 4.8780\n",
            "[Batch 9] Current Loss: 5.0854\n",
            "[Batch 0] Current Loss: 5.0650\n",
            "[Batch 1] Current Loss: 5.5803\n",
            "[Batch 2] Current Loss: 5.4017\n",
            "[Batch 3] Current Loss: 5.3259\n",
            "[Batch 4] Current Loss: 5.8875\n",
            "[Batch 5] Current Loss: 5.0056\n",
            "[Batch 6] Current Loss: 5.5797\n",
            "[Batch 7] Current Loss: 5.5502\n",
            "[Batch 8] Current Loss: 5.2309\n",
            "[Batch 9] Current Loss: 5.4865\n",
            "Ep 1 (Step 006520): Train loss 4.788, Val loss 5.411\n",
            "[Batch 0] Current Loss: 4.3322\n",
            "[Batch 1] Current Loss: 4.4865\n",
            "[Batch 2] Current Loss: 4.7208\n",
            "[Batch 3] Current Loss: 4.6235\n",
            "[Batch 4] Current Loss: 4.7064\n",
            "[Batch 5] Current Loss: 5.1575\n",
            "[Batch 6] Current Loss: 4.4759\n",
            "[Batch 7] Current Loss: 4.8602\n",
            "[Batch 8] Current Loss: 4.5646\n",
            "[Batch 9] Current Loss: 4.6589\n",
            "[Batch 0] Current Loss: 5.8702\n",
            "[Batch 1] Current Loss: 5.3308\n",
            "[Batch 2] Current Loss: 5.6926\n",
            "[Batch 3] Current Loss: 6.0583\n",
            "[Batch 4] Current Loss: 5.4478\n",
            "[Batch 5] Current Loss: 5.5597\n",
            "[Batch 6] Current Loss: 5.3768\n",
            "[Batch 7] Current Loss: 5.5287\n",
            "[Batch 8] Current Loss: 5.9240\n",
            "[Batch 9] Current Loss: 5.3653\n",
            "Ep 1 (Step 006540): Train loss 4.659, Val loss 5.615\n",
            "[Batch 0] Current Loss: 5.0469\n",
            "[Batch 1] Current Loss: 4.6425\n",
            "[Batch 2] Current Loss: 5.0609\n",
            "[Batch 3] Current Loss: 4.6998\n",
            "[Batch 4] Current Loss: 4.3388\n",
            "[Batch 5] Current Loss: 4.8861\n",
            "[Batch 6] Current Loss: 4.5739\n",
            "[Batch 7] Current Loss: 4.3861\n",
            "[Batch 8] Current Loss: 4.4246\n",
            "[Batch 9] Current Loss: 4.9932\n",
            "[Batch 0] Current Loss: 5.4097\n",
            "[Batch 1] Current Loss: 4.7785\n",
            "[Batch 2] Current Loss: 5.1735\n",
            "[Batch 3] Current Loss: 5.6075\n",
            "[Batch 4] Current Loss: 4.9110\n",
            "[Batch 5] Current Loss: 5.1289\n",
            "[Batch 6] Current Loss: 5.6126\n",
            "[Batch 7] Current Loss: 5.8213\n",
            "[Batch 8] Current Loss: 4.8174\n",
            "[Batch 9] Current Loss: 5.1765\n",
            "Ep 1 (Step 006560): Train loss 4.705, Val loss 5.244\n",
            "[Batch 0] Current Loss: 4.9926\n",
            "[Batch 1] Current Loss: 4.0466\n",
            "[Batch 2] Current Loss: 4.5999\n",
            "[Batch 3] Current Loss: 4.9084\n",
            "[Batch 4] Current Loss: 4.3954\n",
            "[Batch 5] Current Loss: 4.7020\n",
            "[Batch 6] Current Loss: 4.2450\n",
            "[Batch 7] Current Loss: 4.5858\n",
            "[Batch 8] Current Loss: 4.8749\n",
            "[Batch 9] Current Loss: 4.7025\n",
            "[Batch 0] Current Loss: 5.9224\n",
            "[Batch 1] Current Loss: 5.3931\n",
            "[Batch 2] Current Loss: 5.4475\n",
            "[Batch 3] Current Loss: 4.5420\n",
            "[Batch 4] Current Loss: 5.5505\n",
            "[Batch 5] Current Loss: 4.7388\n",
            "[Batch 6] Current Loss: 5.0681\n",
            "[Batch 7] Current Loss: 5.3241\n",
            "[Batch 8] Current Loss: 5.2287\n",
            "[Batch 9] Current Loss: 5.4608\n",
            "Ep 1 (Step 006580): Train loss 4.605, Val loss 5.268\n",
            "[Batch 0] Current Loss: 4.4825\n",
            "[Batch 1] Current Loss: 5.2339\n",
            "[Batch 2] Current Loss: 4.6858\n",
            "[Batch 3] Current Loss: 5.1911\n",
            "[Batch 4] Current Loss: 4.6226\n",
            "[Batch 5] Current Loss: 5.0498\n",
            "[Batch 6] Current Loss: 4.3987\n",
            "[Batch 7] Current Loss: 4.6307\n",
            "[Batch 8] Current Loss: 5.0828\n",
            "[Batch 9] Current Loss: 5.0718\n",
            "[Batch 0] Current Loss: 5.4997\n",
            "[Batch 1] Current Loss: 5.7757\n",
            "[Batch 2] Current Loss: 5.2493\n",
            "[Batch 3] Current Loss: 5.7852\n",
            "[Batch 4] Current Loss: 5.6260\n",
            "[Batch 5] Current Loss: 5.4231\n",
            "[Batch 6] Current Loss: 5.3037\n",
            "[Batch 7] Current Loss: 5.3276\n",
            "[Batch 8] Current Loss: 5.3115\n",
            "[Batch 9] Current Loss: 5.1330\n",
            "Ep 1 (Step 006600): Train loss 4.845, Val loss 5.443\n",
            "[Batch 0] Current Loss: 4.8701\n",
            "[Batch 1] Current Loss: 4.7639\n",
            "[Batch 2] Current Loss: 4.8841\n",
            "[Batch 3] Current Loss: 4.8227\n",
            "[Batch 4] Current Loss: 5.0412\n",
            "[Batch 5] Current Loss: 4.3124\n",
            "[Batch 6] Current Loss: 4.5938\n",
            "[Batch 7] Current Loss: 5.1035\n",
            "[Batch 8] Current Loss: 4.3781\n",
            "[Batch 9] Current Loss: 5.1331\n",
            "[Batch 0] Current Loss: 4.7755\n",
            "[Batch 1] Current Loss: 4.9545\n",
            "[Batch 2] Current Loss: 4.8952\n",
            "[Batch 3] Current Loss: 5.8173\n",
            "[Batch 4] Current Loss: 5.0298\n",
            "[Batch 5] Current Loss: 5.5480\n",
            "[Batch 6] Current Loss: 5.4819\n",
            "[Batch 7] Current Loss: 6.6747\n",
            "[Batch 8] Current Loss: 5.2959\n",
            "[Batch 9] Current Loss: 5.2318\n",
            "Ep 1 (Step 006620): Train loss 4.790, Val loss 5.370\n",
            "[Batch 0] Current Loss: 4.6871\n",
            "[Batch 1] Current Loss: 4.9254\n",
            "[Batch 2] Current Loss: 4.3537\n",
            "[Batch 3] Current Loss: 4.8317\n",
            "[Batch 4] Current Loss: 4.5198\n",
            "[Batch 5] Current Loss: 4.5199\n",
            "[Batch 6] Current Loss: 3.9477\n",
            "[Batch 7] Current Loss: 4.5601\n",
            "[Batch 8] Current Loss: 5.0601\n",
            "[Batch 9] Current Loss: 4.4021\n",
            "[Batch 0] Current Loss: 4.8775\n",
            "[Batch 1] Current Loss: 5.4195\n",
            "[Batch 2] Current Loss: 4.9835\n",
            "[Batch 3] Current Loss: 5.6125\n",
            "[Batch 4] Current Loss: 5.5297\n",
            "[Batch 5] Current Loss: 5.3600\n",
            "[Batch 6] Current Loss: 5.1582\n",
            "[Batch 7] Current Loss: 5.9007\n",
            "[Batch 8] Current Loss: 6.0159\n",
            "[Batch 9] Current Loss: 5.0636\n",
            "Ep 1 (Step 006640): Train loss 4.581, Val loss 5.392\n",
            "[Batch 0] Current Loss: 3.6951\n",
            "[Batch 1] Current Loss: 5.1326\n",
            "[Batch 2] Current Loss: 4.9022\n",
            "[Batch 3] Current Loss: 5.1287\n",
            "[Batch 4] Current Loss: 4.9062\n",
            "[Batch 5] Current Loss: 4.7304\n",
            "[Batch 6] Current Loss: 4.6781\n",
            "[Batch 7] Current Loss: 5.0131\n",
            "[Batch 8] Current Loss: 4.2569\n",
            "[Batch 9] Current Loss: 4.7079\n",
            "[Batch 0] Current Loss: 5.1378\n",
            "[Batch 1] Current Loss: 5.3439\n",
            "[Batch 2] Current Loss: 4.9912\n",
            "[Batch 3] Current Loss: 5.5759\n",
            "[Batch 4] Current Loss: 5.6503\n",
            "[Batch 5] Current Loss: 5.0449\n",
            "[Batch 6] Current Loss: 5.8835\n",
            "[Batch 7] Current Loss: 4.7104\n",
            "[Batch 8] Current Loss: 5.2831\n",
            "[Batch 9] Current Loss: 5.2454\n",
            "Ep 1 (Step 006660): Train loss 4.715, Val loss 5.287\n",
            "[Batch 0] Current Loss: 5.3675\n",
            "[Batch 1] Current Loss: 4.8571\n",
            "[Batch 2] Current Loss: 4.7223\n",
            "[Batch 3] Current Loss: 5.0623\n",
            "[Batch 4] Current Loss: 4.5896\n",
            "[Batch 5] Current Loss: 4.5136\n",
            "[Batch 6] Current Loss: 4.8888\n",
            "[Batch 7] Current Loss: 4.4729\n",
            "[Batch 8] Current Loss: 5.2710\n",
            "[Batch 9] Current Loss: 4.6506\n",
            "[Batch 0] Current Loss: 5.1328\n",
            "[Batch 1] Current Loss: 5.6178\n",
            "[Batch 2] Current Loss: 5.4892\n",
            "[Batch 3] Current Loss: 4.9859\n",
            "[Batch 4] Current Loss: 5.1346\n",
            "[Batch 5] Current Loss: 5.3908\n",
            "[Batch 6] Current Loss: 5.0628\n",
            "[Batch 7] Current Loss: 5.4915\n",
            "[Batch 8] Current Loss: 5.9882\n",
            "[Batch 9] Current Loss: 5.0866\n",
            "Ep 1 (Step 006680): Train loss 4.840, Val loss 5.338\n",
            "[Batch 0] Current Loss: 4.5968\n",
            "[Batch 1] Current Loss: 4.7887\n",
            "[Batch 2] Current Loss: 4.6746\n",
            "[Batch 3] Current Loss: 5.0694\n",
            "[Batch 4] Current Loss: 4.9678\n",
            "[Batch 5] Current Loss: 4.5582\n",
            "[Batch 6] Current Loss: 4.6634\n",
            "[Batch 7] Current Loss: 4.8165\n",
            "[Batch 8] Current Loss: 4.5609\n",
            "[Batch 9] Current Loss: 5.0624\n",
            "[Batch 0] Current Loss: 5.1853\n",
            "[Batch 1] Current Loss: 5.2342\n",
            "[Batch 2] Current Loss: 5.3183\n",
            "[Batch 3] Current Loss: 5.8096\n",
            "[Batch 4] Current Loss: 5.7604\n",
            "[Batch 5] Current Loss: 6.0985\n",
            "[Batch 6] Current Loss: 5.1915\n",
            "[Batch 7] Current Loss: 5.5813\n",
            "[Batch 8] Current Loss: 5.3002\n",
            "[Batch 9] Current Loss: 5.0569\n",
            "Ep 1 (Step 006700): Train loss 4.776, Val loss 5.454\n",
            "[Batch 0] Current Loss: 4.9098\n",
            "[Batch 1] Current Loss: 4.8437\n",
            "[Batch 2] Current Loss: 4.8604\n",
            "[Batch 3] Current Loss: 5.0509\n",
            "[Batch 4] Current Loss: 4.5709\n",
            "[Batch 5] Current Loss: 4.6037\n",
            "[Batch 6] Current Loss: 4.5665\n",
            "[Batch 7] Current Loss: 4.2177\n",
            "[Batch 8] Current Loss: 5.0161\n",
            "[Batch 9] Current Loss: 4.4205\n",
            "[Batch 0] Current Loss: 6.2426\n",
            "[Batch 1] Current Loss: 5.8415\n",
            "[Batch 2] Current Loss: 5.3693\n",
            "[Batch 3] Current Loss: 5.2826\n",
            "[Batch 4] Current Loss: 5.1416\n",
            "[Batch 5] Current Loss: 4.8516\n",
            "[Batch 6] Current Loss: 5.6642\n",
            "[Batch 7] Current Loss: 5.4955\n",
            "[Batch 8] Current Loss: 5.4787\n",
            "[Batch 9] Current Loss: 5.7359\n",
            "Ep 1 (Step 006720): Train loss 4.706, Val loss 5.510\n",
            "[Batch 0] Current Loss: 4.5390\n",
            "[Batch 1] Current Loss: 5.1134\n",
            "[Batch 2] Current Loss: 4.9131\n",
            "[Batch 3] Current Loss: 5.5102\n",
            "[Batch 4] Current Loss: 4.9666\n",
            "[Batch 5] Current Loss: 4.9190\n",
            "[Batch 6] Current Loss: 4.8552\n",
            "[Batch 7] Current Loss: 4.8662\n",
            "[Batch 8] Current Loss: 4.3384\n",
            "[Batch 9] Current Loss: 4.6917\n",
            "[Batch 0] Current Loss: 5.5537\n",
            "[Batch 1] Current Loss: 5.4900\n",
            "[Batch 2] Current Loss: 5.3637\n",
            "[Batch 3] Current Loss: 5.2321\n",
            "[Batch 4] Current Loss: 5.2770\n",
            "[Batch 5] Current Loss: 5.1607\n",
            "[Batch 6] Current Loss: 4.9931\n",
            "[Batch 7] Current Loss: 5.7323\n",
            "[Batch 8] Current Loss: 4.8668\n",
            "[Batch 9] Current Loss: 5.6362\n",
            "Ep 1 (Step 006740): Train loss 4.871, Val loss 5.331\n",
            "[Batch 0] Current Loss: 4.3203\n",
            "[Batch 1] Current Loss: 4.7955\n",
            "[Batch 2] Current Loss: 4.8518\n",
            "[Batch 3] Current Loss: 3.9954\n",
            "[Batch 4] Current Loss: 4.4978\n",
            "[Batch 5] Current Loss: 4.4576\n",
            "[Batch 6] Current Loss: 4.5644\n",
            "[Batch 7] Current Loss: 4.6307\n",
            "[Batch 8] Current Loss: 4.3896\n",
            "[Batch 9] Current Loss: 3.9730\n",
            "[Batch 0] Current Loss: 5.5574\n",
            "[Batch 1] Current Loss: 5.6333\n",
            "[Batch 2] Current Loss: 5.6797\n",
            "[Batch 3] Current Loss: 5.3211\n",
            "[Batch 4] Current Loss: 6.0189\n",
            "[Batch 5] Current Loss: 5.4831\n",
            "[Batch 6] Current Loss: 5.8887\n",
            "[Batch 7] Current Loss: 5.5984\n",
            "[Batch 8] Current Loss: 4.9126\n",
            "[Batch 9] Current Loss: 5.4732\n",
            "Ep 1 (Step 006760): Train loss 4.448, Val loss 5.557\n",
            "[Batch 0] Current Loss: 4.3792\n",
            "[Batch 1] Current Loss: 5.0693\n",
            "[Batch 2] Current Loss: 4.2898\n",
            "[Batch 3] Current Loss: 4.3707\n",
            "[Batch 4] Current Loss: 5.1732\n",
            "[Batch 5] Current Loss: 4.6789\n",
            "[Batch 6] Current Loss: 4.8222\n",
            "[Batch 7] Current Loss: 5.3324\n",
            "[Batch 8] Current Loss: 4.6290\n",
            "[Batch 9] Current Loss: 4.8890\n",
            "[Batch 0] Current Loss: 5.6845\n",
            "[Batch 1] Current Loss: 4.8730\n",
            "[Batch 2] Current Loss: 5.2498\n",
            "[Batch 3] Current Loss: 5.1340\n",
            "[Batch 4] Current Loss: 5.6979\n",
            "[Batch 5] Current Loss: 4.9214\n",
            "[Batch 6] Current Loss: 6.4301\n",
            "[Batch 7] Current Loss: 4.5491\n",
            "[Batch 8] Current Loss: 5.6303\n",
            "[Batch 9] Current Loss: 5.2969\n",
            "Ep 1 (Step 006780): Train loss 4.763, Val loss 5.347\n",
            "[Batch 0] Current Loss: 4.5682\n",
            "[Batch 1] Current Loss: 4.4142\n",
            "[Batch 2] Current Loss: 5.0913\n",
            "[Batch 3] Current Loss: 5.1017\n",
            "[Batch 4] Current Loss: 4.6373\n",
            "[Batch 5] Current Loss: 4.6227\n",
            "[Batch 6] Current Loss: 4.7783\n",
            "[Batch 7] Current Loss: 4.9024\n",
            "[Batch 8] Current Loss: 5.1405\n",
            "[Batch 9] Current Loss: 4.6424\n",
            "[Batch 0] Current Loss: 5.0126\n",
            "[Batch 1] Current Loss: 6.1531\n",
            "[Batch 2] Current Loss: 5.6437\n",
            "[Batch 3] Current Loss: 5.4553\n",
            "[Batch 4] Current Loss: 5.3352\n",
            "[Batch 5] Current Loss: 5.8472\n",
            "[Batch 6] Current Loss: 5.8251\n",
            "[Batch 7] Current Loss: 4.6700\n",
            "[Batch 8] Current Loss: 5.6119\n",
            "[Batch 9] Current Loss: 5.9506\n",
            "Ep 1 (Step 006800): Train loss 4.790, Val loss 5.550\n",
            "[Batch 0] Current Loss: 4.6724\n",
            "[Batch 1] Current Loss: 4.6267\n",
            "[Batch 2] Current Loss: 5.0006\n",
            "[Batch 3] Current Loss: 4.7731\n",
            "[Batch 4] Current Loss: 4.7861\n",
            "[Batch 5] Current Loss: 4.7246\n",
            "[Batch 6] Current Loss: 5.0832\n",
            "[Batch 7] Current Loss: 4.5255\n",
            "[Batch 8] Current Loss: 4.7273\n",
            "[Batch 9] Current Loss: 4.4719\n",
            "[Batch 0] Current Loss: 5.2214\n",
            "[Batch 1] Current Loss: 5.3456\n",
            "[Batch 2] Current Loss: 4.9745\n",
            "[Batch 3] Current Loss: 4.7665\n",
            "[Batch 4] Current Loss: 5.3631\n",
            "[Batch 5] Current Loss: 5.3026\n",
            "[Batch 6] Current Loss: 5.4140\n",
            "[Batch 7] Current Loss: 4.6788\n",
            "[Batch 8] Current Loss: 5.4478\n",
            "[Batch 9] Current Loss: 5.5362\n",
            "Ep 1 (Step 006820): Train loss 4.739, Val loss 5.205\n",
            "[Batch 0] Current Loss: 4.5978\n",
            "[Batch 1] Current Loss: 4.6255\n",
            "[Batch 2] Current Loss: 4.5402\n",
            "[Batch 3] Current Loss: 4.1044\n",
            "[Batch 4] Current Loss: 5.0829\n",
            "[Batch 5] Current Loss: 4.8589\n",
            "[Batch 6] Current Loss: 5.0970\n",
            "[Batch 7] Current Loss: 4.7477\n",
            "[Batch 8] Current Loss: 4.9283\n",
            "[Batch 9] Current Loss: 4.2711\n",
            "[Batch 0] Current Loss: 5.3434\n",
            "[Batch 1] Current Loss: 5.3258\n",
            "[Batch 2] Current Loss: 5.9922\n",
            "[Batch 3] Current Loss: 5.4289\n",
            "[Batch 4] Current Loss: 5.5974\n",
            "[Batch 5] Current Loss: 5.1154\n",
            "[Batch 6] Current Loss: 4.7239\n",
            "[Batch 7] Current Loss: 5.1496\n",
            "[Batch 8] Current Loss: 5.9479\n",
            "[Batch 9] Current Loss: 5.1011\n",
            "Ep 1 (Step 006840): Train loss 4.685, Val loss 5.373\n",
            "[Batch 0] Current Loss: 4.5692\n",
            "[Batch 1] Current Loss: 4.9282\n",
            "[Batch 2] Current Loss: 4.8621\n",
            "[Batch 3] Current Loss: 4.7375\n",
            "[Batch 4] Current Loss: 4.9379\n",
            "[Batch 5] Current Loss: 4.5166\n",
            "[Batch 6] Current Loss: 4.7077\n",
            "[Batch 7] Current Loss: 4.5281\n",
            "[Batch 8] Current Loss: 4.4189\n",
            "[Batch 9] Current Loss: 4.8732\n",
            "[Batch 0] Current Loss: 5.5104\n",
            "[Batch 1] Current Loss: 5.2078\n",
            "[Batch 2] Current Loss: 6.0895\n",
            "[Batch 3] Current Loss: 5.2153\n",
            "[Batch 4] Current Loss: 5.2696\n",
            "[Batch 5] Current Loss: 5.7032\n",
            "[Batch 6] Current Loss: 5.1636\n",
            "[Batch 7] Current Loss: 5.2869\n",
            "[Batch 8] Current Loss: 5.1397\n",
            "[Batch 9] Current Loss: 5.4824\n",
            "Ep 1 (Step 006860): Train loss 4.708, Val loss 5.407\n",
            "[Batch 0] Current Loss: 5.2591\n",
            "[Batch 1] Current Loss: 4.5538\n",
            "[Batch 2] Current Loss: 5.0818\n",
            "[Batch 3] Current Loss: 5.3047\n",
            "[Batch 4] Current Loss: 4.6642\n",
            "[Batch 5] Current Loss: 4.9934\n",
            "[Batch 6] Current Loss: 4.6882\n",
            "[Batch 7] Current Loss: 4.7654\n",
            "[Batch 8] Current Loss: 4.4571\n",
            "[Batch 9] Current Loss: 4.3303\n",
            "[Batch 0] Current Loss: 4.8798\n",
            "[Batch 1] Current Loss: 5.4110\n",
            "[Batch 2] Current Loss: 5.8206\n",
            "[Batch 3] Current Loss: 5.3126\n",
            "[Batch 4] Current Loss: 5.3251\n",
            "[Batch 5] Current Loss: 5.5775\n",
            "[Batch 6] Current Loss: 5.4629\n",
            "[Batch 7] Current Loss: 5.6543\n",
            "[Batch 8] Current Loss: 5.3718\n",
            "[Batch 9] Current Loss: 4.9891\n",
            "Ep 1 (Step 006880): Train loss 4.810, Val loss 5.380\n",
            "[Batch 0] Current Loss: 4.7401\n",
            "[Batch 1] Current Loss: 4.6138\n",
            "[Batch 2] Current Loss: 4.7999\n",
            "[Batch 3] Current Loss: 4.0164\n",
            "[Batch 4] Current Loss: 4.3875\n",
            "[Batch 5] Current Loss: 4.1573\n",
            "[Batch 6] Current Loss: 5.0268\n",
            "[Batch 7] Current Loss: 4.5141\n",
            "[Batch 8] Current Loss: 4.9162\n",
            "[Batch 9] Current Loss: 4.1596\n",
            "[Batch 0] Current Loss: 5.0376\n",
            "[Batch 1] Current Loss: 5.7878\n",
            "[Batch 2] Current Loss: 5.0351\n",
            "[Batch 3] Current Loss: 5.0171\n",
            "[Batch 4] Current Loss: 5.3066\n",
            "[Batch 5] Current Loss: 5.1709\n",
            "[Batch 6] Current Loss: 5.3889\n",
            "[Batch 7] Current Loss: 5.6772\n",
            "[Batch 8] Current Loss: 5.6276\n",
            "[Batch 9] Current Loss: 5.6864\n",
            "Ep 1 (Step 006900): Train loss 4.533, Val loss 5.374\n",
            "[Batch 0] Current Loss: 4.7541\n",
            "[Batch 1] Current Loss: 4.6162\n",
            "[Batch 2] Current Loss: 4.2426\n",
            "[Batch 3] Current Loss: 4.5153\n",
            "[Batch 4] Current Loss: 4.2934\n",
            "[Batch 5] Current Loss: 5.0718\n",
            "[Batch 6] Current Loss: 5.1109\n",
            "[Batch 7] Current Loss: 4.4149\n",
            "[Batch 8] Current Loss: 4.5799\n",
            "[Batch 9] Current Loss: 3.9261\n",
            "[Batch 0] Current Loss: 4.8684\n",
            "[Batch 1] Current Loss: 4.7649\n",
            "[Batch 2] Current Loss: 5.6451\n",
            "[Batch 3] Current Loss: 4.9207\n",
            "[Batch 4] Current Loss: 5.1672\n",
            "[Batch 5] Current Loss: 5.6489\n",
            "[Batch 6] Current Loss: 5.6697\n",
            "[Batch 7] Current Loss: 6.1471\n",
            "[Batch 8] Current Loss: 5.2287\n",
            "[Batch 9] Current Loss: 5.5238\n",
            "Ep 1 (Step 006920): Train loss 4.553, Val loss 5.358\n",
            "[Batch 0] Current Loss: 4.4732\n",
            "[Batch 1] Current Loss: 4.7474\n",
            "[Batch 2] Current Loss: 4.4570\n",
            "[Batch 3] Current Loss: 4.7750\n",
            "[Batch 4] Current Loss: 4.9713\n",
            "[Batch 5] Current Loss: 5.1676\n",
            "[Batch 6] Current Loss: 4.7253\n",
            "[Batch 7] Current Loss: 4.5898\n",
            "[Batch 8] Current Loss: 4.8626\n",
            "[Batch 9] Current Loss: 4.6854\n",
            "[Batch 0] Current Loss: 5.1352\n",
            "[Batch 1] Current Loss: 5.6288\n",
            "[Batch 2] Current Loss: 5.7491\n",
            "[Batch 3] Current Loss: 5.6927\n",
            "[Batch 4] Current Loss: 5.4039\n",
            "[Batch 5] Current Loss: 5.2037\n",
            "[Batch 6] Current Loss: 5.1495\n",
            "[Batch 7] Current Loss: 4.8268\n",
            "[Batch 8] Current Loss: 4.8237\n",
            "[Batch 9] Current Loss: 5.0295\n",
            "Ep 1 (Step 006940): Train loss 4.745, Val loss 5.264\n",
            "[Batch 0] Current Loss: 4.7521\n",
            "[Batch 1] Current Loss: 5.2010\n",
            "[Batch 2] Current Loss: 4.2603\n",
            "[Batch 3] Current Loss: 5.2137\n",
            "[Batch 4] Current Loss: 3.9942\n",
            "[Batch 5] Current Loss: 5.0752\n",
            "[Batch 6] Current Loss: 4.7869\n",
            "[Batch 7] Current Loss: 4.6255\n",
            "[Batch 8] Current Loss: 4.9634\n",
            "[Batch 9] Current Loss: 4.6618\n",
            "[Batch 0] Current Loss: 5.0105\n",
            "[Batch 1] Current Loss: 4.6314\n",
            "[Batch 2] Current Loss: 5.2969\n",
            "[Batch 3] Current Loss: 5.1503\n",
            "[Batch 4] Current Loss: 5.7902\n",
            "[Batch 5] Current Loss: 5.1793\n",
            "[Batch 6] Current Loss: 5.7949\n",
            "[Batch 7] Current Loss: 5.0075\n",
            "[Batch 8] Current Loss: 4.8989\n",
            "[Batch 9] Current Loss: 5.3064\n",
            "Ep 1 (Step 006960): Train loss 4.753, Val loss 5.207\n",
            "[Batch 0] Current Loss: 4.6865\n",
            "[Batch 1] Current Loss: 4.5039\n",
            "[Batch 2] Current Loss: 4.6029\n",
            "[Batch 3] Current Loss: 4.3188\n",
            "[Batch 4] Current Loss: 4.8850\n",
            "[Batch 5] Current Loss: 4.6399\n",
            "[Batch 6] Current Loss: 4.4389\n",
            "[Batch 7] Current Loss: 4.1681\n",
            "[Batch 8] Current Loss: 5.1049\n",
            "[Batch 9] Current Loss: 4.7137\n",
            "[Batch 0] Current Loss: 5.3058\n",
            "[Batch 1] Current Loss: 5.8093\n",
            "[Batch 2] Current Loss: 4.8460\n",
            "[Batch 3] Current Loss: 5.4463\n",
            "[Batch 4] Current Loss: 5.8231\n",
            "[Batch 5] Current Loss: 5.8886\n",
            "[Batch 6] Current Loss: 5.5055\n",
            "[Batch 7] Current Loss: 5.7220\n",
            "[Batch 8] Current Loss: 5.2853\n",
            "[Batch 9] Current Loss: 5.8264\n",
            "Ep 1 (Step 006980): Train loss 4.606, Val loss 5.546\n",
            "[Batch 0] Current Loss: 4.8104\n",
            "[Batch 1] Current Loss: 4.3908\n",
            "[Batch 2] Current Loss: 4.8008\n",
            "[Batch 3] Current Loss: 4.9775\n",
            "[Batch 4] Current Loss: 4.5806\n",
            "[Batch 5] Current Loss: 4.7453\n",
            "[Batch 6] Current Loss: 4.5130\n",
            "[Batch 7] Current Loss: 5.3265\n",
            "[Batch 8] Current Loss: 4.6153\n",
            "[Batch 9] Current Loss: 4.9791\n",
            "[Batch 0] Current Loss: 5.4240\n",
            "[Batch 1] Current Loss: 5.3554\n",
            "[Batch 2] Current Loss: 5.1278\n",
            "[Batch 3] Current Loss: 5.0252\n",
            "[Batch 4] Current Loss: 5.3120\n",
            "[Batch 5] Current Loss: 4.8598\n",
            "[Batch 6] Current Loss: 5.1093\n",
            "[Batch 7] Current Loss: 5.2540\n",
            "[Batch 8] Current Loss: 5.5426\n",
            "[Batch 9] Current Loss: 5.7276\n",
            "Ep 1 (Step 007000): Train loss 4.774, Val loss 5.274\n",
            "[Batch 0] Current Loss: 4.6093\n",
            "[Batch 1] Current Loss: 4.6220\n",
            "[Batch 2] Current Loss: 4.3621\n",
            "[Batch 3] Current Loss: 4.8792\n",
            "[Batch 4] Current Loss: 4.4707\n",
            "[Batch 5] Current Loss: 4.8519\n",
            "[Batch 6] Current Loss: 4.8844\n",
            "[Batch 7] Current Loss: 4.6544\n",
            "[Batch 8] Current Loss: 4.5744\n",
            "[Batch 9] Current Loss: 4.2638\n",
            "[Batch 0] Current Loss: 4.6868\n",
            "[Batch 1] Current Loss: 5.6267\n",
            "[Batch 2] Current Loss: 5.4897\n",
            "[Batch 3] Current Loss: 5.3021\n",
            "[Batch 4] Current Loss: 5.7609\n",
            "[Batch 5] Current Loss: 5.0877\n",
            "[Batch 6] Current Loss: 5.4884\n",
            "[Batch 7] Current Loss: 5.2035\n",
            "[Batch 8] Current Loss: 4.8446\n",
            "[Batch 9] Current Loss: 4.9444\n",
            "Ep 1 (Step 007020): Train loss 4.617, Val loss 5.243\n",
            "[Batch 0] Current Loss: 4.9402\n",
            "[Batch 1] Current Loss: 4.2972\n",
            "[Batch 2] Current Loss: 5.2090\n",
            "[Batch 3] Current Loss: 4.4218\n",
            "[Batch 4] Current Loss: 4.0890\n",
            "[Batch 5] Current Loss: 5.1613\n",
            "[Batch 6] Current Loss: 4.7237\n",
            "[Batch 7] Current Loss: 5.0540\n",
            "[Batch 8] Current Loss: 4.5189\n",
            "[Batch 9] Current Loss: 4.8378\n",
            "[Batch 0] Current Loss: 5.3186\n",
            "[Batch 1] Current Loss: 5.7441\n",
            "[Batch 2] Current Loss: 5.2251\n",
            "[Batch 3] Current Loss: 4.9536\n",
            "[Batch 4] Current Loss: 5.0598\n",
            "[Batch 5] Current Loss: 5.5784\n",
            "[Batch 6] Current Loss: 5.2108\n",
            "[Batch 7] Current Loss: 4.9862\n",
            "[Batch 8] Current Loss: 5.5110\n",
            "[Batch 9] Current Loss: 4.8873\n",
            "Ep 1 (Step 007040): Train loss 4.725, Val loss 5.248\n",
            "[Batch 0] Current Loss: 4.7167\n",
            "[Batch 1] Current Loss: 4.6759\n",
            "[Batch 2] Current Loss: 5.0547\n",
            "[Batch 3] Current Loss: 5.1256\n",
            "[Batch 4] Current Loss: 5.1218\n",
            "[Batch 5] Current Loss: 4.3903\n",
            "[Batch 6] Current Loss: 4.3676\n",
            "[Batch 7] Current Loss: 5.1846\n",
            "[Batch 8] Current Loss: 4.9583\n",
            "[Batch 9] Current Loss: 4.5667\n",
            "[Batch 0] Current Loss: 5.7892\n",
            "[Batch 1] Current Loss: 5.1077\n",
            "[Batch 2] Current Loss: 6.1356\n",
            "[Batch 3] Current Loss: 5.3232\n",
            "[Batch 4] Current Loss: 5.3957\n",
            "[Batch 5] Current Loss: 5.3525\n",
            "[Batch 6] Current Loss: 5.0765\n",
            "[Batch 7] Current Loss: 5.0439\n",
            "[Batch 8] Current Loss: 5.3986\n",
            "[Batch 9] Current Loss: 5.0863\n",
            "Ep 1 (Step 007060): Train loss 4.816, Val loss 5.371\n",
            "[Batch 0] Current Loss: 4.2290\n",
            "[Batch 1] Current Loss: 5.0340\n",
            "[Batch 2] Current Loss: 4.8219\n",
            "[Batch 3] Current Loss: 4.7857\n",
            "[Batch 4] Current Loss: 4.9590\n",
            "[Batch 5] Current Loss: 4.5629\n",
            "[Batch 6] Current Loss: 5.1787\n",
            "[Batch 7] Current Loss: 4.8650\n",
            "[Batch 8] Current Loss: 4.5100\n",
            "[Batch 9] Current Loss: 4.8581\n",
            "[Batch 0] Current Loss: 5.5248\n",
            "[Batch 1] Current Loss: 6.0584\n",
            "[Batch 2] Current Loss: 4.9868\n",
            "[Batch 3] Current Loss: 5.2465\n",
            "[Batch 4] Current Loss: 5.9179\n",
            "[Batch 5] Current Loss: 4.9594\n",
            "[Batch 6] Current Loss: 4.5800\n",
            "[Batch 7] Current Loss: 5.4312\n",
            "[Batch 8] Current Loss: 5.6161\n",
            "[Batch 9] Current Loss: 4.8000\n",
            "Ep 1 (Step 007080): Train loss 4.780, Val loss 5.312\n",
            "[Batch 0] Current Loss: 4.9022\n",
            "[Batch 1] Current Loss: 4.8623\n",
            "[Batch 2] Current Loss: 4.9687\n",
            "[Batch 3] Current Loss: 4.7403\n",
            "[Batch 4] Current Loss: 4.3799\n",
            "[Batch 5] Current Loss: 4.7522\n",
            "[Batch 6] Current Loss: 4.2400\n",
            "[Batch 7] Current Loss: 4.6656\n",
            "[Batch 8] Current Loss: 5.4487\n",
            "[Batch 9] Current Loss: 4.4447\n",
            "[Batch 0] Current Loss: 5.7957\n",
            "[Batch 1] Current Loss: 5.1603\n",
            "[Batch 2] Current Loss: 5.0317\n",
            "[Batch 3] Current Loss: 5.4940\n",
            "[Batch 4] Current Loss: 5.1488\n",
            "[Batch 5] Current Loss: 5.4533\n",
            "[Batch 6] Current Loss: 5.1910\n",
            "[Batch 7] Current Loss: 5.0607\n",
            "[Batch 8] Current Loss: 5.3971\n",
            "[Batch 9] Current Loss: 5.2732\n",
            "Ep 1 (Step 007100): Train loss 4.740, Val loss 5.301\n",
            "[Batch 0] Current Loss: 4.5087\n",
            "[Batch 1] Current Loss: 4.6325\n",
            "[Batch 2] Current Loss: 4.5979\n",
            "[Batch 3] Current Loss: 5.0931\n",
            "[Batch 4] Current Loss: 4.2101\n",
            "[Batch 5] Current Loss: 4.8928\n",
            "[Batch 6] Current Loss: 4.5125\n",
            "[Batch 7] Current Loss: 4.2836\n",
            "[Batch 8] Current Loss: 4.7539\n",
            "[Batch 9] Current Loss: 4.7408\n",
            "[Batch 0] Current Loss: 5.5463\n",
            "[Batch 1] Current Loss: 5.9118\n",
            "[Batch 2] Current Loss: 5.9270\n",
            "[Batch 3] Current Loss: 5.1614\n",
            "[Batch 4] Current Loss: 5.0291\n",
            "[Batch 5] Current Loss: 5.7011\n",
            "[Batch 6] Current Loss: 5.2153\n",
            "[Batch 7] Current Loss: 5.7362\n",
            "[Batch 8] Current Loss: 4.9527\n",
            "[Batch 9] Current Loss: 4.9439\n",
            "Ep 1 (Step 007120): Train loss 4.623, Val loss 5.412\n",
            "[Batch 0] Current Loss: 4.9624\n",
            "[Batch 1] Current Loss: 5.2327\n",
            "[Batch 2] Current Loss: 4.8491\n",
            "[Batch 3] Current Loss: 4.5532\n",
            "[Batch 4] Current Loss: 5.2893\n",
            "[Batch 5] Current Loss: 4.2629\n",
            "[Batch 6] Current Loss: 4.7490\n",
            "[Batch 7] Current Loss: 4.3139\n",
            "[Batch 8] Current Loss: 4.7207\n",
            "[Batch 9] Current Loss: 5.1534\n",
            "[Batch 0] Current Loss: 4.8111\n",
            "[Batch 1] Current Loss: 4.7767\n",
            "[Batch 2] Current Loss: 5.6985\n",
            "[Batch 3] Current Loss: 5.8887\n",
            "[Batch 4] Current Loss: 5.8499\n",
            "[Batch 5] Current Loss: 5.2253\n",
            "[Batch 6] Current Loss: 5.7609\n",
            "[Batch 7] Current Loss: 5.1112\n",
            "[Batch 8] Current Loss: 5.6940\n",
            "[Batch 9] Current Loss: 4.6244\n",
            "Ep 1 (Step 007140): Train loss 4.809, Val loss 5.344\n",
            "[Batch 0] Current Loss: 4.6522\n",
            "[Batch 1] Current Loss: 4.4481\n",
            "[Batch 2] Current Loss: 4.1278\n",
            "[Batch 3] Current Loss: 4.4235\n",
            "[Batch 4] Current Loss: 4.7072\n",
            "[Batch 5] Current Loss: 4.9507\n",
            "[Batch 6] Current Loss: 4.3201\n",
            "[Batch 7] Current Loss: 4.3275\n",
            "[Batch 8] Current Loss: 5.5071\n",
            "[Batch 9] Current Loss: 4.7530\n",
            "[Batch 0] Current Loss: 5.6266\n",
            "[Batch 1] Current Loss: 5.7008\n",
            "[Batch 2] Current Loss: 5.6140\n",
            "[Batch 3] Current Loss: 5.1908\n",
            "[Batch 4] Current Loss: 5.3668\n",
            "[Batch 5] Current Loss: 5.9695\n",
            "[Batch 6] Current Loss: 5.2351\n",
            "[Batch 7] Current Loss: 4.7824\n",
            "[Batch 8] Current Loss: 5.3893\n",
            "[Batch 9] Current Loss: 5.5452\n",
            "Ep 1 (Step 007160): Train loss 4.622, Val loss 5.442\n",
            "[Batch 0] Current Loss: 4.1043\n",
            "[Batch 1] Current Loss: 4.6082\n",
            "[Batch 2] Current Loss: 4.9486\n",
            "[Batch 3] Current Loss: 4.8166\n",
            "[Batch 4] Current Loss: 4.1392\n",
            "[Batch 5] Current Loss: 4.5003\n",
            "[Batch 6] Current Loss: 4.3952\n",
            "[Batch 7] Current Loss: 5.0642\n",
            "[Batch 8] Current Loss: 4.6336\n",
            "[Batch 9] Current Loss: 4.7632\n",
            "[Batch 0] Current Loss: 5.2576\n",
            "[Batch 1] Current Loss: 5.2926\n",
            "[Batch 2] Current Loss: 5.6888\n",
            "[Batch 3] Current Loss: 5.3963\n",
            "[Batch 4] Current Loss: 6.1477\n",
            "[Batch 5] Current Loss: 5.3425\n",
            "[Batch 6] Current Loss: 5.3317\n",
            "[Batch 7] Current Loss: 5.1745\n",
            "[Batch 8] Current Loss: 4.8080\n",
            "[Batch 9] Current Loss: 4.8085\n",
            "Ep 1 (Step 007180): Train loss 4.597, Val loss 5.325\n",
            "[Batch 0] Current Loss: 4.7882\n",
            "[Batch 1] Current Loss: 5.1500\n",
            "[Batch 2] Current Loss: 5.0475\n",
            "[Batch 3] Current Loss: 4.9274\n",
            "[Batch 4] Current Loss: 4.6160\n",
            "[Batch 5] Current Loss: 4.3431\n",
            "[Batch 6] Current Loss: 4.1453\n",
            "[Batch 7] Current Loss: 4.6053\n",
            "[Batch 8] Current Loss: 4.5972\n",
            "[Batch 9] Current Loss: 4.3391\n",
            "[Batch 0] Current Loss: 4.5959\n",
            "[Batch 1] Current Loss: 5.7554\n",
            "[Batch 2] Current Loss: 5.2276\n",
            "[Batch 3] Current Loss: 5.3562\n",
            "[Batch 4] Current Loss: 5.2076\n",
            "[Batch 5] Current Loss: 5.8343\n",
            "[Batch 6] Current Loss: 4.6844\n",
            "[Batch 7] Current Loss: 5.0254\n",
            "[Batch 8] Current Loss: 5.2980\n",
            "[Batch 9] Current Loss: 5.4208\n",
            "Ep 1 (Step 007200): Train loss 4.656, Val loss 5.241\n",
            "[Batch 0] Current Loss: 4.2947\n",
            "[Batch 1] Current Loss: 4.8385\n",
            "[Batch 2] Current Loss: 4.8864\n",
            "[Batch 3] Current Loss: 5.1767\n",
            "[Batch 4] Current Loss: 4.8125\n",
            "[Batch 5] Current Loss: 5.0608\n",
            "[Batch 6] Current Loss: 4.5184\n",
            "[Batch 7] Current Loss: 4.6696\n",
            "[Batch 8] Current Loss: 4.5508\n",
            "[Batch 9] Current Loss: 4.7407\n",
            "[Batch 0] Current Loss: 4.5257\n",
            "[Batch 1] Current Loss: 5.5687\n",
            "[Batch 2] Current Loss: 5.3632\n",
            "[Batch 3] Current Loss: 5.1180\n",
            "[Batch 4] Current Loss: 5.6469\n",
            "[Batch 5] Current Loss: 6.1098\n",
            "[Batch 6] Current Loss: 5.5186\n",
            "[Batch 7] Current Loss: 5.6448\n",
            "[Batch 8] Current Loss: 4.8626\n",
            "[Batch 9] Current Loss: 5.4118\n",
            "Ep 1 (Step 007220): Train loss 4.755, Val loss 5.377\n",
            "[Batch 0] Current Loss: 4.6172\n",
            "[Batch 1] Current Loss: 4.6732\n",
            "[Batch 2] Current Loss: 4.5087\n",
            "[Batch 3] Current Loss: 4.7528\n",
            "[Batch 4] Current Loss: 4.3592\n",
            "[Batch 5] Current Loss: 4.8157\n",
            "[Batch 6] Current Loss: 4.6110\n",
            "[Batch 7] Current Loss: 4.3537\n",
            "[Batch 8] Current Loss: 4.7165\n",
            "[Batch 9] Current Loss: 4.9633\n",
            "[Batch 0] Current Loss: 4.8870\n",
            "[Batch 1] Current Loss: 5.0779\n",
            "[Batch 2] Current Loss: 5.1916\n",
            "[Batch 3] Current Loss: 4.5739\n",
            "[Batch 4] Current Loss: 5.6201\n",
            "[Batch 5] Current Loss: 5.2871\n",
            "[Batch 6] Current Loss: 5.6778\n",
            "[Batch 7] Current Loss: 5.6017\n",
            "[Batch 8] Current Loss: 4.7589\n",
            "[Batch 9] Current Loss: 4.9999\n",
            "Ep 1 (Step 007240): Train loss 4.637, Val loss 5.168\n",
            "[Batch 0] Current Loss: 4.4890\n",
            "[Batch 1] Current Loss: 4.4466\n",
            "[Batch 2] Current Loss: 4.7055\n",
            "[Batch 3] Current Loss: 4.3363\n",
            "[Batch 4] Current Loss: 4.8860\n",
            "[Batch 5] Current Loss: 4.9141\n",
            "[Batch 6] Current Loss: 4.9078\n",
            "[Batch 7] Current Loss: 4.5878\n",
            "[Batch 8] Current Loss: 4.5153\n",
            "[Batch 9] Current Loss: 4.8479\n",
            "[Batch 0] Current Loss: 5.1536\n",
            "[Batch 1] Current Loss: 4.1512\n",
            "[Batch 2] Current Loss: 5.4900\n",
            "[Batch 3] Current Loss: 5.7514\n",
            "[Batch 4] Current Loss: 5.6985\n",
            "[Batch 5] Current Loss: 5.5725\n",
            "[Batch 6] Current Loss: 4.5487\n",
            "[Batch 7] Current Loss: 4.7308\n",
            "[Batch 8] Current Loss: 5.6311\n",
            "[Batch 9] Current Loss: 5.0928\n",
            "Ep 1 (Step 007260): Train loss 4.664, Val loss 5.182\n",
            "[Batch 0] Current Loss: 4.4042\n",
            "[Batch 1] Current Loss: 4.8690\n",
            "[Batch 2] Current Loss: 4.6567\n",
            "[Batch 3] Current Loss: 4.4567\n",
            "[Batch 4] Current Loss: 4.6140\n",
            "[Batch 5] Current Loss: 4.7549\n",
            "[Batch 6] Current Loss: 4.3890\n",
            "[Batch 7] Current Loss: 4.7555\n",
            "[Batch 8] Current Loss: 4.8518\n",
            "[Batch 9] Current Loss: 4.0779\n",
            "[Batch 0] Current Loss: 4.9496\n",
            "[Batch 1] Current Loss: 5.4676\n",
            "[Batch 2] Current Loss: 5.4009\n",
            "[Batch 3] Current Loss: 5.4935\n",
            "[Batch 4] Current Loss: 5.7003\n",
            "[Batch 5] Current Loss: 5.5519\n",
            "[Batch 6] Current Loss: 5.0781\n",
            "[Batch 7] Current Loss: 5.6355\n",
            "[Batch 8] Current Loss: 5.0253\n",
            "[Batch 9] Current Loss: 5.1921\n",
            "Ep 1 (Step 007280): Train loss 4.583, Val loss 5.349\n",
            "[Batch 0] Current Loss: 4.5542\n",
            "[Batch 1] Current Loss: 4.5687\n",
            "[Batch 2] Current Loss: 4.7517\n",
            "[Batch 3] Current Loss: 4.6567\n",
            "[Batch 4] Current Loss: 4.7047\n",
            "[Batch 5] Current Loss: 4.8063\n",
            "[Batch 6] Current Loss: 4.2835\n",
            "[Batch 7] Current Loss: 4.2642\n",
            "[Batch 8] Current Loss: 4.8703\n",
            "[Batch 9] Current Loss: 5.3634\n",
            "[Batch 0] Current Loss: 5.0264\n",
            "[Batch 1] Current Loss: 5.2072\n",
            "[Batch 2] Current Loss: 5.2444\n",
            "[Batch 3] Current Loss: 5.3162\n",
            "[Batch 4] Current Loss: 5.6214\n",
            "[Batch 5] Current Loss: 5.1166\n",
            "[Batch 6] Current Loss: 5.2181\n",
            "[Batch 7] Current Loss: 5.2846\n",
            "[Batch 8] Current Loss: 5.7311\n",
            "[Batch 9] Current Loss: 4.8925\n",
            "Ep 1 (Step 007300): Train loss 4.682, Val loss 5.266\n",
            "[Batch 0] Current Loss: 4.6988\n",
            "[Batch 1] Current Loss: 4.2104\n",
            "[Batch 2] Current Loss: 4.5652\n",
            "[Batch 3] Current Loss: 4.4347\n",
            "[Batch 4] Current Loss: 4.2965\n",
            "[Batch 5] Current Loss: 4.5219\n",
            "[Batch 6] Current Loss: 4.5559\n",
            "[Batch 7] Current Loss: 4.7415\n",
            "[Batch 8] Current Loss: 4.7657\n",
            "[Batch 9] Current Loss: 4.4001\n",
            "[Batch 0] Current Loss: 4.6668\n",
            "[Batch 1] Current Loss: 5.2126\n",
            "[Batch 2] Current Loss: 5.5163\n",
            "[Batch 3] Current Loss: 5.7084\n",
            "[Batch 4] Current Loss: 5.4934\n",
            "[Batch 5] Current Loss: 5.4922\n",
            "[Batch 6] Current Loss: 5.4325\n",
            "[Batch 7] Current Loss: 5.3549\n",
            "[Batch 8] Current Loss: 5.5092\n",
            "[Batch 9] Current Loss: 5.5753\n",
            "Ep 1 (Step 007320): Train loss 4.519, Val loss 5.396\n",
            "[Batch 0] Current Loss: 4.5543\n",
            "[Batch 1] Current Loss: 4.8282\n",
            "[Batch 2] Current Loss: 4.4836\n",
            "[Batch 3] Current Loss: 5.1549\n",
            "[Batch 4] Current Loss: 4.8189\n",
            "[Batch 5] Current Loss: 4.0378\n",
            "[Batch 6] Current Loss: 4.3606\n",
            "[Batch 7] Current Loss: 4.5908\n",
            "[Batch 8] Current Loss: 4.7300\n",
            "[Batch 9] Current Loss: 4.6837\n",
            "[Batch 0] Current Loss: 5.4909\n",
            "[Batch 1] Current Loss: 4.7868\n",
            "[Batch 2] Current Loss: 5.8240\n",
            "[Batch 3] Current Loss: 5.0372\n",
            "[Batch 4] Current Loss: 5.3240\n",
            "[Batch 5] Current Loss: 4.5970\n",
            "[Batch 6] Current Loss: 5.1940\n",
            "[Batch 7] Current Loss: 5.5544\n",
            "[Batch 8] Current Loss: 5.0851\n",
            "[Batch 9] Current Loss: 5.2742\n",
            "Ep 1 (Step 007340): Train loss 4.624, Val loss 5.217\n",
            "[Batch 0] Current Loss: 4.2061\n",
            "[Batch 1] Current Loss: 4.0776\n",
            "[Batch 2] Current Loss: 4.6345\n",
            "[Batch 3] Current Loss: 4.7629\n",
            "[Batch 4] Current Loss: 4.6740\n",
            "[Batch 5] Current Loss: 4.8334\n",
            "[Batch 6] Current Loss: 4.7033\n",
            "[Batch 7] Current Loss: 4.1876\n",
            "[Batch 8] Current Loss: 4.2480\n",
            "[Batch 9] Current Loss: 4.6700\n",
            "[Batch 0] Current Loss: 5.8930\n",
            "[Batch 1] Current Loss: 5.1363\n",
            "[Batch 2] Current Loss: 5.2178\n",
            "[Batch 3] Current Loss: 4.2648\n",
            "[Batch 4] Current Loss: 5.3668\n",
            "[Batch 5] Current Loss: 5.8882\n",
            "[Batch 6] Current Loss: 4.5955\n",
            "[Batch 7] Current Loss: 5.2407\n",
            "[Batch 8] Current Loss: 5.7654\n",
            "[Batch 9] Current Loss: 5.4137\n",
            "Ep 1 (Step 007360): Train loss 4.500, Val loss 5.278\n",
            "[Batch 0] Current Loss: 4.5848\n",
            "[Batch 1] Current Loss: 4.4041\n",
            "[Batch 2] Current Loss: 4.6559\n",
            "[Batch 3] Current Loss: 5.2634\n",
            "[Batch 4] Current Loss: 4.6142\n",
            "[Batch 5] Current Loss: 4.9168\n",
            "[Batch 6] Current Loss: 4.9126\n",
            "[Batch 7] Current Loss: 4.9539\n",
            "[Batch 8] Current Loss: 4.7133\n",
            "[Batch 9] Current Loss: 4.5279\n",
            "[Batch 0] Current Loss: 5.8534\n",
            "[Batch 1] Current Loss: 5.6313\n",
            "[Batch 2] Current Loss: 5.3133\n",
            "[Batch 3] Current Loss: 4.8816\n",
            "[Batch 4] Current Loss: 5.3309\n",
            "[Batch 5] Current Loss: 4.9308\n",
            "[Batch 6] Current Loss: 5.2891\n",
            "[Batch 7] Current Loss: 5.3459\n",
            "[Batch 8] Current Loss: 5.0362\n",
            "[Batch 9] Current Loss: 5.2577\n",
            "Ep 1 (Step 007380): Train loss 4.755, Val loss 5.287\n",
            "[Batch 0] Current Loss: 4.3315\n",
            "[Batch 1] Current Loss: 5.1520\n",
            "[Batch 2] Current Loss: 4.6057\n",
            "[Batch 3] Current Loss: 4.6656\n",
            "[Batch 4] Current Loss: 4.2742\n",
            "[Batch 5] Current Loss: 4.6185\n",
            "[Batch 6] Current Loss: 3.8751\n",
            "[Batch 7] Current Loss: 4.8821\n",
            "[Batch 8] Current Loss: 4.6089\n",
            "[Batch 9] Current Loss: 4.4791\n",
            "[Batch 0] Current Loss: 5.1216\n",
            "[Batch 1] Current Loss: 4.7626\n",
            "[Batch 2] Current Loss: 5.2734\n",
            "[Batch 3] Current Loss: 5.0850\n",
            "[Batch 4] Current Loss: 5.3076\n",
            "[Batch 5] Current Loss: 5.9641\n",
            "[Batch 6] Current Loss: 4.6771\n",
            "[Batch 7] Current Loss: 5.1949\n",
            "[Batch 8] Current Loss: 4.8760\n",
            "[Batch 9] Current Loss: 5.4369\n",
            "Ep 1 (Step 007400): Train loss 4.549, Val loss 5.170\n",
            "[Batch 0] Current Loss: 4.9090\n",
            "[Batch 1] Current Loss: 4.4322\n",
            "[Batch 2] Current Loss: 4.7678\n",
            "[Batch 3] Current Loss: 4.2666\n",
            "[Batch 4] Current Loss: 5.1432\n",
            "[Batch 5] Current Loss: 4.9556\n",
            "[Batch 6] Current Loss: 4.1560\n",
            "[Batch 7] Current Loss: 4.4661\n",
            "[Batch 8] Current Loss: 4.8213\n",
            "[Batch 9] Current Loss: 4.5091\n",
            "[Batch 0] Current Loss: 5.5821\n",
            "[Batch 1] Current Loss: 5.6465\n",
            "[Batch 2] Current Loss: 5.0096\n",
            "[Batch 3] Current Loss: 4.9569\n",
            "[Batch 4] Current Loss: 4.6960\n",
            "[Batch 5] Current Loss: 5.4568\n",
            "[Batch 6] Current Loss: 5.4959\n",
            "[Batch 7] Current Loss: 5.5955\n",
            "[Batch 8] Current Loss: 5.3867\n",
            "[Batch 9] Current Loss: 5.3359\n",
            "Ep 1 (Step 007420): Train loss 4.643, Val loss 5.316\n",
            "[Batch 0] Current Loss: 5.1424\n",
            "[Batch 1] Current Loss: 5.1026\n",
            "[Batch 2] Current Loss: 5.0303\n",
            "[Batch 3] Current Loss: 4.6091\n",
            "[Batch 4] Current Loss: 4.7771\n",
            "[Batch 5] Current Loss: 4.2947\n",
            "[Batch 6] Current Loss: 4.6723\n",
            "[Batch 7] Current Loss: 4.8971\n",
            "[Batch 8] Current Loss: 4.3296\n",
            "[Batch 9] Current Loss: 4.7111\n",
            "[Batch 0] Current Loss: 5.3271\n",
            "[Batch 1] Current Loss: 5.4605\n",
            "[Batch 2] Current Loss: 6.0874\n",
            "[Batch 3] Current Loss: 5.2813\n",
            "[Batch 4] Current Loss: 5.5702\n",
            "[Batch 5] Current Loss: 5.4023\n",
            "[Batch 6] Current Loss: 5.4252\n",
            "[Batch 7] Current Loss: 5.7217\n",
            "[Batch 8] Current Loss: 5.5812\n",
            "[Batch 9] Current Loss: 5.6323\n",
            "Ep 1 (Step 007440): Train loss 4.757, Val loss 5.549\n",
            "[Batch 0] Current Loss: 4.6340\n",
            "[Batch 1] Current Loss: 4.8736\n",
            "[Batch 2] Current Loss: 3.9541\n",
            "[Batch 3] Current Loss: 3.7743\n",
            "[Batch 4] Current Loss: 4.4259\n",
            "[Batch 5] Current Loss: 4.7069\n",
            "[Batch 6] Current Loss: 4.6704\n",
            "[Batch 7] Current Loss: 4.3298\n",
            "[Batch 8] Current Loss: 4.5212\n",
            "[Batch 9] Current Loss: 4.4823\n",
            "[Batch 0] Current Loss: 4.8371\n",
            "[Batch 1] Current Loss: 5.4413\n",
            "[Batch 2] Current Loss: 5.6815\n",
            "[Batch 3] Current Loss: 5.7219\n",
            "[Batch 4] Current Loss: 5.3836\n",
            "[Batch 5] Current Loss: 5.6353\n",
            "[Batch 6] Current Loss: 4.9866\n",
            "[Batch 7] Current Loss: 5.7715\n",
            "[Batch 8] Current Loss: 5.4259\n",
            "[Batch 9] Current Loss: 5.6099\n",
            "Ep 1 (Step 007460): Train loss 4.437, Val loss 5.449\n",
            "[Batch 0] Current Loss: 4.9085\n",
            "[Batch 1] Current Loss: 4.4441\n",
            "[Batch 2] Current Loss: 4.6995\n",
            "[Batch 3] Current Loss: 4.4390\n",
            "[Batch 4] Current Loss: 4.1084\n",
            "[Batch 5] Current Loss: 4.5687\n",
            "[Batch 6] Current Loss: 4.3303\n",
            "[Batch 7] Current Loss: 5.0307\n",
            "[Batch 8] Current Loss: 4.5084\n",
            "[Batch 9] Current Loss: 4.9144\n",
            "[Batch 0] Current Loss: 5.3160\n",
            "[Batch 1] Current Loss: 5.4135\n",
            "[Batch 2] Current Loss: 5.6258\n",
            "[Batch 3] Current Loss: 5.1488\n",
            "[Batch 4] Current Loss: 4.9423\n",
            "[Batch 5] Current Loss: 5.4244\n",
            "[Batch 6] Current Loss: 5.3790\n",
            "[Batch 7] Current Loss: 5.5823\n",
            "[Batch 8] Current Loss: 5.0532\n",
            "[Batch 9] Current Loss: 4.8536\n",
            "Ep 1 (Step 007480): Train loss 4.595, Val loss 5.274\n",
            "[Batch 0] Current Loss: 4.5982\n",
            "[Batch 1] Current Loss: 4.2954\n",
            "[Batch 2] Current Loss: 4.4434\n",
            "[Batch 3] Current Loss: 4.6047\n",
            "[Batch 4] Current Loss: 4.6002\n",
            "[Batch 5] Current Loss: 4.4420\n",
            "[Batch 6] Current Loss: 4.6016\n",
            "[Batch 7] Current Loss: 4.4178\n",
            "[Batch 8] Current Loss: 4.4692\n",
            "[Batch 9] Current Loss: 4.4287\n",
            "[Batch 0] Current Loss: 5.3127\n",
            "[Batch 1] Current Loss: 5.2549\n",
            "[Batch 2] Current Loss: 5.5619\n",
            "[Batch 3] Current Loss: 5.7526\n",
            "[Batch 4] Current Loss: 5.4309\n",
            "[Batch 5] Current Loss: 5.2751\n",
            "[Batch 6] Current Loss: 5.2348\n",
            "[Batch 7] Current Loss: 5.0122\n",
            "[Batch 8] Current Loss: 5.1348\n",
            "[Batch 9] Current Loss: 5.1327\n",
            "Ep 1 (Step 007500): Train loss 4.490, Val loss 5.310\n",
            "[Batch 0] Current Loss: 4.8138\n",
            "[Batch 1] Current Loss: 4.5336\n",
            "[Batch 2] Current Loss: 4.8221\n",
            "[Batch 3] Current Loss: 4.3142\n",
            "[Batch 4] Current Loss: 4.1975\n",
            "[Batch 5] Current Loss: 4.9970\n",
            "[Batch 6] Current Loss: 4.5313\n",
            "[Batch 7] Current Loss: 5.1111\n",
            "[Batch 8] Current Loss: 4.6799\n",
            "[Batch 9] Current Loss: 4.7923\n",
            "[Batch 0] Current Loss: 5.5059\n",
            "[Batch 1] Current Loss: 5.7091\n",
            "[Batch 2] Current Loss: 5.3958\n",
            "[Batch 3] Current Loss: 5.1441\n",
            "[Batch 4] Current Loss: 5.5125\n",
            "[Batch 5] Current Loss: 5.3056\n",
            "[Batch 6] Current Loss: 5.3736\n",
            "[Batch 7] Current Loss: 5.0790\n",
            "[Batch 8] Current Loss: 6.3010\n",
            "[Batch 9] Current Loss: 5.5934\n",
            "Ep 1 (Step 007520): Train loss 4.679, Val loss 5.492\n",
            "[Batch 0] Current Loss: 4.1140\n",
            "[Batch 1] Current Loss: 4.8282\n",
            "[Batch 2] Current Loss: 4.1427\n",
            "[Batch 3] Current Loss: 4.1340\n",
            "[Batch 4] Current Loss: 4.8203\n",
            "[Batch 5] Current Loss: 4.7709\n",
            "[Batch 6] Current Loss: 4.7793\n",
            "[Batch 7] Current Loss: 4.5925\n",
            "[Batch 8] Current Loss: 4.9183\n",
            "[Batch 9] Current Loss: 4.4424\n",
            "[Batch 0] Current Loss: 5.4105\n",
            "[Batch 1] Current Loss: 5.4227\n",
            "[Batch 2] Current Loss: 6.0443\n",
            "[Batch 3] Current Loss: 5.4056\n",
            "[Batch 4] Current Loss: 5.3588\n",
            "[Batch 5] Current Loss: 5.6671\n",
            "[Batch 6] Current Loss: 5.6646\n",
            "[Batch 7] Current Loss: 5.3831\n",
            "[Batch 8] Current Loss: 5.4598\n",
            "[Batch 9] Current Loss: 4.8844\n",
            "Ep 1 (Step 007540): Train loss 4.554, Val loss 5.470\n",
            "[Batch 0] Current Loss: 4.4205\n",
            "[Batch 1] Current Loss: 4.7413\n",
            "[Batch 2] Current Loss: 4.6834\n",
            "[Batch 3] Current Loss: 4.8777\n",
            "[Batch 4] Current Loss: 4.6665\n",
            "[Batch 5] Current Loss: 4.6234\n",
            "[Batch 6] Current Loss: 4.2533\n",
            "[Batch 7] Current Loss: 4.8918\n",
            "[Batch 8] Current Loss: 4.7391\n",
            "[Batch 9] Current Loss: 3.9408\n",
            "[Batch 0] Current Loss: 4.8334\n",
            "[Batch 1] Current Loss: 4.9037\n",
            "[Batch 2] Current Loss: 5.0729\n",
            "[Batch 3] Current Loss: 5.4618\n",
            "[Batch 4] Current Loss: 5.1655\n",
            "[Batch 5] Current Loss: 5.3196\n",
            "[Batch 6] Current Loss: 5.6710\n",
            "[Batch 7] Current Loss: 5.6225\n",
            "[Batch 8] Current Loss: 5.6037\n",
            "[Batch 9] Current Loss: 4.7560\n",
            "Ep 1 (Step 007560): Train loss 4.584, Val loss 5.241\n",
            "[Batch 0] Current Loss: 4.8787\n",
            "[Batch 1] Current Loss: 4.7716\n",
            "[Batch 2] Current Loss: 4.6013\n",
            "[Batch 3] Current Loss: 4.1899\n",
            "[Batch 4] Current Loss: 4.5901\n",
            "[Batch 5] Current Loss: 4.8209\n",
            "[Batch 6] Current Loss: 4.9200\n",
            "[Batch 7] Current Loss: 3.9840\n",
            "[Batch 8] Current Loss: 4.1926\n",
            "[Batch 9] Current Loss: 4.3769\n",
            "[Batch 0] Current Loss: 5.2101\n",
            "[Batch 1] Current Loss: 5.2159\n",
            "[Batch 2] Current Loss: 5.2551\n",
            "[Batch 3] Current Loss: 4.6668\n",
            "[Batch 4] Current Loss: 4.9337\n",
            "[Batch 5] Current Loss: 4.8510\n",
            "[Batch 6] Current Loss: 5.7817\n",
            "[Batch 7] Current Loss: 5.7910\n",
            "[Batch 8] Current Loss: 4.4518\n",
            "[Batch 9] Current Loss: 5.6270\n",
            "Ep 1 (Step 007580): Train loss 4.533, Val loss 5.178\n",
            "[Batch 0] Current Loss: 4.8943\n",
            "[Batch 1] Current Loss: 5.0737\n",
            "[Batch 2] Current Loss: 4.3809\n",
            "[Batch 3] Current Loss: 4.4166\n",
            "[Batch 4] Current Loss: 4.7899\n",
            "[Batch 5] Current Loss: 4.5835\n",
            "[Batch 6] Current Loss: 5.0582\n",
            "[Batch 7] Current Loss: 4.5054\n",
            "[Batch 8] Current Loss: 3.7396\n",
            "[Batch 9] Current Loss: 4.2819\n",
            "[Batch 0] Current Loss: 5.1775\n",
            "[Batch 1] Current Loss: 5.4088\n",
            "[Batch 2] Current Loss: 5.4943\n",
            "[Batch 3] Current Loss: 5.4565\n",
            "[Batch 4] Current Loss: 5.3595\n",
            "[Batch 5] Current Loss: 5.6788\n",
            "[Batch 6] Current Loss: 5.9090\n",
            "[Batch 7] Current Loss: 5.6829\n",
            "[Batch 8] Current Loss: 5.5098\n",
            "[Batch 9] Current Loss: 5.0820\n",
            "Ep 1 (Step 007600): Train loss 4.572, Val loss 5.476\n",
            "[Batch 0] Current Loss: 4.7868\n",
            "[Batch 1] Current Loss: 4.9866\n",
            "[Batch 2] Current Loss: 4.5867\n",
            "[Batch 3] Current Loss: 4.6024\n",
            "[Batch 4] Current Loss: 5.0597\n",
            "[Batch 5] Current Loss: 4.7625\n",
            "[Batch 6] Current Loss: 4.3608\n",
            "[Batch 7] Current Loss: 4.3018\n",
            "[Batch 8] Current Loss: 4.4528\n",
            "[Batch 9] Current Loss: 4.6981\n",
            "[Batch 0] Current Loss: 5.6740\n",
            "[Batch 1] Current Loss: 4.4939\n",
            "[Batch 2] Current Loss: 5.1770\n",
            "[Batch 3] Current Loss: 5.5193\n",
            "[Batch 4] Current Loss: 4.7573\n",
            "[Batch 5] Current Loss: 5.3663\n",
            "[Batch 6] Current Loss: 5.5026\n",
            "[Batch 7] Current Loss: 5.3867\n",
            "[Batch 8] Current Loss: 5.8089\n",
            "[Batch 9] Current Loss: 5.2821\n",
            "Ep 1 (Step 007620): Train loss 4.660, Val loss 5.297\n",
            "[Batch 0] Current Loss: 4.0876\n",
            "[Batch 1] Current Loss: 4.6964\n",
            "[Batch 2] Current Loss: 4.3282\n",
            "[Batch 3] Current Loss: 4.3668\n",
            "[Batch 4] Current Loss: 4.4469\n",
            "[Batch 5] Current Loss: 4.4827\n",
            "[Batch 6] Current Loss: 5.0121\n",
            "[Batch 7] Current Loss: 4.8767\n",
            "[Batch 8] Current Loss: 4.8061\n",
            "[Batch 9] Current Loss: 4.1356\n",
            "[Batch 0] Current Loss: 5.4499\n",
            "[Batch 1] Current Loss: 5.2614\n",
            "[Batch 2] Current Loss: 5.4619\n",
            "[Batch 3] Current Loss: 5.1725\n",
            "[Batch 4] Current Loss: 5.4629\n",
            "[Batch 5] Current Loss: 5.1547\n",
            "[Batch 6] Current Loss: 4.6868\n",
            "[Batch 7] Current Loss: 5.4736\n",
            "[Batch 8] Current Loss: 5.6119\n",
            "[Batch 9] Current Loss: 5.2227\n",
            "Ep 1 (Step 007640): Train loss 4.524, Val loss 5.296\n",
            "[Batch 0] Current Loss: 4.1497\n",
            "[Batch 1] Current Loss: 4.3862\n",
            "[Batch 2] Current Loss: 4.4949\n",
            "[Batch 3] Current Loss: 4.8288\n",
            "[Batch 4] Current Loss: 4.4529\n",
            "[Batch 5] Current Loss: 4.0182\n",
            "[Batch 6] Current Loss: 4.6169\n",
            "[Batch 7] Current Loss: 4.6317\n",
            "[Batch 8] Current Loss: 4.8890\n",
            "[Batch 9] Current Loss: 4.6704\n",
            "[Batch 0] Current Loss: 5.0743\n",
            "[Batch 1] Current Loss: 5.6724\n",
            "[Batch 2] Current Loss: 4.8754\n",
            "[Batch 3] Current Loss: 5.0008\n",
            "[Batch 4] Current Loss: 5.0209\n",
            "[Batch 5] Current Loss: 4.9865\n",
            "[Batch 6] Current Loss: 5.2545\n",
            "[Batch 7] Current Loss: 5.1041\n",
            "[Batch 8] Current Loss: 5.0208\n",
            "[Batch 9] Current Loss: 5.5807\n",
            "Ep 1 (Step 007660): Train loss 4.514, Val loss 5.159\n",
            "[Batch 0] Current Loss: 5.0222\n",
            "[Batch 1] Current Loss: 4.4465\n",
            "[Batch 2] Current Loss: 4.7910\n",
            "[Batch 3] Current Loss: 4.7471\n",
            "[Batch 4] Current Loss: 4.3454\n",
            "[Batch 5] Current Loss: 4.6844\n",
            "[Batch 6] Current Loss: 4.4676\n",
            "[Batch 7] Current Loss: 4.4462\n",
            "[Batch 8] Current Loss: 4.8431\n",
            "[Batch 9] Current Loss: 4.6648\n",
            "[Batch 0] Current Loss: 4.8418\n",
            "[Batch 1] Current Loss: 4.9821\n",
            "[Batch 2] Current Loss: 4.9922\n",
            "[Batch 3] Current Loss: 5.2711\n",
            "[Batch 4] Current Loss: 5.7779\n",
            "[Batch 5] Current Loss: 5.8148\n",
            "[Batch 6] Current Loss: 5.6179\n",
            "[Batch 7] Current Loss: 5.3977\n",
            "[Batch 8] Current Loss: 5.2497\n",
            "[Batch 9] Current Loss: 5.8309\n",
            "Ep 1 (Step 007680): Train loss 4.646, Val loss 5.378\n",
            "[Batch 0] Current Loss: 4.8184\n",
            "[Batch 1] Current Loss: 4.5748\n",
            "[Batch 2] Current Loss: 4.9738\n",
            "[Batch 3] Current Loss: 4.9119\n",
            "[Batch 4] Current Loss: 4.7789\n",
            "[Batch 5] Current Loss: 4.7094\n",
            "[Batch 6] Current Loss: 4.8824\n",
            "[Batch 7] Current Loss: 4.5689\n",
            "[Batch 8] Current Loss: 4.3757\n",
            "[Batch 9] Current Loss: 4.4765\n",
            "[Batch 0] Current Loss: 4.9271\n",
            "[Batch 1] Current Loss: 5.2628\n",
            "[Batch 2] Current Loss: 5.3701\n",
            "[Batch 3] Current Loss: 4.9571\n",
            "[Batch 4] Current Loss: 5.3396\n",
            "[Batch 5] Current Loss: 5.4719\n",
            "[Batch 6] Current Loss: 5.7646\n",
            "[Batch 7] Current Loss: 4.9323\n",
            "[Batch 8] Current Loss: 5.3869\n",
            "[Batch 9] Current Loss: 5.4574\n",
            "Ep 1 (Step 007700): Train loss 4.707, Val loss 5.287\n",
            "[Batch 0] Current Loss: 4.2606\n",
            "[Batch 1] Current Loss: 4.7113\n",
            "[Batch 2] Current Loss: 4.6902\n",
            "[Batch 3] Current Loss: 4.3796\n",
            "[Batch 4] Current Loss: 4.4506\n",
            "[Batch 5] Current Loss: 4.7525\n",
            "[Batch 6] Current Loss: 4.7397\n",
            "[Batch 7] Current Loss: 4.3707\n",
            "[Batch 8] Current Loss: 4.6485\n",
            "[Batch 9] Current Loss: 4.4080\n",
            "[Batch 0] Current Loss: 5.9470\n",
            "[Batch 1] Current Loss: 5.4464\n",
            "[Batch 2] Current Loss: 4.5758\n",
            "[Batch 3] Current Loss: 5.1987\n",
            "[Batch 4] Current Loss: 5.8319\n",
            "[Batch 5] Current Loss: 5.6128\n",
            "[Batch 6] Current Loss: 5.0563\n",
            "[Batch 7] Current Loss: 5.1239\n",
            "[Batch 8] Current Loss: 5.4045\n",
            "[Batch 9] Current Loss: 5.3656\n",
            "Ep 1 (Step 007720): Train loss 4.541, Val loss 5.356\n",
            "[Batch 0] Current Loss: 4.3821\n",
            "[Batch 1] Current Loss: 4.4694\n",
            "[Batch 2] Current Loss: 5.1668\n",
            "[Batch 3] Current Loss: 4.7130\n",
            "[Batch 4] Current Loss: 4.4917\n",
            "[Batch 5] Current Loss: 4.5669\n",
            "[Batch 6] Current Loss: 4.8891\n",
            "[Batch 7] Current Loss: 4.6334\n",
            "[Batch 8] Current Loss: 4.5149\n",
            "[Batch 9] Current Loss: 4.1920\n",
            "[Batch 0] Current Loss: 5.5742\n",
            "[Batch 1] Current Loss: 5.0267\n",
            "[Batch 2] Current Loss: 5.6514\n",
            "[Batch 3] Current Loss: 5.3328\n",
            "[Batch 4] Current Loss: 4.4529\n",
            "[Batch 5] Current Loss: 4.7876\n",
            "[Batch 6] Current Loss: 5.3210\n",
            "[Batch 7] Current Loss: 4.9369\n",
            "[Batch 8] Current Loss: 5.6198\n",
            "[Batch 9] Current Loss: 5.6280\n",
            "Ep 1 (Step 007740): Train loss 4.602, Val loss 5.233\n",
            "[Batch 0] Current Loss: 4.9823\n",
            "[Batch 1] Current Loss: 4.8529\n",
            "[Batch 2] Current Loss: 4.5625\n",
            "[Batch 3] Current Loss: 4.7515\n",
            "[Batch 4] Current Loss: 4.9464\n",
            "[Batch 5] Current Loss: 4.4715\n",
            "[Batch 6] Current Loss: 4.3638\n",
            "[Batch 7] Current Loss: 4.8372\n",
            "[Batch 8] Current Loss: 4.9094\n",
            "[Batch 9] Current Loss: 4.6076\n",
            "[Batch 0] Current Loss: 6.0116\n",
            "[Batch 1] Current Loss: 5.4465\n",
            "[Batch 2] Current Loss: 5.1762\n",
            "[Batch 3] Current Loss: 5.2958\n",
            "[Batch 4] Current Loss: 5.4320\n",
            "[Batch 5] Current Loss: 5.1834\n",
            "[Batch 6] Current Loss: 5.5277\n",
            "[Batch 7] Current Loss: 4.8274\n",
            "[Batch 8] Current Loss: 5.4611\n",
            "[Batch 9] Current Loss: 4.9144\n",
            "Ep 1 (Step 007760): Train loss 4.729, Val loss 5.328\n",
            "[Batch 0] Current Loss: 4.6022\n",
            "[Batch 1] Current Loss: 4.3396\n",
            "[Batch 2] Current Loss: 4.9728\n",
            "[Batch 3] Current Loss: 4.7018\n",
            "[Batch 4] Current Loss: 4.6906\n",
            "[Batch 5] Current Loss: 4.2779\n",
            "[Batch 6] Current Loss: 5.1078\n",
            "[Batch 7] Current Loss: 4.4354\n",
            "[Batch 8] Current Loss: 4.7551\n",
            "[Batch 9] Current Loss: 4.2713\n",
            "[Batch 0] Current Loss: 5.0291\n",
            "[Batch 1] Current Loss: 5.1345\n",
            "[Batch 2] Current Loss: 5.4437\n",
            "[Batch 3] Current Loss: 4.8737\n",
            "[Batch 4] Current Loss: 4.9356\n",
            "[Batch 5] Current Loss: 5.8072\n",
            "[Batch 6] Current Loss: 5.4564\n",
            "[Batch 7] Current Loss: 5.5963\n",
            "[Batch 8] Current Loss: 4.7080\n",
            "[Batch 9] Current Loss: 5.1521\n",
            "Ep 1 (Step 007780): Train loss 4.615, Val loss 5.214\n",
            "[Batch 0] Current Loss: 5.2115\n",
            "[Batch 1] Current Loss: 3.8058\n",
            "[Batch 2] Current Loss: 4.9572\n",
            "[Batch 3] Current Loss: 4.2236\n",
            "[Batch 4] Current Loss: 4.9234\n",
            "[Batch 5] Current Loss: 4.5360\n",
            "[Batch 6] Current Loss: 4.5620\n",
            "[Batch 7] Current Loss: 4.5309\n",
            "[Batch 8] Current Loss: 4.5425\n",
            "[Batch 9] Current Loss: 4.2678\n",
            "[Batch 0] Current Loss: 5.3068\n",
            "[Batch 1] Current Loss: 4.8341\n",
            "[Batch 2] Current Loss: 4.5252\n",
            "[Batch 3] Current Loss: 5.8369\n",
            "[Batch 4] Current Loss: 5.0902\n",
            "[Batch 5] Current Loss: 5.5406\n",
            "[Batch 6] Current Loss: 5.0138\n",
            "[Batch 7] Current Loss: 5.1420\n",
            "[Batch 8] Current Loss: 5.6087\n",
            "[Batch 9] Current Loss: 5.3047\n",
            "Ep 1 (Step 007800): Train loss 4.556, Val loss 5.220\n",
            "[Batch 0] Current Loss: 5.1050\n",
            "[Batch 1] Current Loss: 4.6831\n",
            "[Batch 2] Current Loss: 4.5516\n",
            "[Batch 3] Current Loss: 5.0899\n",
            "[Batch 4] Current Loss: 4.3925\n",
            "[Batch 5] Current Loss: 4.3802\n",
            "[Batch 6] Current Loss: 4.7900\n",
            "[Batch 7] Current Loss: 5.0347\n",
            "[Batch 8] Current Loss: 4.2799\n",
            "[Batch 9] Current Loss: 4.8387\n",
            "[Batch 0] Current Loss: 5.3174\n",
            "[Batch 1] Current Loss: 5.0087\n",
            "[Batch 2] Current Loss: 4.9754\n",
            "[Batch 3] Current Loss: 5.2103\n",
            "[Batch 4] Current Loss: 5.7194\n",
            "[Batch 5] Current Loss: 5.3521\n",
            "[Batch 6] Current Loss: 5.8403\n",
            "[Batch 7] Current Loss: 5.5601\n",
            "[Batch 8] Current Loss: 5.1180\n",
            "[Batch 9] Current Loss: 5.6989\n",
            "Ep 1 (Step 007820): Train loss 4.715, Val loss 5.380\n",
            "[Batch 0] Current Loss: 4.4840\n",
            "[Batch 1] Current Loss: 4.0937\n",
            "[Batch 2] Current Loss: 5.1514\n",
            "[Batch 3] Current Loss: 4.5597\n",
            "[Batch 4] Current Loss: 4.9839\n",
            "[Batch 5] Current Loss: 3.9388\n",
            "[Batch 6] Current Loss: 4.7308\n",
            "[Batch 7] Current Loss: 4.7317\n",
            "[Batch 8] Current Loss: 4.6988\n",
            "[Batch 9] Current Loss: 4.0518\n",
            "[Batch 0] Current Loss: 5.1716\n",
            "[Batch 1] Current Loss: 4.7400\n",
            "[Batch 2] Current Loss: 4.9508\n",
            "[Batch 3] Current Loss: 5.2165\n",
            "[Batch 4] Current Loss: 5.1746\n",
            "[Batch 5] Current Loss: 5.6518\n",
            "[Batch 6] Current Loss: 4.8609\n",
            "[Batch 7] Current Loss: 4.9081\n",
            "[Batch 8] Current Loss: 4.9721\n",
            "[Batch 9] Current Loss: 4.7941\n",
            "Ep 1 (Step 007840): Train loss 4.542, Val loss 5.044\n",
            "[Batch 0] Current Loss: 4.7873\n",
            "[Batch 1] Current Loss: 4.1254\n",
            "[Batch 2] Current Loss: 4.7646\n",
            "[Batch 3] Current Loss: 4.6372\n",
            "[Batch 4] Current Loss: 4.4408\n",
            "[Batch 5] Current Loss: 4.9020\n",
            "[Batch 6] Current Loss: 4.4983\n",
            "[Batch 7] Current Loss: 4.6516\n",
            "[Batch 8] Current Loss: 4.4745\n",
            "[Batch 9] Current Loss: 4.5990\n",
            "[Batch 0] Current Loss: 5.4193\n",
            "[Batch 1] Current Loss: 5.8318\n",
            "[Batch 2] Current Loss: 5.0476\n",
            "[Batch 3] Current Loss: 5.5467\n",
            "[Batch 4] Current Loss: 5.1561\n",
            "[Batch 5] Current Loss: 4.9594\n",
            "[Batch 6] Current Loss: 5.0902\n",
            "[Batch 7] Current Loss: 5.0957\n",
            "[Batch 8] Current Loss: 5.1511\n",
            "[Batch 9] Current Loss: 5.3367\n",
            "Ep 1 (Step 007860): Train loss 4.588, Val loss 5.263\n",
            "[Batch 0] Current Loss: 4.4690\n",
            "[Batch 1] Current Loss: 4.4529\n",
            "[Batch 2] Current Loss: 4.9288\n",
            "[Batch 3] Current Loss: 4.6162\n",
            "[Batch 4] Current Loss: 4.7133\n",
            "[Batch 5] Current Loss: 5.0367\n",
            "[Batch 6] Current Loss: 4.6937\n",
            "[Batch 7] Current Loss: 4.3298\n",
            "[Batch 8] Current Loss: 4.8686\n",
            "[Batch 9] Current Loss: 4.6169\n",
            "[Batch 0] Current Loss: 6.1261\n",
            "[Batch 1] Current Loss: 5.2772\n",
            "[Batch 2] Current Loss: 5.0716\n",
            "[Batch 3] Current Loss: 5.4700\n",
            "[Batch 4] Current Loss: 4.9644\n",
            "[Batch 5] Current Loss: 5.6483\n",
            "[Batch 6] Current Loss: 4.7857\n",
            "[Batch 7] Current Loss: 5.0115\n",
            "[Batch 8] Current Loss: 5.3349\n",
            "[Batch 9] Current Loss: 6.0953\n",
            "Ep 1 (Step 007880): Train loss 4.673, Val loss 5.379\n",
            "[Batch 0] Current Loss: 4.6610\n",
            "[Batch 1] Current Loss: 3.9956\n",
            "[Batch 2] Current Loss: 4.0891\n",
            "[Batch 3] Current Loss: 4.0796\n",
            "[Batch 4] Current Loss: 4.6872\n",
            "[Batch 5] Current Loss: 4.6192\n",
            "[Batch 6] Current Loss: 4.6932\n",
            "[Batch 7] Current Loss: 4.6436\n",
            "[Batch 8] Current Loss: 4.3131\n",
            "[Batch 9] Current Loss: 4.8655\n",
            "[Batch 0] Current Loss: 5.4883\n",
            "[Batch 1] Current Loss: 5.1593\n",
            "[Batch 2] Current Loss: 5.2322\n",
            "[Batch 3] Current Loss: 5.5454\n",
            "[Batch 4] Current Loss: 5.3239\n",
            "[Batch 5] Current Loss: 5.1433\n",
            "[Batch 6] Current Loss: 5.1154\n",
            "[Batch 7] Current Loss: 4.4141\n",
            "[Batch 8] Current Loss: 5.3515\n",
            "[Batch 9] Current Loss: 4.9534\n",
            "Ep 1 (Step 007900): Train loss 4.465, Val loss 5.173\n",
            "[Batch 0] Current Loss: 4.7146\n",
            "[Batch 1] Current Loss: 4.5174\n",
            "[Batch 2] Current Loss: 4.1368\n",
            "[Batch 3] Current Loss: 4.3167\n",
            "[Batch 4] Current Loss: 4.4473\n",
            "[Batch 5] Current Loss: 4.4463\n",
            "[Batch 6] Current Loss: 4.6759\n",
            "[Batch 7] Current Loss: 4.5776\n",
            "[Batch 8] Current Loss: 4.1401\n",
            "[Batch 9] Current Loss: 4.4250\n",
            "[Batch 0] Current Loss: 5.4599\n",
            "[Batch 1] Current Loss: 4.7104\n",
            "[Batch 2] Current Loss: 5.1446\n",
            "[Batch 3] Current Loss: 5.8536\n",
            "[Batch 4] Current Loss: 5.5984\n",
            "[Batch 5] Current Loss: 5.6236\n",
            "[Batch 6] Current Loss: 5.5402\n",
            "[Batch 7] Current Loss: 5.4507\n",
            "[Batch 8] Current Loss: 5.5475\n",
            "[Batch 9] Current Loss: 4.8233\n",
            "Ep 1 (Step 007920): Train loss 4.440, Val loss 5.375\n",
            "[Batch 0] Current Loss: 4.5984\n",
            "[Batch 1] Current Loss: 4.6288\n",
            "[Batch 2] Current Loss: 4.6678\n",
            "[Batch 3] Current Loss: 4.5821\n",
            "[Batch 4] Current Loss: 4.6455\n",
            "[Batch 5] Current Loss: 4.6309\n",
            "[Batch 6] Current Loss: 4.4700\n",
            "[Batch 7] Current Loss: 4.4487\n",
            "[Batch 8] Current Loss: 4.7104\n",
            "[Batch 9] Current Loss: 4.6103\n",
            "[Batch 0] Current Loss: 5.5397\n",
            "[Batch 1] Current Loss: 4.6956\n",
            "[Batch 2] Current Loss: 5.1062\n",
            "[Batch 3] Current Loss: 5.1316\n",
            "[Batch 4] Current Loss: 5.4486\n",
            "[Batch 5] Current Loss: 5.4229\n",
            "[Batch 6] Current Loss: 5.4878\n",
            "[Batch 7] Current Loss: 5.3866\n",
            "[Batch 8] Current Loss: 5.7049\n",
            "[Batch 9] Current Loss: 5.5109\n",
            "Ep 1 (Step 007940): Train loss 4.599, Val loss 5.343\n",
            "[Batch 0] Current Loss: 5.0716\n",
            "[Batch 1] Current Loss: 4.9864\n",
            "[Batch 2] Current Loss: 4.3596\n",
            "[Batch 3] Current Loss: 4.6425\n",
            "[Batch 4] Current Loss: 4.4733\n",
            "[Batch 5] Current Loss: 3.9381\n",
            "[Batch 6] Current Loss: 4.5024\n",
            "[Batch 7] Current Loss: 4.4091\n",
            "[Batch 8] Current Loss: 4.5286\n",
            "[Batch 9] Current Loss: 4.6176\n",
            "[Batch 0] Current Loss: 5.2270\n",
            "[Batch 1] Current Loss: 5.4714\n",
            "[Batch 2] Current Loss: 5.4434\n",
            "[Batch 3] Current Loss: 5.7520\n",
            "[Batch 4] Current Loss: 5.4651\n",
            "[Batch 5] Current Loss: 5.4409\n",
            "[Batch 6] Current Loss: 5.3428\n",
            "[Batch 7] Current Loss: 4.8554\n",
            "[Batch 8] Current Loss: 5.1589\n",
            "[Batch 9] Current Loss: 5.9586\n",
            "Ep 1 (Step 007960): Train loss 4.553, Val loss 5.412\n",
            "[Batch 0] Current Loss: 4.5339\n",
            "[Batch 1] Current Loss: 4.2390\n",
            "[Batch 2] Current Loss: 4.4300\n",
            "[Batch 3] Current Loss: 4.6058\n",
            "[Batch 4] Current Loss: 4.9485\n",
            "[Batch 5] Current Loss: 4.6893\n",
            "[Batch 6] Current Loss: 4.6715\n",
            "[Batch 7] Current Loss: 4.3417\n",
            "[Batch 8] Current Loss: 4.8134\n",
            "[Batch 9] Current Loss: 4.7311\n",
            "[Batch 0] Current Loss: 5.7704\n",
            "[Batch 1] Current Loss: 5.3071\n",
            "[Batch 2] Current Loss: 5.1008\n",
            "[Batch 3] Current Loss: 5.4898\n",
            "[Batch 4] Current Loss: 5.1391\n",
            "[Batch 5] Current Loss: 5.6691\n",
            "[Batch 6] Current Loss: 5.4681\n",
            "[Batch 7] Current Loss: 5.0617\n",
            "[Batch 8] Current Loss: 5.7652\n",
            "[Batch 9] Current Loss: 4.7202\n",
            "Ep 1 (Step 007980): Train loss 4.600, Val loss 5.349\n",
            "[Batch 0] Current Loss: 4.6713\n",
            "[Batch 1] Current Loss: 4.2782\n",
            "[Batch 2] Current Loss: 4.6279\n",
            "[Batch 3] Current Loss: 4.5762\n",
            "[Batch 4] Current Loss: 4.1582\n",
            "[Batch 5] Current Loss: 3.9330\n",
            "[Batch 6] Current Loss: 4.2723\n",
            "[Batch 7] Current Loss: 4.3095\n",
            "[Batch 8] Current Loss: 4.6770\n",
            "[Batch 9] Current Loss: 4.4572\n",
            "[Batch 0] Current Loss: 5.7020\n",
            "[Batch 1] Current Loss: 4.8890\n",
            "[Batch 2] Current Loss: 5.8763\n",
            "[Batch 3] Current Loss: 5.3470\n",
            "[Batch 4] Current Loss: 5.1576\n",
            "[Batch 5] Current Loss: 5.5557\n",
            "[Batch 6] Current Loss: 5.0782\n",
            "[Batch 7] Current Loss: 5.2440\n",
            "[Batch 8] Current Loss: 5.0878\n",
            "[Batch 9] Current Loss: 5.4577\n",
            "Ep 1 (Step 008000): Train loss 4.396, Val loss 5.340\n",
            "[Batch 0] Current Loss: 5.2547\n",
            "[Batch 1] Current Loss: 4.4623\n",
            "[Batch 2] Current Loss: 4.3789\n",
            "[Batch 3] Current Loss: 4.1781\n",
            "[Batch 4] Current Loss: 4.6745\n",
            "[Batch 5] Current Loss: 4.3577\n",
            "[Batch 6] Current Loss: 4.8457\n",
            "[Batch 7] Current Loss: 4.3215\n",
            "[Batch 8] Current Loss: 3.9354\n",
            "[Batch 9] Current Loss: 4.1382\n",
            "[Batch 0] Current Loss: 5.2084\n",
            "[Batch 1] Current Loss: 4.7362\n",
            "[Batch 2] Current Loss: 4.9584\n",
            "[Batch 3] Current Loss: 5.4338\n",
            "[Batch 4] Current Loss: 4.9531\n",
            "[Batch 5] Current Loss: 5.2823\n",
            "[Batch 6] Current Loss: 5.5179\n",
            "[Batch 7] Current Loss: 5.2887\n",
            "[Batch 8] Current Loss: 5.4341\n",
            "[Batch 9] Current Loss: 5.5405\n",
            "Ep 1 (Step 008020): Train loss 4.455, Val loss 5.235\n",
            "[Batch 0] Current Loss: 4.3472\n",
            "[Batch 1] Current Loss: 4.3573\n",
            "[Batch 2] Current Loss: 4.8169\n",
            "[Batch 3] Current Loss: 4.8188\n",
            "[Batch 4] Current Loss: 4.1374\n",
            "[Batch 5] Current Loss: 3.9719\n",
            "[Batch 6] Current Loss: 3.9860\n",
            "[Batch 7] Current Loss: 4.5420\n",
            "[Batch 8] Current Loss: 4.4958\n",
            "[Batch 9] Current Loss: 3.8123\n",
            "[Batch 0] Current Loss: 5.4131\n",
            "[Batch 1] Current Loss: 5.4039\n",
            "[Batch 2] Current Loss: 4.8835\n",
            "[Batch 3] Current Loss: 4.9615\n",
            "[Batch 4] Current Loss: 5.3721\n",
            "[Batch 5] Current Loss: 5.3635\n",
            "[Batch 6] Current Loss: 5.4791\n",
            "[Batch 7] Current Loss: 5.4487\n",
            "[Batch 8] Current Loss: 5.3035\n",
            "[Batch 9] Current Loss: 5.0335\n",
            "Ep 1 (Step 008040): Train loss 4.329, Val loss 5.266\n",
            "[Batch 0] Current Loss: 4.7002\n",
            "[Batch 1] Current Loss: 4.4365\n",
            "[Batch 2] Current Loss: 4.4690\n",
            "[Batch 3] Current Loss: 4.8125\n",
            "[Batch 4] Current Loss: 4.4460\n",
            "[Batch 5] Current Loss: 4.6653\n",
            "[Batch 6] Current Loss: 4.1702\n",
            "[Batch 7] Current Loss: 4.7567\n",
            "[Batch 8] Current Loss: 4.3529\n",
            "[Batch 9] Current Loss: 4.4004\n",
            "[Batch 0] Current Loss: 5.5855\n",
            "[Batch 1] Current Loss: 4.4671\n",
            "[Batch 2] Current Loss: 5.3110\n",
            "[Batch 3] Current Loss: 5.3280\n",
            "[Batch 4] Current Loss: 4.7153\n",
            "[Batch 5] Current Loss: 5.6415\n",
            "[Batch 6] Current Loss: 5.2686\n",
            "[Batch 7] Current Loss: 5.2801\n",
            "[Batch 8] Current Loss: 5.8625\n",
            "[Batch 9] Current Loss: 4.9299\n",
            "Ep 1 (Step 008060): Train loss 4.521, Val loss 5.239\n",
            "[Batch 0] Current Loss: 4.6163\n",
            "[Batch 1] Current Loss: 4.4800\n",
            "[Batch 2] Current Loss: 4.1874\n",
            "[Batch 3] Current Loss: 4.7825\n",
            "[Batch 4] Current Loss: 4.0396\n",
            "[Batch 5] Current Loss: 4.4926\n",
            "[Batch 6] Current Loss: 4.3907\n",
            "[Batch 7] Current Loss: 4.4599\n",
            "[Batch 8] Current Loss: 4.1895\n",
            "[Batch 9] Current Loss: 4.5784\n",
            "[Batch 0] Current Loss: 6.2905\n",
            "[Batch 1] Current Loss: 5.0837\n",
            "[Batch 2] Current Loss: 5.1975\n",
            "[Batch 3] Current Loss: 5.5163\n",
            "[Batch 4] Current Loss: 5.2402\n",
            "[Batch 5] Current Loss: 4.8533\n",
            "[Batch 6] Current Loss: 5.4196\n",
            "[Batch 7] Current Loss: 5.5776\n",
            "[Batch 8] Current Loss: 5.6447\n",
            "[Batch 9] Current Loss: 4.9266\n",
            "Ep 1 (Step 008080): Train loss 4.422, Val loss 5.375\n",
            "[Batch 0] Current Loss: 4.1155\n",
            "[Batch 1] Current Loss: 5.1038\n",
            "[Batch 2] Current Loss: 4.2830\n",
            "[Batch 3] Current Loss: 4.2372\n",
            "[Batch 4] Current Loss: 4.6195\n",
            "[Batch 5] Current Loss: 4.5056\n",
            "[Batch 6] Current Loss: 4.6201\n",
            "[Batch 7] Current Loss: 4.1481\n",
            "[Batch 8] Current Loss: 3.8000\n",
            "[Batch 9] Current Loss: 4.7780\n",
            "[Batch 0] Current Loss: 5.0219\n",
            "[Batch 1] Current Loss: 5.2478\n",
            "[Batch 2] Current Loss: 5.1110\n",
            "[Batch 3] Current Loss: 5.9823\n",
            "[Batch 4] Current Loss: 5.7218\n",
            "[Batch 5] Current Loss: 5.2673\n",
            "[Batch 6] Current Loss: 4.4755\n",
            "[Batch 7] Current Loss: 5.7161\n",
            "[Batch 8] Current Loss: 5.9791\n",
            "[Batch 9] Current Loss: 5.3620\n",
            "Ep 1 (Step 008100): Train loss 4.421, Val loss 5.388\n",
            "[Batch 0] Current Loss: 4.7548\n",
            "[Batch 1] Current Loss: 4.3765\n",
            "[Batch 2] Current Loss: 4.3200\n",
            "[Batch 3] Current Loss: 4.7754\n",
            "[Batch 4] Current Loss: 4.3957\n",
            "[Batch 5] Current Loss: 4.0947\n",
            "[Batch 6] Current Loss: 4.4844\n",
            "[Batch 7] Current Loss: 4.9024\n",
            "[Batch 8] Current Loss: 4.4825\n",
            "[Batch 9] Current Loss: 4.6031\n",
            "[Batch 0] Current Loss: 5.6001\n",
            "[Batch 1] Current Loss: 5.1181\n",
            "[Batch 2] Current Loss: 5.3721\n",
            "[Batch 3] Current Loss: 5.5632\n",
            "[Batch 4] Current Loss: 5.1551\n",
            "[Batch 5] Current Loss: 5.1574\n",
            "[Batch 6] Current Loss: 5.3073\n",
            "[Batch 7] Current Loss: 5.4145\n",
            "[Batch 8] Current Loss: 5.4672\n",
            "[Batch 9] Current Loss: 5.3916\n",
            "Ep 1 (Step 008120): Train loss 4.519, Val loss 5.355\n",
            "[Batch 0] Current Loss: 3.9841\n",
            "[Batch 1] Current Loss: 4.7242\n",
            "[Batch 2] Current Loss: 4.5219\n",
            "[Batch 3] Current Loss: 4.5742\n",
            "[Batch 4] Current Loss: 4.9203\n",
            "[Batch 5] Current Loss: 4.0854\n",
            "[Batch 6] Current Loss: 4.5760\n",
            "[Batch 7] Current Loss: 4.4592\n",
            "[Batch 8] Current Loss: 4.5441\n",
            "[Batch 9] Current Loss: 4.5030\n",
            "[Batch 0] Current Loss: 4.8140\n",
            "[Batch 1] Current Loss: 5.3525\n",
            "[Batch 2] Current Loss: 5.0073\n",
            "[Batch 3] Current Loss: 5.9131\n",
            "[Batch 4] Current Loss: 5.2594\n",
            "[Batch 5] Current Loss: 5.4324\n",
            "[Batch 6] Current Loss: 4.7145\n",
            "[Batch 7] Current Loss: 5.3707\n",
            "[Batch 8] Current Loss: 5.3164\n",
            "[Batch 9] Current Loss: 4.8966\n",
            "Ep 1 (Step 008140): Train loss 4.489, Val loss 5.208\n",
            "[Batch 0] Current Loss: 4.1508\n",
            "[Batch 1] Current Loss: 4.5050\n",
            "[Batch 2] Current Loss: 4.4442\n",
            "[Batch 3] Current Loss: 4.4753\n",
            "[Batch 4] Current Loss: 4.2754\n",
            "[Batch 5] Current Loss: 4.7055\n",
            "[Batch 6] Current Loss: 5.0710\n",
            "[Batch 7] Current Loss: 4.7906\n",
            "[Batch 8] Current Loss: 4.3684\n",
            "[Batch 9] Current Loss: 4.9182\n",
            "[Batch 0] Current Loss: 5.0957\n",
            "[Batch 1] Current Loss: 5.1198\n",
            "[Batch 2] Current Loss: 5.3267\n",
            "[Batch 3] Current Loss: 5.5333\n",
            "[Batch 4] Current Loss: 5.5809\n",
            "[Batch 5] Current Loss: 5.3484\n",
            "[Batch 6] Current Loss: 6.0451\n",
            "[Batch 7] Current Loss: 5.2012\n",
            "[Batch 8] Current Loss: 4.1737\n",
            "[Batch 9] Current Loss: 5.6210\n",
            "Ep 1 (Step 008160): Train loss 4.570, Val loss 5.305\n",
            "[Batch 0] Current Loss: 4.9398\n",
            "[Batch 1] Current Loss: 4.6051\n",
            "[Batch 2] Current Loss: 4.5955\n",
            "[Batch 3] Current Loss: 4.5925\n",
            "[Batch 4] Current Loss: 4.4972\n",
            "[Batch 5] Current Loss: 5.2899\n",
            "[Batch 6] Current Loss: 4.7550\n",
            "[Batch 7] Current Loss: 4.8629\n",
            "[Batch 8] Current Loss: 3.6496\n",
            "[Batch 9] Current Loss: 4.4535\n",
            "[Batch 0] Current Loss: 5.3298\n",
            "[Batch 1] Current Loss: 4.8447\n",
            "[Batch 2] Current Loss: 5.0219\n",
            "[Batch 3] Current Loss: 5.9053\n",
            "[Batch 4] Current Loss: 5.6894\n",
            "[Batch 5] Current Loss: 5.2799\n",
            "[Batch 6] Current Loss: 5.5411\n",
            "[Batch 7] Current Loss: 4.8117\n",
            "[Batch 8] Current Loss: 4.8183\n",
            "[Batch 9] Current Loss: 5.5945\n",
            "Ep 1 (Step 008180): Train loss 4.624, Val loss 5.284\n",
            "[Batch 0] Current Loss: 4.8261\n",
            "[Batch 1] Current Loss: 4.1909\n",
            "[Batch 2] Current Loss: 4.5776\n",
            "[Batch 3] Current Loss: 4.8703\n",
            "[Batch 4] Current Loss: 4.8179\n",
            "[Batch 5] Current Loss: 4.3039\n",
            "[Batch 6] Current Loss: 4.9263\n",
            "[Batch 7] Current Loss: 4.6727\n",
            "[Batch 8] Current Loss: 4.6539\n",
            "[Batch 9] Current Loss: 4.8176\n",
            "[Batch 0] Current Loss: 5.3154\n",
            "[Batch 1] Current Loss: 5.6312\n",
            "[Batch 2] Current Loss: 5.0087\n",
            "[Batch 3] Current Loss: 5.0142\n",
            "[Batch 4] Current Loss: 5.5640\n",
            "[Batch 5] Current Loss: 5.3108\n",
            "[Batch 6] Current Loss: 5.0785\n",
            "[Batch 7] Current Loss: 5.3025\n",
            "[Batch 8] Current Loss: 5.3078\n",
            "[Batch 9] Current Loss: 5.2864\n",
            "Ep 1 (Step 008200): Train loss 4.666, Val loss 5.282\n",
            "[Batch 0] Current Loss: 4.1074\n",
            "[Batch 1] Current Loss: 4.3524\n",
            "[Batch 2] Current Loss: 4.6024\n",
            "[Batch 3] Current Loss: 5.1690\n",
            "[Batch 4] Current Loss: 4.2061\n",
            "[Batch 5] Current Loss: 4.5370\n",
            "[Batch 6] Current Loss: 4.2836\n",
            "[Batch 7] Current Loss: 5.0330\n",
            "[Batch 8] Current Loss: 4.8037\n",
            "[Batch 9] Current Loss: 4.7891\n",
            "[Batch 0] Current Loss: 5.1330\n",
            "[Batch 1] Current Loss: 5.2396\n",
            "[Batch 2] Current Loss: 5.4368\n",
            "[Batch 3] Current Loss: 5.8773\n",
            "[Batch 4] Current Loss: 5.5209\n",
            "[Batch 5] Current Loss: 5.3892\n",
            "[Batch 6] Current Loss: 5.4278\n",
            "[Batch 7] Current Loss: 5.4085\n",
            "[Batch 8] Current Loss: 4.3916\n",
            "[Batch 9] Current Loss: 5.1390\n",
            "Ep 1 (Step 008220): Train loss 4.588, Val loss 5.296\n",
            "[Batch 0] Current Loss: 4.2765\n",
            "[Batch 1] Current Loss: 4.0366\n",
            "[Batch 2] Current Loss: 4.6834\n",
            "[Batch 3] Current Loss: 4.4735\n",
            "[Batch 4] Current Loss: 4.3981\n",
            "[Batch 5] Current Loss: 4.2477\n",
            "[Batch 6] Current Loss: 4.4892\n",
            "[Batch 7] Current Loss: 3.8773\n",
            "[Batch 8] Current Loss: 3.8171\n",
            "[Batch 9] Current Loss: 4.4317\n",
            "[Batch 0] Current Loss: 5.7187\n",
            "[Batch 1] Current Loss: 4.8519\n",
            "[Batch 2] Current Loss: 5.7846\n",
            "[Batch 3] Current Loss: 4.9555\n",
            "[Batch 4] Current Loss: 4.9894\n",
            "[Batch 5] Current Loss: 5.1733\n",
            "[Batch 6] Current Loss: 5.1621\n",
            "[Batch 7] Current Loss: 5.1245\n",
            "[Batch 8] Current Loss: 5.2369\n",
            "[Batch 9] Current Loss: 4.6972\n",
            "Ep 1 (Step 008240): Train loss 4.273, Val loss 5.169\n",
            "[Batch 0] Current Loss: 4.0205\n",
            "[Batch 1] Current Loss: 4.2588\n",
            "[Batch 2] Current Loss: 4.3714\n",
            "[Batch 3] Current Loss: 4.5135\n",
            "[Batch 4] Current Loss: 4.1684\n",
            "[Batch 5] Current Loss: 4.9621\n",
            "[Batch 6] Current Loss: 4.6829\n",
            "[Batch 7] Current Loss: 4.7780\n",
            "[Batch 8] Current Loss: 4.1067\n",
            "[Batch 9] Current Loss: 4.8034\n",
            "[Batch 0] Current Loss: 5.6169\n",
            "[Batch 1] Current Loss: 5.5023\n",
            "[Batch 2] Current Loss: 4.9927\n",
            "[Batch 3] Current Loss: 5.5404\n",
            "[Batch 4] Current Loss: 5.5358\n",
            "[Batch 5] Current Loss: 6.2920\n",
            "[Batch 6] Current Loss: 5.5144\n",
            "[Batch 7] Current Loss: 4.2967\n",
            "[Batch 8] Current Loss: 5.2726\n",
            "[Batch 9] Current Loss: 4.3411\n",
            "Ep 1 (Step 008260): Train loss 4.467, Val loss 5.290\n",
            "[Batch 0] Current Loss: 4.6531\n",
            "[Batch 1] Current Loss: 3.8852\n",
            "[Batch 2] Current Loss: 4.3665\n",
            "[Batch 3] Current Loss: 4.5542\n",
            "[Batch 4] Current Loss: 3.9461\n",
            "[Batch 5] Current Loss: 4.2793\n",
            "[Batch 6] Current Loss: 4.6518\n",
            "[Batch 7] Current Loss: 4.7526\n",
            "[Batch 8] Current Loss: 3.9737\n",
            "[Batch 9] Current Loss: 4.7474\n",
            "[Batch 0] Current Loss: 5.2924\n",
            "[Batch 1] Current Loss: 5.2223\n",
            "[Batch 2] Current Loss: 4.6182\n",
            "[Batch 3] Current Loss: 5.0721\n",
            "[Batch 4] Current Loss: 5.6099\n",
            "[Batch 5] Current Loss: 5.5402\n",
            "[Batch 6] Current Loss: 4.7970\n",
            "[Batch 7] Current Loss: 4.9729\n",
            "[Batch 8] Current Loss: 4.8874\n",
            "[Batch 9] Current Loss: 4.6699\n",
            "Ep 1 (Step 008280): Train loss 4.381, Val loss 5.068\n",
            "[Batch 0] Current Loss: 3.9465\n",
            "[Batch 1] Current Loss: 4.6266\n",
            "[Batch 2] Current Loss: 4.3959\n",
            "[Batch 3] Current Loss: 4.3075\n",
            "[Batch 4] Current Loss: 4.7454\n",
            "[Batch 5] Current Loss: 4.2435\n",
            "[Batch 6] Current Loss: 4.0492\n",
            "[Batch 7] Current Loss: 4.4521\n",
            "[Batch 8] Current Loss: 4.3336\n",
            "[Batch 9] Current Loss: 4.4892\n",
            "[Batch 0] Current Loss: 5.7946\n",
            "[Batch 1] Current Loss: 5.0776\n",
            "[Batch 2] Current Loss: 5.2304\n",
            "[Batch 3] Current Loss: 5.8335\n",
            "[Batch 4] Current Loss: 4.9416\n",
            "[Batch 5] Current Loss: 5.3077\n",
            "[Batch 6] Current Loss: 5.2866\n",
            "[Batch 7] Current Loss: 5.2757\n",
            "[Batch 8] Current Loss: 5.3517\n",
            "[Batch 9] Current Loss: 5.5746\n",
            "Ep 1 (Step 008300): Train loss 4.359, Val loss 5.367\n",
            "[Batch 0] Current Loss: 4.3612\n",
            "[Batch 1] Current Loss: 4.5985\n",
            "[Batch 2] Current Loss: 4.4032\n",
            "[Batch 3] Current Loss: 5.0957\n",
            "[Batch 4] Current Loss: 4.1308\n",
            "[Batch 5] Current Loss: 3.9082\n",
            "[Batch 6] Current Loss: 4.3428\n",
            "[Batch 7] Current Loss: 3.9718\n",
            "[Batch 8] Current Loss: 4.3640\n",
            "[Batch 9] Current Loss: 4.1498\n",
            "[Batch 0] Current Loss: 5.5643\n",
            "[Batch 1] Current Loss: 4.8844\n",
            "[Batch 2] Current Loss: 5.2986\n",
            "[Batch 3] Current Loss: 5.3153\n",
            "[Batch 4] Current Loss: 4.5491\n",
            "[Batch 5] Current Loss: 5.2838\n",
            "[Batch 6] Current Loss: 5.4911\n",
            "[Batch 7] Current Loss: 5.5007\n",
            "[Batch 8] Current Loss: 5.1467\n",
            "[Batch 9] Current Loss: 5.4873\n",
            "Ep 1 (Step 008320): Train loss 4.333, Val loss 5.252\n",
            "[Batch 0] Current Loss: 4.4705\n",
            "[Batch 1] Current Loss: 4.2549\n",
            "[Batch 2] Current Loss: 4.0958\n",
            "[Batch 3] Current Loss: 4.2854\n",
            "[Batch 4] Current Loss: 4.3977\n",
            "[Batch 5] Current Loss: 4.9528\n",
            "[Batch 6] Current Loss: 4.2499\n",
            "[Batch 7] Current Loss: 4.2351\n",
            "[Batch 8] Current Loss: 4.8596\n",
            "[Batch 9] Current Loss: 4.5447\n",
            "[Batch 0] Current Loss: 4.9477\n",
            "[Batch 1] Current Loss: 5.1851\n",
            "[Batch 2] Current Loss: 5.5406\n",
            "[Batch 3] Current Loss: 5.0098\n",
            "[Batch 4] Current Loss: 5.0021\n",
            "[Batch 5] Current Loss: 5.0079\n",
            "[Batch 6] Current Loss: 6.0891\n",
            "[Batch 7] Current Loss: 5.1350\n",
            "[Batch 8] Current Loss: 5.3909\n",
            "[Batch 9] Current Loss: 5.7046\n",
            "Ep 1 (Step 008340): Train loss 4.435, Val loss 5.301\n",
            "[Batch 0] Current Loss: 4.9144\n",
            "[Batch 1] Current Loss: 4.6965\n",
            "[Batch 2] Current Loss: 4.5666\n",
            "[Batch 3] Current Loss: 4.8794\n",
            "[Batch 4] Current Loss: 4.2300\n",
            "[Batch 5] Current Loss: 4.3588\n",
            "[Batch 6] Current Loss: 4.4560\n",
            "[Batch 7] Current Loss: 4.5962\n",
            "[Batch 8] Current Loss: 4.2834\n",
            "[Batch 9] Current Loss: 4.6375\n",
            "[Batch 0] Current Loss: 5.3931\n",
            "[Batch 1] Current Loss: 4.9025\n",
            "[Batch 2] Current Loss: 5.3450\n",
            "[Batch 3] Current Loss: 5.5111\n",
            "[Batch 4] Current Loss: 5.5736\n",
            "[Batch 5] Current Loss: 5.2607\n",
            "[Batch 6] Current Loss: 5.7048\n",
            "[Batch 7] Current Loss: 5.2573\n",
            "[Batch 8] Current Loss: 5.3503\n",
            "[Batch 9] Current Loss: 5.2955\n",
            "Ep 1 (Step 008360): Train loss 4.562, Val loss 5.359\n",
            "[Batch 0] Current Loss: 4.8483\n",
            "[Batch 1] Current Loss: 4.5308\n",
            "[Batch 2] Current Loss: 4.4616\n",
            "[Batch 3] Current Loss: 4.9105\n",
            "[Batch 4] Current Loss: 5.0161\n",
            "[Batch 5] Current Loss: 4.2828\n",
            "[Batch 6] Current Loss: 4.1629\n",
            "[Batch 7] Current Loss: 4.4066\n",
            "[Batch 8] Current Loss: 4.2138\n",
            "[Batch 9] Current Loss: 4.7077\n",
            "[Batch 0] Current Loss: 5.1632\n",
            "[Batch 1] Current Loss: 5.4212\n",
            "[Batch 2] Current Loss: 6.0103\n",
            "[Batch 3] Current Loss: 4.8029\n",
            "[Batch 4] Current Loss: 4.9741\n",
            "[Batch 5] Current Loss: 5.1096\n",
            "[Batch 6] Current Loss: 4.8084\n",
            "[Batch 7] Current Loss: 5.6571\n",
            "[Batch 8] Current Loss: 4.8359\n",
            "[Batch 9] Current Loss: 5.5080\n",
            "Ep 1 (Step 008380): Train loss 4.554, Val loss 5.229\n",
            "[Batch 0] Current Loss: 4.2770\n",
            "[Batch 1] Current Loss: 4.2871\n",
            "[Batch 2] Current Loss: 3.9675\n",
            "[Batch 3] Current Loss: 4.8767\n",
            "[Batch 4] Current Loss: 4.6527\n",
            "[Batch 5] Current Loss: 4.2397\n",
            "[Batch 6] Current Loss: 4.2479\n",
            "[Batch 7] Current Loss: 3.9527\n",
            "[Batch 8] Current Loss: 4.9674\n",
            "[Batch 9] Current Loss: 4.6132\n",
            "[Batch 0] Current Loss: 5.0971\n",
            "[Batch 1] Current Loss: 5.3493\n",
            "[Batch 2] Current Loss: 5.4491\n",
            "[Batch 3] Current Loss: 4.9738\n",
            "[Batch 4] Current Loss: 5.0484\n",
            "[Batch 5] Current Loss: 5.4588\n",
            "[Batch 6] Current Loss: 5.3814\n",
            "[Batch 7] Current Loss: 5.2298\n",
            "[Batch 8] Current Loss: 5.5449\n",
            "[Batch 9] Current Loss: 5.3551\n",
            "Ep 1 (Step 008400): Train loss 4.408, Val loss 5.289\n",
            "[Batch 0] Current Loss: 4.0704\n",
            "[Batch 1] Current Loss: 4.6128\n",
            "[Batch 2] Current Loss: 4.1399\n",
            "[Batch 3] Current Loss: 4.9828\n",
            "[Batch 4] Current Loss: 4.5151\n",
            "[Batch 5] Current Loss: 3.6913\n",
            "[Batch 6] Current Loss: 4.2849\n",
            "[Batch 7] Current Loss: 4.0512\n",
            "[Batch 8] Current Loss: 4.8191\n",
            "[Batch 9] Current Loss: 5.0432\n",
            "[Batch 0] Current Loss: 5.2456\n",
            "[Batch 1] Current Loss: 5.6411\n",
            "[Batch 2] Current Loss: 5.4388\n",
            "[Batch 3] Current Loss: 5.4304\n",
            "[Batch 4] Current Loss: 5.1843\n",
            "[Batch 5] Current Loss: 5.3881\n",
            "[Batch 6] Current Loss: 5.6703\n",
            "[Batch 7] Current Loss: 5.5235\n",
            "[Batch 8] Current Loss: 5.0599\n",
            "[Batch 9] Current Loss: 5.2978\n",
            "Ep 1 (Step 008420): Train loss 4.421, Val loss 5.388\n",
            "[Batch 0] Current Loss: 4.2469\n",
            "[Batch 1] Current Loss: 3.9929\n",
            "[Batch 2] Current Loss: 4.3141\n",
            "[Batch 3] Current Loss: 3.9516\n",
            "[Batch 4] Current Loss: 4.8792\n",
            "[Batch 5] Current Loss: 4.4980\n",
            "[Batch 6] Current Loss: 4.6177\n",
            "[Batch 7] Current Loss: 3.9465\n",
            "[Batch 8] Current Loss: 4.2931\n",
            "[Batch 9] Current Loss: 4.7544\n",
            "[Batch 0] Current Loss: 5.1437\n",
            "[Batch 1] Current Loss: 4.8944\n",
            "[Batch 2] Current Loss: 5.2518\n",
            "[Batch 3] Current Loss: 5.1028\n",
            "[Batch 4] Current Loss: 5.3090\n",
            "[Batch 5] Current Loss: 4.9368\n",
            "[Batch 6] Current Loss: 5.4934\n",
            "[Batch 7] Current Loss: 5.4762\n",
            "[Batch 8] Current Loss: 4.5212\n",
            "[Batch 9] Current Loss: 5.2122\n",
            "Ep 1 (Step 008440): Train loss 4.349, Val loss 5.134\n",
            "Every effort moves you can see how you can make a little bit more comfortable with your family.  If you're feeling anxious and lonely and feel anxious about what you're feeling?  I don't know what to do.  I don't know what\n",
            "[Batch 0] Current Loss: 4.5191\n",
            "[Batch 1] Current Loss: 4.7850\n",
            "[Batch 2] Current Loss: 4.6366\n",
            "[Batch 3] Current Loss: 3.9523\n",
            "[Batch 4] Current Loss: 4.1857\n",
            "[Batch 5] Current Loss: 4.5792\n",
            "[Batch 6] Current Loss: 4.2977\n",
            "[Batch 7] Current Loss: 4.6163\n",
            "[Batch 8] Current Loss: 4.1245\n",
            "[Batch 9] Current Loss: 4.6975\n",
            "[Batch 0] Current Loss: 4.9387\n",
            "[Batch 1] Current Loss: 4.8387\n",
            "[Batch 2] Current Loss: 4.7675\n",
            "[Batch 3] Current Loss: 5.2696\n",
            "[Batch 4] Current Loss: 5.5695\n",
            "[Batch 5] Current Loss: 5.1561\n",
            "[Batch 6] Current Loss: 5.4071\n",
            "[Batch 7] Current Loss: 5.5091\n",
            "[Batch 8] Current Loss: 5.2715\n",
            "[Batch 9] Current Loss: 5.6210\n",
            "Ep 2 (Step 008460): Train loss 4.439, Val loss 5.235\n",
            "[Batch 0] Current Loss: 4.8264\n",
            "[Batch 1] Current Loss: 4.1913\n",
            "[Batch 2] Current Loss: 4.8483\n",
            "[Batch 3] Current Loss: 5.4421\n",
            "[Batch 4] Current Loss: 4.8870\n",
            "[Batch 5] Current Loss: 4.3598\n",
            "[Batch 6] Current Loss: 4.3695\n",
            "[Batch 7] Current Loss: 4.2882\n",
            "[Batch 8] Current Loss: 4.8820\n",
            "[Batch 9] Current Loss: 4.3850\n",
            "[Batch 0] Current Loss: 5.3136\n",
            "[Batch 1] Current Loss: 5.2259\n",
            "[Batch 2] Current Loss: 4.6102\n",
            "[Batch 3] Current Loss: 5.5327\n",
            "[Batch 4] Current Loss: 5.3030\n",
            "[Batch 5] Current Loss: 5.1148\n",
            "[Batch 6] Current Loss: 4.8893\n",
            "[Batch 7] Current Loss: 5.6218\n",
            "[Batch 8] Current Loss: 5.5761\n",
            "[Batch 9] Current Loss: 4.5604\n",
            "Ep 2 (Step 008480): Train loss 4.648, Val loss 5.175\n",
            "[Batch 0] Current Loss: 3.8725\n",
            "[Batch 1] Current Loss: 4.5676\n",
            "[Batch 2] Current Loss: 4.3853\n",
            "[Batch 3] Current Loss: 3.9908\n",
            "[Batch 4] Current Loss: 4.8477\n",
            "[Batch 5] Current Loss: 4.3193\n",
            "[Batch 6] Current Loss: 5.2154\n",
            "[Batch 7] Current Loss: 4.4917\n",
            "[Batch 8] Current Loss: 4.4292\n",
            "[Batch 9] Current Loss: 3.8462\n",
            "[Batch 0] Current Loss: 5.1090\n",
            "[Batch 1] Current Loss: 5.3843\n",
            "[Batch 2] Current Loss: 5.8128\n",
            "[Batch 3] Current Loss: 5.7865\n",
            "[Batch 4] Current Loss: 5.4041\n",
            "[Batch 5] Current Loss: 4.9175\n",
            "[Batch 6] Current Loss: 5.5069\n",
            "[Batch 7] Current Loss: 4.6707\n",
            "[Batch 8] Current Loss: 5.7075\n",
            "[Batch 9] Current Loss: 5.5093\n",
            "Ep 2 (Step 008500): Train loss 4.397, Val loss 5.381\n",
            "[Batch 0] Current Loss: 4.4036\n",
            "[Batch 1] Current Loss: 4.2204\n",
            "[Batch 2] Current Loss: 4.7712\n",
            "[Batch 3] Current Loss: 4.3856\n",
            "[Batch 4] Current Loss: 5.0709\n",
            "[Batch 5] Current Loss: 4.4341\n",
            "[Batch 6] Current Loss: 4.3805\n",
            "[Batch 7] Current Loss: 4.6993\n",
            "[Batch 8] Current Loss: 3.9339\n",
            "[Batch 9] Current Loss: 4.7930\n",
            "[Batch 0] Current Loss: 4.8669\n",
            "[Batch 1] Current Loss: 5.3413\n",
            "[Batch 2] Current Loss: 5.3755\n",
            "[Batch 3] Current Loss: 5.0613\n",
            "[Batch 4] Current Loss: 5.6313\n",
            "[Batch 5] Current Loss: 5.3611\n",
            "[Batch 6] Current Loss: 5.3110\n",
            "[Batch 7] Current Loss: 5.8050\n",
            "[Batch 8] Current Loss: 5.1829\n",
            "[Batch 9] Current Loss: 5.4118\n",
            "Ep 2 (Step 008520): Train loss 4.509, Val loss 5.335\n",
            "[Batch 0] Current Loss: 3.9958\n",
            "[Batch 1] Current Loss: 4.3597\n",
            "[Batch 2] Current Loss: 4.3327\n",
            "[Batch 3] Current Loss: 4.8894\n",
            "[Batch 4] Current Loss: 4.6839\n",
            "[Batch 5] Current Loss: 4.9442\n",
            "[Batch 6] Current Loss: 4.2765\n",
            "[Batch 7] Current Loss: 4.5391\n",
            "[Batch 8] Current Loss: 4.8720\n",
            "[Batch 9] Current Loss: 4.6949\n",
            "[Batch 0] Current Loss: 5.6498\n",
            "[Batch 1] Current Loss: 5.2821\n",
            "[Batch 2] Current Loss: 5.5783\n",
            "[Batch 3] Current Loss: 5.2209\n",
            "[Batch 4] Current Loss: 5.1522\n",
            "[Batch 5] Current Loss: 5.7734\n",
            "[Batch 6] Current Loss: 5.7429\n",
            "[Batch 7] Current Loss: 5.1613\n",
            "[Batch 8] Current Loss: 5.5401\n",
            "[Batch 9] Current Loss: 5.7682\n",
            "Ep 2 (Step 008540): Train loss 4.559, Val loss 5.487\n",
            "[Batch 0] Current Loss: 4.0488\n",
            "[Batch 1] Current Loss: 4.7428\n",
            "[Batch 2] Current Loss: 4.6189\n",
            "[Batch 3] Current Loss: 4.5406\n",
            "[Batch 4] Current Loss: 3.8777\n",
            "[Batch 5] Current Loss: 4.1343\n",
            "[Batch 6] Current Loss: 4.6622\n",
            "[Batch 7] Current Loss: 5.4242\n",
            "[Batch 8] Current Loss: 4.7991\n",
            "[Batch 9] Current Loss: 4.7414\n",
            "[Batch 0] Current Loss: 5.0595\n",
            "[Batch 1] Current Loss: 4.9748\n",
            "[Batch 2] Current Loss: 5.6147\n",
            "[Batch 3] Current Loss: 4.8731\n",
            "[Batch 4] Current Loss: 5.4348\n",
            "[Batch 5] Current Loss: 5.0560\n",
            "[Batch 6] Current Loss: 5.3988\n",
            "[Batch 7] Current Loss: 5.6466\n",
            "[Batch 8] Current Loss: 5.7446\n",
            "[Batch 9] Current Loss: 5.4428\n",
            "Ep 2 (Step 008560): Train loss 4.559, Val loss 5.325\n",
            "[Batch 0] Current Loss: 4.7879\n",
            "[Batch 1] Current Loss: 4.4270\n",
            "[Batch 2] Current Loss: 4.5981\n",
            "[Batch 3] Current Loss: 4.8845\n",
            "[Batch 4] Current Loss: 4.4014\n",
            "[Batch 5] Current Loss: 4.5645\n",
            "[Batch 6] Current Loss: 4.3655\n",
            "[Batch 7] Current Loss: 4.3030\n",
            "[Batch 8] Current Loss: 4.6094\n",
            "[Batch 9] Current Loss: 3.6469\n",
            "[Batch 0] Current Loss: 5.5143\n",
            "[Batch 1] Current Loss: 5.9769\n",
            "[Batch 2] Current Loss: 4.9531\n",
            "[Batch 3] Current Loss: 4.7639\n",
            "[Batch 4] Current Loss: 5.6881\n",
            "[Batch 5] Current Loss: 5.7943\n",
            "[Batch 6] Current Loss: 5.8813\n",
            "[Batch 7] Current Loss: 5.6340\n",
            "[Batch 8] Current Loss: 5.2863\n",
            "[Batch 9] Current Loss: 4.8103\n",
            "Ep 2 (Step 008580): Train loss 4.459, Val loss 5.430\n",
            "[Batch 0] Current Loss: 4.0973\n",
            "[Batch 1] Current Loss: 4.8476\n",
            "[Batch 2] Current Loss: 5.0472\n",
            "[Batch 3] Current Loss: 4.7258\n",
            "[Batch 4] Current Loss: 4.3296\n",
            "[Batch 5] Current Loss: 4.2678\n",
            "[Batch 6] Current Loss: 4.3185\n",
            "[Batch 7] Current Loss: 4.5370\n",
            "[Batch 8] Current Loss: 4.3663\n",
            "[Batch 9] Current Loss: 4.0383\n",
            "[Batch 0] Current Loss: 4.8367\n",
            "[Batch 1] Current Loss: 5.4950\n",
            "[Batch 2] Current Loss: 5.1309\n",
            "[Batch 3] Current Loss: 5.1308\n",
            "[Batch 4] Current Loss: 5.1198\n",
            "[Batch 5] Current Loss: 5.5941\n",
            "[Batch 6] Current Loss: 4.6861\n",
            "[Batch 7] Current Loss: 5.6358\n",
            "[Batch 8] Current Loss: 4.5101\n",
            "[Batch 9] Current Loss: 5.8194\n",
            "Ep 2 (Step 008600): Train loss 4.458, Val loss 5.196\n",
            "[Batch 0] Current Loss: 4.1776\n",
            "[Batch 1] Current Loss: 4.3058\n",
            "[Batch 2] Current Loss: 4.1233\n",
            "[Batch 3] Current Loss: 4.2876\n",
            "[Batch 4] Current Loss: 4.6782\n",
            "[Batch 5] Current Loss: 4.4816\n",
            "[Batch 6] Current Loss: 4.2537\n",
            "[Batch 7] Current Loss: 4.1671\n",
            "[Batch 8] Current Loss: 3.7611\n",
            "[Batch 9] Current Loss: 4.3936\n",
            "[Batch 0] Current Loss: 5.4236\n",
            "[Batch 1] Current Loss: 4.9578\n",
            "[Batch 2] Current Loss: 5.1468\n",
            "[Batch 3] Current Loss: 5.2111\n",
            "[Batch 4] Current Loss: 5.3159\n",
            "[Batch 5] Current Loss: 5.2344\n",
            "[Batch 6] Current Loss: 5.2329\n",
            "[Batch 7] Current Loss: 5.5265\n",
            "[Batch 8] Current Loss: 5.3405\n",
            "[Batch 9] Current Loss: 5.4481\n",
            "Ep 2 (Step 008620): Train loss 4.263, Val loss 5.284\n",
            "[Batch 0] Current Loss: 3.9937\n",
            "[Batch 1] Current Loss: 4.4855\n",
            "[Batch 2] Current Loss: 4.2346\n",
            "[Batch 3] Current Loss: 4.1216\n",
            "[Batch 4] Current Loss: 4.3399\n",
            "[Batch 5] Current Loss: 4.0318\n",
            "[Batch 6] Current Loss: 4.2518\n",
            "[Batch 7] Current Loss: 4.2300\n",
            "[Batch 8] Current Loss: 4.3115\n",
            "[Batch 9] Current Loss: 4.4153\n",
            "[Batch 0] Current Loss: 5.2493\n",
            "[Batch 1] Current Loss: 5.3607\n",
            "[Batch 2] Current Loss: 4.4347\n",
            "[Batch 3] Current Loss: 5.5180\n",
            "[Batch 4] Current Loss: 5.1102\n",
            "[Batch 5] Current Loss: 5.1559\n",
            "[Batch 6] Current Loss: 5.5890\n",
            "[Batch 7] Current Loss: 5.4148\n",
            "[Batch 8] Current Loss: 5.1465\n",
            "[Batch 9] Current Loss: 4.8718\n",
            "Ep 2 (Step 008640): Train loss 4.242, Val loss 5.185\n",
            "[Batch 0] Current Loss: 4.7591\n",
            "[Batch 1] Current Loss: 4.2598\n",
            "[Batch 2] Current Loss: 4.6270\n",
            "[Batch 3] Current Loss: 4.1325\n",
            "[Batch 4] Current Loss: 4.4576\n",
            "[Batch 5] Current Loss: 4.8133\n",
            "[Batch 6] Current Loss: 4.2384\n",
            "[Batch 7] Current Loss: 4.6026\n",
            "[Batch 8] Current Loss: 4.3925\n",
            "[Batch 9] Current Loss: 4.7261\n",
            "[Batch 0] Current Loss: 5.2146\n",
            "[Batch 1] Current Loss: 4.3464\n",
            "[Batch 2] Current Loss: 4.7528\n",
            "[Batch 3] Current Loss: 4.8812\n",
            "[Batch 4] Current Loss: 5.5353\n",
            "[Batch 5] Current Loss: 4.6414\n",
            "[Batch 6] Current Loss: 5.6221\n",
            "[Batch 7] Current Loss: 5.2418\n",
            "[Batch 8] Current Loss: 4.6532\n",
            "[Batch 9] Current Loss: 5.0826\n",
            "Ep 2 (Step 008660): Train loss 4.501, Val loss 4.997\n",
            "[Batch 0] Current Loss: 4.0364\n",
            "[Batch 1] Current Loss: 4.6921\n",
            "[Batch 2] Current Loss: 4.1556\n",
            "[Batch 3] Current Loss: 4.3448\n",
            "[Batch 4] Current Loss: 4.4693\n",
            "[Batch 5] Current Loss: 4.2385\n",
            "[Batch 6] Current Loss: 3.5618\n",
            "[Batch 7] Current Loss: 3.8122\n",
            "[Batch 8] Current Loss: 3.9007\n",
            "[Batch 9] Current Loss: 4.2015\n",
            "[Batch 0] Current Loss: 5.4828\n",
            "[Batch 1] Current Loss: 5.7252\n",
            "[Batch 2] Current Loss: 4.6082\n",
            "[Batch 3] Current Loss: 5.6823\n",
            "[Batch 4] Current Loss: 5.1251\n",
            "[Batch 5] Current Loss: 5.3960\n",
            "[Batch 6] Current Loss: 5.4962\n",
            "[Batch 7] Current Loss: 5.3852\n",
            "[Batch 8] Current Loss: 5.0181\n",
            "[Batch 9] Current Loss: 5.7594\n",
            "Ep 2 (Step 008680): Train loss 4.141, Val loss 5.368\n",
            "[Batch 0] Current Loss: 4.3588\n",
            "[Batch 1] Current Loss: 4.5584\n",
            "[Batch 2] Current Loss: 4.5896\n",
            "[Batch 3] Current Loss: 4.4590\n",
            "[Batch 4] Current Loss: 4.7182\n",
            "[Batch 5] Current Loss: 4.1903\n",
            "[Batch 6] Current Loss: 4.4325\n",
            "[Batch 7] Current Loss: 4.5475\n",
            "[Batch 8] Current Loss: 4.2658\n",
            "[Batch 9] Current Loss: 4.5721\n",
            "[Batch 0] Current Loss: 5.0181\n",
            "[Batch 1] Current Loss: 5.2347\n",
            "[Batch 2] Current Loss: 5.3275\n",
            "[Batch 3] Current Loss: 5.1687\n",
            "[Batch 4] Current Loss: 5.1321\n",
            "[Batch 5] Current Loss: 5.0265\n",
            "[Batch 6] Current Loss: 5.4773\n",
            "[Batch 7] Current Loss: 5.1748\n",
            "[Batch 8] Current Loss: 4.6636\n",
            "[Batch 9] Current Loss: 5.2751\n",
            "Ep 2 (Step 008700): Train loss 4.469, Val loss 5.150\n",
            "[Batch 0] Current Loss: 4.4662\n",
            "[Batch 1] Current Loss: 4.5163\n",
            "[Batch 2] Current Loss: 4.5736\n",
            "[Batch 3] Current Loss: 4.0833\n",
            "[Batch 4] Current Loss: 4.7381\n",
            "[Batch 5] Current Loss: 4.2582\n",
            "[Batch 6] Current Loss: 4.1914\n",
            "[Batch 7] Current Loss: 3.8707\n",
            "[Batch 8] Current Loss: 3.9099\n",
            "[Batch 9] Current Loss: 4.7186\n",
            "[Batch 0] Current Loss: 5.5524\n",
            "[Batch 1] Current Loss: 5.1493\n",
            "[Batch 2] Current Loss: 5.4695\n",
            "[Batch 3] Current Loss: 5.2116\n",
            "[Batch 4] Current Loss: 5.0561\n",
            "[Batch 5] Current Loss: 5.9149\n",
            "[Batch 6] Current Loss: 5.4552\n",
            "[Batch 7] Current Loss: 5.4783\n",
            "[Batch 8] Current Loss: 5.3323\n",
            "[Batch 9] Current Loss: 5.5151\n",
            "Ep 2 (Step 008720): Train loss 4.333, Val loss 5.413\n",
            "[Batch 0] Current Loss: 4.2672\n",
            "[Batch 1] Current Loss: 4.9324\n",
            "[Batch 2] Current Loss: 4.5820\n",
            "[Batch 3] Current Loss: 4.7855\n",
            "[Batch 4] Current Loss: 3.9160\n",
            "[Batch 5] Current Loss: 4.6057\n",
            "[Batch 6] Current Loss: 4.3989\n",
            "[Batch 7] Current Loss: 4.5487\n",
            "[Batch 8] Current Loss: 4.9419\n",
            "[Batch 9] Current Loss: 4.1270\n",
            "[Batch 0] Current Loss: 5.7877\n",
            "[Batch 1] Current Loss: 5.3670\n",
            "[Batch 2] Current Loss: 5.7602\n",
            "[Batch 3] Current Loss: 5.2576\n",
            "[Batch 4] Current Loss: 5.6163\n",
            "[Batch 5] Current Loss: 5.6440\n",
            "[Batch 6] Current Loss: 5.3501\n",
            "[Batch 7] Current Loss: 5.1741\n",
            "[Batch 8] Current Loss: 5.3251\n",
            "[Batch 9] Current Loss: 4.9757\n",
            "Ep 2 (Step 008740): Train loss 4.511, Val loss 5.426\n",
            "[Batch 0] Current Loss: 4.3969\n",
            "[Batch 1] Current Loss: 4.9493\n",
            "[Batch 2] Current Loss: 4.6136\n",
            "[Batch 3] Current Loss: 4.5870\n",
            "[Batch 4] Current Loss: 4.2961\n",
            "[Batch 5] Current Loss: 3.7135\n",
            "[Batch 6] Current Loss: 4.5040\n",
            "[Batch 7] Current Loss: 3.8252\n",
            "[Batch 8] Current Loss: 4.2860\n",
            "[Batch 9] Current Loss: 4.1494\n",
            "[Batch 0] Current Loss: 5.5723\n",
            "[Batch 1] Current Loss: 4.9978\n",
            "[Batch 2] Current Loss: 4.8865\n",
            "[Batch 3] Current Loss: 5.5434\n",
            "[Batch 4] Current Loss: 5.2823\n",
            "[Batch 5] Current Loss: 5.2270\n",
            "[Batch 6] Current Loss: 5.4078\n",
            "[Batch 7] Current Loss: 5.0711\n",
            "[Batch 8] Current Loss: 4.9961\n",
            "[Batch 9] Current Loss: 5.7242\n",
            "Ep 2 (Step 008760): Train loss 4.332, Val loss 5.271\n",
            "[Batch 0] Current Loss: 4.3771\n",
            "[Batch 1] Current Loss: 4.5320\n",
            "[Batch 2] Current Loss: 4.2025\n",
            "[Batch 3] Current Loss: 4.0423\n",
            "[Batch 4] Current Loss: 4.1164\n",
            "[Batch 5] Current Loss: 4.2162\n",
            "[Batch 6] Current Loss: 4.5545\n",
            "[Batch 7] Current Loss: 3.9160\n",
            "[Batch 8] Current Loss: 4.2844\n",
            "[Batch 9] Current Loss: 4.0115\n",
            "[Batch 0] Current Loss: 4.9893\n",
            "[Batch 1] Current Loss: 5.2964\n",
            "[Batch 2] Current Loss: 5.3947\n",
            "[Batch 3] Current Loss: 4.7378\n",
            "[Batch 4] Current Loss: 5.2824\n",
            "[Batch 5] Current Loss: 5.3850\n",
            "[Batch 6] Current Loss: 5.5619\n",
            "[Batch 7] Current Loss: 5.4915\n",
            "[Batch 8] Current Loss: 4.4532\n",
            "[Batch 9] Current Loss: 4.3352\n",
            "Ep 2 (Step 008780): Train loss 4.225, Val loss 5.093\n",
            "[Batch 0] Current Loss: 4.7099\n",
            "[Batch 1] Current Loss: 4.1054\n",
            "[Batch 2] Current Loss: 4.2172\n",
            "[Batch 3] Current Loss: 4.6840\n",
            "[Batch 4] Current Loss: 4.3942\n",
            "[Batch 5] Current Loss: 3.9437\n",
            "[Batch 6] Current Loss: 4.6708\n",
            "[Batch 7] Current Loss: 4.1661\n",
            "[Batch 8] Current Loss: 4.5449\n",
            "[Batch 9] Current Loss: 4.8390\n",
            "[Batch 0] Current Loss: 5.7113\n",
            "[Batch 1] Current Loss: 5.3645\n",
            "[Batch 2] Current Loss: 5.1939\n",
            "[Batch 3] Current Loss: 5.1574\n",
            "[Batch 4] Current Loss: 5.1526\n",
            "[Batch 5] Current Loss: 5.4939\n",
            "[Batch 6] Current Loss: 4.6884\n",
            "[Batch 7] Current Loss: 5.1575\n",
            "[Batch 8] Current Loss: 5.4929\n",
            "[Batch 9] Current Loss: 4.8498\n",
            "Ep 2 (Step 008800): Train loss 4.428, Val loss 5.226\n",
            "[Batch 0] Current Loss: 3.9073\n",
            "[Batch 1] Current Loss: 4.3471\n",
            "[Batch 2] Current Loss: 4.3173\n",
            "[Batch 3] Current Loss: 4.2691\n",
            "[Batch 4] Current Loss: 4.4376\n",
            "[Batch 5] Current Loss: 4.8947\n",
            "[Batch 6] Current Loss: 4.6957\n",
            "[Batch 7] Current Loss: 4.4145\n",
            "[Batch 8] Current Loss: 4.5461\n",
            "[Batch 9] Current Loss: 4.4244\n",
            "[Batch 0] Current Loss: 5.5943\n",
            "[Batch 1] Current Loss: 5.8967\n",
            "[Batch 2] Current Loss: 5.3895\n",
            "[Batch 3] Current Loss: 5.2655\n",
            "[Batch 4] Current Loss: 5.0824\n",
            "[Batch 5] Current Loss: 5.3316\n",
            "[Batch 6] Current Loss: 5.9544\n",
            "[Batch 7] Current Loss: 5.0128\n",
            "[Batch 8] Current Loss: 5.6990\n",
            "[Batch 9] Current Loss: 5.2150\n",
            "Ep 2 (Step 008820): Train loss 4.425, Val loss 5.444\n",
            "[Batch 0] Current Loss: 3.9027\n",
            "[Batch 1] Current Loss: 4.1131\n",
            "[Batch 2] Current Loss: 4.4566\n",
            "[Batch 3] Current Loss: 4.3860\n",
            "[Batch 4] Current Loss: 3.7595\n",
            "[Batch 5] Current Loss: 4.6352\n",
            "[Batch 6] Current Loss: 4.6740\n",
            "[Batch 7] Current Loss: 4.7105\n",
            "[Batch 8] Current Loss: 4.0617\n",
            "[Batch 9] Current Loss: 5.0242\n",
            "[Batch 0] Current Loss: 5.4543\n",
            "[Batch 1] Current Loss: 5.5115\n",
            "[Batch 2] Current Loss: 5.9043\n",
            "[Batch 3] Current Loss: 5.3728\n",
            "[Batch 4] Current Loss: 4.9476\n",
            "[Batch 5] Current Loss: 5.7401\n",
            "[Batch 6] Current Loss: 4.7837\n",
            "[Batch 7] Current Loss: 4.7980\n",
            "[Batch 8] Current Loss: 4.8428\n",
            "[Batch 9] Current Loss: 5.5246\n",
            "Ep 2 (Step 008840): Train loss 4.372, Val loss 5.288\n",
            "[Batch 0] Current Loss: 4.7821\n",
            "[Batch 1] Current Loss: 4.2633\n",
            "[Batch 2] Current Loss: 4.7359\n",
            "[Batch 3] Current Loss: 4.7093\n",
            "[Batch 4] Current Loss: 4.6908\n",
            "[Batch 5] Current Loss: 4.6226\n",
            "[Batch 6] Current Loss: 3.9072\n",
            "[Batch 7] Current Loss: 4.6992\n",
            "[Batch 8] Current Loss: 4.8240\n",
            "[Batch 9] Current Loss: 4.1228\n",
            "[Batch 0] Current Loss: 5.8770\n",
            "[Batch 1] Current Loss: 5.3625\n",
            "[Batch 2] Current Loss: 5.5933\n",
            "[Batch 3] Current Loss: 5.1261\n",
            "[Batch 4] Current Loss: 4.8840\n",
            "[Batch 5] Current Loss: 4.9829\n",
            "[Batch 6] Current Loss: 5.6270\n",
            "[Batch 7] Current Loss: 4.7428\n",
            "[Batch 8] Current Loss: 5.4904\n",
            "[Batch 9] Current Loss: 5.2054\n",
            "Ep 2 (Step 008860): Train loss 4.536, Val loss 5.289\n",
            "[Batch 0] Current Loss: 3.9354\n",
            "[Batch 1] Current Loss: 3.9542\n",
            "[Batch 2] Current Loss: 4.9192\n",
            "[Batch 3] Current Loss: 4.5507\n",
            "[Batch 4] Current Loss: 4.4144\n",
            "[Batch 5] Current Loss: 4.5481\n",
            "[Batch 6] Current Loss: 4.3612\n",
            "[Batch 7] Current Loss: 4.9900\n",
            "[Batch 8] Current Loss: 4.3876\n",
            "[Batch 9] Current Loss: 4.3967\n",
            "[Batch 0] Current Loss: 5.3555\n",
            "[Batch 1] Current Loss: 5.7292\n",
            "[Batch 2] Current Loss: 5.2525\n",
            "[Batch 3] Current Loss: 5.4182\n",
            "[Batch 4] Current Loss: 4.5431\n",
            "[Batch 5] Current Loss: 5.6373\n",
            "[Batch 6] Current Loss: 5.5660\n",
            "[Batch 7] Current Loss: 5.1495\n",
            "[Batch 8] Current Loss: 5.5649\n",
            "[Batch 9] Current Loss: 5.0780\n",
            "Ep 2 (Step 008880): Train loss 4.446, Val loss 5.329\n",
            "[Batch 0] Current Loss: 4.5248\n",
            "[Batch 1] Current Loss: 4.1478\n",
            "[Batch 2] Current Loss: 4.4309\n",
            "[Batch 3] Current Loss: 4.7376\n",
            "[Batch 4] Current Loss: 4.2872\n",
            "[Batch 5] Current Loss: 4.1145\n",
            "[Batch 6] Current Loss: 4.6638\n",
            "[Batch 7] Current Loss: 4.3064\n",
            "[Batch 8] Current Loss: 4.3313\n",
            "[Batch 9] Current Loss: 4.2450\n",
            "[Batch 0] Current Loss: 5.7072\n",
            "[Batch 1] Current Loss: 5.4106\n",
            "[Batch 2] Current Loss: 5.5554\n",
            "[Batch 3] Current Loss: 5.7782\n",
            "[Batch 4] Current Loss: 5.5178\n",
            "[Batch 5] Current Loss: 4.9155\n",
            "[Batch 6] Current Loss: 4.9731\n",
            "[Batch 7] Current Loss: 5.4311\n",
            "[Batch 8] Current Loss: 5.5668\n",
            "[Batch 9] Current Loss: 4.4695\n",
            "Ep 2 (Step 008900): Train loss 4.379, Val loss 5.333\n",
            "[Batch 0] Current Loss: 4.3700\n",
            "[Batch 1] Current Loss: 4.2428\n",
            "[Batch 2] Current Loss: 4.4801\n",
            "[Batch 3] Current Loss: 4.0143\n",
            "[Batch 4] Current Loss: 4.6677\n",
            "[Batch 5] Current Loss: 4.6955\n",
            "[Batch 6] Current Loss: 4.6605\n",
            "[Batch 7] Current Loss: 4.9867\n",
            "[Batch 8] Current Loss: 4.3936\n",
            "[Batch 9] Current Loss: 4.4336\n",
            "[Batch 0] Current Loss: 5.5950\n",
            "[Batch 1] Current Loss: 5.7177\n",
            "[Batch 2] Current Loss: 5.3773\n",
            "[Batch 3] Current Loss: 5.6204\n",
            "[Batch 4] Current Loss: 5.2389\n",
            "[Batch 5] Current Loss: 4.7912\n",
            "[Batch 6] Current Loss: 4.7015\n",
            "[Batch 7] Current Loss: 5.8632\n",
            "[Batch 8] Current Loss: 5.9148\n",
            "[Batch 9] Current Loss: 5.8255\n",
            "Ep 2 (Step 008920): Train loss 4.494, Val loss 5.465\n",
            "[Batch 0] Current Loss: 4.2468\n",
            "[Batch 1] Current Loss: 4.4184\n",
            "[Batch 2] Current Loss: 3.9943\n",
            "[Batch 3] Current Loss: 4.6180\n",
            "[Batch 4] Current Loss: 4.5393\n",
            "[Batch 5] Current Loss: 4.3611\n",
            "[Batch 6] Current Loss: 4.2663\n",
            "[Batch 7] Current Loss: 4.0826\n",
            "[Batch 8] Current Loss: 4.0099\n",
            "[Batch 9] Current Loss: 4.3717\n",
            "[Batch 0] Current Loss: 5.4952\n",
            "[Batch 1] Current Loss: 5.5036\n",
            "[Batch 2] Current Loss: 4.9146\n",
            "[Batch 3] Current Loss: 5.8054\n",
            "[Batch 4] Current Loss: 5.1193\n",
            "[Batch 5] Current Loss: 4.9849\n",
            "[Batch 6] Current Loss: 5.5086\n",
            "[Batch 7] Current Loss: 5.3135\n",
            "[Batch 8] Current Loss: 5.4872\n",
            "[Batch 9] Current Loss: 5.7059\n",
            "Ep 2 (Step 008940): Train loss 4.291, Val loss 5.384\n",
            "[Batch 0] Current Loss: 4.3882\n",
            "[Batch 1] Current Loss: 4.2154\n",
            "[Batch 2] Current Loss: 4.6666\n",
            "[Batch 3] Current Loss: 4.1300\n",
            "[Batch 4] Current Loss: 4.1151\n",
            "[Batch 5] Current Loss: 4.1832\n",
            "[Batch 6] Current Loss: 4.6248\n",
            "[Batch 7] Current Loss: 4.7936\n",
            "[Batch 8] Current Loss: 4.1416\n",
            "[Batch 9] Current Loss: 4.2643\n",
            "[Batch 0] Current Loss: 4.9322\n",
            "[Batch 1] Current Loss: 5.0781\n",
            "[Batch 2] Current Loss: 5.5217\n",
            "[Batch 3] Current Loss: 5.6388\n",
            "[Batch 4] Current Loss: 5.2253\n",
            "[Batch 5] Current Loss: 5.2735\n",
            "[Batch 6] Current Loss: 5.0639\n",
            "[Batch 7] Current Loss: 5.4176\n",
            "[Batch 8] Current Loss: 5.3297\n",
            "[Batch 9] Current Loss: 5.4836\n",
            "Ep 2 (Step 008960): Train loss 4.352, Val loss 5.296\n",
            "[Batch 0] Current Loss: 4.7658\n",
            "[Batch 1] Current Loss: 4.3835\n",
            "[Batch 2] Current Loss: 4.4102\n",
            "[Batch 3] Current Loss: 4.5268\n",
            "[Batch 4] Current Loss: 4.0935\n",
            "[Batch 5] Current Loss: 4.2305\n",
            "[Batch 6] Current Loss: 4.5260\n",
            "[Batch 7] Current Loss: 4.5039\n",
            "[Batch 8] Current Loss: 3.9038\n",
            "[Batch 9] Current Loss: 3.5491\n",
            "[Batch 0] Current Loss: 5.3884\n",
            "[Batch 1] Current Loss: 5.9151\n",
            "[Batch 2] Current Loss: 5.2342\n",
            "[Batch 3] Current Loss: 4.7755\n",
            "[Batch 4] Current Loss: 4.9957\n",
            "[Batch 5] Current Loss: 5.7584\n",
            "[Batch 6] Current Loss: 5.5233\n",
            "[Batch 7] Current Loss: 5.1489\n",
            "[Batch 8] Current Loss: 5.5583\n",
            "[Batch 9] Current Loss: 4.5577\n",
            "Ep 2 (Step 008980): Train loss 4.289, Val loss 5.286\n",
            "[Batch 0] Current Loss: 4.3024\n",
            "[Batch 1] Current Loss: 4.1328\n",
            "[Batch 2] Current Loss: 4.2707\n",
            "[Batch 3] Current Loss: 3.9159\n",
            "[Batch 4] Current Loss: 4.5042\n",
            "[Batch 5] Current Loss: 4.4427\n",
            "[Batch 6] Current Loss: 3.8098\n",
            "[Batch 7] Current Loss: 4.6610\n",
            "[Batch 8] Current Loss: 5.0092\n",
            "[Batch 9] Current Loss: 4.2815\n",
            "[Batch 0] Current Loss: 4.9231\n",
            "[Batch 1] Current Loss: 5.1753\n",
            "[Batch 2] Current Loss: 5.5504\n",
            "[Batch 3] Current Loss: 5.5441\n",
            "[Batch 4] Current Loss: 5.2727\n",
            "[Batch 5] Current Loss: 5.5473\n",
            "[Batch 6] Current Loss: 5.1703\n",
            "[Batch 7] Current Loss: 4.3973\n",
            "[Batch 8] Current Loss: 5.5741\n",
            "[Batch 9] Current Loss: 5.8725\n",
            "Ep 2 (Step 009000): Train loss 4.333, Val loss 5.303\n",
            "[Batch 0] Current Loss: 3.9650\n",
            "[Batch 1] Current Loss: 4.8461\n",
            "[Batch 2] Current Loss: 4.3093\n",
            "[Batch 3] Current Loss: 4.6570\n",
            "[Batch 4] Current Loss: 3.3826\n",
            "[Batch 5] Current Loss: 4.4449\n",
            "[Batch 6] Current Loss: 4.5301\n",
            "[Batch 7] Current Loss: 4.3648\n",
            "[Batch 8] Current Loss: 4.5528\n",
            "[Batch 9] Current Loss: 3.7114\n",
            "[Batch 0] Current Loss: 5.3389\n",
            "[Batch 1] Current Loss: 5.1602\n",
            "[Batch 2] Current Loss: 5.1285\n",
            "[Batch 3] Current Loss: 5.1323\n",
            "[Batch 4] Current Loss: 5.0783\n",
            "[Batch 5] Current Loss: 5.7602\n",
            "[Batch 6] Current Loss: 5.4697\n",
            "[Batch 7] Current Loss: 5.6495\n",
            "[Batch 8] Current Loss: 4.9902\n",
            "[Batch 9] Current Loss: 4.7424\n",
            "Ep 2 (Step 009020): Train loss 4.276, Val loss 5.245\n",
            "[Batch 0] Current Loss: 3.8991\n",
            "[Batch 1] Current Loss: 4.4166\n",
            "[Batch 2] Current Loss: 3.5430\n",
            "[Batch 3] Current Loss: 3.8101\n",
            "[Batch 4] Current Loss: 4.5443\n",
            "[Batch 5] Current Loss: 4.2822\n",
            "[Batch 6] Current Loss: 4.8793\n",
            "[Batch 7] Current Loss: 4.3161\n",
            "[Batch 8] Current Loss: 4.1567\n",
            "[Batch 9] Current Loss: 4.3390\n",
            "[Batch 0] Current Loss: 5.3311\n",
            "[Batch 1] Current Loss: 5.4194\n",
            "[Batch 2] Current Loss: 5.1827\n",
            "[Batch 3] Current Loss: 5.1967\n",
            "[Batch 4] Current Loss: 4.8530\n",
            "[Batch 5] Current Loss: 5.9267\n",
            "[Batch 6] Current Loss: 5.3577\n",
            "[Batch 7] Current Loss: 5.5036\n",
            "[Batch 8] Current Loss: 5.4157\n",
            "[Batch 9] Current Loss: 5.8168\n",
            "Ep 2 (Step 009040): Train loss 4.219, Val loss 5.400\n",
            "[Batch 0] Current Loss: 4.8544\n",
            "[Batch 1] Current Loss: 4.1916\n",
            "[Batch 2] Current Loss: 4.9563\n",
            "[Batch 3] Current Loss: 4.7905\n",
            "[Batch 4] Current Loss: 4.0754\n",
            "[Batch 5] Current Loss: 4.3148\n",
            "[Batch 6] Current Loss: 3.8383\n",
            "[Batch 7] Current Loss: 4.3084\n",
            "[Batch 8] Current Loss: 4.6478\n",
            "[Batch 9] Current Loss: 4.2914\n",
            "[Batch 0] Current Loss: 5.2295\n",
            "[Batch 1] Current Loss: 5.3700\n",
            "[Batch 2] Current Loss: 5.7746\n",
            "[Batch 3] Current Loss: 5.5749\n",
            "[Batch 4] Current Loss: 5.3587\n",
            "[Batch 5] Current Loss: 5.2407\n",
            "[Batch 6] Current Loss: 4.5414\n",
            "[Batch 7] Current Loss: 5.2186\n",
            "[Batch 8] Current Loss: 5.8152\n",
            "[Batch 9] Current Loss: 5.5758\n",
            "Ep 2 (Step 009060): Train loss 4.427, Val loss 5.370\n",
            "[Batch 0] Current Loss: 3.5448\n",
            "[Batch 1] Current Loss: 4.5495\n",
            "[Batch 2] Current Loss: 4.4477\n",
            "[Batch 3] Current Loss: 4.7153\n",
            "[Batch 4] Current Loss: 4.4379\n",
            "[Batch 5] Current Loss: 4.7147\n",
            "[Batch 6] Current Loss: 4.0173\n",
            "[Batch 7] Current Loss: 4.0445\n",
            "[Batch 8] Current Loss: 4.3310\n",
            "[Batch 9] Current Loss: 4.4920\n",
            "[Batch 0] Current Loss: 5.0429\n",
            "[Batch 1] Current Loss: 5.1013\n",
            "[Batch 2] Current Loss: 5.3696\n",
            "[Batch 3] Current Loss: 5.2530\n",
            "[Batch 4] Current Loss: 4.8861\n",
            "[Batch 5] Current Loss: 5.4870\n",
            "[Batch 6] Current Loss: 5.0556\n",
            "[Batch 7] Current Loss: 5.2547\n",
            "[Batch 8] Current Loss: 5.3414\n",
            "[Batch 9] Current Loss: 5.0626\n",
            "Ep 2 (Step 009080): Train loss 4.329, Val loss 5.185\n",
            "[Batch 0] Current Loss: 4.4541\n",
            "[Batch 1] Current Loss: 4.6425\n",
            "[Batch 2] Current Loss: 4.2593\n",
            "[Batch 3] Current Loss: 4.3265\n",
            "[Batch 4] Current Loss: 4.2415\n",
            "[Batch 5] Current Loss: 4.2290\n",
            "[Batch 6] Current Loss: 4.5360\n",
            "[Batch 7] Current Loss: 3.4585\n",
            "[Batch 8] Current Loss: 4.1245\n",
            "[Batch 9] Current Loss: 4.5043\n",
            "[Batch 0] Current Loss: 4.5219\n",
            "[Batch 1] Current Loss: 4.5942\n",
            "[Batch 2] Current Loss: 5.8225\n",
            "[Batch 3] Current Loss: 5.6305\n",
            "[Batch 4] Current Loss: 5.7408\n",
            "[Batch 5] Current Loss: 5.3526\n",
            "[Batch 6] Current Loss: 5.6523\n",
            "[Batch 7] Current Loss: 5.8363\n",
            "[Batch 8] Current Loss: 5.3380\n",
            "[Batch 9] Current Loss: 5.2207\n",
            "Ep 2 (Step 009100): Train loss 4.278, Val loss 5.371\n",
            "[Batch 0] Current Loss: 4.4642\n",
            "[Batch 1] Current Loss: 4.0828\n",
            "[Batch 2] Current Loss: 4.0045\n",
            "[Batch 3] Current Loss: 4.3762\n",
            "[Batch 4] Current Loss: 4.2254\n",
            "[Batch 5] Current Loss: 4.2444\n",
            "[Batch 6] Current Loss: 3.6943\n",
            "[Batch 7] Current Loss: 4.2291\n",
            "[Batch 8] Current Loss: 4.3673\n",
            "[Batch 9] Current Loss: 4.4149\n",
            "[Batch 0] Current Loss: 4.7012\n",
            "[Batch 1] Current Loss: 5.4670\n",
            "[Batch 2] Current Loss: 5.0088\n",
            "[Batch 3] Current Loss: 5.1864\n",
            "[Batch 4] Current Loss: 4.7354\n",
            "[Batch 5] Current Loss: 4.9757\n",
            "[Batch 6] Current Loss: 5.4983\n",
            "[Batch 7] Current Loss: 4.9574\n",
            "[Batch 8] Current Loss: 5.5764\n",
            "[Batch 9] Current Loss: 5.6506\n",
            "Ep 2 (Step 009120): Train loss 4.210, Val loss 5.176\n",
            "[Batch 0] Current Loss: 4.1876\n",
            "[Batch 1] Current Loss: 4.7797\n",
            "[Batch 2] Current Loss: 4.6748\n",
            "[Batch 3] Current Loss: 4.5700\n",
            "[Batch 4] Current Loss: 4.5525\n",
            "[Batch 5] Current Loss: 4.0400\n",
            "[Batch 6] Current Loss: 4.1048\n",
            "[Batch 7] Current Loss: 4.0430\n",
            "[Batch 8] Current Loss: 4.4676\n",
            "[Batch 9] Current Loss: 4.0659\n",
            "[Batch 0] Current Loss: 5.7150\n",
            "[Batch 1] Current Loss: 5.2362\n",
            "[Batch 2] Current Loss: 5.6785\n",
            "[Batch 3] Current Loss: 5.1892\n",
            "[Batch 4] Current Loss: 5.6491\n",
            "[Batch 5] Current Loss: 5.2818\n",
            "[Batch 6] Current Loss: 5.1901\n",
            "[Batch 7] Current Loss: 5.5198\n",
            "[Batch 8] Current Loss: 4.9945\n",
            "[Batch 9] Current Loss: 5.5461\n",
            "Ep 2 (Step 009140): Train loss 4.349, Val loss 5.400\n",
            "[Batch 0] Current Loss: 4.0152\n",
            "[Batch 1] Current Loss: 4.5207\n",
            "[Batch 2] Current Loss: 4.9447\n",
            "[Batch 3] Current Loss: 4.6643\n",
            "[Batch 4] Current Loss: 4.1835\n",
            "[Batch 5] Current Loss: 4.9834\n",
            "[Batch 6] Current Loss: 4.2725\n",
            "[Batch 7] Current Loss: 4.4784\n",
            "[Batch 8] Current Loss: 3.9404\n",
            "[Batch 9] Current Loss: 3.9769\n",
            "[Batch 0] Current Loss: 4.7373\n",
            "[Batch 1] Current Loss: 5.7090\n",
            "[Batch 2] Current Loss: 5.3524\n",
            "[Batch 3] Current Loss: 5.2990\n",
            "[Batch 4] Current Loss: 5.0350\n",
            "[Batch 5] Current Loss: 5.3579\n",
            "[Batch 6] Current Loss: 5.7101\n",
            "[Batch 7] Current Loss: 5.3843\n",
            "[Batch 8] Current Loss: 5.1881\n",
            "[Batch 9] Current Loss: 5.4146\n",
            "Ep 2 (Step 009160): Train loss 4.398, Val loss 5.319\n",
            "[Batch 0] Current Loss: 3.8661\n",
            "[Batch 1] Current Loss: 4.2853\n",
            "[Batch 2] Current Loss: 4.6249\n",
            "[Batch 3] Current Loss: 3.6672\n",
            "[Batch 4] Current Loss: 5.0554\n",
            "[Batch 5] Current Loss: 4.1150\n",
            "[Batch 6] Current Loss: 4.2957\n",
            "[Batch 7] Current Loss: 3.9862\n",
            "[Batch 8] Current Loss: 4.9196\n",
            "[Batch 9] Current Loss: 2.9852\n",
            "[Batch 0] Current Loss: 5.5782\n",
            "[Batch 1] Current Loss: 5.7516\n",
            "[Batch 2] Current Loss: 5.6116\n",
            "[Batch 3] Current Loss: 5.5821\n",
            "[Batch 4] Current Loss: 5.5913\n",
            "[Batch 5] Current Loss: 5.3078\n",
            "[Batch 6] Current Loss: 5.3613\n",
            "[Batch 7] Current Loss: 5.9815\n",
            "[Batch 8] Current Loss: 4.5824\n",
            "[Batch 9] Current Loss: 5.6177\n",
            "Ep 2 (Step 009180): Train loss 4.180, Val loss 5.497\n",
            "[Batch 0] Current Loss: 4.3013\n",
            "[Batch 1] Current Loss: 4.4858\n",
            "[Batch 2] Current Loss: 4.1224\n",
            "[Batch 3] Current Loss: 4.5951\n",
            "[Batch 4] Current Loss: 4.1774\n",
            "[Batch 5] Current Loss: 4.5828\n",
            "[Batch 6] Current Loss: 4.8368\n",
            "[Batch 7] Current Loss: 4.1559\n",
            "[Batch 8] Current Loss: 4.2215\n",
            "[Batch 9] Current Loss: 3.9620\n",
            "[Batch 0] Current Loss: 5.0808\n",
            "[Batch 1] Current Loss: 5.3637\n",
            "[Batch 2] Current Loss: 4.7630\n",
            "[Batch 3] Current Loss: 4.6885\n",
            "[Batch 4] Current Loss: 5.0693\n",
            "[Batch 5] Current Loss: 5.3144\n",
            "[Batch 6] Current Loss: 5.2721\n",
            "[Batch 7] Current Loss: 5.5496\n",
            "[Batch 8] Current Loss: 4.5982\n",
            "[Batch 9] Current Loss: 5.3422\n",
            "Ep 2 (Step 009200): Train loss 4.344, Val loss 5.104\n",
            "[Batch 0] Current Loss: 4.1530\n",
            "[Batch 1] Current Loss: 4.6277\n",
            "[Batch 2] Current Loss: 4.3454\n",
            "[Batch 3] Current Loss: 3.7012\n",
            "[Batch 4] Current Loss: 4.0264\n",
            "[Batch 5] Current Loss: 4.3988\n",
            "[Batch 6] Current Loss: 4.7580\n",
            "[Batch 7] Current Loss: 4.8001\n",
            "[Batch 8] Current Loss: 3.7596\n",
            "[Batch 9] Current Loss: 3.7857\n",
            "[Batch 0] Current Loss: 5.0211\n",
            "[Batch 1] Current Loss: 4.9129\n",
            "[Batch 2] Current Loss: 5.6765\n",
            "[Batch 3] Current Loss: 5.4947\n",
            "[Batch 4] Current Loss: 4.6387\n",
            "[Batch 5] Current Loss: 5.8987\n",
            "[Batch 6] Current Loss: 6.0915\n",
            "[Batch 7] Current Loss: 5.6557\n",
            "[Batch 8] Current Loss: 5.2497\n",
            "[Batch 9] Current Loss: 5.5521\n",
            "Ep 2 (Step 009220): Train loss 4.236, Val loss 5.419\n",
            "[Batch 0] Current Loss: 3.5109\n",
            "[Batch 1] Current Loss: 3.2768\n",
            "[Batch 2] Current Loss: 4.0621\n",
            "[Batch 3] Current Loss: 4.4376\n",
            "[Batch 4] Current Loss: 4.5057\n",
            "[Batch 5] Current Loss: 3.9398\n",
            "[Batch 6] Current Loss: 4.2457\n",
            "[Batch 7] Current Loss: 4.6493\n",
            "[Batch 8] Current Loss: 4.2410\n",
            "[Batch 9] Current Loss: 4.7146\n",
            "[Batch 0] Current Loss: 5.5900\n",
            "[Batch 1] Current Loss: 6.1851\n",
            "[Batch 2] Current Loss: 4.5002\n",
            "[Batch 3] Current Loss: 4.8041\n",
            "[Batch 4] Current Loss: 5.3982\n",
            "[Batch 5] Current Loss: 5.2601\n",
            "[Batch 6] Current Loss: 5.4587\n",
            "[Batch 7] Current Loss: 5.0353\n",
            "[Batch 8] Current Loss: 5.3635\n",
            "[Batch 9] Current Loss: 5.4926\n",
            "Ep 2 (Step 009240): Train loss 4.158, Val loss 5.309\n",
            "[Batch 0] Current Loss: 4.3142\n",
            "[Batch 1] Current Loss: 4.5388\n",
            "[Batch 2] Current Loss: 4.6219\n",
            "[Batch 3] Current Loss: 4.3177\n",
            "[Batch 4] Current Loss: 4.1859\n",
            "[Batch 5] Current Loss: 3.9966\n",
            "[Batch 6] Current Loss: 4.7910\n",
            "[Batch 7] Current Loss: 4.3337\n",
            "[Batch 8] Current Loss: 4.1470\n",
            "[Batch 9] Current Loss: 4.2411\n",
            "[Batch 0] Current Loss: 5.2331\n",
            "[Batch 1] Current Loss: 5.6108\n",
            "[Batch 2] Current Loss: 4.9016\n",
            "[Batch 3] Current Loss: 5.5454\n",
            "[Batch 4] Current Loss: 5.7405\n",
            "[Batch 5] Current Loss: 4.8556\n",
            "[Batch 6] Current Loss: 5.0496\n",
            "[Batch 7] Current Loss: 4.8464\n",
            "[Batch 8] Current Loss: 4.7545\n",
            "[Batch 9] Current Loss: 5.1387\n",
            "Ep 2 (Step 009260): Train loss 4.349, Val loss 5.168\n",
            "[Batch 0] Current Loss: 4.2203\n",
            "[Batch 1] Current Loss: 4.1258\n",
            "[Batch 2] Current Loss: 4.3542\n",
            "[Batch 3] Current Loss: 4.7490\n",
            "[Batch 4] Current Loss: 4.3574\n",
            "[Batch 5] Current Loss: 4.0388\n",
            "[Batch 6] Current Loss: 4.1210\n",
            "[Batch 7] Current Loss: 3.8362\n",
            "[Batch 8] Current Loss: 3.9438\n",
            "[Batch 9] Current Loss: 4.1550\n",
            "[Batch 0] Current Loss: 4.9449\n",
            "[Batch 1] Current Loss: 5.6441\n",
            "[Batch 2] Current Loss: 4.9452\n",
            "[Batch 3] Current Loss: 4.6977\n",
            "[Batch 4] Current Loss: 5.7510\n",
            "[Batch 5] Current Loss: 4.9071\n",
            "[Batch 6] Current Loss: 5.2258\n",
            "[Batch 7] Current Loss: 5.4193\n",
            "[Batch 8] Current Loss: 5.1834\n",
            "[Batch 9] Current Loss: 5.2474\n",
            "Ep 2 (Step 009280): Train loss 4.190, Val loss 5.197\n",
            "[Batch 0] Current Loss: 4.2430\n",
            "[Batch 1] Current Loss: 4.3929\n",
            "[Batch 2] Current Loss: 4.5037\n",
            "[Batch 3] Current Loss: 4.5721\n",
            "[Batch 4] Current Loss: 4.3174\n",
            "[Batch 5] Current Loss: 3.4908\n",
            "[Batch 6] Current Loss: 4.5309\n",
            "[Batch 7] Current Loss: 4.6365\n",
            "[Batch 8] Current Loss: 4.1538\n",
            "[Batch 9] Current Loss: 4.0046\n",
            "[Batch 0] Current Loss: 5.4281\n",
            "[Batch 1] Current Loss: 5.5290\n",
            "[Batch 2] Current Loss: 5.3492\n",
            "[Batch 3] Current Loss: 5.2022\n",
            "[Batch 4] Current Loss: 5.3411\n",
            "[Batch 5] Current Loss: 5.4111\n",
            "[Batch 6] Current Loss: 5.7487\n",
            "[Batch 7] Current Loss: 4.8345\n",
            "[Batch 8] Current Loss: 5.4927\n",
            "[Batch 9] Current Loss: 5.3600\n",
            "Ep 2 (Step 009300): Train loss 4.285, Val loss 5.370\n",
            "[Batch 0] Current Loss: 4.1345\n",
            "[Batch 1] Current Loss: 3.7838\n",
            "[Batch 2] Current Loss: 3.4065\n",
            "[Batch 3] Current Loss: 4.5740\n",
            "[Batch 4] Current Loss: 4.7149\n",
            "[Batch 5] Current Loss: 4.4796\n",
            "[Batch 6] Current Loss: 4.4967\n",
            "[Batch 7] Current Loss: 4.3493\n",
            "[Batch 8] Current Loss: 4.1358\n",
            "[Batch 9] Current Loss: 4.4767\n",
            "[Batch 0] Current Loss: 5.5139\n",
            "[Batch 1] Current Loss: 5.0753\n",
            "[Batch 2] Current Loss: 5.8561\n",
            "[Batch 3] Current Loss: 4.8591\n",
            "[Batch 4] Current Loss: 5.4449\n",
            "[Batch 5] Current Loss: 5.5910\n",
            "[Batch 6] Current Loss: 5.5178\n",
            "[Batch 7] Current Loss: 4.5715\n",
            "[Batch 8] Current Loss: 5.1534\n",
            "[Batch 9] Current Loss: 5.4816\n",
            "Ep 2 (Step 009320): Train loss 4.255, Val loss 5.306\n",
            "[Batch 0] Current Loss: 4.6318\n",
            "[Batch 1] Current Loss: 4.0919\n",
            "[Batch 2] Current Loss: 4.3841\n",
            "[Batch 3] Current Loss: 3.7198\n",
            "[Batch 4] Current Loss: 5.0464\n",
            "[Batch 5] Current Loss: 4.1394\n",
            "[Batch 6] Current Loss: 4.9706\n",
            "[Batch 7] Current Loss: 4.7125\n",
            "[Batch 8] Current Loss: 4.0761\n",
            "[Batch 9] Current Loss: 4.1066\n",
            "[Batch 0] Current Loss: 4.5971\n",
            "[Batch 1] Current Loss: 4.7782\n",
            "[Batch 2] Current Loss: 4.9884\n",
            "[Batch 3] Current Loss: 5.1276\n",
            "[Batch 4] Current Loss: 5.1614\n",
            "[Batch 5] Current Loss: 5.4507\n",
            "[Batch 6] Current Loss: 5.5206\n",
            "[Batch 7] Current Loss: 5.6819\n",
            "[Batch 8] Current Loss: 5.3555\n",
            "[Batch 9] Current Loss: 5.7773\n",
            "Ep 2 (Step 009340): Train loss 4.388, Val loss 5.244\n",
            "[Batch 0] Current Loss: 4.2431\n",
            "[Batch 1] Current Loss: 5.2788\n",
            "[Batch 2] Current Loss: 4.1616\n",
            "[Batch 3] Current Loss: 3.9806\n",
            "[Batch 4] Current Loss: 4.4305\n",
            "[Batch 5] Current Loss: 3.8429\n",
            "[Batch 6] Current Loss: 5.0252\n",
            "[Batch 7] Current Loss: 4.5923\n",
            "[Batch 8] Current Loss: 4.3566\n",
            "[Batch 9] Current Loss: 4.4887\n",
            "[Batch 0] Current Loss: 5.6518\n",
            "[Batch 1] Current Loss: 5.3513\n",
            "[Batch 2] Current Loss: 5.4191\n",
            "[Batch 3] Current Loss: 5.4143\n",
            "[Batch 4] Current Loss: 5.0113\n",
            "[Batch 5] Current Loss: 4.9995\n",
            "[Batch 6] Current Loss: 5.6455\n",
            "[Batch 7] Current Loss: 5.4438\n",
            "[Batch 8] Current Loss: 5.1395\n",
            "[Batch 9] Current Loss: 4.6945\n",
            "Ep 2 (Step 009360): Train loss 4.440, Val loss 5.277\n",
            "[Batch 0] Current Loss: 4.3560\n",
            "[Batch 1] Current Loss: 3.8059\n",
            "[Batch 2] Current Loss: 4.6290\n",
            "[Batch 3] Current Loss: 3.7740\n",
            "[Batch 4] Current Loss: 4.2424\n",
            "[Batch 5] Current Loss: 4.4745\n",
            "[Batch 6] Current Loss: 3.8268\n",
            "[Batch 7] Current Loss: 3.9666\n",
            "[Batch 8] Current Loss: 4.9210\n",
            "[Batch 9] Current Loss: 4.3321\n",
            "[Batch 0] Current Loss: 4.6997\n",
            "[Batch 1] Current Loss: 5.2020\n",
            "[Batch 2] Current Loss: 4.8558\n",
            "[Batch 3] Current Loss: 5.2471\n",
            "[Batch 4] Current Loss: 5.2458\n",
            "[Batch 5] Current Loss: 4.5171\n",
            "[Batch 6] Current Loss: 5.4020\n",
            "[Batch 7] Current Loss: 5.6731\n",
            "[Batch 8] Current Loss: 5.9170\n",
            "[Batch 9] Current Loss: 5.4774\n",
            "Ep 2 (Step 009380): Train loss 4.233, Val loss 5.224\n",
            "[Batch 0] Current Loss: 4.3643\n",
            "[Batch 1] Current Loss: 4.1555\n",
            "[Batch 2] Current Loss: 4.2928\n",
            "[Batch 3] Current Loss: 4.0644\n",
            "[Batch 4] Current Loss: 4.2614\n",
            "[Batch 5] Current Loss: 4.4414\n",
            "[Batch 6] Current Loss: 4.4038\n",
            "[Batch 7] Current Loss: 4.4803\n",
            "[Batch 8] Current Loss: 4.4393\n",
            "[Batch 9] Current Loss: 4.6217\n",
            "[Batch 0] Current Loss: 5.8786\n",
            "[Batch 1] Current Loss: 5.3140\n",
            "[Batch 2] Current Loss: 5.5811\n",
            "[Batch 3] Current Loss: 5.3243\n",
            "[Batch 4] Current Loss: 5.6866\n",
            "[Batch 5] Current Loss: 5.1036\n",
            "[Batch 6] Current Loss: 4.4706\n",
            "[Batch 7] Current Loss: 4.9220\n",
            "[Batch 8] Current Loss: 5.4230\n",
            "[Batch 9] Current Loss: 4.5665\n",
            "Ep 2 (Step 009400): Train loss 4.352, Val loss 5.227\n",
            "[Batch 0] Current Loss: 4.5543\n",
            "[Batch 1] Current Loss: 4.1999\n",
            "[Batch 2] Current Loss: 3.9566\n",
            "[Batch 3] Current Loss: 4.7047\n",
            "[Batch 4] Current Loss: 4.3510\n",
            "[Batch 5] Current Loss: 4.7624\n",
            "[Batch 6] Current Loss: 4.4538\n",
            "[Batch 7] Current Loss: 3.5995\n",
            "[Batch 8] Current Loss: 4.5153\n",
            "[Batch 9] Current Loss: 4.8608\n",
            "[Batch 0] Current Loss: 5.5484\n",
            "[Batch 1] Current Loss: 5.0430\n",
            "[Batch 2] Current Loss: 6.0490\n",
            "[Batch 3] Current Loss: 5.8073\n",
            "[Batch 4] Current Loss: 5.6120\n",
            "[Batch 5] Current Loss: 5.2461\n",
            "[Batch 6] Current Loss: 5.4161\n",
            "[Batch 7] Current Loss: 5.5210\n",
            "[Batch 8] Current Loss: 4.9661\n",
            "[Batch 9] Current Loss: 5.4987\n",
            "Ep 2 (Step 009420): Train loss 4.396, Val loss 5.471\n",
            "[Batch 0] Current Loss: 4.4616\n",
            "[Batch 1] Current Loss: 4.1183\n",
            "[Batch 2] Current Loss: 4.4770\n",
            "[Batch 3] Current Loss: 4.3793\n",
            "[Batch 4] Current Loss: 4.6061\n",
            "[Batch 5] Current Loss: 3.9231\n",
            "[Batch 6] Current Loss: 4.1219\n",
            "[Batch 7] Current Loss: 3.7987\n",
            "[Batch 8] Current Loss: 3.9848\n",
            "[Batch 9] Current Loss: 4.4757\n",
            "[Batch 0] Current Loss: 4.7281\n",
            "[Batch 1] Current Loss: 5.5030\n",
            "[Batch 2] Current Loss: 5.0248\n",
            "[Batch 3] Current Loss: 5.3400\n",
            "[Batch 4] Current Loss: 5.2685\n",
            "[Batch 5] Current Loss: 4.8410\n",
            "[Batch 6] Current Loss: 5.3626\n",
            "[Batch 7] Current Loss: 4.7211\n",
            "[Batch 8] Current Loss: 5.0077\n",
            "[Batch 9] Current Loss: 5.9418\n",
            "Ep 2 (Step 009440): Train loss 4.235, Val loss 5.174\n",
            "[Batch 0] Current Loss: 4.5996\n",
            "[Batch 1] Current Loss: 4.1274\n",
            "[Batch 2] Current Loss: 3.9244\n",
            "[Batch 3] Current Loss: 4.6661\n",
            "[Batch 4] Current Loss: 4.3767\n",
            "[Batch 5] Current Loss: 4.6460\n",
            "[Batch 6] Current Loss: 3.8029\n",
            "[Batch 7] Current Loss: 4.4698\n",
            "[Batch 8] Current Loss: 4.8903\n",
            "[Batch 9] Current Loss: 4.5515\n",
            "[Batch 0] Current Loss: 5.6102\n",
            "[Batch 1] Current Loss: 5.1742\n",
            "[Batch 2] Current Loss: 5.6109\n",
            "[Batch 3] Current Loss: 5.0942\n",
            "[Batch 4] Current Loss: 4.8825\n",
            "[Batch 5] Current Loss: 4.9429\n",
            "[Batch 6] Current Loss: 5.8359\n",
            "[Batch 7] Current Loss: 5.2061\n",
            "[Batch 8] Current Loss: 5.5597\n",
            "[Batch 9] Current Loss: 4.4765\n",
            "Ep 2 (Step 009460): Train loss 4.405, Val loss 5.239\n",
            "[Batch 0] Current Loss: 4.1239\n",
            "[Batch 1] Current Loss: 5.0476\n",
            "[Batch 2] Current Loss: 4.3733\n",
            "[Batch 3] Current Loss: 3.6141\n",
            "[Batch 4] Current Loss: 4.0826\n",
            "[Batch 5] Current Loss: 4.4490\n",
            "[Batch 6] Current Loss: 4.3514\n",
            "[Batch 7] Current Loss: 4.6507\n",
            "[Batch 8] Current Loss: 4.5459\n",
            "[Batch 9] Current Loss: 4.6682\n",
            "[Batch 0] Current Loss: 5.5076\n",
            "[Batch 1] Current Loss: 5.4368\n",
            "[Batch 2] Current Loss: 4.8816\n",
            "[Batch 3] Current Loss: 5.7527\n",
            "[Batch 4] Current Loss: 5.1874\n",
            "[Batch 5] Current Loss: 5.8706\n",
            "[Batch 6] Current Loss: 5.3699\n",
            "[Batch 7] Current Loss: 5.3024\n",
            "[Batch 8] Current Loss: 5.4962\n",
            "[Batch 9] Current Loss: 5.0002\n",
            "Ep 2 (Step 009480): Train loss 4.391, Val loss 5.381\n",
            "[Batch 0] Current Loss: 4.3786\n",
            "[Batch 1] Current Loss: 4.2603\n",
            "[Batch 2] Current Loss: 4.0688\n",
            "[Batch 3] Current Loss: 3.9208\n",
            "[Batch 4] Current Loss: 4.4992\n",
            "[Batch 5] Current Loss: 4.1823\n",
            "[Batch 6] Current Loss: 4.2547\n",
            "[Batch 7] Current Loss: 4.5627\n",
            "[Batch 8] Current Loss: 4.6182\n",
            "[Batch 9] Current Loss: 4.3873\n",
            "[Batch 0] Current Loss: 4.5005\n",
            "[Batch 1] Current Loss: 5.5104\n",
            "[Batch 2] Current Loss: 5.1784\n",
            "[Batch 3] Current Loss: 5.4011\n",
            "[Batch 4] Current Loss: 5.4241\n",
            "[Batch 5] Current Loss: 4.9728\n",
            "[Batch 6] Current Loss: 4.8992\n",
            "[Batch 7] Current Loss: 5.4024\n",
            "[Batch 8] Current Loss: 5.3830\n",
            "[Batch 9] Current Loss: 5.0501\n",
            "Ep 2 (Step 009500): Train loss 4.313, Val loss 5.172\n",
            "[Batch 0] Current Loss: 4.3690\n",
            "[Batch 1] Current Loss: 3.7487\n",
            "[Batch 2] Current Loss: 4.6447\n",
            "[Batch 3] Current Loss: 4.4219\n",
            "[Batch 4] Current Loss: 3.8619\n",
            "[Batch 5] Current Loss: 4.0873\n",
            "[Batch 6] Current Loss: 4.5995\n",
            "[Batch 7] Current Loss: 4.4588\n",
            "[Batch 8] Current Loss: 3.7388\n",
            "[Batch 9] Current Loss: 4.1363\n",
            "[Batch 0] Current Loss: 5.4027\n",
            "[Batch 1] Current Loss: 4.7060\n",
            "[Batch 2] Current Loss: 4.6974\n",
            "[Batch 3] Current Loss: 6.0930\n",
            "[Batch 4] Current Loss: 5.2276\n",
            "[Batch 5] Current Loss: 5.4113\n",
            "[Batch 6] Current Loss: 5.7856\n",
            "[Batch 7] Current Loss: 5.6442\n",
            "[Batch 8] Current Loss: 5.0342\n",
            "[Batch 9] Current Loss: 5.5637\n",
            "Ep 2 (Step 009520): Train loss 4.207, Val loss 5.357\n",
            "[Batch 0] Current Loss: 3.3088\n",
            "[Batch 1] Current Loss: 4.3199\n",
            "[Batch 2] Current Loss: 4.6332\n",
            "[Batch 3] Current Loss: 4.0747\n",
            "[Batch 4] Current Loss: 4.7749\n",
            "[Batch 5] Current Loss: 4.2966\n",
            "[Batch 6] Current Loss: 3.4668\n",
            "[Batch 7] Current Loss: 4.3213\n",
            "[Batch 8] Current Loss: 4.4467\n",
            "[Batch 9] Current Loss: 4.4342\n",
            "[Batch 0] Current Loss: 5.6468\n",
            "[Batch 1] Current Loss: 5.3144\n",
            "[Batch 2] Current Loss: 5.2209\n",
            "[Batch 3] Current Loss: 5.0725\n",
            "[Batch 4] Current Loss: 5.2135\n",
            "[Batch 5] Current Loss: 4.9915\n",
            "[Batch 6] Current Loss: 5.6972\n",
            "[Batch 7] Current Loss: 5.8769\n",
            "[Batch 8] Current Loss: 5.9909\n",
            "[Batch 9] Current Loss: 4.9105\n",
            "Ep 2 (Step 009540): Train loss 4.208, Val loss 5.394\n",
            "[Batch 0] Current Loss: 4.5208\n",
            "[Batch 1] Current Loss: 4.3095\n",
            "[Batch 2] Current Loss: 4.1753\n",
            "[Batch 3] Current Loss: 4.1631\n",
            "[Batch 4] Current Loss: 4.0964\n",
            "[Batch 5] Current Loss: 4.1840\n",
            "[Batch 6] Current Loss: 4.5046\n",
            "[Batch 7] Current Loss: 4.4391\n",
            "[Batch 8] Current Loss: 3.9303\n",
            "[Batch 9] Current Loss: 4.1840\n",
            "[Batch 0] Current Loss: 5.1100\n",
            "[Batch 1] Current Loss: 5.1910\n",
            "[Batch 2] Current Loss: 5.8831\n",
            "[Batch 3] Current Loss: 4.3645\n",
            "[Batch 4] Current Loss: 4.5755\n",
            "[Batch 5] Current Loss: 5.3985\n",
            "[Batch 6] Current Loss: 5.0986\n",
            "[Batch 7] Current Loss: 5.2625\n",
            "[Batch 8] Current Loss: 5.6047\n",
            "[Batch 9] Current Loss: 5.9594\n",
            "Ep 2 (Step 009560): Train loss 4.251, Val loss 5.245\n",
            "[Batch 0] Current Loss: 4.4830\n",
            "[Batch 1] Current Loss: 4.8657\n",
            "[Batch 2] Current Loss: 4.1019\n",
            "[Batch 3] Current Loss: 4.4968\n",
            "[Batch 4] Current Loss: 4.5039\n",
            "[Batch 5] Current Loss: 4.1280\n",
            "[Batch 6] Current Loss: 3.7887\n",
            "[Batch 7] Current Loss: 4.5164\n",
            "[Batch 8] Current Loss: 4.4471\n",
            "[Batch 9] Current Loss: 4.5859\n",
            "[Batch 0] Current Loss: 4.9367\n",
            "[Batch 1] Current Loss: 5.0734\n",
            "[Batch 2] Current Loss: 5.0436\n",
            "[Batch 3] Current Loss: 4.9807\n",
            "[Batch 4] Current Loss: 4.4803\n",
            "[Batch 5] Current Loss: 5.2378\n",
            "[Batch 6] Current Loss: 4.8827\n",
            "[Batch 7] Current Loss: 5.3816\n",
            "[Batch 8] Current Loss: 4.8674\n",
            "[Batch 9] Current Loss: 5.4734\n",
            "Ep 2 (Step 009580): Train loss 4.392, Val loss 5.036\n",
            "[Batch 0] Current Loss: 3.6624\n",
            "[Batch 1] Current Loss: 4.7129\n",
            "[Batch 2] Current Loss: 3.8580\n",
            "[Batch 3] Current Loss: 4.5888\n",
            "[Batch 4] Current Loss: 4.4365\n",
            "[Batch 5] Current Loss: 3.8105\n",
            "[Batch 6] Current Loss: 4.0608\n",
            "[Batch 7] Current Loss: 4.1885\n",
            "[Batch 8] Current Loss: 4.1561\n",
            "[Batch 9] Current Loss: 4.2595\n",
            "[Batch 0] Current Loss: 5.4753\n",
            "[Batch 1] Current Loss: 5.2605\n",
            "[Batch 2] Current Loss: 5.7869\n",
            "[Batch 3] Current Loss: 5.6972\n",
            "[Batch 4] Current Loss: 5.1335\n",
            "[Batch 5] Current Loss: 5.7266\n",
            "[Batch 6] Current Loss: 5.4240\n",
            "[Batch 7] Current Loss: 5.8055\n",
            "[Batch 8] Current Loss: 4.9899\n",
            "[Batch 9] Current Loss: 4.9387\n",
            "Ep 2 (Step 009600): Train loss 4.173, Val loss 5.424\n",
            "[Batch 0] Current Loss: 3.8507\n",
            "[Batch 1] Current Loss: 5.0058\n",
            "[Batch 2] Current Loss: 4.3406\n",
            "[Batch 3] Current Loss: 4.8870\n",
            "[Batch 4] Current Loss: 3.9080\n",
            "[Batch 5] Current Loss: 4.3814\n",
            "[Batch 6] Current Loss: 4.1781\n",
            "[Batch 7] Current Loss: 3.6609\n",
            "[Batch 8] Current Loss: 4.3642\n",
            "[Batch 9] Current Loss: 4.6002\n",
            "[Batch 0] Current Loss: 5.1419\n",
            "[Batch 1] Current Loss: 4.9181\n",
            "[Batch 2] Current Loss: 5.6985\n",
            "[Batch 3] Current Loss: 5.1576\n",
            "[Batch 4] Current Loss: 5.3224\n",
            "[Batch 5] Current Loss: 5.8930\n",
            "[Batch 6] Current Loss: 5.2195\n",
            "[Batch 7] Current Loss: 5.4366\n",
            "[Batch 8] Current Loss: 5.3077\n",
            "[Batch 9] Current Loss: 5.6161\n",
            "Ep 2 (Step 009620): Train loss 4.318, Val loss 5.371\n",
            "[Batch 0] Current Loss: 4.4005\n",
            "[Batch 1] Current Loss: 3.6049\n",
            "[Batch 2] Current Loss: 3.8882\n",
            "[Batch 3] Current Loss: 4.2818\n",
            "[Batch 4] Current Loss: 4.1566\n",
            "[Batch 5] Current Loss: 4.5979\n",
            "[Batch 6] Current Loss: 3.9452\n",
            "[Batch 7] Current Loss: 4.2155\n",
            "[Batch 8] Current Loss: 3.6967\n",
            "[Batch 9] Current Loss: 3.9201\n",
            "[Batch 0] Current Loss: 5.1350\n",
            "[Batch 1] Current Loss: 4.7585\n",
            "[Batch 2] Current Loss: 5.6834\n",
            "[Batch 3] Current Loss: 4.5885\n",
            "[Batch 4] Current Loss: 5.3908\n",
            "[Batch 5] Current Loss: 4.6105\n",
            "[Batch 6] Current Loss: 5.3275\n",
            "[Batch 7] Current Loss: 6.1268\n",
            "[Batch 8] Current Loss: 5.5484\n",
            "[Batch 9] Current Loss: 5.2416\n",
            "Ep 2 (Step 009640): Train loss 4.071, Val loss 5.241\n",
            "[Batch 0] Current Loss: 3.8882\n",
            "[Batch 1] Current Loss: 4.6694\n",
            "[Batch 2] Current Loss: 4.5976\n",
            "[Batch 3] Current Loss: 4.0065\n",
            "[Batch 4] Current Loss: 4.0840\n",
            "[Batch 5] Current Loss: 4.0147\n",
            "[Batch 6] Current Loss: 4.6146\n",
            "[Batch 7] Current Loss: 4.2731\n",
            "[Batch 8] Current Loss: 4.0207\n",
            "[Batch 9] Current Loss: 4.1739\n",
            "[Batch 0] Current Loss: 5.4177\n",
            "[Batch 1] Current Loss: 5.2990\n",
            "[Batch 2] Current Loss: 5.3866\n",
            "[Batch 3] Current Loss: 5.7445\n",
            "[Batch 4] Current Loss: 5.3714\n",
            "[Batch 5] Current Loss: 5.4365\n",
            "[Batch 6] Current Loss: 4.6778\n",
            "[Batch 7] Current Loss: 5.9315\n",
            "[Batch 8] Current Loss: 4.7707\n",
            "[Batch 9] Current Loss: 4.9829\n",
            "Ep 2 (Step 009660): Train loss 4.234, Val loss 5.302\n",
            "[Batch 0] Current Loss: 4.2721\n",
            "[Batch 1] Current Loss: 4.3869\n",
            "[Batch 2] Current Loss: 4.4377\n",
            "[Batch 3] Current Loss: 4.3082\n",
            "[Batch 4] Current Loss: 3.8276\n",
            "[Batch 5] Current Loss: 3.7627\n",
            "[Batch 6] Current Loss: 3.4766\n",
            "[Batch 7] Current Loss: 4.4544\n",
            "[Batch 8] Current Loss: 3.8900\n",
            "[Batch 9] Current Loss: 4.2673\n",
            "[Batch 0] Current Loss: 4.7940\n",
            "[Batch 1] Current Loss: 5.8129\n",
            "[Batch 2] Current Loss: 5.1632\n",
            "[Batch 3] Current Loss: 4.3693\n",
            "[Batch 4] Current Loss: 5.4773\n",
            "[Batch 5] Current Loss: 4.5424\n",
            "[Batch 6] Current Loss: 5.4768\n",
            "[Batch 7] Current Loss: 5.0886\n",
            "[Batch 8] Current Loss: 5.7410\n",
            "[Batch 9] Current Loss: 5.9741\n",
            "Ep 2 (Step 009680): Train loss 4.108, Val loss 5.244\n",
            "[Batch 0] Current Loss: 3.4586\n",
            "[Batch 1] Current Loss: 3.7829\n",
            "[Batch 2] Current Loss: 4.8845\n",
            "[Batch 3] Current Loss: 4.7568\n",
            "[Batch 4] Current Loss: 4.5136\n",
            "[Batch 5] Current Loss: 4.9908\n",
            "[Batch 6] Current Loss: 4.2817\n",
            "[Batch 7] Current Loss: 3.9930\n",
            "[Batch 8] Current Loss: 4.2732\n",
            "[Batch 9] Current Loss: 4.5958\n",
            "[Batch 0] Current Loss: 5.3960\n",
            "[Batch 1] Current Loss: 5.6747\n",
            "[Batch 2] Current Loss: 5.4375\n",
            "[Batch 3] Current Loss: 5.6439\n",
            "[Batch 4] Current Loss: 5.7732\n",
            "[Batch 5] Current Loss: 4.3005\n",
            "[Batch 6] Current Loss: 5.1184\n",
            "[Batch 7] Current Loss: 5.5821\n",
            "[Batch 8] Current Loss: 4.8861\n",
            "[Batch 9] Current Loss: 4.1034\n",
            "Ep 2 (Step 009700): Train loss 4.353, Val loss 5.192\n",
            "[Batch 0] Current Loss: 4.1091\n",
            "[Batch 1] Current Loss: 4.2068\n",
            "[Batch 2] Current Loss: 4.2575\n",
            "[Batch 3] Current Loss: 3.9629\n",
            "[Batch 4] Current Loss: 4.2151\n",
            "[Batch 5] Current Loss: 4.7444\n",
            "[Batch 6] Current Loss: 4.5787\n",
            "[Batch 7] Current Loss: 4.3616\n",
            "[Batch 8] Current Loss: 3.8398\n",
            "[Batch 9] Current Loss: 4.2662\n",
            "[Batch 0] Current Loss: 5.5083\n",
            "[Batch 1] Current Loss: 6.0802\n",
            "[Batch 2] Current Loss: 5.6307\n",
            "[Batch 3] Current Loss: 5.4924\n",
            "[Batch 4] Current Loss: 5.7408\n",
            "[Batch 5] Current Loss: 5.3261\n",
            "[Batch 6] Current Loss: 5.7734\n",
            "[Batch 7] Current Loss: 5.0673\n",
            "[Batch 8] Current Loss: 5.6194\n",
            "[Batch 9] Current Loss: 4.9650\n",
            "Ep 2 (Step 009720): Train loss 4.254, Val loss 5.520\n",
            "[Batch 0] Current Loss: 3.2547\n",
            "[Batch 1] Current Loss: 4.4268\n",
            "[Batch 2] Current Loss: 4.0363\n",
            "[Batch 3] Current Loss: 4.2179\n",
            "[Batch 4] Current Loss: 4.1348\n",
            "[Batch 5] Current Loss: 3.4132\n",
            "[Batch 6] Current Loss: 4.2225\n",
            "[Batch 7] Current Loss: 3.7453\n",
            "[Batch 8] Current Loss: 4.3858\n",
            "[Batch 9] Current Loss: 4.3981\n",
            "[Batch 0] Current Loss: 5.4635\n",
            "[Batch 1] Current Loss: 4.7841\n",
            "[Batch 2] Current Loss: 5.1671\n",
            "[Batch 3] Current Loss: 4.9412\n",
            "[Batch 4] Current Loss: 5.4173\n",
            "[Batch 5] Current Loss: 4.9895\n",
            "[Batch 6] Current Loss: 5.0406\n",
            "[Batch 7] Current Loss: 4.6000\n",
            "[Batch 8] Current Loss: 5.2698\n",
            "[Batch 9] Current Loss: 4.9388\n",
            "Ep 2 (Step 009740): Train loss 4.024, Val loss 5.061\n",
            "[Batch 0] Current Loss: 3.7825\n",
            "[Batch 1] Current Loss: 4.5059\n",
            "[Batch 2] Current Loss: 3.7799\n",
            "[Batch 3] Current Loss: 3.8296\n",
            "[Batch 4] Current Loss: 4.6134\n",
            "[Batch 5] Current Loss: 4.9585\n",
            "[Batch 6] Current Loss: 4.2621\n",
            "[Batch 7] Current Loss: 4.5060\n",
            "[Batch 8] Current Loss: 4.1137\n",
            "[Batch 9] Current Loss: 4.3357\n",
            "[Batch 0] Current Loss: 5.1300\n",
            "[Batch 1] Current Loss: 5.5638\n",
            "[Batch 2] Current Loss: 5.4322\n",
            "[Batch 3] Current Loss: 5.5074\n",
            "[Batch 4] Current Loss: 5.5754\n",
            "[Batch 5] Current Loss: 4.6977\n",
            "[Batch 6] Current Loss: 5.8627\n",
            "[Batch 7] Current Loss: 4.6694\n",
            "[Batch 8] Current Loss: 6.2869\n",
            "[Batch 9] Current Loss: 5.5606\n",
            "Ep 2 (Step 009760): Train loss 4.269, Val loss 5.429\n",
            "[Batch 0] Current Loss: 4.5339\n",
            "[Batch 1] Current Loss: 4.3536\n",
            "[Batch 2] Current Loss: 4.4969\n",
            "[Batch 3] Current Loss: 4.9679\n",
            "[Batch 4] Current Loss: 4.4825\n",
            "[Batch 5] Current Loss: 4.6255\n",
            "[Batch 6] Current Loss: 3.9110\n",
            "[Batch 7] Current Loss: 4.3782\n",
            "[Batch 8] Current Loss: 4.4712\n",
            "[Batch 9] Current Loss: 4.1996\n",
            "[Batch 0] Current Loss: 5.2567\n",
            "[Batch 1] Current Loss: 5.3062\n",
            "[Batch 2] Current Loss: 5.0192\n",
            "[Batch 3] Current Loss: 4.8562\n",
            "[Batch 4] Current Loss: 5.1041\n",
            "[Batch 5] Current Loss: 5.2064\n",
            "[Batch 6] Current Loss: 5.1241\n",
            "[Batch 7] Current Loss: 5.3430\n",
            "[Batch 8] Current Loss: 5.2088\n",
            "[Batch 9] Current Loss: 5.2956\n",
            "Ep 2 (Step 009780): Train loss 4.442, Val loss 5.172\n",
            "[Batch 0] Current Loss: 3.8776\n",
            "[Batch 1] Current Loss: 4.8861\n",
            "[Batch 2] Current Loss: 4.3576\n",
            "[Batch 3] Current Loss: 4.3594\n",
            "[Batch 4] Current Loss: 4.3265\n",
            "[Batch 5] Current Loss: 4.3737\n",
            "[Batch 6] Current Loss: 4.4527\n",
            "[Batch 7] Current Loss: 4.1342\n",
            "[Batch 8] Current Loss: 4.3236\n",
            "[Batch 9] Current Loss: 4.5518\n",
            "[Batch 0] Current Loss: 5.0017\n",
            "[Batch 1] Current Loss: 4.6861\n",
            "[Batch 2] Current Loss: 5.4350\n",
            "[Batch 3] Current Loss: 5.7167\n",
            "[Batch 4] Current Loss: 4.9812\n",
            "[Batch 5] Current Loss: 5.3506\n",
            "[Batch 6] Current Loss: 5.6053\n",
            "[Batch 7] Current Loss: 5.1656\n",
            "[Batch 8] Current Loss: 5.2520\n",
            "[Batch 9] Current Loss: 5.4347\n",
            "Ep 2 (Step 009800): Train loss 4.364, Val loss 5.263\n",
            "[Batch 0] Current Loss: 4.0753\n",
            "[Batch 1] Current Loss: 4.1096\n",
            "[Batch 2] Current Loss: 4.3756\n",
            "[Batch 3] Current Loss: 3.9055\n",
            "[Batch 4] Current Loss: 4.2685\n",
            "[Batch 5] Current Loss: 4.6652\n",
            "[Batch 6] Current Loss: 4.5463\n",
            "[Batch 7] Current Loss: 4.3632\n",
            "[Batch 8] Current Loss: 4.5609\n",
            "[Batch 9] Current Loss: 4.4971\n",
            "[Batch 0] Current Loss: 5.2631\n",
            "[Batch 1] Current Loss: 5.4598\n",
            "[Batch 2] Current Loss: 5.4449\n",
            "[Batch 3] Current Loss: 4.6546\n",
            "[Batch 4] Current Loss: 4.8379\n",
            "[Batch 5] Current Loss: 5.3646\n",
            "[Batch 6] Current Loss: 4.8024\n",
            "[Batch 7] Current Loss: 5.4349\n",
            "[Batch 8] Current Loss: 5.1687\n",
            "[Batch 9] Current Loss: 5.5168\n",
            "Ep 2 (Step 009820): Train loss 4.337, Val loss 5.195\n",
            "[Batch 0] Current Loss: 4.0673\n",
            "[Batch 1] Current Loss: 4.5114\n",
            "[Batch 2] Current Loss: 4.3261\n",
            "[Batch 3] Current Loss: 4.6788\n",
            "[Batch 4] Current Loss: 4.5189\n",
            "[Batch 5] Current Loss: 4.0748\n",
            "[Batch 6] Current Loss: 4.3998\n",
            "[Batch 7] Current Loss: 4.1228\n",
            "[Batch 8] Current Loss: 5.2667\n",
            "[Batch 9] Current Loss: 4.3819\n",
            "[Batch 0] Current Loss: 5.6919\n",
            "[Batch 1] Current Loss: 4.8139\n",
            "[Batch 2] Current Loss: 5.2825\n",
            "[Batch 3] Current Loss: 5.0002\n",
            "[Batch 4] Current Loss: 5.3722\n",
            "[Batch 5] Current Loss: 5.5415\n",
            "[Batch 6] Current Loss: 5.5102\n",
            "[Batch 7] Current Loss: 5.2188\n",
            "[Batch 8] Current Loss: 5.7690\n",
            "[Batch 9] Current Loss: 4.6433\n",
            "Ep 2 (Step 009840): Train loss 4.435, Val loss 5.284\n",
            "[Batch 0] Current Loss: 4.2334\n",
            "[Batch 1] Current Loss: 3.8831\n",
            "[Batch 2] Current Loss: 4.0942\n",
            "[Batch 3] Current Loss: 4.6298\n",
            "[Batch 4] Current Loss: 4.4254\n",
            "[Batch 5] Current Loss: 4.5693\n",
            "[Batch 6] Current Loss: 3.7124\n",
            "[Batch 7] Current Loss: 4.0235\n",
            "[Batch 8] Current Loss: 4.1224\n",
            "[Batch 9] Current Loss: 4.4271\n",
            "[Batch 0] Current Loss: 5.1058\n",
            "[Batch 1] Current Loss: 5.6130\n",
            "[Batch 2] Current Loss: 5.5286\n",
            "[Batch 3] Current Loss: 5.3780\n",
            "[Batch 4] Current Loss: 4.8824\n",
            "[Batch 5] Current Loss: 6.0395\n",
            "[Batch 6] Current Loss: 5.1060\n",
            "[Batch 7] Current Loss: 4.5200\n",
            "[Batch 8] Current Loss: 5.0134\n",
            "[Batch 9] Current Loss: 5.9545\n",
            "Ep 2 (Step 009860): Train loss 4.212, Val loss 5.314\n",
            "[Batch 0] Current Loss: 4.7720\n",
            "[Batch 1] Current Loss: 4.4032\n",
            "[Batch 2] Current Loss: 4.4370\n",
            "[Batch 3] Current Loss: 4.3039\n",
            "[Batch 4] Current Loss: 4.2716\n",
            "[Batch 5] Current Loss: 4.2720\n",
            "[Batch 6] Current Loss: 3.9639\n",
            "[Batch 7] Current Loss: 3.9644\n",
            "[Batch 8] Current Loss: 3.9148\n",
            "[Batch 9] Current Loss: 4.3643\n",
            "[Batch 0] Current Loss: 4.7930\n",
            "[Batch 1] Current Loss: 5.3532\n",
            "[Batch 2] Current Loss: 5.7501\n",
            "[Batch 3] Current Loss: 5.1961\n",
            "[Batch 4] Current Loss: 5.0586\n",
            "[Batch 5] Current Loss: 5.4622\n",
            "[Batch 6] Current Loss: 5.5699\n",
            "[Batch 7] Current Loss: 4.9246\n",
            "[Batch 8] Current Loss: 5.3090\n",
            "[Batch 9] Current Loss: 5.3713\n",
            "Ep 2 (Step 009880): Train loss 4.267, Val loss 5.279\n",
            "[Batch 0] Current Loss: 4.9172\n",
            "[Batch 1] Current Loss: 3.5314\n",
            "[Batch 2] Current Loss: 4.3591\n",
            "[Batch 3] Current Loss: 4.5620\n",
            "[Batch 4] Current Loss: 4.4432\n",
            "[Batch 5] Current Loss: 4.3846\n",
            "[Batch 6] Current Loss: 4.2116\n",
            "[Batch 7] Current Loss: 3.7786\n",
            "[Batch 8] Current Loss: 4.4504\n",
            "[Batch 9] Current Loss: 4.7151\n",
            "[Batch 0] Current Loss: 5.2559\n",
            "[Batch 1] Current Loss: 5.0629\n",
            "[Batch 2] Current Loss: 5.4223\n",
            "[Batch 3] Current Loss: 5.1427\n",
            "[Batch 4] Current Loss: 5.2649\n",
            "[Batch 5] Current Loss: 5.4079\n",
            "[Batch 6] Current Loss: 5.4944\n",
            "[Batch 7] Current Loss: 5.3152\n",
            "[Batch 8] Current Loss: 5.3330\n",
            "[Batch 9] Current Loss: 5.3906\n",
            "Ep 2 (Step 009900): Train loss 4.335, Val loss 5.309\n",
            "[Batch 0] Current Loss: 3.3756\n",
            "[Batch 1] Current Loss: 3.9715\n",
            "[Batch 2] Current Loss: 4.1717\n",
            "[Batch 3] Current Loss: 4.2863\n",
            "[Batch 4] Current Loss: 4.1651\n",
            "[Batch 5] Current Loss: 4.3070\n",
            "[Batch 6] Current Loss: 4.5162\n",
            "[Batch 7] Current Loss: 4.6348\n",
            "[Batch 8] Current Loss: 3.5712\n",
            "[Batch 9] Current Loss: 4.4429\n",
            "[Batch 0] Current Loss: 5.7833\n",
            "[Batch 1] Current Loss: 5.2696\n",
            "[Batch 2] Current Loss: 5.7486\n",
            "[Batch 3] Current Loss: 5.3779\n",
            "[Batch 4] Current Loss: 5.5438\n",
            "[Batch 5] Current Loss: 5.1720\n",
            "[Batch 6] Current Loss: 5.7701\n",
            "[Batch 7] Current Loss: 5.6763\n",
            "[Batch 8] Current Loss: 5.8950\n",
            "[Batch 9] Current Loss: 5.5947\n",
            "Ep 2 (Step 009920): Train loss 4.144, Val loss 5.583\n",
            "[Batch 0] Current Loss: 4.0111\n",
            "[Batch 1] Current Loss: 4.0752\n",
            "[Batch 2] Current Loss: 3.8982\n",
            "[Batch 3] Current Loss: 4.5077\n",
            "[Batch 4] Current Loss: 4.0446\n",
            "[Batch 5] Current Loss: 4.6364\n",
            "[Batch 6] Current Loss: 3.6008\n",
            "[Batch 7] Current Loss: 4.4212\n",
            "[Batch 8] Current Loss: 4.2064\n",
            "[Batch 9] Current Loss: 4.5753\n",
            "[Batch 0] Current Loss: 4.7635\n",
            "[Batch 1] Current Loss: 5.0733\n",
            "[Batch 2] Current Loss: 5.4332\n",
            "[Batch 3] Current Loss: 5.4758\n",
            "[Batch 4] Current Loss: 5.7516\n",
            "[Batch 5] Current Loss: 5.2371\n",
            "[Batch 6] Current Loss: 5.2030\n",
            "[Batch 7] Current Loss: 5.6719\n",
            "[Batch 8] Current Loss: 5.4074\n",
            "[Batch 9] Current Loss: 5.7188\n",
            "Ep 2 (Step 009940): Train loss 4.198, Val loss 5.374\n",
            "[Batch 0] Current Loss: 3.8263\n",
            "[Batch 1] Current Loss: 3.7781\n",
            "[Batch 2] Current Loss: 4.3794\n",
            "[Batch 3] Current Loss: 4.7975\n",
            "[Batch 4] Current Loss: 3.1709\n",
            "[Batch 5] Current Loss: 4.1773\n",
            "[Batch 6] Current Loss: 4.2935\n",
            "[Batch 7] Current Loss: 4.4594\n",
            "[Batch 8] Current Loss: 4.0286\n",
            "[Batch 9] Current Loss: 4.1950\n",
            "[Batch 0] Current Loss: 5.2185\n",
            "[Batch 1] Current Loss: 4.6424\n",
            "[Batch 2] Current Loss: 5.4937\n",
            "[Batch 3] Current Loss: 5.2934\n",
            "[Batch 4] Current Loss: 5.5199\n",
            "[Batch 5] Current Loss: 5.8262\n",
            "[Batch 6] Current Loss: 5.4307\n",
            "[Batch 7] Current Loss: 4.9589\n",
            "[Batch 8] Current Loss: 5.5148\n",
            "[Batch 9] Current Loss: 5.8589\n",
            "Ep 2 (Step 009960): Train loss 4.111, Val loss 5.376\n",
            "[Batch 0] Current Loss: 3.8855\n",
            "[Batch 1] Current Loss: 4.2983\n",
            "[Batch 2] Current Loss: 4.2351\n",
            "[Batch 3] Current Loss: 3.8866\n",
            "[Batch 4] Current Loss: 4.4280\n",
            "[Batch 5] Current Loss: 4.2219\n",
            "[Batch 6] Current Loss: 4.0914\n",
            "[Batch 7] Current Loss: 3.9727\n",
            "[Batch 8] Current Loss: 4.0882\n",
            "[Batch 9] Current Loss: 4.2512\n",
            "[Batch 0] Current Loss: 5.9410\n",
            "[Batch 1] Current Loss: 5.4434\n",
            "[Batch 2] Current Loss: 4.9734\n",
            "[Batch 3] Current Loss: 4.6389\n",
            "[Batch 4] Current Loss: 5.0719\n",
            "[Batch 5] Current Loss: 4.9679\n",
            "[Batch 6] Current Loss: 5.3753\n",
            "[Batch 7] Current Loss: 4.6858\n",
            "[Batch 8] Current Loss: 5.6395\n",
            "[Batch 9] Current Loss: 5.4057\n",
            "Ep 2 (Step 009980): Train loss 4.136, Val loss 5.214\n",
            "[Batch 0] Current Loss: 3.2902\n",
            "[Batch 1] Current Loss: 4.0639\n",
            "[Batch 2] Current Loss: 4.1252\n",
            "[Batch 3] Current Loss: 4.4245\n",
            "[Batch 4] Current Loss: 4.2525\n",
            "[Batch 5] Current Loss: 3.7902\n",
            "[Batch 6] Current Loss: 4.5629\n",
            "[Batch 7] Current Loss: 4.1145\n",
            "[Batch 8] Current Loss: 4.3465\n",
            "[Batch 9] Current Loss: 3.8258\n",
            "[Batch 0] Current Loss: 4.5045\n",
            "[Batch 1] Current Loss: 5.7177\n",
            "[Batch 2] Current Loss: 4.5563\n",
            "[Batch 3] Current Loss: 5.4363\n",
            "[Batch 4] Current Loss: 5.5992\n",
            "[Batch 5] Current Loss: 6.0615\n",
            "[Batch 6] Current Loss: 5.6998\n",
            "[Batch 7] Current Loss: 5.0770\n",
            "[Batch 8] Current Loss: 5.1065\n",
            "[Batch 9] Current Loss: 5.0634\n",
            "Ep 2 (Step 010000): Train loss 4.080, Val loss 5.282\n",
            "[Batch 0] Current Loss: 3.9701\n",
            "[Batch 1] Current Loss: 4.3179\n",
            "[Batch 2] Current Loss: 4.2684\n",
            "[Batch 3] Current Loss: 3.8365\n",
            "[Batch 4] Current Loss: 4.3154\n",
            "[Batch 5] Current Loss: 4.0972\n",
            "[Batch 6] Current Loss: 3.8792\n",
            "[Batch 7] Current Loss: 3.8085\n",
            "[Batch 8] Current Loss: 4.1520\n",
            "[Batch 9] Current Loss: 3.7741\n",
            "[Batch 0] Current Loss: 4.7195\n",
            "[Batch 1] Current Loss: 5.4089\n",
            "[Batch 2] Current Loss: 4.6345\n",
            "[Batch 3] Current Loss: 5.1492\n",
            "[Batch 4] Current Loss: 5.2510\n",
            "[Batch 5] Current Loss: 5.5787\n",
            "[Batch 6] Current Loss: 5.3557\n",
            "[Batch 7] Current Loss: 5.3458\n",
            "[Batch 8] Current Loss: 4.7126\n",
            "[Batch 9] Current Loss: 5.5433\n",
            "Ep 2 (Step 010020): Train loss 4.042, Val loss 5.170\n",
            "[Batch 0] Current Loss: 4.2017\n",
            "[Batch 1] Current Loss: 4.5758\n",
            "[Batch 2] Current Loss: 4.4703\n",
            "[Batch 3] Current Loss: 4.1904\n",
            "[Batch 4] Current Loss: 4.6538\n",
            "[Batch 5] Current Loss: 4.3336\n",
            "[Batch 6] Current Loss: 4.1464\n",
            "[Batch 7] Current Loss: 4.7804\n",
            "[Batch 8] Current Loss: 3.8557\n",
            "[Batch 9] Current Loss: 4.4651\n",
            "[Batch 0] Current Loss: 5.4882\n",
            "[Batch 1] Current Loss: 5.3494\n",
            "[Batch 2] Current Loss: 5.4174\n",
            "[Batch 3] Current Loss: 4.7493\n",
            "[Batch 4] Current Loss: 6.1662\n",
            "[Batch 5] Current Loss: 4.6577\n",
            "[Batch 6] Current Loss: 4.5641\n",
            "[Batch 7] Current Loss: 5.6431\n",
            "[Batch 8] Current Loss: 5.6777\n",
            "[Batch 9] Current Loss: 4.9449\n",
            "Ep 2 (Step 010040): Train loss 4.367, Val loss 5.266\n",
            "[Batch 0] Current Loss: 4.4918\n",
            "[Batch 1] Current Loss: 4.3006\n",
            "[Batch 2] Current Loss: 3.5900\n",
            "[Batch 3] Current Loss: 4.1130\n",
            "[Batch 4] Current Loss: 4.9358\n",
            "[Batch 5] Current Loss: 4.8013\n",
            "[Batch 6] Current Loss: 4.1284\n",
            "[Batch 7] Current Loss: 3.9509\n",
            "[Batch 8] Current Loss: 4.5478\n",
            "[Batch 9] Current Loss: 4.7557\n",
            "[Batch 0] Current Loss: 4.7988\n",
            "[Batch 1] Current Loss: 5.1267\n",
            "[Batch 2] Current Loss: 5.2339\n",
            "[Batch 3] Current Loss: 5.0408\n",
            "[Batch 4] Current Loss: 5.3382\n",
            "[Batch 5] Current Loss: 5.9843\n",
            "[Batch 6] Current Loss: 5.4491\n",
            "[Batch 7] Current Loss: 5.6446\n",
            "[Batch 8] Current Loss: 5.1712\n",
            "[Batch 9] Current Loss: 5.7149\n",
            "Ep 2 (Step 010060): Train loss 4.362, Val loss 5.350\n",
            "[Batch 0] Current Loss: 4.5019\n",
            "[Batch 1] Current Loss: 3.7918\n",
            "[Batch 2] Current Loss: 3.5400\n",
            "[Batch 3] Current Loss: 4.5670\n",
            "[Batch 4] Current Loss: 3.8357\n",
            "[Batch 5] Current Loss: 4.4562\n",
            "[Batch 6] Current Loss: 5.0557\n",
            "[Batch 7] Current Loss: 3.6440\n",
            "[Batch 8] Current Loss: 4.0661\n",
            "[Batch 9] Current Loss: 3.9304\n",
            "[Batch 0] Current Loss: 5.6952\n",
            "[Batch 1] Current Loss: 5.3185\n",
            "[Batch 2] Current Loss: 6.0819\n",
            "[Batch 3] Current Loss: 4.9311\n",
            "[Batch 4] Current Loss: 5.5705\n",
            "[Batch 5] Current Loss: 5.5503\n",
            "[Batch 6] Current Loss: 5.6061\n",
            "[Batch 7] Current Loss: 5.0096\n",
            "[Batch 8] Current Loss: 5.3317\n",
            "[Batch 9] Current Loss: 5.5390\n",
            "Ep 2 (Step 010080): Train loss 4.139, Val loss 5.463\n",
            "[Batch 0] Current Loss: 3.5761\n",
            "[Batch 1] Current Loss: 3.1726\n",
            "[Batch 2] Current Loss: 4.4977\n",
            "[Batch 3] Current Loss: 4.4145\n",
            "[Batch 4] Current Loss: 4.6064\n",
            "[Batch 5] Current Loss: 3.7636\n",
            "[Batch 6] Current Loss: 4.1018\n",
            "[Batch 7] Current Loss: 3.5365\n",
            "[Batch 8] Current Loss: 4.2790\n",
            "[Batch 9] Current Loss: 4.0889\n",
            "[Batch 0] Current Loss: 4.3687\n",
            "[Batch 1] Current Loss: 5.3367\n",
            "[Batch 2] Current Loss: 5.7856\n",
            "[Batch 3] Current Loss: 5.2055\n",
            "[Batch 4] Current Loss: 5.2038\n",
            "[Batch 5] Current Loss: 6.2709\n",
            "[Batch 6] Current Loss: 5.5258\n",
            "[Batch 7] Current Loss: 4.8227\n",
            "[Batch 8] Current Loss: 5.2862\n",
            "[Batch 9] Current Loss: 5.0006\n",
            "Ep 2 (Step 010100): Train loss 4.004, Val loss 5.281\n",
            "[Batch 0] Current Loss: 4.5654\n",
            "[Batch 1] Current Loss: 3.8874\n",
            "[Batch 2] Current Loss: 3.3739\n",
            "[Batch 3] Current Loss: 4.6571\n",
            "[Batch 4] Current Loss: 3.8111\n",
            "[Batch 5] Current Loss: 4.7387\n",
            "[Batch 6] Current Loss: 3.7720\n",
            "[Batch 7] Current Loss: 4.0659\n",
            "[Batch 8] Current Loss: 3.6454\n",
            "[Batch 9] Current Loss: 4.5449\n",
            "[Batch 0] Current Loss: 5.0947\n",
            "[Batch 1] Current Loss: 5.7320\n",
            "[Batch 2] Current Loss: 5.8692\n",
            "[Batch 3] Current Loss: 5.5458\n",
            "[Batch 4] Current Loss: 5.1616\n",
            "[Batch 5] Current Loss: 5.7883\n",
            "[Batch 6] Current Loss: 5.4487\n",
            "[Batch 7] Current Loss: 5.0141\n",
            "[Batch 8] Current Loss: 4.6031\n",
            "[Batch 9] Current Loss: 5.7729\n",
            "Ep 2 (Step 010120): Train loss 4.106, Val loss 5.403\n",
            "[Batch 0] Current Loss: 4.5092\n",
            "[Batch 1] Current Loss: 4.4171\n",
            "[Batch 2] Current Loss: 4.0779\n",
            "[Batch 3] Current Loss: 4.3229\n",
            "[Batch 4] Current Loss: 4.2707\n",
            "[Batch 5] Current Loss: 4.5421\n",
            "[Batch 6] Current Loss: 3.0589\n",
            "[Batch 7] Current Loss: 4.2178\n",
            "[Batch 8] Current Loss: 4.3081\n",
            "[Batch 9] Current Loss: 4.6363\n",
            "[Batch 0] Current Loss: 5.6786\n",
            "[Batch 1] Current Loss: 5.7103\n",
            "[Batch 2] Current Loss: 5.5117\n",
            "[Batch 3] Current Loss: 5.1632\n",
            "[Batch 4] Current Loss: 4.9318\n",
            "[Batch 5] Current Loss: 5.3283\n",
            "[Batch 6] Current Loss: 5.4972\n",
            "[Batch 7] Current Loss: 5.7109\n",
            "[Batch 8] Current Loss: 5.0988\n",
            "[Batch 9] Current Loss: 5.7847\n",
            "Ep 2 (Step 010140): Train loss 4.236, Val loss 5.442\n",
            "[Batch 0] Current Loss: 4.2073\n",
            "[Batch 1] Current Loss: 4.0893\n",
            "[Batch 2] Current Loss: 4.6339\n",
            "[Batch 3] Current Loss: 3.4481\n",
            "[Batch 4] Current Loss: 4.4994\n",
            "[Batch 5] Current Loss: 4.0948\n",
            "[Batch 6] Current Loss: 4.3237\n",
            "[Batch 7] Current Loss: 4.3404\n",
            "[Batch 8] Current Loss: 4.4189\n",
            "[Batch 9] Current Loss: 4.7243\n",
            "[Batch 0] Current Loss: 5.2773\n",
            "[Batch 1] Current Loss: 4.7449\n",
            "[Batch 2] Current Loss: 5.5400\n",
            "[Batch 3] Current Loss: 5.9089\n",
            "[Batch 4] Current Loss: 5.2796\n",
            "[Batch 5] Current Loss: 5.1117\n",
            "[Batch 6] Current Loss: 5.0019\n",
            "[Batch 7] Current Loss: 5.8034\n",
            "[Batch 8] Current Loss: 5.3141\n",
            "[Batch 9] Current Loss: 5.7254\n",
            "Ep 2 (Step 010160): Train loss 4.278, Val loss 5.371\n",
            "[Batch 0] Current Loss: 4.1092\n",
            "[Batch 1] Current Loss: 4.1867\n",
            "[Batch 2] Current Loss: 4.6910\n",
            "[Batch 3] Current Loss: 4.5460\n",
            "[Batch 4] Current Loss: 4.2563\n",
            "[Batch 5] Current Loss: 4.3928\n",
            "[Batch 6] Current Loss: 4.0854\n",
            "[Batch 7] Current Loss: 4.3411\n",
            "[Batch 8] Current Loss: 3.9483\n",
            "[Batch 9] Current Loss: 4.2738\n",
            "[Batch 0] Current Loss: 5.0022\n",
            "[Batch 1] Current Loss: 5.3291\n",
            "[Batch 2] Current Loss: 5.2135\n",
            "[Batch 3] Current Loss: 5.7371\n",
            "[Batch 4] Current Loss: 5.7279\n",
            "[Batch 5] Current Loss: 5.3504\n",
            "[Batch 6] Current Loss: 5.3173\n",
            "[Batch 7] Current Loss: 4.3713\n",
            "[Batch 8] Current Loss: 4.7683\n",
            "[Batch 9] Current Loss: 5.5742\n",
            "Ep 2 (Step 010180): Train loss 4.283, Val loss 5.239\n",
            "[Batch 0] Current Loss: 4.5354\n",
            "[Batch 1] Current Loss: 3.8245\n",
            "[Batch 2] Current Loss: 3.9801\n",
            "[Batch 3] Current Loss: 4.5078\n",
            "[Batch 4] Current Loss: 3.9549\n",
            "[Batch 5] Current Loss: 4.3906\n",
            "[Batch 6] Current Loss: 4.4028\n",
            "[Batch 7] Current Loss: 4.3270\n",
            "[Batch 8] Current Loss: 3.9566\n",
            "[Batch 9] Current Loss: 3.8051\n",
            "[Batch 0] Current Loss: 4.9939\n",
            "[Batch 1] Current Loss: 5.9807\n",
            "[Batch 2] Current Loss: 4.7779\n",
            "[Batch 3] Current Loss: 5.0699\n",
            "[Batch 4] Current Loss: 5.8760\n",
            "[Batch 5] Current Loss: 5.8517\n",
            "[Batch 6] Current Loss: 4.7636\n",
            "[Batch 7] Current Loss: 5.3348\n",
            "[Batch 8] Current Loss: 5.9221\n",
            "[Batch 9] Current Loss: 5.2953\n",
            "Ep 2 (Step 010200): Train loss 4.168, Val loss 5.387\n",
            "[Batch 0] Current Loss: 4.4859\n",
            "[Batch 1] Current Loss: 4.1958\n",
            "[Batch 2] Current Loss: 4.5094\n",
            "[Batch 3] Current Loss: 4.6745\n",
            "[Batch 4] Current Loss: 4.1229\n",
            "[Batch 5] Current Loss: 4.1898\n",
            "[Batch 6] Current Loss: 4.5161\n",
            "[Batch 7] Current Loss: 4.1822\n",
            "[Batch 8] Current Loss: 3.9746\n",
            "[Batch 9] Current Loss: 4.7413\n",
            "[Batch 0] Current Loss: 5.4988\n",
            "[Batch 1] Current Loss: 5.2782\n",
            "[Batch 2] Current Loss: 5.8236\n",
            "[Batch 3] Current Loss: 5.9596\n",
            "[Batch 4] Current Loss: 4.3111\n",
            "[Batch 5] Current Loss: 5.6385\n",
            "[Batch 6] Current Loss: 5.7271\n",
            "[Batch 7] Current Loss: 4.9542\n",
            "[Batch 8] Current Loss: 4.3257\n",
            "[Batch 9] Current Loss: 5.0018\n",
            "Ep 2 (Step 010220): Train loss 4.359, Val loss 5.252\n",
            "[Batch 0] Current Loss: 4.1606\n",
            "[Batch 1] Current Loss: 4.2026\n",
            "[Batch 2] Current Loss: 4.0485\n",
            "[Batch 3] Current Loss: 3.8260\n",
            "[Batch 4] Current Loss: 4.7499\n",
            "[Batch 5] Current Loss: 3.6955\n",
            "[Batch 6] Current Loss: 3.8755\n",
            "[Batch 7] Current Loss: 3.4856\n",
            "[Batch 8] Current Loss: 4.8325\n",
            "[Batch 9] Current Loss: 5.3465\n",
            "[Batch 0] Current Loss: 5.4084\n",
            "[Batch 1] Current Loss: 5.3687\n",
            "[Batch 2] Current Loss: 4.9536\n",
            "[Batch 3] Current Loss: 5.0157\n",
            "[Batch 4] Current Loss: 5.3596\n",
            "[Batch 5] Current Loss: 4.7475\n",
            "[Batch 6] Current Loss: 5.7336\n",
            "[Batch 7] Current Loss: 4.9849\n",
            "[Batch 8] Current Loss: 5.2871\n",
            "[Batch 9] Current Loss: 5.5236\n",
            "Ep 2 (Step 010240): Train loss 4.222, Val loss 5.238\n",
            "[Batch 0] Current Loss: 4.3325\n",
            "[Batch 1] Current Loss: 4.3122\n",
            "[Batch 2] Current Loss: 3.8120\n",
            "[Batch 3] Current Loss: 4.1234\n",
            "[Batch 4] Current Loss: 3.8774\n",
            "[Batch 5] Current Loss: 3.8224\n",
            "[Batch 6] Current Loss: 4.4165\n",
            "[Batch 7] Current Loss: 4.1210\n",
            "[Batch 8] Current Loss: 4.2264\n",
            "[Batch 9] Current Loss: 4.6209\n",
            "[Batch 0] Current Loss: 5.3256\n",
            "[Batch 1] Current Loss: 5.0914\n",
            "[Batch 2] Current Loss: 5.3033\n",
            "[Batch 3] Current Loss: 4.8886\n",
            "[Batch 4] Current Loss: 5.7992\n",
            "[Batch 5] Current Loss: 5.5186\n",
            "[Batch 6] Current Loss: 5.4127\n",
            "[Batch 7] Current Loss: 5.6489\n",
            "[Batch 8] Current Loss: 5.3680\n",
            "[Batch 9] Current Loss: 4.8553\n",
            "Ep 2 (Step 010260): Train loss 4.166, Val loss 5.321\n",
            "[Batch 0] Current Loss: 4.2191\n",
            "[Batch 1] Current Loss: 3.8438\n",
            "[Batch 2] Current Loss: 4.5316\n",
            "[Batch 3] Current Loss: 4.2627\n",
            "[Batch 4] Current Loss: 4.0779\n",
            "[Batch 5] Current Loss: 3.8650\n",
            "[Batch 6] Current Loss: 3.7775\n",
            "[Batch 7] Current Loss: 3.4950\n",
            "[Batch 8] Current Loss: 4.0936\n",
            "[Batch 9] Current Loss: 4.5026\n",
            "[Batch 0] Current Loss: 5.7118\n",
            "[Batch 1] Current Loss: 4.9772\n",
            "[Batch 2] Current Loss: 5.3238\n",
            "[Batch 3] Current Loss: 5.5156\n",
            "[Batch 4] Current Loss: 5.1452\n",
            "[Batch 5] Current Loss: 5.8181\n",
            "[Batch 6] Current Loss: 5.6409\n",
            "[Batch 7] Current Loss: 5.6919\n",
            "[Batch 8] Current Loss: 5.4407\n",
            "[Batch 9] Current Loss: 5.6747\n",
            "Ep 2 (Step 010280): Train loss 4.067, Val loss 5.494\n",
            "[Batch 0] Current Loss: 4.1134\n",
            "[Batch 1] Current Loss: 3.7164\n",
            "[Batch 2] Current Loss: 4.0358\n",
            "[Batch 3] Current Loss: 3.1717\n",
            "[Batch 4] Current Loss: 3.9721\n",
            "[Batch 5] Current Loss: 4.6550\n",
            "[Batch 6] Current Loss: 4.2923\n",
            "[Batch 7] Current Loss: 4.1941\n",
            "[Batch 8] Current Loss: 3.9397\n",
            "[Batch 9] Current Loss: 3.9730\n",
            "[Batch 0] Current Loss: 5.3463\n",
            "[Batch 1] Current Loss: 5.6232\n",
            "[Batch 2] Current Loss: 5.2289\n",
            "[Batch 3] Current Loss: 5.3650\n",
            "[Batch 4] Current Loss: 5.1713\n",
            "[Batch 5] Current Loss: 5.1623\n",
            "[Batch 6] Current Loss: 5.2695\n",
            "[Batch 7] Current Loss: 5.7003\n",
            "[Batch 8] Current Loss: 5.7205\n",
            "[Batch 9] Current Loss: 5.3656\n",
            "Ep 2 (Step 010300): Train loss 4.006, Val loss 5.395\n",
            "[Batch 0] Current Loss: 3.8425\n",
            "[Batch 1] Current Loss: 4.2681\n",
            "[Batch 2] Current Loss: 4.5983\n",
            "[Batch 3] Current Loss: 4.0245\n",
            "[Batch 4] Current Loss: 3.7857\n",
            "[Batch 5] Current Loss: 3.6608\n",
            "[Batch 6] Current Loss: 4.3905\n",
            "[Batch 7] Current Loss: 4.1669\n",
            "[Batch 8] Current Loss: 4.0934\n",
            "[Batch 9] Current Loss: 3.5832\n",
            "[Batch 0] Current Loss: 5.3018\n",
            "[Batch 1] Current Loss: 5.8755\n",
            "[Batch 2] Current Loss: 5.1335\n",
            "[Batch 3] Current Loss: 5.3144\n",
            "[Batch 4] Current Loss: 4.3366\n",
            "[Batch 5] Current Loss: 6.0377\n",
            "[Batch 6] Current Loss: 5.0920\n",
            "[Batch 7] Current Loss: 5.3021\n",
            "[Batch 8] Current Loss: 5.6998\n",
            "[Batch 9] Current Loss: 5.4154\n",
            "Ep 2 (Step 010320): Train loss 4.041, Val loss 5.351\n",
            "[Batch 0] Current Loss: 3.9771\n",
            "[Batch 1] Current Loss: 4.6641\n",
            "[Batch 2] Current Loss: 3.9826\n",
            "[Batch 3] Current Loss: 4.0998\n",
            "[Batch 4] Current Loss: 3.7763\n",
            "[Batch 5] Current Loss: 4.5458\n",
            "[Batch 6] Current Loss: 4.0736\n",
            "[Batch 7] Current Loss: 4.5004\n",
            "[Batch 8] Current Loss: 3.9924\n",
            "[Batch 9] Current Loss: 3.6019\n",
            "[Batch 0] Current Loss: 4.9929\n",
            "[Batch 1] Current Loss: 5.4703\n",
            "[Batch 2] Current Loss: 5.1777\n",
            "[Batch 3] Current Loss: 5.7083\n",
            "[Batch 4] Current Loss: 4.8350\n",
            "[Batch 5] Current Loss: 5.1261\n",
            "[Batch 6] Current Loss: 5.5330\n",
            "[Batch 7] Current Loss: 5.2592\n",
            "[Batch 8] Current Loss: 4.7715\n",
            "[Batch 9] Current Loss: 5.7383\n",
            "Ep 2 (Step 010340): Train loss 4.121, Val loss 5.261\n",
            "[Batch 0] Current Loss: 4.4670\n",
            "[Batch 1] Current Loss: 3.7434\n",
            "[Batch 2] Current Loss: 4.4599\n",
            "[Batch 3] Current Loss: 4.1215\n",
            "[Batch 4] Current Loss: 4.3675\n",
            "[Batch 5] Current Loss: 4.2510\n",
            "[Batch 6] Current Loss: 4.0554\n",
            "[Batch 7] Current Loss: 3.9864\n",
            "[Batch 8] Current Loss: 3.7958\n",
            "[Batch 9] Current Loss: 4.5350\n",
            "[Batch 0] Current Loss: 4.4948\n",
            "[Batch 1] Current Loss: 5.9578\n",
            "[Batch 2] Current Loss: 4.6311\n",
            "[Batch 3] Current Loss: 5.8511\n",
            "[Batch 4] Current Loss: 5.5687\n",
            "[Batch 5] Current Loss: 5.0935\n",
            "[Batch 6] Current Loss: 5.7410\n",
            "[Batch 7] Current Loss: 4.9597\n",
            "[Batch 8] Current Loss: 5.1352\n",
            "[Batch 9] Current Loss: 4.4030\n",
            "Ep 2 (Step 010360): Train loss 4.178, Val loss 5.184\n",
            "[Batch 0] Current Loss: 3.8048\n",
            "[Batch 1] Current Loss: 4.3229\n",
            "[Batch 2] Current Loss: 3.7829\n",
            "[Batch 3] Current Loss: 4.2380\n",
            "[Batch 4] Current Loss: 3.9118\n",
            "[Batch 5] Current Loss: 4.1237\n",
            "[Batch 6] Current Loss: 3.7706\n",
            "[Batch 7] Current Loss: 4.2280\n",
            "[Batch 8] Current Loss: 4.6938\n",
            "[Batch 9] Current Loss: 4.0903\n",
            "[Batch 0] Current Loss: 4.7247\n",
            "[Batch 1] Current Loss: 5.3514\n",
            "[Batch 2] Current Loss: 5.2091\n",
            "[Batch 3] Current Loss: 5.8573\n",
            "[Batch 4] Current Loss: 4.9285\n",
            "[Batch 5] Current Loss: 5.3126\n",
            "[Batch 6] Current Loss: 5.5075\n",
            "[Batch 7] Current Loss: 4.9491\n",
            "[Batch 8] Current Loss: 5.5851\n",
            "[Batch 9] Current Loss: 5.5795\n",
            "Ep 2 (Step 010380): Train loss 4.097, Val loss 5.300\n",
            "[Batch 0] Current Loss: 4.5936\n",
            "[Batch 1] Current Loss: 3.7243\n",
            "[Batch 2] Current Loss: 3.5945\n",
            "[Batch 3] Current Loss: 4.0920\n",
            "[Batch 4] Current Loss: 4.0759\n",
            "[Batch 5] Current Loss: 4.3957\n",
            "[Batch 6] Current Loss: 4.5385\n",
            "[Batch 7] Current Loss: 4.0840\n",
            "[Batch 8] Current Loss: 4.9300\n",
            "[Batch 9] Current Loss: 4.1626\n",
            "[Batch 0] Current Loss: 5.1477\n",
            "[Batch 1] Current Loss: 5.6457\n",
            "[Batch 2] Current Loss: 5.0944\n",
            "[Batch 3] Current Loss: 4.7353\n",
            "[Batch 4] Current Loss: 5.3452\n",
            "[Batch 5] Current Loss: 5.4521\n",
            "[Batch 6] Current Loss: 4.5146\n",
            "[Batch 7] Current Loss: 5.2455\n",
            "[Batch 8] Current Loss: 5.4071\n",
            "[Batch 9] Current Loss: 5.5212\n",
            "Ep 2 (Step 010400): Train loss 4.219, Val loss 5.211\n",
            "[Batch 0] Current Loss: 3.4111\n",
            "[Batch 1] Current Loss: 4.2348\n",
            "[Batch 2] Current Loss: 3.6780\n",
            "[Batch 3] Current Loss: 4.3206\n",
            "[Batch 4] Current Loss: 4.2530\n",
            "[Batch 5] Current Loss: 3.6401\n",
            "[Batch 6] Current Loss: 3.8667\n",
            "[Batch 7] Current Loss: 4.3649\n",
            "[Batch 8] Current Loss: 4.0069\n",
            "[Batch 9] Current Loss: 4.0827\n",
            "[Batch 0] Current Loss: 5.9339\n",
            "[Batch 1] Current Loss: 5.3738\n",
            "[Batch 2] Current Loss: 5.5447\n",
            "[Batch 3] Current Loss: 5.6623\n",
            "[Batch 4] Current Loss: 4.5200\n",
            "[Batch 5] Current Loss: 5.0591\n",
            "[Batch 6] Current Loss: 5.5598\n",
            "[Batch 7] Current Loss: 5.3258\n",
            "[Batch 8] Current Loss: 5.0592\n",
            "[Batch 9] Current Loss: 4.8552\n",
            "Ep 2 (Step 010420): Train loss 3.986, Val loss 5.289\n",
            "[Batch 0] Current Loss: 4.4393\n",
            "[Batch 1] Current Loss: 4.0148\n",
            "[Batch 2] Current Loss: 4.6988\n",
            "[Batch 3] Current Loss: 3.8676\n",
            "[Batch 4] Current Loss: 3.6719\n",
            "[Batch 5] Current Loss: 4.4037\n",
            "[Batch 6] Current Loss: 4.6768\n",
            "[Batch 7] Current Loss: 4.4455\n",
            "[Batch 8] Current Loss: 3.1609\n",
            "[Batch 9] Current Loss: 3.9867\n",
            "[Batch 0] Current Loss: 5.2920\n",
            "[Batch 1] Current Loss: 5.4413\n",
            "[Batch 2] Current Loss: 5.0626\n",
            "[Batch 3] Current Loss: 5.6017\n",
            "[Batch 4] Current Loss: 5.4970\n",
            "[Batch 5] Current Loss: 4.7528\n",
            "[Batch 6] Current Loss: 5.4615\n",
            "[Batch 7] Current Loss: 5.0308\n",
            "[Batch 8] Current Loss: 4.9815\n",
            "[Batch 9] Current Loss: 4.8551\n",
            "Ep 2 (Step 010440): Train loss 4.137, Val loss 5.198\n",
            "[Batch 0] Current Loss: 4.1232\n",
            "[Batch 1] Current Loss: 4.4162\n",
            "[Batch 2] Current Loss: 4.2433\n",
            "[Batch 3] Current Loss: 4.0133\n",
            "[Batch 4] Current Loss: 3.8898\n",
            "[Batch 5] Current Loss: 4.1415\n",
            "[Batch 6] Current Loss: 3.5855\n",
            "[Batch 7] Current Loss: 3.9249\n",
            "[Batch 8] Current Loss: 4.5636\n",
            "[Batch 9] Current Loss: 3.4447\n",
            "[Batch 0] Current Loss: 5.3290\n",
            "[Batch 1] Current Loss: 4.8298\n",
            "[Batch 2] Current Loss: 4.7659\n",
            "[Batch 3] Current Loss: 5.0096\n",
            "[Batch 4] Current Loss: 5.9585\n",
            "[Batch 5] Current Loss: 5.0630\n",
            "[Batch 6] Current Loss: 5.4062\n",
            "[Batch 7] Current Loss: 5.7170\n",
            "[Batch 8] Current Loss: 5.7521\n",
            "[Batch 9] Current Loss: 5.4059\n",
            "Ep 2 (Step 010460): Train loss 4.035, Val loss 5.324\n",
            "[Batch 0] Current Loss: 4.3730\n",
            "[Batch 1] Current Loss: 4.6913\n",
            "[Batch 2] Current Loss: 3.9655\n",
            "[Batch 3] Current Loss: 3.8633\n",
            "[Batch 4] Current Loss: 4.5329\n",
            "[Batch 5] Current Loss: 4.7090\n",
            "[Batch 6] Current Loss: 4.0202\n",
            "[Batch 7] Current Loss: 3.7706\n",
            "[Batch 8] Current Loss: 4.3565\n",
            "[Batch 9] Current Loss: 3.9134\n",
            "[Batch 0] Current Loss: 5.0527\n",
            "[Batch 1] Current Loss: 5.6834\n",
            "[Batch 2] Current Loss: 4.5497\n",
            "[Batch 3] Current Loss: 5.6674\n",
            "[Batch 4] Current Loss: 5.2912\n",
            "[Batch 5] Current Loss: 5.6432\n",
            "[Batch 6] Current Loss: 4.8435\n",
            "[Batch 7] Current Loss: 5.1348\n",
            "[Batch 8] Current Loss: 5.1432\n",
            "[Batch 9] Current Loss: 5.0238\n",
            "Ep 2 (Step 010480): Train loss 4.220, Val loss 5.203\n",
            "[Batch 0] Current Loss: 3.9583\n",
            "[Batch 1] Current Loss: 3.9708\n",
            "[Batch 2] Current Loss: 3.8920\n",
            "[Batch 3] Current Loss: 4.2779\n",
            "[Batch 4] Current Loss: 3.8946\n",
            "[Batch 5] Current Loss: 3.7867\n",
            "[Batch 6] Current Loss: 4.0470\n",
            "[Batch 7] Current Loss: 4.3439\n",
            "[Batch 8] Current Loss: 4.6213\n",
            "[Batch 9] Current Loss: 3.6457\n",
            "[Batch 0] Current Loss: 5.1161\n",
            "[Batch 1] Current Loss: 5.3199\n",
            "[Batch 2] Current Loss: 5.0059\n",
            "[Batch 3] Current Loss: 5.1915\n",
            "[Batch 4] Current Loss: 5.1773\n",
            "[Batch 5] Current Loss: 5.2906\n",
            "[Batch 6] Current Loss: 5.5419\n",
            "[Batch 7] Current Loss: 5.0237\n",
            "[Batch 8] Current Loss: 5.0250\n",
            "[Batch 9] Current Loss: 4.9214\n",
            "Ep 2 (Step 010500): Train loss 4.044, Val loss 5.161\n",
            "[Batch 0] Current Loss: 4.3130\n",
            "[Batch 1] Current Loss: 4.0043\n",
            "[Batch 2] Current Loss: 4.0235\n",
            "[Batch 3] Current Loss: 4.7081\n",
            "[Batch 4] Current Loss: 3.6344\n",
            "[Batch 5] Current Loss: 4.3525\n",
            "[Batch 6] Current Loss: 4.6501\n",
            "[Batch 7] Current Loss: 2.9408\n",
            "[Batch 8] Current Loss: 4.2933\n",
            "[Batch 9] Current Loss: 4.6387\n",
            "[Batch 0] Current Loss: 4.8592\n",
            "[Batch 1] Current Loss: 5.6018\n",
            "[Batch 2] Current Loss: 5.8695\n",
            "[Batch 3] Current Loss: 4.5551\n",
            "[Batch 4] Current Loss: 4.9073\n",
            "[Batch 5] Current Loss: 5.4374\n",
            "[Batch 6] Current Loss: 5.2257\n",
            "[Batch 7] Current Loss: 5.7172\n",
            "[Batch 8] Current Loss: 5.9165\n",
            "[Batch 9] Current Loss: 5.0331\n",
            "Ep 2 (Step 010520): Train loss 4.156, Val loss 5.312\n",
            "[Batch 0] Current Loss: 5.1575\n",
            "[Batch 1] Current Loss: 4.3991\n",
            "[Batch 2] Current Loss: 4.6780\n",
            "[Batch 3] Current Loss: 4.1229\n",
            "[Batch 4] Current Loss: 4.0138\n",
            "[Batch 5] Current Loss: 3.7066\n",
            "[Batch 6] Current Loss: 4.8420\n",
            "[Batch 7] Current Loss: 3.7664\n",
            "[Batch 8] Current Loss: 4.3754\n",
            "[Batch 9] Current Loss: 4.2620\n",
            "[Batch 0] Current Loss: 4.8385\n",
            "[Batch 1] Current Loss: 5.1141\n",
            "[Batch 2] Current Loss: 6.0335\n",
            "[Batch 3] Current Loss: 5.3832\n",
            "[Batch 4] Current Loss: 5.0403\n",
            "[Batch 5] Current Loss: 5.2346\n",
            "[Batch 6] Current Loss: 5.5905\n",
            "[Batch 7] Current Loss: 4.8682\n",
            "[Batch 8] Current Loss: 4.7123\n",
            "[Batch 9] Current Loss: 5.6209\n",
            "Ep 2 (Step 010540): Train loss 4.332, Val loss 5.244\n",
            "[Batch 0] Current Loss: 4.2527\n",
            "[Batch 1] Current Loss: 3.9262\n",
            "[Batch 2] Current Loss: 4.7333\n",
            "[Batch 3] Current Loss: 4.3043\n",
            "[Batch 4] Current Loss: 3.8015\n",
            "[Batch 5] Current Loss: 3.7565\n",
            "[Batch 6] Current Loss: 3.5106\n",
            "[Batch 7] Current Loss: 4.1607\n",
            "[Batch 8] Current Loss: 4.0306\n",
            "[Batch 9] Current Loss: 3.7494\n",
            "[Batch 0] Current Loss: 5.5992\n",
            "[Batch 1] Current Loss: 5.0669\n",
            "[Batch 2] Current Loss: 5.2095\n",
            "[Batch 3] Current Loss: 5.3619\n",
            "[Batch 4] Current Loss: 5.1687\n",
            "[Batch 5] Current Loss: 4.7077\n",
            "[Batch 6] Current Loss: 6.0481\n",
            "[Batch 7] Current Loss: 5.0756\n",
            "[Batch 8] Current Loss: 5.6218\n",
            "[Batch 9] Current Loss: 5.3330\n",
            "Ep 2 (Step 010560): Train loss 4.023, Val loss 5.319\n",
            "[Batch 0] Current Loss: 4.6374\n",
            "[Batch 1] Current Loss: 4.2661\n",
            "[Batch 2] Current Loss: 4.3339\n",
            "[Batch 3] Current Loss: 3.9298\n",
            "[Batch 4] Current Loss: 4.7266\n",
            "[Batch 5] Current Loss: 4.2134\n",
            "[Batch 6] Current Loss: 3.9302\n",
            "[Batch 7] Current Loss: 3.7489\n",
            "[Batch 8] Current Loss: 4.1090\n",
            "[Batch 9] Current Loss: 4.6285\n",
            "[Batch 0] Current Loss: 6.2817\n",
            "[Batch 1] Current Loss: 5.2100\n",
            "[Batch 2] Current Loss: 5.1512\n",
            "[Batch 3] Current Loss: 5.3343\n",
            "[Batch 4] Current Loss: 5.0015\n",
            "[Batch 5] Current Loss: 5.2330\n",
            "[Batch 6] Current Loss: 5.4609\n",
            "[Batch 7] Current Loss: 5.1728\n",
            "[Batch 8] Current Loss: 5.5367\n",
            "[Batch 9] Current Loss: 5.8349\n",
            "Ep 2 (Step 010580): Train loss 4.252, Val loss 5.422\n",
            "[Batch 0] Current Loss: 3.6590\n",
            "[Batch 1] Current Loss: 4.5609\n",
            "[Batch 2] Current Loss: 3.7755\n",
            "[Batch 3] Current Loss: 4.3003\n",
            "[Batch 4] Current Loss: 4.1339\n",
            "[Batch 5] Current Loss: 3.7606\n",
            "[Batch 6] Current Loss: 4.4493\n",
            "[Batch 7] Current Loss: 5.1755\n",
            "[Batch 8] Current Loss: 4.2324\n",
            "[Batch 9] Current Loss: 3.8511\n",
            "[Batch 0] Current Loss: 5.6668\n",
            "[Batch 1] Current Loss: 5.5261\n",
            "[Batch 2] Current Loss: 5.4474\n",
            "[Batch 3] Current Loss: 4.6413\n",
            "[Batch 4] Current Loss: 5.3522\n",
            "[Batch 5] Current Loss: 4.5720\n",
            "[Batch 6] Current Loss: 5.4722\n",
            "[Batch 7] Current Loss: 5.8883\n",
            "[Batch 8] Current Loss: 5.4046\n",
            "[Batch 9] Current Loss: 5.5431\n",
            "Ep 2 (Step 010600): Train loss 4.190, Val loss 5.351\n",
            "[Batch 0] Current Loss: 4.5946\n",
            "[Batch 1] Current Loss: 4.3051\n",
            "[Batch 2] Current Loss: 4.4339\n",
            "[Batch 3] Current Loss: 4.2030\n",
            "[Batch 4] Current Loss: 4.2308\n",
            "[Batch 5] Current Loss: 3.4819\n",
            "[Batch 6] Current Loss: 3.9971\n",
            "[Batch 7] Current Loss: 4.5843\n",
            "[Batch 8] Current Loss: 3.6257\n",
            "[Batch 9] Current Loss: 4.2766\n",
            "[Batch 0] Current Loss: 5.4193\n",
            "[Batch 1] Current Loss: 4.7860\n",
            "[Batch 2] Current Loss: 5.1616\n",
            "[Batch 3] Current Loss: 4.7988\n",
            "[Batch 4] Current Loss: 4.9477\n",
            "[Batch 5] Current Loss: 5.6733\n",
            "[Batch 6] Current Loss: 5.8995\n",
            "[Batch 7] Current Loss: 5.4737\n",
            "[Batch 8] Current Loss: 5.3247\n",
            "[Batch 9] Current Loss: 4.7956\n",
            "Ep 2 (Step 010620): Train loss 4.173, Val loss 5.228\n",
            "[Batch 0] Current Loss: 4.5315\n",
            "[Batch 1] Current Loss: 4.2055\n",
            "[Batch 2] Current Loss: 4.3129\n",
            "[Batch 3] Current Loss: 3.8744\n",
            "[Batch 4] Current Loss: 4.5971\n",
            "[Batch 5] Current Loss: 3.7893\n",
            "[Batch 6] Current Loss: 4.2859\n",
            "[Batch 7] Current Loss: 4.2382\n",
            "[Batch 8] Current Loss: 4.4024\n",
            "[Batch 9] Current Loss: 3.9359\n",
            "[Batch 0] Current Loss: 5.9797\n",
            "[Batch 1] Current Loss: 5.2902\n",
            "[Batch 2] Current Loss: 5.1818\n",
            "[Batch 3] Current Loss: 4.8976\n",
            "[Batch 4] Current Loss: 5.3134\n",
            "[Batch 5] Current Loss: 5.0587\n",
            "[Batch 6] Current Loss: 5.3600\n",
            "[Batch 7] Current Loss: 4.7686\n",
            "[Batch 8] Current Loss: 6.5295\n",
            "[Batch 9] Current Loss: 5.5755\n",
            "Ep 2 (Step 010640): Train loss 4.217, Val loss 5.396\n",
            "[Batch 0] Current Loss: 4.2095\n",
            "[Batch 1] Current Loss: 4.4662\n",
            "[Batch 2] Current Loss: 3.7904\n",
            "[Batch 3] Current Loss: 4.6767\n",
            "[Batch 4] Current Loss: 4.1840\n",
            "[Batch 5] Current Loss: 3.5344\n",
            "[Batch 6] Current Loss: 4.3412\n",
            "[Batch 7] Current Loss: 4.0322\n",
            "[Batch 8] Current Loss: 4.2745\n",
            "[Batch 9] Current Loss: 4.0991\n",
            "[Batch 0] Current Loss: 5.2521\n",
            "[Batch 1] Current Loss: 5.2821\n",
            "[Batch 2] Current Loss: 5.5141\n",
            "[Batch 3] Current Loss: 4.6694\n",
            "[Batch 4] Current Loss: 4.8650\n",
            "[Batch 5] Current Loss: 5.4573\n",
            "[Batch 6] Current Loss: 5.0421\n",
            "[Batch 7] Current Loss: 5.3493\n",
            "[Batch 8] Current Loss: 5.8620\n",
            "[Batch 9] Current Loss: 4.9086\n",
            "Ep 2 (Step 010660): Train loss 4.161, Val loss 5.220\n",
            "[Batch 0] Current Loss: 4.4684\n",
            "[Batch 1] Current Loss: 4.1109\n",
            "[Batch 2] Current Loss: 4.3348\n",
            "[Batch 3] Current Loss: 4.1699\n",
            "[Batch 4] Current Loss: 4.0920\n",
            "[Batch 5] Current Loss: 3.9213\n",
            "[Batch 6] Current Loss: 4.0180\n",
            "[Batch 7] Current Loss: 3.6518\n",
            "[Batch 8] Current Loss: 3.8600\n",
            "[Batch 9] Current Loss: 4.2991\n",
            "[Batch 0] Current Loss: 5.6425\n",
            "[Batch 1] Current Loss: 4.8666\n",
            "[Batch 2] Current Loss: 5.4418\n",
            "[Batch 3] Current Loss: 5.1528\n",
            "[Batch 4] Current Loss: 5.6036\n",
            "[Batch 5] Current Loss: 5.7669\n",
            "[Batch 6] Current Loss: 4.8546\n",
            "[Batch 7] Current Loss: 4.7806\n",
            "[Batch 8] Current Loss: 5.5056\n",
            "[Batch 9] Current Loss: 5.8455\n",
            "Ep 2 (Step 010680): Train loss 4.093, Val loss 5.346\n",
            "[Batch 0] Current Loss: 4.7730\n",
            "[Batch 1] Current Loss: 3.5291\n",
            "[Batch 2] Current Loss: 4.0592\n",
            "[Batch 3] Current Loss: 3.8212\n",
            "[Batch 4] Current Loss: 4.4174\n",
            "[Batch 5] Current Loss: 3.8609\n",
            "[Batch 6] Current Loss: 3.6680\n",
            "[Batch 7] Current Loss: 4.1265\n",
            "[Batch 8] Current Loss: 3.9847\n",
            "[Batch 9] Current Loss: 4.2166\n",
            "[Batch 0] Current Loss: 5.2808\n",
            "[Batch 1] Current Loss: 5.6978\n",
            "[Batch 2] Current Loss: 4.8901\n",
            "[Batch 3] Current Loss: 5.3327\n",
            "[Batch 4] Current Loss: 5.7052\n",
            "[Batch 5] Current Loss: 4.4907\n",
            "[Batch 6] Current Loss: 4.9353\n",
            "[Batch 7] Current Loss: 5.7156\n",
            "[Batch 8] Current Loss: 5.4540\n",
            "[Batch 9] Current Loss: 4.8783\n",
            "Ep 2 (Step 010700): Train loss 4.046, Val loss 5.238\n",
            "[Batch 0] Current Loss: 4.4323\n",
            "[Batch 1] Current Loss: 3.9183\n",
            "[Batch 2] Current Loss: 3.8387\n",
            "[Batch 3] Current Loss: 3.7654\n",
            "[Batch 4] Current Loss: 3.9277\n",
            "[Batch 5] Current Loss: 4.1942\n",
            "[Batch 6] Current Loss: 3.3953\n",
            "[Batch 7] Current Loss: 4.5918\n",
            "[Batch 8] Current Loss: 3.7816\n",
            "[Batch 9] Current Loss: 4.0814\n",
            "[Batch 0] Current Loss: 4.8444\n",
            "[Batch 1] Current Loss: 4.9397\n",
            "[Batch 2] Current Loss: 5.5596\n",
            "[Batch 3] Current Loss: 4.4859\n",
            "[Batch 4] Current Loss: 5.0946\n",
            "[Batch 5] Current Loss: 5.2867\n",
            "[Batch 6] Current Loss: 5.8987\n",
            "[Batch 7] Current Loss: 4.9817\n",
            "[Batch 8] Current Loss: 5.0832\n",
            "[Batch 9] Current Loss: 4.8336\n",
            "Ep 2 (Step 010720): Train loss 3.993, Val loss 5.101\n",
            "[Batch 0] Current Loss: 4.4209\n",
            "[Batch 1] Current Loss: 4.6716\n",
            "[Batch 2] Current Loss: 4.4563\n",
            "[Batch 3] Current Loss: 4.4055\n",
            "[Batch 4] Current Loss: 3.4907\n",
            "[Batch 5] Current Loss: 4.4162\n",
            "[Batch 6] Current Loss: 4.4892\n",
            "[Batch 7] Current Loss: 4.3813\n",
            "[Batch 8] Current Loss: 4.1995\n",
            "[Batch 9] Current Loss: 4.4116\n",
            "[Batch 0] Current Loss: 4.6946\n",
            "[Batch 1] Current Loss: 5.5349\n",
            "[Batch 2] Current Loss: 5.4620\n",
            "[Batch 3] Current Loss: 5.4715\n",
            "[Batch 4] Current Loss: 4.9824\n",
            "[Batch 5] Current Loss: 5.9395\n",
            "[Batch 6] Current Loss: 5.1230\n",
            "[Batch 7] Current Loss: 5.4499\n",
            "[Batch 8] Current Loss: 5.4921\n",
            "[Batch 9] Current Loss: 5.4047\n",
            "Ep 2 (Step 010740): Train loss 4.334, Val loss 5.355\n",
            "[Batch 0] Current Loss: 3.4867\n",
            "[Batch 1] Current Loss: 3.9417\n",
            "[Batch 2] Current Loss: 3.8415\n",
            "[Batch 3] Current Loss: 4.0091\n",
            "[Batch 4] Current Loss: 3.8433\n",
            "[Batch 5] Current Loss: 3.9371\n",
            "[Batch 6] Current Loss: 3.9112\n",
            "[Batch 7] Current Loss: 4.4275\n",
            "[Batch 8] Current Loss: 4.2801\n",
            "[Batch 9] Current Loss: 4.4704\n",
            "[Batch 0] Current Loss: 5.6250\n",
            "[Batch 1] Current Loss: 5.2147\n",
            "[Batch 2] Current Loss: 5.1962\n",
            "[Batch 3] Current Loss: 5.2222\n",
            "[Batch 4] Current Loss: 5.0723\n",
            "[Batch 5] Current Loss: 5.7250\n",
            "[Batch 6] Current Loss: 5.2382\n",
            "[Batch 7] Current Loss: 5.5192\n",
            "[Batch 8] Current Loss: 4.2661\n",
            "[Batch 9] Current Loss: 4.7077\n",
            "Ep 2 (Step 010760): Train loss 4.015, Val loss 5.179\n",
            "[Batch 0] Current Loss: 4.0346\n",
            "[Batch 1] Current Loss: 4.0331\n",
            "[Batch 2] Current Loss: 3.9390\n",
            "[Batch 3] Current Loss: 4.3006\n",
            "[Batch 4] Current Loss: 4.5907\n",
            "[Batch 5] Current Loss: 3.8795\n",
            "[Batch 6] Current Loss: 4.2869\n",
            "[Batch 7] Current Loss: 4.6123\n",
            "[Batch 8] Current Loss: 3.8877\n",
            "[Batch 9] Current Loss: 4.0643\n",
            "[Batch 0] Current Loss: 4.8928\n",
            "[Batch 1] Current Loss: 5.0083\n",
            "[Batch 2] Current Loss: 5.3077\n",
            "[Batch 3] Current Loss: 5.3625\n",
            "[Batch 4] Current Loss: 5.6132\n",
            "[Batch 5] Current Loss: 5.7357\n",
            "[Batch 6] Current Loss: 5.0778\n",
            "[Batch 7] Current Loss: 4.9278\n",
            "[Batch 8] Current Loss: 4.9872\n",
            "[Batch 9] Current Loss: 5.2944\n",
            "Ep 2 (Step 010780): Train loss 4.163, Val loss 5.221\n",
            "[Batch 0] Current Loss: 3.3985\n",
            "[Batch 1] Current Loss: 3.7222\n",
            "[Batch 2] Current Loss: 3.5534\n",
            "[Batch 3] Current Loss: 4.5387\n",
            "[Batch 4] Current Loss: 4.1318\n",
            "[Batch 5] Current Loss: 4.1493\n",
            "[Batch 6] Current Loss: 3.6990\n",
            "[Batch 7] Current Loss: 4.1756\n",
            "[Batch 8] Current Loss: 4.2019\n",
            "[Batch 9] Current Loss: 4.5761\n",
            "[Batch 0] Current Loss: 5.3187\n",
            "[Batch 1] Current Loss: 4.9956\n",
            "[Batch 2] Current Loss: 5.0268\n",
            "[Batch 3] Current Loss: 4.1425\n",
            "[Batch 4] Current Loss: 5.3376\n",
            "[Batch 5] Current Loss: 5.6424\n",
            "[Batch 6] Current Loss: 5.4702\n",
            "[Batch 7] Current Loss: 5.7945\n",
            "[Batch 8] Current Loss: 5.3703\n",
            "[Batch 9] Current Loss: 5.1933\n",
            "Ep 2 (Step 010800): Train loss 4.015, Val loss 5.229\n",
            "[Batch 0] Current Loss: 3.7507\n",
            "[Batch 1] Current Loss: 4.0322\n",
            "[Batch 2] Current Loss: 4.7714\n",
            "[Batch 3] Current Loss: 4.3083\n",
            "[Batch 4] Current Loss: 4.0949\n",
            "[Batch 5] Current Loss: 4.2385\n",
            "[Batch 6] Current Loss: 4.0367\n",
            "[Batch 7] Current Loss: 3.6951\n",
            "[Batch 8] Current Loss: 3.8868\n",
            "[Batch 9] Current Loss: 4.3933\n",
            "[Batch 0] Current Loss: 5.3819\n",
            "[Batch 1] Current Loss: 5.2900\n",
            "[Batch 2] Current Loss: 4.6655\n",
            "[Batch 3] Current Loss: 4.8580\n",
            "[Batch 4] Current Loss: 5.0653\n",
            "[Batch 5] Current Loss: 4.9138\n",
            "[Batch 6] Current Loss: 4.9354\n",
            "[Batch 7] Current Loss: 4.9880\n",
            "[Batch 8] Current Loss: 4.9004\n",
            "[Batch 9] Current Loss: 5.5027\n",
            "Ep 2 (Step 010820): Train loss 4.121, Val loss 5.050\n",
            "[Batch 0] Current Loss: 4.3756\n",
            "[Batch 1] Current Loss: 3.5405\n",
            "[Batch 2] Current Loss: 3.4258\n",
            "[Batch 3] Current Loss: 3.9384\n",
            "[Batch 4] Current Loss: 3.9520\n",
            "[Batch 5] Current Loss: 3.6975\n",
            "[Batch 6] Current Loss: 3.5594\n",
            "[Batch 7] Current Loss: 3.8509\n",
            "[Batch 8] Current Loss: 4.5888\n",
            "[Batch 9] Current Loss: 3.8804\n",
            "[Batch 0] Current Loss: 5.1723\n",
            "[Batch 1] Current Loss: 4.9662\n",
            "[Batch 2] Current Loss: 5.3354\n",
            "[Batch 3] Current Loss: 5.1761\n",
            "[Batch 4] Current Loss: 5.9700\n",
            "[Batch 5] Current Loss: 5.2557\n",
            "[Batch 6] Current Loss: 4.9047\n",
            "[Batch 7] Current Loss: 5.1262\n",
            "[Batch 8] Current Loss: 5.2416\n",
            "[Batch 9] Current Loss: 5.7085\n",
            "Ep 2 (Step 010840): Train loss 3.881, Val loss 5.286\n",
            "[Batch 0] Current Loss: 3.5107\n",
            "[Batch 1] Current Loss: 3.6043\n",
            "[Batch 2] Current Loss: 3.9581\n",
            "[Batch 3] Current Loss: 3.8316\n",
            "[Batch 4] Current Loss: 3.9932\n",
            "[Batch 5] Current Loss: 4.5707\n",
            "[Batch 6] Current Loss: 4.5555\n",
            "[Batch 7] Current Loss: 4.2633\n",
            "[Batch 8] Current Loss: 4.2782\n",
            "[Batch 9] Current Loss: 4.3498\n",
            "[Batch 0] Current Loss: 4.7901\n",
            "[Batch 1] Current Loss: 4.9870\n",
            "[Batch 2] Current Loss: 5.7252\n",
            "[Batch 3] Current Loss: 5.8443\n",
            "[Batch 4] Current Loss: 4.8139\n",
            "[Batch 5] Current Loss: 5.7863\n",
            "[Batch 6] Current Loss: 5.4147\n",
            "[Batch 7] Current Loss: 5.3703\n",
            "[Batch 8] Current Loss: 5.5633\n",
            "[Batch 9] Current Loss: 5.4475\n",
            "Ep 2 (Step 010860): Train loss 4.092, Val loss 5.374\n",
            "[Batch 0] Current Loss: 3.7594\n",
            "[Batch 1] Current Loss: 3.1986\n",
            "[Batch 2] Current Loss: 3.7729\n",
            "[Batch 3] Current Loss: 4.2452\n",
            "[Batch 4] Current Loss: 3.8364\n",
            "[Batch 5] Current Loss: 3.9531\n",
            "[Batch 6] Current Loss: 3.4874\n",
            "[Batch 7] Current Loss: 3.8452\n",
            "[Batch 8] Current Loss: 3.6513\n",
            "[Batch 9] Current Loss: 4.2344\n",
            "[Batch 0] Current Loss: 4.9839\n",
            "[Batch 1] Current Loss: 5.3710\n",
            "[Batch 2] Current Loss: 5.4247\n",
            "[Batch 3] Current Loss: 5.1492\n",
            "[Batch 4] Current Loss: 4.9504\n",
            "[Batch 5] Current Loss: 5.7057\n",
            "[Batch 6] Current Loss: 5.1942\n",
            "[Batch 7] Current Loss: 5.5685\n",
            "[Batch 8] Current Loss: 5.2603\n",
            "[Batch 9] Current Loss: 5.2689\n",
            "Ep 2 (Step 010880): Train loss 3.798, Val loss 5.288\n",
            "[Batch 0] Current Loss: 3.8410\n",
            "[Batch 1] Current Loss: 4.2551\n",
            "[Batch 2] Current Loss: 4.2223\n",
            "[Batch 3] Current Loss: 4.2392\n",
            "[Batch 4] Current Loss: 4.2438\n",
            "[Batch 5] Current Loss: 4.5233\n",
            "[Batch 6] Current Loss: 4.1739\n",
            "[Batch 7] Current Loss: 3.6146\n",
            "[Batch 8] Current Loss: 4.3139\n",
            "[Batch 9] Current Loss: 4.6043\n",
            "[Batch 0] Current Loss: 5.1170\n",
            "[Batch 1] Current Loss: 5.0867\n",
            "[Batch 2] Current Loss: 5.8719\n",
            "[Batch 3] Current Loss: 5.7496\n",
            "[Batch 4] Current Loss: 5.1217\n",
            "[Batch 5] Current Loss: 5.2901\n",
            "[Batch 6] Current Loss: 5.7838\n",
            "[Batch 7] Current Loss: 5.0459\n",
            "[Batch 8] Current Loss: 5.6708\n",
            "[Batch 9] Current Loss: 5.2725\n",
            "Ep 2 (Step 010900): Train loss 4.203, Val loss 5.401\n",
            "[Batch 0] Current Loss: 3.9542\n",
            "[Batch 1] Current Loss: 4.3229\n",
            "[Batch 2] Current Loss: 4.3015\n",
            "[Batch 3] Current Loss: 3.8554\n",
            "[Batch 4] Current Loss: 3.6877\n",
            "[Batch 5] Current Loss: 4.5313\n",
            "[Batch 6] Current Loss: 3.6844\n",
            "[Batch 7] Current Loss: 3.7325\n",
            "[Batch 8] Current Loss: 4.6998\n",
            "[Batch 9] Current Loss: 4.6027\n",
            "[Batch 0] Current Loss: 6.2125\n",
            "[Batch 1] Current Loss: 5.0543\n",
            "[Batch 2] Current Loss: 5.5591\n",
            "[Batch 3] Current Loss: 5.2501\n",
            "[Batch 4] Current Loss: 5.6779\n",
            "[Batch 5] Current Loss: 5.4837\n",
            "[Batch 6] Current Loss: 5.2472\n",
            "[Batch 7] Current Loss: 5.7063\n",
            "[Batch 8] Current Loss: 6.0013\n",
            "[Batch 9] Current Loss: 5.5671\n",
            "Ep 2 (Step 010920): Train loss 4.137, Val loss 5.576\n",
            "[Batch 0] Current Loss: 3.7125\n",
            "[Batch 1] Current Loss: 3.9394\n",
            "[Batch 2] Current Loss: 3.9597\n",
            "[Batch 3] Current Loss: 4.0046\n",
            "[Batch 4] Current Loss: 4.4720\n",
            "[Batch 5] Current Loss: 3.8172\n",
            "[Batch 6] Current Loss: 4.0534\n",
            "[Batch 7] Current Loss: 3.9629\n",
            "[Batch 8] Current Loss: 4.9683\n",
            "[Batch 9] Current Loss: 3.9094\n",
            "[Batch 0] Current Loss: 4.7433\n",
            "[Batch 1] Current Loss: 4.6478\n",
            "[Batch 2] Current Loss: 5.6015\n",
            "[Batch 3] Current Loss: 5.1485\n",
            "[Batch 4] Current Loss: 5.0995\n",
            "[Batch 5] Current Loss: 5.3444\n",
            "[Batch 6] Current Loss: 5.5322\n",
            "[Batch 7] Current Loss: 5.1521\n",
            "[Batch 8] Current Loss: 4.5863\n",
            "[Batch 9] Current Loss: 5.0033\n",
            "Ep 2 (Step 010940): Train loss 4.080, Val loss 5.086\n",
            "[Batch 0] Current Loss: 3.7418\n",
            "[Batch 1] Current Loss: 3.5991\n",
            "[Batch 2] Current Loss: 4.4670\n",
            "[Batch 3] Current Loss: 3.9883\n",
            "[Batch 4] Current Loss: 3.9130\n",
            "[Batch 5] Current Loss: 3.7493\n",
            "[Batch 6] Current Loss: 3.7651\n",
            "[Batch 7] Current Loss: 4.2218\n",
            "[Batch 8] Current Loss: 4.1849\n",
            "[Batch 9] Current Loss: 3.8510\n",
            "[Batch 0] Current Loss: 5.2160\n",
            "[Batch 1] Current Loss: 4.9785\n",
            "[Batch 2] Current Loss: 5.4848\n",
            "[Batch 3] Current Loss: 4.8847\n",
            "[Batch 4] Current Loss: 5.4994\n",
            "[Batch 5] Current Loss: 5.1347\n",
            "[Batch 6] Current Loss: 4.9494\n",
            "[Batch 7] Current Loss: 5.3500\n",
            "[Batch 8] Current Loss: 6.0847\n",
            "[Batch 9] Current Loss: 5.0868\n",
            "Ep 2 (Step 010960): Train loss 3.948, Val loss 5.267\n",
            "[Batch 0] Current Loss: 3.5230\n",
            "[Batch 1] Current Loss: 3.9418\n",
            "[Batch 2] Current Loss: 3.7667\n",
            "[Batch 3] Current Loss: 3.7210\n",
            "[Batch 4] Current Loss: 4.2857\n",
            "[Batch 5] Current Loss: 4.5640\n",
            "[Batch 6] Current Loss: 3.2806\n",
            "[Batch 7] Current Loss: 3.8757\n",
            "[Batch 8] Current Loss: 4.0383\n",
            "[Batch 9] Current Loss: 4.2965\n",
            "[Batch 0] Current Loss: 5.2868\n",
            "[Batch 1] Current Loss: 5.3387\n",
            "[Batch 2] Current Loss: 5.3273\n",
            "[Batch 3] Current Loss: 5.6514\n",
            "[Batch 4] Current Loss: 5.2265\n",
            "[Batch 5] Current Loss: 5.3832\n",
            "[Batch 6] Current Loss: 4.5788\n",
            "[Batch 7] Current Loss: 4.9199\n",
            "[Batch 8] Current Loss: 5.0170\n",
            "[Batch 9] Current Loss: 4.8858\n",
            "Ep 2 (Step 010980): Train loss 3.929, Val loss 5.162\n",
            "[Batch 0] Current Loss: 3.7046\n",
            "[Batch 1] Current Loss: 4.2655\n",
            "[Batch 2] Current Loss: 4.2449\n",
            "[Batch 3] Current Loss: 4.5440\n",
            "[Batch 4] Current Loss: 4.4884\n",
            "[Batch 5] Current Loss: 4.7605\n",
            "[Batch 6] Current Loss: 3.1757\n",
            "[Batch 7] Current Loss: 4.4932\n",
            "[Batch 8] Current Loss: 3.7205\n",
            "[Batch 9] Current Loss: 4.2355\n",
            "[Batch 0] Current Loss: 5.9956\n",
            "[Batch 1] Current Loss: 5.4470\n",
            "[Batch 2] Current Loss: 4.9617\n",
            "[Batch 3] Current Loss: 5.7282\n",
            "[Batch 4] Current Loss: 4.9345\n",
            "[Batch 5] Current Loss: 4.7166\n",
            "[Batch 6] Current Loss: 5.7305\n",
            "[Batch 7] Current Loss: 5.5007\n",
            "[Batch 8] Current Loss: 5.3485\n",
            "[Batch 9] Current Loss: 5.6260\n",
            "Ep 2 (Step 011000): Train loss 4.163, Val loss 5.399\n",
            "[Batch 0] Current Loss: 4.3794\n",
            "[Batch 1] Current Loss: 3.7761\n",
            "[Batch 2] Current Loss: 4.3064\n",
            "[Batch 3] Current Loss: 4.1975\n",
            "[Batch 4] Current Loss: 4.8424\n",
            "[Batch 5] Current Loss: 4.4286\n",
            "[Batch 6] Current Loss: 4.1417\n",
            "[Batch 7] Current Loss: 4.2321\n",
            "[Batch 8] Current Loss: 3.7296\n",
            "[Batch 9] Current Loss: 4.3348\n",
            "[Batch 0] Current Loss: 5.2964\n",
            "[Batch 1] Current Loss: 5.4926\n",
            "[Batch 2] Current Loss: 5.7427\n",
            "[Batch 3] Current Loss: 5.4927\n",
            "[Batch 4] Current Loss: 5.8466\n",
            "[Batch 5] Current Loss: 4.9115\n",
            "[Batch 6] Current Loss: 5.3612\n",
            "[Batch 7] Current Loss: 5.7590\n",
            "[Batch 8] Current Loss: 6.0557\n",
            "[Batch 9] Current Loss: 5.2326\n",
            "Ep 2 (Step 011020): Train loss 4.237, Val loss 5.519\n",
            "[Batch 0] Current Loss: 4.1491\n",
            "[Batch 1] Current Loss: 4.1283\n",
            "[Batch 2] Current Loss: 4.1336\n",
            "[Batch 3] Current Loss: 3.9514\n",
            "[Batch 4] Current Loss: 4.0692\n",
            "[Batch 5] Current Loss: 4.2951\n",
            "[Batch 6] Current Loss: 3.6423\n",
            "[Batch 7] Current Loss: 4.1004\n",
            "[Batch 8] Current Loss: 4.4702\n",
            "[Batch 9] Current Loss: 4.7550\n",
            "[Batch 0] Current Loss: 4.6005\n",
            "[Batch 1] Current Loss: 5.3852\n",
            "[Batch 2] Current Loss: 5.3898\n",
            "[Batch 3] Current Loss: 5.1112\n",
            "[Batch 4] Current Loss: 6.0113\n",
            "[Batch 5] Current Loss: 4.9196\n",
            "[Batch 6] Current Loss: 5.2888\n",
            "[Batch 7] Current Loss: 5.0641\n",
            "[Batch 8] Current Loss: 5.6751\n",
            "[Batch 9] Current Loss: 5.5113\n",
            "Ep 2 (Step 011040): Train loss 4.169, Val loss 5.296\n",
            "[Batch 0] Current Loss: 4.5794\n",
            "[Batch 1] Current Loss: 3.9444\n",
            "[Batch 2] Current Loss: 3.4366\n",
            "[Batch 3] Current Loss: 4.5337\n",
            "[Batch 4] Current Loss: 4.0206\n",
            "[Batch 5] Current Loss: 4.4944\n",
            "[Batch 6] Current Loss: 3.7772\n",
            "[Batch 7] Current Loss: 3.6007\n",
            "[Batch 8] Current Loss: 4.0511\n",
            "[Batch 9] Current Loss: 3.7125\n",
            "[Batch 0] Current Loss: 5.0096\n",
            "[Batch 1] Current Loss: 4.7000\n",
            "[Batch 2] Current Loss: 5.4496\n",
            "[Batch 3] Current Loss: 5.3916\n",
            "[Batch 4] Current Loss: 5.3150\n",
            "[Batch 5] Current Loss: 5.3386\n",
            "[Batch 6] Current Loss: 5.1822\n",
            "[Batch 7] Current Loss: 5.8279\n",
            "[Batch 8] Current Loss: 4.9051\n",
            "[Batch 9] Current Loss: 5.4607\n",
            "Ep 2 (Step 011060): Train loss 4.015, Val loss 5.258\n",
            "[Batch 0] Current Loss: 4.1278\n",
            "[Batch 1] Current Loss: 3.7680\n",
            "[Batch 2] Current Loss: 3.7646\n",
            "[Batch 3] Current Loss: 4.0659\n",
            "[Batch 4] Current Loss: 3.9914\n",
            "[Batch 5] Current Loss: 3.9094\n",
            "[Batch 6] Current Loss: 3.7236\n",
            "[Batch 7] Current Loss: 3.8581\n",
            "[Batch 8] Current Loss: 3.6217\n",
            "[Batch 9] Current Loss: 4.4598\n",
            "[Batch 0] Current Loss: 4.9126\n",
            "[Batch 1] Current Loss: 5.3991\n",
            "[Batch 2] Current Loss: 5.5185\n",
            "[Batch 3] Current Loss: 5.1405\n",
            "[Batch 4] Current Loss: 4.6543\n",
            "[Batch 5] Current Loss: 4.9585\n",
            "[Batch 6] Current Loss: 5.3701\n",
            "[Batch 7] Current Loss: 5.2153\n",
            "[Batch 8] Current Loss: 5.7288\n",
            "[Batch 9] Current Loss: 4.6080\n",
            "Ep 2 (Step 011080): Train loss 3.929, Val loss 5.151\n",
            "[Batch 0] Current Loss: 4.3025\n",
            "[Batch 1] Current Loss: 4.8418\n",
            "[Batch 2] Current Loss: 3.8761\n",
            "[Batch 3] Current Loss: 3.7710\n",
            "[Batch 4] Current Loss: 3.8951\n",
            "[Batch 5] Current Loss: 3.8119\n",
            "[Batch 6] Current Loss: 3.8859\n",
            "[Batch 7] Current Loss: 3.6963\n",
            "[Batch 8] Current Loss: 3.7939\n",
            "[Batch 9] Current Loss: 4.5431\n",
            "[Batch 0] Current Loss: 4.7293\n",
            "[Batch 1] Current Loss: 5.2673\n",
            "[Batch 2] Current Loss: 5.0689\n",
            "[Batch 3] Current Loss: 5.5236\n",
            "[Batch 4] Current Loss: 4.3613\n",
            "[Batch 5] Current Loss: 5.3522\n",
            "[Batch 6] Current Loss: 5.3020\n",
            "[Batch 7] Current Loss: 5.3947\n",
            "[Batch 8] Current Loss: 5.3874\n",
            "[Batch 9] Current Loss: 4.1952\n",
            "Ep 2 (Step 011100): Train loss 4.042, Val loss 5.058\n",
            "[Batch 0] Current Loss: 4.1361\n",
            "[Batch 1] Current Loss: 4.1000\n",
            "[Batch 2] Current Loss: 4.4456\n",
            "[Batch 3] Current Loss: 3.9273\n",
            "[Batch 4] Current Loss: 4.3559\n",
            "[Batch 5] Current Loss: 4.2438\n",
            "[Batch 6] Current Loss: 3.7447\n",
            "[Batch 7] Current Loss: 4.1299\n",
            "[Batch 8] Current Loss: 3.9542\n",
            "[Batch 9] Current Loss: 3.6231\n",
            "[Batch 0] Current Loss: 5.6947\n",
            "[Batch 1] Current Loss: 5.2356\n",
            "[Batch 2] Current Loss: 5.7720\n",
            "[Batch 3] Current Loss: 5.6374\n",
            "[Batch 4] Current Loss: 5.4176\n",
            "[Batch 5] Current Loss: 5.4265\n",
            "[Batch 6] Current Loss: 5.4413\n",
            "[Batch 7] Current Loss: 5.5800\n",
            "[Batch 8] Current Loss: 4.7261\n",
            "[Batch 9] Current Loss: 5.9475\n",
            "Ep 2 (Step 011120): Train loss 4.066, Val loss 5.488\n",
            "[Batch 0] Current Loss: 4.3890\n",
            "[Batch 1] Current Loss: 3.7841\n",
            "[Batch 2] Current Loss: 3.7243\n",
            "[Batch 3] Current Loss: 4.3638\n",
            "[Batch 4] Current Loss: 3.6852\n",
            "[Batch 5] Current Loss: 4.5183\n",
            "[Batch 6] Current Loss: 3.7724\n",
            "[Batch 7] Current Loss: 3.8570\n",
            "[Batch 8] Current Loss: 4.1564\n",
            "[Batch 9] Current Loss: 4.5096\n",
            "[Batch 0] Current Loss: 5.4846\n",
            "[Batch 1] Current Loss: 3.8196\n",
            "[Batch 2] Current Loss: 5.7857\n",
            "[Batch 3] Current Loss: 5.6013\n",
            "[Batch 4] Current Loss: 4.7318\n",
            "[Batch 5] Current Loss: 5.2212\n",
            "[Batch 6] Current Loss: 5.2903\n",
            "[Batch 7] Current Loss: 4.9267\n",
            "[Batch 8] Current Loss: 5.6670\n",
            "[Batch 9] Current Loss: 5.2291\n",
            "Ep 2 (Step 011140): Train loss 4.076, Val loss 5.176\n",
            "[Batch 0] Current Loss: 3.6985\n",
            "[Batch 1] Current Loss: 3.9912\n",
            "[Batch 2] Current Loss: 4.1869\n",
            "[Batch 3] Current Loss: 3.8812\n",
            "[Batch 4] Current Loss: 4.4047\n",
            "[Batch 5] Current Loss: 3.6961\n",
            "[Batch 6] Current Loss: 3.9758\n",
            "[Batch 7] Current Loss: 3.5754\n",
            "[Batch 8] Current Loss: 4.7313\n",
            "[Batch 9] Current Loss: 4.3699\n",
            "[Batch 0] Current Loss: 5.2253\n",
            "[Batch 1] Current Loss: 5.2310\n",
            "[Batch 2] Current Loss: 5.4356\n",
            "[Batch 3] Current Loss: 4.9324\n",
            "[Batch 4] Current Loss: 5.2581\n",
            "[Batch 5] Current Loss: 5.2304\n",
            "[Batch 6] Current Loss: 5.1396\n",
            "[Batch 7] Current Loss: 5.4899\n",
            "[Batch 8] Current Loss: 5.2749\n",
            "[Batch 9] Current Loss: 4.6456\n",
            "Ep 2 (Step 011160): Train loss 4.051, Val loss 5.186\n",
            "[Batch 0] Current Loss: 3.7114\n",
            "[Batch 1] Current Loss: 4.3531\n",
            "[Batch 2] Current Loss: 4.1976\n",
            "[Batch 3] Current Loss: 3.8341\n",
            "[Batch 4] Current Loss: 3.7031\n",
            "[Batch 5] Current Loss: 4.1469\n",
            "[Batch 6] Current Loss: 4.0090\n",
            "[Batch 7] Current Loss: 4.6434\n",
            "[Batch 8] Current Loss: 3.9219\n",
            "[Batch 9] Current Loss: 3.7493\n",
            "[Batch 0] Current Loss: 4.5826\n",
            "[Batch 1] Current Loss: 5.4790\n",
            "[Batch 2] Current Loss: 5.2542\n",
            "[Batch 3] Current Loss: 5.5238\n",
            "[Batch 4] Current Loss: 5.6090\n",
            "[Batch 5] Current Loss: 5.6303\n",
            "[Batch 6] Current Loss: 4.8378\n",
            "[Batch 7] Current Loss: 5.0138\n",
            "[Batch 8] Current Loss: 5.3198\n",
            "[Batch 9] Current Loss: 5.3193\n",
            "Ep 2 (Step 011180): Train loss 4.027, Val loss 5.257\n",
            "[Batch 0] Current Loss: 3.5308\n",
            "[Batch 1] Current Loss: 3.2350\n",
            "[Batch 2] Current Loss: 4.4503\n",
            "[Batch 3] Current Loss: 4.2019\n",
            "[Batch 4] Current Loss: 3.4338\n",
            "[Batch 5] Current Loss: 3.5369\n",
            "[Batch 6] Current Loss: 4.7246\n",
            "[Batch 7] Current Loss: 3.8451\n",
            "[Batch 8] Current Loss: 3.9465\n",
            "[Batch 9] Current Loss: 3.9509\n",
            "[Batch 0] Current Loss: 5.8727\n",
            "[Batch 1] Current Loss: 5.5479\n",
            "[Batch 2] Current Loss: 4.9410\n",
            "[Batch 3] Current Loss: 5.5014\n",
            "[Batch 4] Current Loss: 5.0630\n",
            "[Batch 5] Current Loss: 5.3047\n",
            "[Batch 6] Current Loss: 5.4383\n",
            "[Batch 7] Current Loss: 5.7385\n",
            "[Batch 8] Current Loss: 5.1233\n",
            "[Batch 9] Current Loss: 5.7220\n",
            "Ep 2 (Step 011200): Train loss 3.886, Val loss 5.425\n",
            "[Batch 0] Current Loss: 4.0379\n",
            "[Batch 1] Current Loss: 4.3690\n",
            "[Batch 2] Current Loss: 4.0160\n",
            "[Batch 3] Current Loss: 4.0747\n",
            "[Batch 4] Current Loss: 3.8921\n",
            "[Batch 5] Current Loss: 3.7884\n",
            "[Batch 6] Current Loss: 3.3875\n",
            "[Batch 7] Current Loss: 4.0983\n",
            "[Batch 8] Current Loss: 4.0835\n",
            "[Batch 9] Current Loss: 3.9762\n",
            "[Batch 0] Current Loss: 4.9126\n",
            "[Batch 1] Current Loss: 5.2613\n",
            "[Batch 2] Current Loss: 5.4201\n",
            "[Batch 3] Current Loss: 4.8837\n",
            "[Batch 4] Current Loss: 5.5120\n",
            "[Batch 5] Current Loss: 5.3158\n",
            "[Batch 6] Current Loss: 5.5243\n",
            "[Batch 7] Current Loss: 5.2446\n",
            "[Batch 8] Current Loss: 5.8204\n",
            "[Batch 9] Current Loss: 4.8913\n",
            "Ep 2 (Step 011220): Train loss 3.972, Val loss 5.279\n",
            "[Batch 0] Current Loss: 4.3627\n",
            "[Batch 1] Current Loss: 3.9259\n",
            "[Batch 2] Current Loss: 3.8181\n",
            "[Batch 3] Current Loss: 3.7791\n",
            "[Batch 4] Current Loss: 3.8280\n",
            "[Batch 5] Current Loss: 3.8199\n",
            "[Batch 6] Current Loss: 4.4121\n",
            "[Batch 7] Current Loss: 4.3252\n",
            "[Batch 8] Current Loss: 4.0817\n",
            "[Batch 9] Current Loss: 4.0051\n",
            "[Batch 0] Current Loss: 5.3371\n",
            "[Batch 1] Current Loss: 5.4855\n",
            "[Batch 2] Current Loss: 5.2640\n",
            "[Batch 3] Current Loss: 5.6466\n",
            "[Batch 4] Current Loss: 5.1805\n",
            "[Batch 5] Current Loss: 4.5397\n",
            "[Batch 6] Current Loss: 4.4485\n",
            "[Batch 7] Current Loss: 4.8415\n",
            "[Batch 8] Current Loss: 5.0852\n",
            "[Batch 9] Current Loss: 4.8340\n",
            "Ep 2 (Step 011240): Train loss 4.036, Val loss 5.066\n",
            "[Batch 0] Current Loss: 3.8748\n",
            "[Batch 1] Current Loss: 4.0842\n",
            "[Batch 2] Current Loss: 3.5069\n",
            "[Batch 3] Current Loss: 3.6306\n",
            "[Batch 4] Current Loss: 4.1982\n",
            "[Batch 5] Current Loss: 3.4864\n",
            "[Batch 6] Current Loss: 3.9614\n",
            "[Batch 7] Current Loss: 4.3344\n",
            "[Batch 8] Current Loss: 3.9125\n",
            "[Batch 9] Current Loss: 3.5159\n",
            "[Batch 0] Current Loss: 5.4972\n",
            "[Batch 1] Current Loss: 6.1218\n",
            "[Batch 2] Current Loss: 4.7074\n",
            "[Batch 3] Current Loss: 4.9998\n",
            "[Batch 4] Current Loss: 5.3311\n",
            "[Batch 5] Current Loss: 4.9073\n",
            "[Batch 6] Current Loss: 5.1330\n",
            "[Batch 7] Current Loss: 5.1513\n",
            "[Batch 8] Current Loss: 5.0594\n",
            "[Batch 9] Current Loss: 5.0295\n",
            "Ep 2 (Step 011260): Train loss 3.851, Val loss 5.194\n",
            "[Batch 0] Current Loss: 4.5793\n",
            "[Batch 1] Current Loss: 4.2140\n",
            "[Batch 2] Current Loss: 4.0077\n",
            "[Batch 3] Current Loss: 3.1951\n",
            "[Batch 4] Current Loss: 3.6234\n",
            "[Batch 5] Current Loss: 4.1569\n",
            "[Batch 6] Current Loss: 4.0694\n",
            "[Batch 7] Current Loss: 4.2487\n",
            "[Batch 8] Current Loss: 4.3234\n",
            "[Batch 9] Current Loss: 4.0445\n",
            "[Batch 0] Current Loss: 5.1132\n",
            "[Batch 1] Current Loss: 5.1264\n",
            "[Batch 2] Current Loss: 5.5546\n",
            "[Batch 3] Current Loss: 5.6045\n",
            "[Batch 4] Current Loss: 5.2937\n",
            "[Batch 5] Current Loss: 5.3885\n",
            "[Batch 6] Current Loss: 5.9380\n",
            "[Batch 7] Current Loss: 5.7810\n",
            "[Batch 8] Current Loss: 5.5786\n",
            "[Batch 9] Current Loss: 5.6359\n",
            "Ep 2 (Step 011280): Train loss 4.046, Val loss 5.501\n",
            "[Batch 0] Current Loss: 3.8406\n",
            "[Batch 1] Current Loss: 3.6181\n",
            "[Batch 2] Current Loss: 3.8301\n",
            "[Batch 3] Current Loss: 4.1613\n",
            "[Batch 4] Current Loss: 3.3511\n",
            "[Batch 5] Current Loss: 4.0680\n",
            "[Batch 6] Current Loss: 4.6567\n",
            "[Batch 7] Current Loss: 4.3966\n",
            "[Batch 8] Current Loss: 3.6342\n",
            "[Batch 9] Current Loss: 4.3329\n",
            "[Batch 0] Current Loss: 4.8771\n",
            "[Batch 1] Current Loss: 6.0992\n",
            "[Batch 2] Current Loss: 4.6378\n",
            "[Batch 3] Current Loss: 5.6253\n",
            "[Batch 4] Current Loss: 4.6983\n",
            "[Batch 5] Current Loss: 5.5012\n",
            "[Batch 6] Current Loss: 5.2888\n",
            "[Batch 7] Current Loss: 5.0384\n",
            "[Batch 8] Current Loss: 4.1447\n",
            "[Batch 9] Current Loss: 5.7146\n",
            "Ep 2 (Step 011300): Train loss 3.989, Val loss 5.163\n",
            "[Batch 0] Current Loss: 4.2679\n",
            "[Batch 1] Current Loss: 4.9231\n",
            "[Batch 2] Current Loss: 3.7780\n",
            "[Batch 3] Current Loss: 3.7487\n",
            "[Batch 4] Current Loss: 3.8248\n",
            "[Batch 5] Current Loss: 4.4733\n",
            "[Batch 6] Current Loss: 3.5054\n",
            "[Batch 7] Current Loss: 3.8689\n",
            "[Batch 8] Current Loss: 4.5333\n",
            "[Batch 9] Current Loss: 4.1870\n",
            "[Batch 0] Current Loss: 5.2581\n",
            "[Batch 1] Current Loss: 5.0439\n",
            "[Batch 2] Current Loss: 5.9440\n",
            "[Batch 3] Current Loss: 5.4010\n",
            "[Batch 4] Current Loss: 5.4140\n",
            "[Batch 5] Current Loss: 5.4079\n",
            "[Batch 6] Current Loss: 5.4706\n",
            "[Batch 7] Current Loss: 5.0133\n",
            "[Batch 8] Current Loss: 5.2513\n",
            "[Batch 9] Current Loss: 5.0495\n",
            "Ep 2 (Step 011320): Train loss 4.111, Val loss 5.325\n",
            "[Batch 0] Current Loss: 3.9858\n",
            "[Batch 1] Current Loss: 3.8713\n",
            "[Batch 2] Current Loss: 3.9358\n",
            "[Batch 3] Current Loss: 3.7171\n",
            "[Batch 4] Current Loss: 3.9145\n",
            "[Batch 5] Current Loss: 3.8591\n",
            "[Batch 6] Current Loss: 4.1229\n",
            "[Batch 7] Current Loss: 3.4111\n",
            "[Batch 8] Current Loss: 4.3097\n",
            "[Batch 9] Current Loss: 4.2657\n",
            "[Batch 0] Current Loss: 5.6937\n",
            "[Batch 1] Current Loss: 5.2071\n",
            "[Batch 2] Current Loss: 5.6995\n",
            "[Batch 3] Current Loss: 5.5992\n",
            "[Batch 4] Current Loss: 5.3727\n",
            "[Batch 5] Current Loss: 5.2317\n",
            "[Batch 6] Current Loss: 5.4531\n",
            "[Batch 7] Current Loss: 5.8348\n",
            "[Batch 8] Current Loss: 4.9520\n",
            "[Batch 9] Current Loss: 5.6919\n",
            "Ep 2 (Step 011340): Train loss 3.939, Val loss 5.474\n",
            "[Batch 0] Current Loss: 4.0758\n",
            "[Batch 1] Current Loss: 3.6236\n",
            "[Batch 2] Current Loss: 4.2202\n",
            "[Batch 3] Current Loss: 4.0763\n",
            "[Batch 4] Current Loss: 4.3816\n",
            "[Batch 5] Current Loss: 4.2073\n",
            "[Batch 6] Current Loss: 3.9183\n",
            "[Batch 7] Current Loss: 4.1199\n",
            "[Batch 8] Current Loss: 4.5017\n",
            "[Batch 9] Current Loss: 3.5556\n",
            "[Batch 0] Current Loss: 4.7581\n",
            "[Batch 1] Current Loss: 4.8261\n",
            "[Batch 2] Current Loss: 5.7661\n",
            "[Batch 3] Current Loss: 4.7629\n",
            "[Batch 4] Current Loss: 5.4256\n",
            "[Batch 5] Current Loss: 4.9848\n",
            "[Batch 6] Current Loss: 5.2060\n",
            "[Batch 7] Current Loss: 5.3075\n",
            "[Batch 8] Current Loss: 5.8271\n",
            "[Batch 9] Current Loss: 4.7154\n",
            "Ep 2 (Step 011360): Train loss 4.068, Val loss 5.158\n",
            "[Batch 0] Current Loss: 3.9243\n",
            "[Batch 1] Current Loss: 4.1834\n",
            "[Batch 2] Current Loss: 4.0426\n",
            "[Batch 3] Current Loss: 4.0626\n",
            "[Batch 4] Current Loss: 4.5109\n",
            "[Batch 5] Current Loss: 4.0191\n",
            "[Batch 6] Current Loss: 3.5707\n",
            "[Batch 7] Current Loss: 3.9227\n",
            "[Batch 8] Current Loss: 4.4643\n",
            "[Batch 9] Current Loss: 4.1671\n",
            "[Batch 0] Current Loss: 5.2689\n",
            "[Batch 1] Current Loss: 5.2552\n",
            "[Batch 2] Current Loss: 5.0251\n",
            "[Batch 3] Current Loss: 5.9154\n",
            "[Batch 4] Current Loss: 6.2098\n",
            "[Batch 5] Current Loss: 5.5202\n",
            "[Batch 6] Current Loss: 4.9336\n",
            "[Batch 7] Current Loss: 5.1636\n",
            "[Batch 8] Current Loss: 5.0939\n",
            "[Batch 9] Current Loss: 5.1812\n",
            "Ep 2 (Step 011380): Train loss 4.087, Val loss 5.357\n",
            "[Batch 0] Current Loss: 3.8997\n",
            "[Batch 1] Current Loss: 4.1172\n",
            "[Batch 2] Current Loss: 4.4642\n",
            "[Batch 3] Current Loss: 4.1376\n",
            "[Batch 4] Current Loss: 4.4372\n",
            "[Batch 5] Current Loss: 4.3913\n",
            "[Batch 6] Current Loss: 4.1771\n",
            "[Batch 7] Current Loss: 4.1419\n",
            "[Batch 8] Current Loss: 3.8136\n",
            "[Batch 9] Current Loss: 3.8153\n",
            "[Batch 0] Current Loss: 5.0670\n",
            "[Batch 1] Current Loss: 5.3437\n",
            "[Batch 2] Current Loss: 5.6355\n",
            "[Batch 3] Current Loss: 5.6721\n",
            "[Batch 4] Current Loss: 5.3750\n",
            "[Batch 5] Current Loss: 5.2861\n",
            "[Batch 6] Current Loss: 5.5063\n",
            "[Batch 7] Current Loss: 5.4985\n",
            "[Batch 8] Current Loss: 4.2734\n",
            "[Batch 9] Current Loss: 5.2399\n",
            "Ep 2 (Step 011400): Train loss 4.140, Val loss 5.290\n",
            "[Batch 0] Current Loss: 3.6469\n",
            "[Batch 1] Current Loss: 4.2218\n",
            "[Batch 2] Current Loss: 4.1108\n",
            "[Batch 3] Current Loss: 3.5736\n",
            "[Batch 4] Current Loss: 4.5564\n",
            "[Batch 5] Current Loss: 4.4037\n",
            "[Batch 6] Current Loss: 4.2993\n",
            "[Batch 7] Current Loss: 3.6155\n",
            "[Batch 8] Current Loss: 3.7780\n",
            "[Batch 9] Current Loss: 3.6659\n",
            "[Batch 0] Current Loss: 4.7816\n",
            "[Batch 1] Current Loss: 5.1326\n",
            "[Batch 2] Current Loss: 5.3661\n",
            "[Batch 3] Current Loss: 5.4433\n",
            "[Batch 4] Current Loss: 4.9502\n",
            "[Batch 5] Current Loss: 5.2531\n",
            "[Batch 6] Current Loss: 5.1977\n",
            "[Batch 7] Current Loss: 5.4496\n",
            "[Batch 8] Current Loss: 4.6590\n",
            "[Batch 9] Current Loss: 5.7465\n",
            "Ep 2 (Step 011420): Train loss 3.987, Val loss 5.198\n",
            "[Batch 0] Current Loss: 3.8760\n",
            "[Batch 1] Current Loss: 4.1002\n",
            "[Batch 2] Current Loss: 3.6565\n",
            "[Batch 3] Current Loss: 4.1136\n",
            "[Batch 4] Current Loss: 4.3179\n",
            "[Batch 5] Current Loss: 4.1836\n",
            "[Batch 6] Current Loss: 4.3680\n",
            "[Batch 7] Current Loss: 3.7500\n",
            "[Batch 8] Current Loss: 4.1164\n",
            "[Batch 9] Current Loss: 3.5181\n",
            "[Batch 0] Current Loss: 5.7711\n",
            "[Batch 1] Current Loss: 4.8361\n",
            "[Batch 2] Current Loss: 5.9770\n",
            "[Batch 3] Current Loss: 5.1505\n",
            "[Batch 4] Current Loss: 5.9304\n",
            "[Batch 5] Current Loss: 5.9114\n",
            "[Batch 6] Current Loss: 5.0413\n",
            "[Batch 7] Current Loss: 5.4688\n",
            "[Batch 8] Current Loss: 5.0728\n",
            "[Batch 9] Current Loss: 5.1794\n",
            "Ep 2 (Step 011440): Train loss 4.000, Val loss 5.434\n",
            "[Batch 0] Current Loss: 3.5971\n",
            "[Batch 1] Current Loss: 3.3957\n",
            "[Batch 2] Current Loss: 4.3018\n",
            "[Batch 3] Current Loss: 4.2034\n",
            "[Batch 4] Current Loss: 3.8753\n",
            "[Batch 5] Current Loss: 4.2822\n",
            "[Batch 6] Current Loss: 4.1814\n",
            "[Batch 7] Current Loss: 3.7991\n",
            "[Batch 8] Current Loss: 4.6371\n",
            "[Batch 9] Current Loss: 4.6125\n",
            "[Batch 0] Current Loss: 4.0769\n",
            "[Batch 1] Current Loss: 5.6013\n",
            "[Batch 2] Current Loss: 5.3008\n",
            "[Batch 3] Current Loss: 5.6319\n",
            "[Batch 4] Current Loss: 5.9538\n",
            "[Batch 5] Current Loss: 5.4524\n",
            "[Batch 6] Current Loss: 4.4740\n",
            "[Batch 7] Current Loss: 5.0534\n",
            "[Batch 8] Current Loss: 5.8198\n",
            "[Batch 9] Current Loss: 5.3704\n",
            "Ep 2 (Step 011460): Train loss 4.089, Val loss 5.273\n",
            "[Batch 0] Current Loss: 4.4084\n",
            "[Batch 1] Current Loss: 3.7746\n",
            "[Batch 2] Current Loss: 4.3136\n",
            "[Batch 3] Current Loss: 4.6497\n",
            "[Batch 4] Current Loss: 3.8777\n",
            "[Batch 5] Current Loss: 4.3903\n",
            "[Batch 6] Current Loss: 3.9568\n",
            "[Batch 7] Current Loss: 4.0777\n",
            "[Batch 8] Current Loss: 4.5908\n",
            "[Batch 9] Current Loss: 3.9113\n",
            "[Batch 0] Current Loss: 5.2683\n",
            "[Batch 1] Current Loss: 5.2390\n",
            "[Batch 2] Current Loss: 5.0227\n",
            "[Batch 3] Current Loss: 5.9389\n",
            "[Batch 4] Current Loss: 5.3903\n",
            "[Batch 5] Current Loss: 5.3317\n",
            "[Batch 6] Current Loss: 5.5581\n",
            "[Batch 7] Current Loss: 5.3052\n",
            "[Batch 8] Current Loss: 5.4208\n",
            "[Batch 9] Current Loss: 5.5732\n",
            "Ep 2 (Step 011480): Train loss 4.195, Val loss 5.405\n",
            "[Batch 0] Current Loss: 4.0034\n",
            "[Batch 1] Current Loss: 4.2719\n",
            "[Batch 2] Current Loss: 3.2490\n",
            "[Batch 3] Current Loss: 4.5768\n",
            "[Batch 4] Current Loss: 3.7132\n",
            "[Batch 5] Current Loss: 4.0146\n",
            "[Batch 6] Current Loss: 4.2280\n",
            "[Batch 7] Current Loss: 4.0388\n",
            "[Batch 8] Current Loss: 4.0358\n",
            "[Batch 9] Current Loss: 3.9713\n",
            "[Batch 0] Current Loss: 5.5079\n",
            "[Batch 1] Current Loss: 5.4993\n",
            "[Batch 2] Current Loss: 5.2018\n",
            "[Batch 3] Current Loss: 4.6798\n",
            "[Batch 4] Current Loss: 4.6752\n",
            "[Batch 5] Current Loss: 5.0312\n",
            "[Batch 6] Current Loss: 4.8486\n",
            "[Batch 7] Current Loss: 4.7926\n",
            "[Batch 8] Current Loss: 5.4079\n",
            "[Batch 9] Current Loss: 4.9443\n",
            "Ep 2 (Step 011500): Train loss 4.010, Val loss 5.059\n",
            "[Batch 0] Current Loss: 4.3703\n",
            "[Batch 1] Current Loss: 3.8506\n",
            "[Batch 2] Current Loss: 4.4661\n",
            "[Batch 3] Current Loss: 4.4247\n",
            "[Batch 4] Current Loss: 4.4055\n",
            "[Batch 5] Current Loss: 4.1285\n",
            "[Batch 6] Current Loss: 3.9060\n",
            "[Batch 7] Current Loss: 3.8977\n",
            "[Batch 8] Current Loss: 4.1376\n",
            "[Batch 9] Current Loss: 3.3851\n",
            "[Batch 0] Current Loss: 4.9463\n",
            "[Batch 1] Current Loss: 4.6719\n",
            "[Batch 2] Current Loss: 5.2815\n",
            "[Batch 3] Current Loss: 6.1271\n",
            "[Batch 4] Current Loss: 5.2349\n",
            "[Batch 5] Current Loss: 5.1422\n",
            "[Batch 6] Current Loss: 4.9244\n",
            "[Batch 7] Current Loss: 4.8570\n",
            "[Batch 8] Current Loss: 5.5182\n",
            "[Batch 9] Current Loss: 5.7264\n",
            "Ep 2 (Step 011520): Train loss 4.097, Val loss 5.243\n",
            "[Batch 0] Current Loss: 3.9819\n",
            "[Batch 1] Current Loss: 3.9793\n",
            "[Batch 2] Current Loss: 3.7035\n",
            "[Batch 3] Current Loss: 4.0253\n",
            "[Batch 4] Current Loss: 4.1155\n",
            "[Batch 5] Current Loss: 3.6879\n",
            "[Batch 6] Current Loss: 3.8032\n",
            "[Batch 7] Current Loss: 3.9511\n",
            "[Batch 8] Current Loss: 4.3162\n",
            "[Batch 9] Current Loss: 3.8419\n",
            "[Batch 0] Current Loss: 5.9435\n",
            "[Batch 1] Current Loss: 5.4027\n",
            "[Batch 2] Current Loss: 5.2196\n",
            "[Batch 3] Current Loss: 4.6882\n",
            "[Batch 4] Current Loss: 5.4176\n",
            "[Batch 5] Current Loss: 5.2281\n",
            "[Batch 6] Current Loss: 5.4398\n",
            "[Batch 7] Current Loss: 5.3304\n",
            "[Batch 8] Current Loss: 5.2392\n",
            "[Batch 9] Current Loss: 5.2161\n",
            "Ep 2 (Step 011540): Train loss 3.941, Val loss 5.313\n",
            "[Batch 0] Current Loss: 4.5086\n",
            "[Batch 1] Current Loss: 4.5245\n",
            "[Batch 2] Current Loss: 3.9330\n",
            "[Batch 3] Current Loss: 4.7933\n",
            "[Batch 4] Current Loss: 4.1088\n",
            "[Batch 5] Current Loss: 3.9009\n",
            "[Batch 6] Current Loss: 4.0887\n",
            "[Batch 7] Current Loss: 4.1688\n",
            "[Batch 8] Current Loss: 3.9868\n",
            "[Batch 9] Current Loss: 4.2390\n",
            "[Batch 0] Current Loss: 5.9094\n",
            "[Batch 1] Current Loss: 5.4648\n",
            "[Batch 2] Current Loss: 5.2868\n",
            "[Batch 3] Current Loss: 4.6864\n",
            "[Batch 4] Current Loss: 5.2309\n",
            "[Batch 5] Current Loss: 5.8799\n",
            "[Batch 6] Current Loss: 5.3625\n",
            "[Batch 7] Current Loss: 5.0220\n",
            "[Batch 8] Current Loss: 4.7419\n",
            "[Batch 9] Current Loss: 5.3672\n",
            "Ep 2 (Step 011560): Train loss 4.225, Val loss 5.295\n",
            "[Batch 0] Current Loss: 4.1208\n",
            "[Batch 1] Current Loss: 4.1442\n",
            "[Batch 2] Current Loss: 4.0852\n",
            "[Batch 3] Current Loss: 4.1556\n",
            "[Batch 4] Current Loss: 4.2777\n",
            "[Batch 5] Current Loss: 3.9016\n",
            "[Batch 6] Current Loss: 2.9782\n",
            "[Batch 7] Current Loss: 4.3414\n",
            "[Batch 8] Current Loss: 3.8055\n",
            "[Batch 9] Current Loss: 3.8006\n",
            "[Batch 0] Current Loss: 5.1405\n",
            "[Batch 1] Current Loss: 5.6122\n",
            "[Batch 2] Current Loss: 5.3342\n",
            "[Batch 3] Current Loss: 5.2983\n",
            "[Batch 4] Current Loss: 4.9407\n",
            "[Batch 5] Current Loss: 5.9110\n",
            "[Batch 6] Current Loss: 5.5615\n",
            "[Batch 7] Current Loss: 4.9839\n",
            "[Batch 8] Current Loss: 5.2177\n",
            "[Batch 9] Current Loss: 4.6928\n",
            "Ep 2 (Step 011580): Train loss 3.961, Val loss 5.269\n",
            "[Batch 0] Current Loss: 4.2669\n",
            "[Batch 1] Current Loss: 4.1634\n",
            "[Batch 2] Current Loss: 4.2224\n",
            "[Batch 3] Current Loss: 4.3515\n",
            "[Batch 4] Current Loss: 3.8235\n",
            "[Batch 5] Current Loss: 4.4747\n",
            "[Batch 6] Current Loss: 4.4960\n",
            "[Batch 7] Current Loss: 3.9060\n",
            "[Batch 8] Current Loss: 3.5557\n",
            "[Batch 9] Current Loss: 3.6276\n",
            "[Batch 0] Current Loss: 5.3890\n",
            "[Batch 1] Current Loss: 4.7992\n",
            "[Batch 2] Current Loss: 5.0593\n",
            "[Batch 3] Current Loss: 5.3467\n",
            "[Batch 4] Current Loss: 5.1032\n",
            "[Batch 5] Current Loss: 5.4879\n",
            "[Batch 6] Current Loss: 5.3343\n",
            "[Batch 7] Current Loss: 5.4486\n",
            "[Batch 8] Current Loss: 5.1150\n",
            "[Batch 9] Current Loss: 5.0245\n",
            "Ep 2 (Step 011600): Train loss 4.089, Val loss 5.211\n",
            "[Batch 0] Current Loss: 4.6015\n",
            "[Batch 1] Current Loss: 3.9611\n",
            "[Batch 2] Current Loss: 3.6726\n",
            "[Batch 3] Current Loss: 3.7000\n",
            "[Batch 4] Current Loss: 3.4563\n",
            "[Batch 5] Current Loss: 3.3845\n",
            "[Batch 6] Current Loss: 4.8640\n",
            "[Batch 7] Current Loss: 4.5441\n",
            "[Batch 8] Current Loss: 3.9193\n",
            "[Batch 9] Current Loss: 4.0171\n",
            "[Batch 0] Current Loss: 5.3717\n",
            "[Batch 1] Current Loss: 4.9429\n",
            "[Batch 2] Current Loss: 5.3986\n",
            "[Batch 3] Current Loss: 5.2459\n",
            "[Batch 4] Current Loss: 5.9139\n",
            "[Batch 5] Current Loss: 5.6490\n",
            "[Batch 6] Current Loss: 5.1754\n",
            "[Batch 7] Current Loss: 5.2199\n",
            "[Batch 8] Current Loss: 4.8301\n",
            "[Batch 9] Current Loss: 5.4060\n",
            "Ep 2 (Step 011620): Train loss 4.012, Val loss 5.315\n",
            "[Batch 0] Current Loss: 3.7858\n",
            "[Batch 1] Current Loss: 3.6998\n",
            "[Batch 2] Current Loss: 4.0017\n",
            "[Batch 3] Current Loss: 3.8245\n",
            "[Batch 4] Current Loss: 3.5625\n",
            "[Batch 5] Current Loss: 3.6700\n",
            "[Batch 6] Current Loss: 4.0889\n",
            "[Batch 7] Current Loss: 3.6557\n",
            "[Batch 8] Current Loss: 4.2592\n",
            "[Batch 9] Current Loss: 4.6026\n",
            "[Batch 0] Current Loss: 5.2967\n",
            "[Batch 1] Current Loss: 4.7452\n",
            "[Batch 2] Current Loss: 5.3161\n",
            "[Batch 3] Current Loss: 4.8228\n",
            "[Batch 4] Current Loss: 5.8370\n",
            "[Batch 5] Current Loss: 4.6439\n",
            "[Batch 6] Current Loss: 5.2309\n",
            "[Batch 7] Current Loss: 4.8203\n",
            "[Batch 8] Current Loss: 5.3960\n",
            "[Batch 9] Current Loss: 5.7181\n",
            "Ep 2 (Step 011640): Train loss 3.915, Val loss 5.183\n",
            "[Batch 0] Current Loss: 4.6819\n",
            "[Batch 1] Current Loss: 3.8244\n",
            "[Batch 2] Current Loss: 4.1346\n",
            "[Batch 3] Current Loss: 4.5563\n",
            "[Batch 4] Current Loss: 3.8110\n",
            "[Batch 5] Current Loss: 3.2126\n",
            "[Batch 6] Current Loss: 3.6253\n",
            "[Batch 7] Current Loss: 4.3389\n",
            "[Batch 8] Current Loss: 3.8667\n",
            "[Batch 9] Current Loss: 4.1621\n",
            "[Batch 0] Current Loss: 5.3231\n",
            "[Batch 1] Current Loss: 5.3202\n",
            "[Batch 2] Current Loss: 5.2220\n",
            "[Batch 3] Current Loss: 4.4624\n",
            "[Batch 4] Current Loss: 4.8961\n",
            "[Batch 5] Current Loss: 5.9110\n",
            "[Batch 6] Current Loss: 5.2553\n",
            "[Batch 7] Current Loss: 5.2678\n",
            "[Batch 8] Current Loss: 4.8956\n",
            "[Batch 9] Current Loss: 5.6687\n",
            "Ep 2 (Step 011660): Train loss 4.021, Val loss 5.222\n",
            "[Batch 0] Current Loss: 4.5344\n",
            "[Batch 1] Current Loss: 4.1799\n",
            "[Batch 2] Current Loss: 3.9616\n",
            "[Batch 3] Current Loss: 3.9983\n",
            "[Batch 4] Current Loss: 4.1862\n",
            "[Batch 5] Current Loss: 3.6905\n",
            "[Batch 6] Current Loss: 4.5902\n",
            "[Batch 7] Current Loss: 3.7680\n",
            "[Batch 8] Current Loss: 3.8139\n",
            "[Batch 9] Current Loss: 3.8953\n",
            "[Batch 0] Current Loss: 5.4794\n",
            "[Batch 1] Current Loss: 5.2509\n",
            "[Batch 2] Current Loss: 5.2860\n",
            "[Batch 3] Current Loss: 4.9936\n",
            "[Batch 4] Current Loss: 4.7104\n",
            "[Batch 5] Current Loss: 5.7170\n",
            "[Batch 6] Current Loss: 5.3268\n",
            "[Batch 7] Current Loss: 6.4391\n",
            "[Batch 8] Current Loss: 5.6049\n",
            "[Batch 9] Current Loss: 5.2574\n",
            "Ep 2 (Step 011680): Train loss 4.062, Val loss 5.407\n",
            "[Batch 0] Current Loss: 3.7842\n",
            "[Batch 1] Current Loss: 4.6294\n",
            "[Batch 2] Current Loss: 3.8952\n",
            "[Batch 3] Current Loss: 4.1582\n",
            "[Batch 4] Current Loss: 3.6802\n",
            "[Batch 5] Current Loss: 3.9304\n",
            "[Batch 6] Current Loss: 3.7870\n",
            "[Batch 7] Current Loss: 4.1757\n",
            "[Batch 8] Current Loss: 3.8114\n",
            "[Batch 9] Current Loss: 4.2384\n",
            "[Batch 0] Current Loss: 5.4306\n",
            "[Batch 1] Current Loss: 4.8471\n",
            "[Batch 2] Current Loss: 5.2145\n",
            "[Batch 3] Current Loss: 4.9852\n",
            "[Batch 4] Current Loss: 5.2475\n",
            "[Batch 5] Current Loss: 5.0870\n",
            "[Batch 6] Current Loss: 4.5440\n",
            "[Batch 7] Current Loss: 4.9845\n",
            "[Batch 8] Current Loss: 5.5017\n",
            "[Batch 9] Current Loss: 5.6673\n",
            "Ep 2 (Step 011700): Train loss 4.009, Val loss 5.151\n",
            "[Batch 0] Current Loss: 3.4142\n",
            "[Batch 1] Current Loss: 4.6434\n",
            "[Batch 2] Current Loss: 4.5958\n",
            "[Batch 3] Current Loss: 3.9726\n",
            "[Batch 4] Current Loss: 3.4966\n",
            "[Batch 5] Current Loss: 4.2331\n",
            "[Batch 6] Current Loss: 4.2253\n",
            "[Batch 7] Current Loss: 3.9168\n",
            "[Batch 8] Current Loss: 3.1544\n",
            "[Batch 9] Current Loss: 4.1492\n",
            "[Batch 0] Current Loss: 5.2652\n",
            "[Batch 1] Current Loss: 4.3810\n",
            "[Batch 2] Current Loss: 5.3112\n",
            "[Batch 3] Current Loss: 5.1856\n",
            "[Batch 4] Current Loss: 5.2001\n",
            "[Batch 5] Current Loss: 4.6849\n",
            "[Batch 6] Current Loss: 5.2599\n",
            "[Batch 7] Current Loss: 5.0589\n",
            "[Batch 8] Current Loss: 5.6937\n",
            "[Batch 9] Current Loss: 4.5919\n",
            "Ep 2 (Step 011720): Train loss 3.980, Val loss 5.063\n",
            "[Batch 0] Current Loss: 3.7973\n",
            "[Batch 1] Current Loss: 3.3897\n",
            "[Batch 2] Current Loss: 3.8564\n",
            "[Batch 3] Current Loss: 4.3198\n",
            "[Batch 4] Current Loss: 4.3870\n",
            "[Batch 5] Current Loss: 4.1115\n",
            "[Batch 6] Current Loss: 4.3183\n",
            "[Batch 7] Current Loss: 4.0465\n",
            "[Batch 8] Current Loss: 3.9422\n",
            "[Batch 9] Current Loss: 3.6792\n",
            "[Batch 0] Current Loss: 6.0325\n",
            "[Batch 1] Current Loss: 5.7132\n",
            "[Batch 2] Current Loss: 6.1274\n",
            "[Batch 3] Current Loss: 5.2289\n",
            "[Batch 4] Current Loss: 5.1849\n",
            "[Batch 5] Current Loss: 5.6759\n",
            "[Batch 6] Current Loss: 5.9087\n",
            "[Batch 7] Current Loss: 5.7338\n",
            "[Batch 8] Current Loss: 5.2945\n",
            "[Batch 9] Current Loss: 5.7998\n",
            "Ep 2 (Step 011740): Train loss 3.985, Val loss 5.670\n",
            "[Batch 0] Current Loss: 4.2437\n",
            "[Batch 1] Current Loss: 3.9121\n",
            "[Batch 2] Current Loss: 4.3046\n",
            "[Batch 3] Current Loss: 3.8025\n",
            "[Batch 4] Current Loss: 3.8680\n",
            "[Batch 5] Current Loss: 4.1808\n",
            "[Batch 6] Current Loss: 3.7411\n",
            "[Batch 7] Current Loss: 4.5136\n",
            "[Batch 8] Current Loss: 3.8305\n",
            "[Batch 9] Current Loss: 4.2138\n",
            "[Batch 0] Current Loss: 5.2639\n",
            "[Batch 1] Current Loss: 5.2129\n",
            "[Batch 2] Current Loss: 5.2338\n",
            "[Batch 3] Current Loss: 4.6234\n",
            "[Batch 4] Current Loss: 5.0725\n",
            "[Batch 5] Current Loss: 5.1071\n",
            "[Batch 6] Current Loss: 4.8367\n",
            "[Batch 7] Current Loss: 4.7085\n",
            "[Batch 8] Current Loss: 4.7943\n",
            "[Batch 9] Current Loss: 5.1852\n",
            "Ep 2 (Step 011760): Train loss 4.061, Val loss 5.004\n",
            "[Batch 0] Current Loss: 3.7562\n",
            "[Batch 1] Current Loss: 4.1254\n",
            "[Batch 2] Current Loss: 4.0514\n",
            "[Batch 3] Current Loss: 4.7465\n",
            "[Batch 4] Current Loss: 4.0475\n",
            "[Batch 5] Current Loss: 4.1257\n",
            "[Batch 6] Current Loss: 3.9226\n",
            "[Batch 7] Current Loss: 3.6453\n",
            "[Batch 8] Current Loss: 3.8713\n",
            "[Batch 9] Current Loss: 4.0857\n",
            "[Batch 0] Current Loss: 4.8186\n",
            "[Batch 1] Current Loss: 5.0531\n",
            "[Batch 2] Current Loss: 4.2349\n",
            "[Batch 3] Current Loss: 5.6822\n",
            "[Batch 4] Current Loss: 5.0805\n",
            "[Batch 5] Current Loss: 5.4169\n",
            "[Batch 6] Current Loss: 5.0859\n",
            "[Batch 7] Current Loss: 5.2981\n",
            "[Batch 8] Current Loss: 5.7754\n",
            "[Batch 9] Current Loss: 4.9762\n",
            "Ep 2 (Step 011780): Train loss 4.038, Val loss 5.142\n",
            "[Batch 0] Current Loss: 3.9912\n",
            "[Batch 1] Current Loss: 4.2110\n",
            "[Batch 2] Current Loss: 3.9348\n",
            "[Batch 3] Current Loss: 3.8547\n",
            "[Batch 4] Current Loss: 4.5139\n",
            "[Batch 5] Current Loss: 4.0130\n",
            "[Batch 6] Current Loss: 4.4394\n",
            "[Batch 7] Current Loss: 3.9221\n",
            "[Batch 8] Current Loss: 3.8999\n",
            "[Batch 9] Current Loss: 3.9669\n",
            "[Batch 0] Current Loss: 5.5831\n",
            "[Batch 1] Current Loss: 5.2124\n",
            "[Batch 2] Current Loss: 5.4056\n",
            "[Batch 3] Current Loss: 5.5012\n",
            "[Batch 4] Current Loss: 5.1558\n",
            "[Batch 5] Current Loss: 4.8812\n",
            "[Batch 6] Current Loss: 5.3179\n",
            "[Batch 7] Current Loss: 5.5463\n",
            "[Batch 8] Current Loss: 5.5073\n",
            "[Batch 9] Current Loss: 5.7118\n",
            "Ep 2 (Step 011800): Train loss 4.075, Val loss 5.382\n",
            "[Batch 0] Current Loss: 4.3509\n",
            "[Batch 1] Current Loss: 3.5226\n",
            "[Batch 2] Current Loss: 4.0765\n",
            "[Batch 3] Current Loss: 4.5690\n",
            "[Batch 4] Current Loss: 3.6338\n",
            "[Batch 5] Current Loss: 3.1333\n",
            "[Batch 6] Current Loss: 3.6771\n",
            "[Batch 7] Current Loss: 3.7018\n",
            "[Batch 8] Current Loss: 4.0008\n",
            "[Batch 9] Current Loss: 3.6043\n",
            "[Batch 0] Current Loss: 5.2249\n",
            "[Batch 1] Current Loss: 5.7199\n",
            "[Batch 2] Current Loss: 5.3280\n",
            "[Batch 3] Current Loss: 5.1372\n",
            "[Batch 4] Current Loss: 5.4399\n",
            "[Batch 5] Current Loss: 5.4306\n",
            "[Batch 6] Current Loss: 5.1353\n",
            "[Batch 7] Current Loss: 5.7629\n",
            "[Batch 8] Current Loss: 5.6339\n",
            "[Batch 9] Current Loss: 5.3402\n",
            "Ep 2 (Step 011820): Train loss 3.827, Val loss 5.415\n",
            "[Batch 0] Current Loss: 3.6627\n",
            "[Batch 1] Current Loss: 3.8377\n",
            "[Batch 2] Current Loss: 4.1536\n",
            "[Batch 3] Current Loss: 3.7242\n",
            "[Batch 4] Current Loss: 3.7576\n",
            "[Batch 5] Current Loss: 3.1829\n",
            "[Batch 6] Current Loss: 3.9860\n",
            "[Batch 7] Current Loss: 4.4988\n",
            "[Batch 8] Current Loss: 4.3718\n",
            "[Batch 9] Current Loss: 3.5786\n",
            "[Batch 0] Current Loss: 5.5720\n",
            "[Batch 1] Current Loss: 5.7725\n",
            "[Batch 2] Current Loss: 4.9608\n",
            "[Batch 3] Current Loss: 4.8985\n",
            "[Batch 4] Current Loss: 5.7726\n",
            "[Batch 5] Current Loss: 4.7796\n",
            "[Batch 6] Current Loss: 5.4893\n",
            "[Batch 7] Current Loss: 5.2899\n",
            "[Batch 8] Current Loss: 5.2231\n",
            "[Batch 9] Current Loss: 5.0670\n",
            "Ep 2 (Step 011840): Train loss 3.875, Val loss 5.283\n",
            "[Batch 0] Current Loss: 3.5542\n",
            "[Batch 1] Current Loss: 3.4967\n",
            "[Batch 2] Current Loss: 3.9558\n",
            "[Batch 3] Current Loss: 3.7191\n",
            "[Batch 4] Current Loss: 4.1992\n",
            "[Batch 5] Current Loss: 4.3747\n",
            "[Batch 6] Current Loss: 3.8545\n",
            "[Batch 7] Current Loss: 3.9453\n",
            "[Batch 8] Current Loss: 4.5351\n",
            "[Batch 9] Current Loss: 3.7948\n",
            "[Batch 0] Current Loss: 5.4000\n",
            "[Batch 1] Current Loss: 5.0601\n",
            "[Batch 2] Current Loss: 5.0018\n",
            "[Batch 3] Current Loss: 5.2585\n",
            "[Batch 4] Current Loss: 5.1645\n",
            "[Batch 5] Current Loss: 5.0929\n",
            "[Batch 6] Current Loss: 5.7900\n",
            "[Batch 7] Current Loss: 4.8856\n",
            "[Batch 8] Current Loss: 4.7731\n",
            "[Batch 9] Current Loss: 5.0963\n",
            "Ep 2 (Step 011860): Train loss 3.943, Val loss 5.152\n",
            "[Batch 0] Current Loss: 3.4335\n",
            "[Batch 1] Current Loss: 3.2932\n",
            "[Batch 2] Current Loss: 4.4765\n",
            "[Batch 3] Current Loss: 4.0974\n",
            "[Batch 4] Current Loss: 3.6998\n",
            "[Batch 5] Current Loss: 3.6558\n",
            "[Batch 6] Current Loss: 4.1228\n",
            "[Batch 7] Current Loss: 4.0989\n",
            "[Batch 8] Current Loss: 4.3107\n",
            "[Batch 9] Current Loss: 4.3557\n",
            "[Batch 0] Current Loss: 4.8746\n",
            "[Batch 1] Current Loss: 5.3942\n",
            "[Batch 2] Current Loss: 4.7935\n",
            "[Batch 3] Current Loss: 4.8546\n",
            "[Batch 4] Current Loss: 4.6956\n",
            "[Batch 5] Current Loss: 5.3314\n",
            "[Batch 6] Current Loss: 5.5796\n",
            "[Batch 7] Current Loss: 5.3813\n",
            "[Batch 8] Current Loss: 5.3227\n",
            "[Batch 9] Current Loss: 5.7071\n",
            "Ep 2 (Step 011880): Train loss 3.954, Val loss 5.193\n",
            "[Batch 0] Current Loss: 3.7774\n",
            "[Batch 1] Current Loss: 3.9475\n",
            "[Batch 2] Current Loss: 3.5005\n",
            "[Batch 3] Current Loss: 3.4486\n",
            "[Batch 4] Current Loss: 4.3688\n",
            "[Batch 5] Current Loss: 4.1853\n",
            "[Batch 6] Current Loss: 4.2732\n",
            "[Batch 7] Current Loss: 3.6734\n",
            "[Batch 8] Current Loss: 4.1827\n",
            "[Batch 9] Current Loss: 4.8169\n",
            "[Batch 0] Current Loss: 4.6564\n",
            "[Batch 1] Current Loss: 4.4424\n",
            "[Batch 2] Current Loss: 4.9707\n",
            "[Batch 3] Current Loss: 5.7470\n",
            "[Batch 4] Current Loss: 5.6624\n",
            "[Batch 5] Current Loss: 5.0371\n",
            "[Batch 6] Current Loss: 5.5388\n",
            "[Batch 7] Current Loss: 5.6971\n",
            "[Batch 8] Current Loss: 4.8008\n",
            "[Batch 9] Current Loss: 4.9993\n",
            "Ep 2 (Step 011900): Train loss 4.017, Val loss 5.155\n",
            "[Batch 0] Current Loss: 4.3003\n",
            "[Batch 1] Current Loss: 3.7326\n",
            "[Batch 2] Current Loss: 3.6028\n",
            "[Batch 3] Current Loss: 3.5861\n",
            "[Batch 4] Current Loss: 3.9036\n",
            "[Batch 5] Current Loss: 4.4768\n",
            "[Batch 6] Current Loss: 4.3016\n",
            "[Batch 7] Current Loss: 4.1150\n",
            "[Batch 8] Current Loss: 4.2043\n",
            "[Batch 9] Current Loss: 3.5275\n",
            "[Batch 0] Current Loss: 5.2467\n",
            "[Batch 1] Current Loss: 5.9540\n",
            "[Batch 2] Current Loss: 5.1908\n",
            "[Batch 3] Current Loss: 5.1557\n",
            "[Batch 4] Current Loss: 4.8591\n",
            "[Batch 5] Current Loss: 4.7760\n",
            "[Batch 6] Current Loss: 5.2530\n",
            "[Batch 7] Current Loss: 5.2166\n",
            "[Batch 8] Current Loss: 4.8891\n",
            "[Batch 9] Current Loss: 5.3817\n",
            "Ep 2 (Step 011920): Train loss 3.975, Val loss 5.192\n",
            "[Batch 0] Current Loss: 4.1683\n",
            "[Batch 1] Current Loss: 4.5398\n",
            "[Batch 2] Current Loss: 3.8477\n",
            "[Batch 3] Current Loss: 4.3354\n",
            "[Batch 4] Current Loss: 4.1469\n",
            "[Batch 5] Current Loss: 4.0157\n",
            "[Batch 6] Current Loss: 4.0953\n",
            "[Batch 7] Current Loss: 3.8433\n",
            "[Batch 8] Current Loss: 4.8852\n",
            "[Batch 9] Current Loss: 4.1740\n",
            "[Batch 0] Current Loss: 5.3181\n",
            "[Batch 1] Current Loss: 4.8794\n",
            "[Batch 2] Current Loss: 5.0776\n",
            "[Batch 3] Current Loss: 5.3297\n",
            "[Batch 4] Current Loss: 5.4575\n",
            "[Batch 5] Current Loss: 5.6175\n",
            "[Batch 6] Current Loss: 4.8942\n",
            "[Batch 7] Current Loss: 5.1954\n",
            "[Batch 8] Current Loss: 5.0875\n",
            "[Batch 9] Current Loss: 5.0639\n",
            "Ep 2 (Step 011940): Train loss 4.205, Val loss 5.192\n",
            "[Batch 0] Current Loss: 4.0303\n",
            "[Batch 1] Current Loss: 3.9350\n",
            "[Batch 2] Current Loss: 3.7267\n",
            "[Batch 3] Current Loss: 4.2712\n",
            "[Batch 4] Current Loss: 4.0581\n",
            "[Batch 5] Current Loss: 3.7620\n",
            "[Batch 6] Current Loss: 3.8008\n",
            "[Batch 7] Current Loss: 4.0245\n",
            "[Batch 8] Current Loss: 4.0106\n",
            "[Batch 9] Current Loss: 4.4028\n",
            "[Batch 0] Current Loss: 5.2210\n",
            "[Batch 1] Current Loss: 5.5266\n",
            "[Batch 2] Current Loss: 5.2559\n",
            "[Batch 3] Current Loss: 5.6630\n",
            "[Batch 4] Current Loss: 5.4429\n",
            "[Batch 5] Current Loss: 4.3660\n",
            "[Batch 6] Current Loss: 5.6946\n",
            "[Batch 7] Current Loss: 4.4266\n",
            "[Batch 8] Current Loss: 5.6336\n",
            "[Batch 9] Current Loss: 5.0809\n",
            "Ep 2 (Step 011960): Train loss 4.002, Val loss 5.231\n",
            "[Batch 0] Current Loss: 3.2849\n",
            "[Batch 1] Current Loss: 4.0097\n",
            "[Batch 2] Current Loss: 4.0835\n",
            "[Batch 3] Current Loss: 4.2904\n",
            "[Batch 4] Current Loss: 3.6153\n",
            "[Batch 5] Current Loss: 3.8417\n",
            "[Batch 6] Current Loss: 4.3176\n",
            "[Batch 7] Current Loss: 4.2216\n",
            "[Batch 8] Current Loss: 3.5950\n",
            "[Batch 9] Current Loss: 4.0670\n",
            "[Batch 0] Current Loss: 4.8490\n",
            "[Batch 1] Current Loss: 5.5818\n",
            "[Batch 2] Current Loss: 5.2489\n",
            "[Batch 3] Current Loss: 5.6182\n",
            "[Batch 4] Current Loss: 5.0233\n",
            "[Batch 5] Current Loss: 5.5048\n",
            "[Batch 6] Current Loss: 5.3796\n",
            "[Batch 7] Current Loss: 5.2838\n",
            "[Batch 8] Current Loss: 5.6232\n",
            "[Batch 9] Current Loss: 4.9344\n",
            "Ep 2 (Step 011980): Train loss 3.933, Val loss 5.305\n",
            "[Batch 0] Current Loss: 3.6545\n",
            "[Batch 1] Current Loss: 3.9281\n",
            "[Batch 2] Current Loss: 3.5497\n",
            "[Batch 3] Current Loss: 4.4622\n",
            "[Batch 4] Current Loss: 3.5546\n",
            "[Batch 5] Current Loss: 3.6794\n",
            "[Batch 6] Current Loss: 4.5405\n",
            "[Batch 7] Current Loss: 4.1373\n",
            "[Batch 8] Current Loss: 4.2882\n",
            "[Batch 9] Current Loss: 4.1562\n",
            "[Batch 0] Current Loss: 5.0404\n",
            "[Batch 1] Current Loss: 5.6202\n",
            "[Batch 2] Current Loss: 5.3144\n",
            "[Batch 3] Current Loss: 5.6836\n",
            "[Batch 4] Current Loss: 4.6901\n",
            "[Batch 5] Current Loss: 5.2496\n",
            "[Batch 6] Current Loss: 5.6009\n",
            "[Batch 7] Current Loss: 5.6000\n",
            "[Batch 8] Current Loss: 4.6051\n",
            "[Batch 9] Current Loss: 5.8786\n",
            "Ep 2 (Step 012000): Train loss 3.995, Val loss 5.328\n",
            "[Batch 0] Current Loss: 4.2299\n",
            "[Batch 1] Current Loss: 4.1884\n",
            "[Batch 2] Current Loss: 4.4349\n",
            "[Batch 3] Current Loss: 3.8925\n",
            "[Batch 4] Current Loss: 4.5685\n",
            "[Batch 5] Current Loss: 3.7088\n",
            "[Batch 6] Current Loss: 4.1009\n",
            "[Batch 7] Current Loss: 3.8775\n",
            "[Batch 8] Current Loss: 3.1839\n",
            "[Batch 9] Current Loss: 3.5831\n",
            "[Batch 0] Current Loss: 4.9391\n",
            "[Batch 1] Current Loss: 4.9302\n",
            "[Batch 2] Current Loss: 5.7252\n",
            "[Batch 3] Current Loss: 4.4767\n",
            "[Batch 4] Current Loss: 5.0458\n",
            "[Batch 5] Current Loss: 4.8259\n",
            "[Batch 6] Current Loss: 5.0688\n",
            "[Batch 7] Current Loss: 5.9241\n",
            "[Batch 8] Current Loss: 5.1579\n",
            "[Batch 9] Current Loss: 4.7988\n",
            "Ep 2 (Step 012020): Train loss 3.977, Val loss 5.089\n",
            "[Batch 0] Current Loss: 3.5202\n",
            "[Batch 1] Current Loss: 3.9928\n",
            "[Batch 2] Current Loss: 3.6498\n",
            "[Batch 3] Current Loss: 3.8571\n",
            "[Batch 4] Current Loss: 3.7673\n",
            "[Batch 5] Current Loss: 3.6810\n",
            "[Batch 6] Current Loss: 4.1083\n",
            "[Batch 7] Current Loss: 3.4999\n",
            "[Batch 8] Current Loss: 4.5785\n",
            "[Batch 9] Current Loss: 3.8369\n",
            "[Batch 0] Current Loss: 5.0022\n",
            "[Batch 1] Current Loss: 5.7011\n",
            "[Batch 2] Current Loss: 4.0675\n",
            "[Batch 3] Current Loss: 4.9654\n",
            "[Batch 4] Current Loss: 5.0384\n",
            "[Batch 5] Current Loss: 5.1682\n",
            "[Batch 6] Current Loss: 5.2850\n",
            "[Batch 7] Current Loss: 5.1755\n",
            "[Batch 8] Current Loss: 5.3577\n",
            "[Batch 9] Current Loss: 5.2549\n",
            "Ep 2 (Step 012040): Train loss 3.849, Val loss 5.102\n",
            "[Batch 0] Current Loss: 3.5711\n",
            "[Batch 1] Current Loss: 3.6636\n",
            "[Batch 2] Current Loss: 4.2084\n",
            "[Batch 3] Current Loss: 3.7015\n",
            "[Batch 4] Current Loss: 3.9556\n",
            "[Batch 5] Current Loss: 4.2143\n",
            "[Batch 6] Current Loss: 3.7967\n",
            "[Batch 7] Current Loss: 3.9046\n",
            "[Batch 8] Current Loss: 3.9013\n",
            "[Batch 9] Current Loss: 3.0785\n",
            "[Batch 0] Current Loss: 5.2483\n",
            "[Batch 1] Current Loss: 5.4441\n",
            "[Batch 2] Current Loss: 4.9568\n",
            "[Batch 3] Current Loss: 4.9999\n",
            "[Batch 4] Current Loss: 5.5099\n",
            "[Batch 5] Current Loss: 5.0064\n",
            "[Batch 6] Current Loss: 5.6992\n",
            "[Batch 7] Current Loss: 5.0431\n",
            "[Batch 8] Current Loss: 4.7629\n",
            "[Batch 9] Current Loss: 5.2019\n",
            "Ep 2 (Step 012060): Train loss 3.800, Val loss 5.187\n",
            "[Batch 0] Current Loss: 3.5327\n",
            "[Batch 1] Current Loss: 4.0640\n",
            "[Batch 2] Current Loss: 4.5079\n",
            "[Batch 3] Current Loss: 4.7374\n",
            "[Batch 4] Current Loss: 4.5559\n",
            "[Batch 5] Current Loss: 4.3486\n",
            "[Batch 6] Current Loss: 4.4095\n",
            "[Batch 7] Current Loss: 4.0808\n",
            "[Batch 8] Current Loss: 3.8584\n",
            "[Batch 9] Current Loss: 4.1212\n",
            "[Batch 0] Current Loss: 5.0045\n",
            "[Batch 1] Current Loss: 5.0661\n",
            "[Batch 2] Current Loss: 5.5702\n",
            "[Batch 3] Current Loss: 5.6789\n",
            "[Batch 4] Current Loss: 5.6625\n",
            "[Batch 5] Current Loss: 5.5967\n",
            "[Batch 6] Current Loss: 5.1274\n",
            "[Batch 7] Current Loss: 5.6680\n",
            "[Batch 8] Current Loss: 5.1982\n",
            "[Batch 9] Current Loss: 5.3858\n",
            "Ep 2 (Step 012080): Train loss 4.222, Val loss 5.396\n",
            "[Batch 0] Current Loss: 4.0729\n",
            "[Batch 1] Current Loss: 4.0664\n",
            "[Batch 2] Current Loss: 4.1087\n",
            "[Batch 3] Current Loss: 4.0040\n",
            "[Batch 4] Current Loss: 3.4761\n",
            "[Batch 5] Current Loss: 4.4298\n",
            "[Batch 6] Current Loss: 4.2995\n",
            "[Batch 7] Current Loss: 4.4422\n",
            "[Batch 8] Current Loss: 4.2636\n",
            "[Batch 9] Current Loss: 4.1575\n",
            "[Batch 0] Current Loss: 4.8425\n",
            "[Batch 1] Current Loss: 5.2753\n",
            "[Batch 2] Current Loss: 4.8861\n",
            "[Batch 3] Current Loss: 5.2389\n",
            "[Batch 4] Current Loss: 5.0753\n",
            "[Batch 5] Current Loss: 5.6253\n",
            "[Batch 6] Current Loss: 5.0602\n",
            "[Batch 7] Current Loss: 5.3990\n",
            "[Batch 8] Current Loss: 5.5507\n",
            "[Batch 9] Current Loss: 5.8209\n",
            "Ep 2 (Step 012100): Train loss 4.132, Val loss 5.277\n",
            "[Batch 0] Current Loss: 4.3114\n",
            "[Batch 1] Current Loss: 3.5141\n",
            "[Batch 2] Current Loss: 3.3678\n",
            "[Batch 3] Current Loss: 3.8927\n",
            "[Batch 4] Current Loss: 4.1664\n",
            "[Batch 5] Current Loss: 4.1457\n",
            "[Batch 6] Current Loss: 3.8063\n",
            "[Batch 7] Current Loss: 4.2303\n",
            "[Batch 8] Current Loss: 3.8657\n",
            "[Batch 9] Current Loss: 4.1263\n",
            "[Batch 0] Current Loss: 5.1561\n",
            "[Batch 1] Current Loss: 5.5463\n",
            "[Batch 2] Current Loss: 5.2861\n",
            "[Batch 3] Current Loss: 5.5448\n",
            "[Batch 4] Current Loss: 5.5644\n",
            "[Batch 5] Current Loss: 4.7750\n",
            "[Batch 6] Current Loss: 5.4653\n",
            "[Batch 7] Current Loss: 4.9284\n",
            "[Batch 8] Current Loss: 5.1075\n",
            "[Batch 9] Current Loss: 4.6664\n",
            "Ep 2 (Step 012120): Train loss 3.943, Val loss 5.204\n",
            "[Batch 0] Current Loss: 4.3870\n",
            "[Batch 1] Current Loss: 4.1587\n",
            "[Batch 2] Current Loss: 4.1121\n",
            "[Batch 3] Current Loss: 3.7480\n",
            "[Batch 4] Current Loss: 4.5911\n",
            "[Batch 5] Current Loss: 3.8607\n",
            "[Batch 6] Current Loss: 3.8027\n",
            "[Batch 7] Current Loss: 4.0197\n",
            "[Batch 8] Current Loss: 4.0986\n",
            "[Batch 9] Current Loss: 4.2299\n",
            "[Batch 0] Current Loss: 5.1596\n",
            "[Batch 1] Current Loss: 5.3344\n",
            "[Batch 2] Current Loss: 5.8217\n",
            "[Batch 3] Current Loss: 5.3724\n",
            "[Batch 4] Current Loss: 5.3369\n",
            "[Batch 5] Current Loss: 5.5843\n",
            "[Batch 6] Current Loss: 5.8172\n",
            "[Batch 7] Current Loss: 4.7881\n",
            "[Batch 8] Current Loss: 5.2358\n",
            "[Batch 9] Current Loss: 5.3750\n",
            "Ep 2 (Step 012140): Train loss 4.101, Val loss 5.383\n",
            "[Batch 0] Current Loss: 3.4856\n",
            "[Batch 1] Current Loss: 4.4998\n",
            "[Batch 2] Current Loss: 3.8304\n",
            "[Batch 3] Current Loss: 4.0079\n",
            "[Batch 4] Current Loss: 3.9942\n",
            "[Batch 5] Current Loss: 3.9250\n",
            "[Batch 6] Current Loss: 3.5935\n",
            "[Batch 7] Current Loss: 3.3407\n",
            "[Batch 8] Current Loss: 3.7040\n",
            "[Batch 9] Current Loss: 4.4812\n",
            "[Batch 0] Current Loss: 5.4711\n",
            "[Batch 1] Current Loss: 4.5558\n",
            "[Batch 2] Current Loss: 5.1213\n",
            "[Batch 3] Current Loss: 5.6614\n",
            "[Batch 4] Current Loss: 5.6424\n",
            "[Batch 5] Current Loss: 4.9614\n",
            "[Batch 6] Current Loss: 5.5598\n",
            "[Batch 7] Current Loss: 5.0730\n",
            "[Batch 8] Current Loss: 5.5961\n",
            "[Batch 9] Current Loss: 5.4787\n",
            "Ep 2 (Step 012160): Train loss 3.886, Val loss 5.312\n",
            "[Batch 0] Current Loss: 4.0810\n",
            "[Batch 1] Current Loss: 4.0660\n",
            "[Batch 2] Current Loss: 3.9702\n",
            "[Batch 3] Current Loss: 3.5227\n",
            "[Batch 4] Current Loss: 3.6304\n",
            "[Batch 5] Current Loss: 4.0476\n",
            "[Batch 6] Current Loss: 2.9002\n",
            "[Batch 7] Current Loss: 3.8848\n",
            "[Batch 8] Current Loss: 3.9425\n",
            "[Batch 9] Current Loss: 3.7717\n",
            "[Batch 0] Current Loss: 5.4157\n",
            "[Batch 1] Current Loss: 5.5383\n",
            "[Batch 2] Current Loss: 4.9364\n",
            "[Batch 3] Current Loss: 5.6221\n",
            "[Batch 4] Current Loss: 5.4930\n",
            "[Batch 5] Current Loss: 5.2396\n",
            "[Batch 6] Current Loss: 5.3101\n",
            "[Batch 7] Current Loss: 5.1310\n",
            "[Batch 8] Current Loss: 5.4393\n",
            "[Batch 9] Current Loss: 5.3251\n",
            "Ep 2 (Step 012180): Train loss 3.782, Val loss 5.345\n",
            "[Batch 0] Current Loss: 4.4508\n",
            "[Batch 1] Current Loss: 4.3037\n",
            "[Batch 2] Current Loss: 4.4982\n",
            "[Batch 3] Current Loss: 3.6760\n",
            "[Batch 4] Current Loss: 3.6446\n",
            "[Batch 5] Current Loss: 3.8184\n",
            "[Batch 6] Current Loss: 3.2545\n",
            "[Batch 7] Current Loss: 4.7499\n",
            "[Batch 8] Current Loss: 3.6247\n",
            "[Batch 9] Current Loss: 3.3560\n",
            "[Batch 0] Current Loss: 4.6020\n",
            "[Batch 1] Current Loss: 5.1870\n",
            "[Batch 2] Current Loss: 5.6417\n",
            "[Batch 3] Current Loss: 6.1003\n",
            "[Batch 4] Current Loss: 5.4210\n",
            "[Batch 5] Current Loss: 5.4003\n",
            "[Batch 6] Current Loss: 5.7669\n",
            "[Batch 7] Current Loss: 5.1286\n",
            "[Batch 8] Current Loss: 5.5259\n",
            "[Batch 9] Current Loss: 5.4205\n",
            "Ep 2 (Step 012200): Train loss 3.938, Val loss 5.419\n",
            "[Batch 0] Current Loss: 4.3015\n",
            "[Batch 1] Current Loss: 3.7858\n",
            "[Batch 2] Current Loss: 3.3303\n",
            "[Batch 3] Current Loss: 3.8417\n",
            "[Batch 4] Current Loss: 3.6591\n",
            "[Batch 5] Current Loss: 3.7920\n",
            "[Batch 6] Current Loss: 4.1218\n",
            "[Batch 7] Current Loss: 3.9309\n",
            "[Batch 8] Current Loss: 3.3861\n",
            "[Batch 9] Current Loss: 4.2755\n",
            "[Batch 0] Current Loss: 4.9344\n",
            "[Batch 1] Current Loss: 4.7659\n",
            "[Batch 2] Current Loss: 5.0674\n",
            "[Batch 3] Current Loss: 6.0158\n",
            "[Batch 4] Current Loss: 5.2166\n",
            "[Batch 5] Current Loss: 4.7000\n",
            "[Batch 6] Current Loss: 5.0501\n",
            "[Batch 7] Current Loss: 5.3662\n",
            "[Batch 8] Current Loss: 5.6183\n",
            "[Batch 9] Current Loss: 5.4832\n",
            "Ep 2 (Step 012220): Train loss 3.842, Val loss 5.222\n",
            "[Batch 0] Current Loss: 4.3872\n",
            "[Batch 1] Current Loss: 3.5987\n",
            "[Batch 2] Current Loss: 3.7782\n",
            "[Batch 3] Current Loss: 4.4387\n",
            "[Batch 4] Current Loss: 4.6781\n",
            "[Batch 5] Current Loss: 4.5718\n",
            "[Batch 6] Current Loss: 4.0723\n",
            "[Batch 7] Current Loss: 4.0765\n",
            "[Batch 8] Current Loss: 3.1416\n",
            "[Batch 9] Current Loss: 4.2100\n",
            "[Batch 0] Current Loss: 5.4257\n",
            "[Batch 1] Current Loss: 5.3841\n",
            "[Batch 2] Current Loss: 5.7296\n",
            "[Batch 3] Current Loss: 5.0226\n",
            "[Batch 4] Current Loss: 5.1951\n",
            "[Batch 5] Current Loss: 5.1028\n",
            "[Batch 6] Current Loss: 5.5691\n",
            "[Batch 7] Current Loss: 5.2612\n",
            "[Batch 8] Current Loss: 4.8821\n",
            "[Batch 9] Current Loss: 4.7753\n",
            "Ep 2 (Step 012240): Train loss 4.095, Val loss 5.235\n",
            "[Batch 0] Current Loss: 3.6869\n",
            "[Batch 1] Current Loss: 4.1933\n",
            "[Batch 2] Current Loss: 4.3600\n",
            "[Batch 3] Current Loss: 3.9917\n",
            "[Batch 4] Current Loss: 3.4781\n",
            "[Batch 5] Current Loss: 3.7195\n",
            "[Batch 6] Current Loss: 3.7446\n",
            "[Batch 7] Current Loss: 4.0034\n",
            "[Batch 8] Current Loss: 4.2810\n",
            "[Batch 9] Current Loss: 3.3918\n",
            "[Batch 0] Current Loss: 4.4776\n",
            "[Batch 1] Current Loss: 4.9634\n",
            "[Batch 2] Current Loss: 5.5034\n",
            "[Batch 3] Current Loss: 5.0894\n",
            "[Batch 4] Current Loss: 5.1994\n",
            "[Batch 5] Current Loss: 5.3117\n",
            "[Batch 6] Current Loss: 5.3984\n",
            "[Batch 7] Current Loss: 5.2752\n",
            "[Batch 8] Current Loss: 5.0884\n",
            "[Batch 9] Current Loss: 5.8341\n",
            "Ep 2 (Step 012260): Train loss 3.885, Val loss 5.214\n",
            "[Batch 0] Current Loss: 4.4980\n",
            "[Batch 1] Current Loss: 3.5585\n",
            "[Batch 2] Current Loss: 4.0360\n",
            "[Batch 3] Current Loss: 3.5793\n",
            "[Batch 4] Current Loss: 4.1982\n",
            "[Batch 5] Current Loss: 4.2246\n",
            "[Batch 6] Current Loss: 3.9781\n",
            "[Batch 7] Current Loss: 3.5007\n",
            "[Batch 8] Current Loss: 3.7166\n",
            "[Batch 9] Current Loss: 3.6580\n",
            "[Batch 0] Current Loss: 5.1546\n",
            "[Batch 1] Current Loss: 5.6492\n",
            "[Batch 2] Current Loss: 5.5285\n",
            "[Batch 3] Current Loss: 5.5245\n",
            "[Batch 4] Current Loss: 5.0591\n",
            "[Batch 5] Current Loss: 4.4148\n",
            "[Batch 6] Current Loss: 5.0510\n",
            "[Batch 7] Current Loss: 5.5196\n",
            "[Batch 8] Current Loss: 5.1260\n",
            "[Batch 9] Current Loss: 5.1502\n",
            "Ep 2 (Step 012280): Train loss 3.895, Val loss 5.218\n",
            "[Batch 0] Current Loss: 3.7695\n",
            "[Batch 1] Current Loss: 3.9600\n",
            "[Batch 2] Current Loss: 4.6712\n",
            "[Batch 3] Current Loss: 4.3297\n",
            "[Batch 4] Current Loss: 3.7419\n",
            "[Batch 5] Current Loss: 3.7345\n",
            "[Batch 6] Current Loss: 4.0213\n",
            "[Batch 7] Current Loss: 3.8330\n",
            "[Batch 8] Current Loss: 4.1064\n",
            "[Batch 9] Current Loss: 3.6810\n",
            "[Batch 0] Current Loss: 5.3163\n",
            "[Batch 1] Current Loss: 4.8745\n",
            "[Batch 2] Current Loss: 4.2729\n",
            "[Batch 3] Current Loss: 4.7657\n",
            "[Batch 4] Current Loss: 5.4318\n",
            "[Batch 5] Current Loss: 5.1357\n",
            "[Batch 6] Current Loss: 6.1567\n",
            "[Batch 7] Current Loss: 5.4444\n",
            "[Batch 8] Current Loss: 5.3812\n",
            "[Batch 9] Current Loss: 5.5993\n",
            "Ep 2 (Step 012300): Train loss 3.985, Val loss 5.238\n",
            "[Batch 0] Current Loss: 4.4396\n",
            "[Batch 1] Current Loss: 3.9353\n",
            "[Batch 2] Current Loss: 3.9951\n",
            "[Batch 3] Current Loss: 3.8816\n",
            "[Batch 4] Current Loss: 3.4834\n",
            "[Batch 5] Current Loss: 3.5927\n",
            "[Batch 6] Current Loss: 3.8191\n",
            "[Batch 7] Current Loss: 4.0395\n",
            "[Batch 8] Current Loss: 3.6925\n",
            "[Batch 9] Current Loss: 4.3794\n",
            "[Batch 0] Current Loss: 5.2595\n",
            "[Batch 1] Current Loss: 5.6029\n",
            "[Batch 2] Current Loss: 5.0250\n",
            "[Batch 3] Current Loss: 5.0070\n",
            "[Batch 4] Current Loss: 5.5009\n",
            "[Batch 5] Current Loss: 5.4378\n",
            "[Batch 6] Current Loss: 5.2516\n",
            "[Batch 7] Current Loss: 5.1026\n",
            "[Batch 8] Current Loss: 4.8570\n",
            "[Batch 9] Current Loss: 5.8406\n",
            "Ep 2 (Step 012320): Train loss 3.926, Val loss 5.288\n",
            "[Batch 0] Current Loss: 4.2046\n",
            "[Batch 1] Current Loss: 4.0298\n",
            "[Batch 2] Current Loss: 4.1510\n",
            "[Batch 3] Current Loss: 3.5672\n",
            "[Batch 4] Current Loss: 3.6959\n",
            "[Batch 5] Current Loss: 3.7964\n",
            "[Batch 6] Current Loss: 3.7176\n",
            "[Batch 7] Current Loss: 4.4274\n",
            "[Batch 8] Current Loss: 3.4385\n",
            "[Batch 9] Current Loss: 4.0556\n",
            "[Batch 0] Current Loss: 4.9196\n",
            "[Batch 1] Current Loss: 5.8772\n",
            "[Batch 2] Current Loss: 4.9562\n",
            "[Batch 3] Current Loss: 4.7192\n",
            "[Batch 4] Current Loss: 5.4841\n",
            "[Batch 5] Current Loss: 5.4352\n",
            "[Batch 6] Current Loss: 5.1677\n",
            "[Batch 7] Current Loss: 5.6704\n",
            "[Batch 8] Current Loss: 5.0049\n",
            "[Batch 9] Current Loss: 4.9045\n",
            "Ep 2 (Step 012340): Train loss 3.908, Val loss 5.214\n",
            "[Batch 0] Current Loss: 3.9763\n",
            "[Batch 1] Current Loss: 4.4992\n",
            "[Batch 2] Current Loss: 3.2385\n",
            "[Batch 3] Current Loss: 4.0543\n",
            "[Batch 4] Current Loss: 4.4580\n",
            "[Batch 5] Current Loss: 3.9567\n",
            "[Batch 6] Current Loss: 4.0647\n",
            "[Batch 7] Current Loss: 4.0550\n",
            "[Batch 8] Current Loss: 3.5774\n",
            "[Batch 9] Current Loss: 4.0784\n",
            "[Batch 0] Current Loss: 5.3700\n",
            "[Batch 1] Current Loss: 5.1044\n",
            "[Batch 2] Current Loss: 4.7292\n",
            "[Batch 3] Current Loss: 5.4015\n",
            "[Batch 4] Current Loss: 5.5495\n",
            "[Batch 5] Current Loss: 5.4409\n",
            "[Batch 6] Current Loss: 5.4362\n",
            "[Batch 7] Current Loss: 4.8690\n",
            "[Batch 8] Current Loss: 5.0197\n",
            "[Batch 9] Current Loss: 4.0929\n",
            "Ep 2 (Step 012360): Train loss 3.996, Val loss 5.101\n",
            "[Batch 0] Current Loss: 4.2004\n",
            "[Batch 1] Current Loss: 4.1584\n",
            "[Batch 2] Current Loss: 3.9942\n",
            "[Batch 3] Current Loss: 3.9542\n",
            "[Batch 4] Current Loss: 4.0153\n",
            "[Batch 5] Current Loss: 3.8778\n",
            "[Batch 6] Current Loss: 4.1598\n",
            "[Batch 7] Current Loss: 3.8941\n",
            "[Batch 8] Current Loss: 3.6442\n",
            "[Batch 9] Current Loss: 3.8095\n",
            "[Batch 0] Current Loss: 5.6165\n",
            "[Batch 1] Current Loss: 5.6552\n",
            "[Batch 2] Current Loss: 5.5304\n",
            "[Batch 3] Current Loss: 4.0865\n",
            "[Batch 4] Current Loss: 5.3507\n",
            "[Batch 5] Current Loss: 5.2411\n",
            "[Batch 6] Current Loss: 5.3284\n",
            "[Batch 7] Current Loss: 4.7007\n",
            "[Batch 8] Current Loss: 4.9371\n",
            "[Batch 9] Current Loss: 5.8313\n",
            "Ep 2 (Step 012380): Train loss 3.971, Val loss 5.228\n",
            "[Batch 0] Current Loss: 3.8198\n",
            "[Batch 1] Current Loss: 3.5434\n",
            "[Batch 2] Current Loss: 4.0551\n",
            "[Batch 3] Current Loss: 3.5437\n",
            "[Batch 4] Current Loss: 4.1195\n",
            "[Batch 5] Current Loss: 3.9787\n",
            "[Batch 6] Current Loss: 4.0122\n",
            "[Batch 7] Current Loss: 3.6083\n",
            "[Batch 8] Current Loss: 3.6292\n",
            "[Batch 9] Current Loss: 3.4501\n",
            "[Batch 0] Current Loss: 5.7521\n",
            "[Batch 1] Current Loss: 5.3580\n",
            "[Batch 2] Current Loss: 5.2004\n",
            "[Batch 3] Current Loss: 5.3559\n",
            "[Batch 4] Current Loss: 5.5062\n",
            "[Batch 5] Current Loss: 4.8445\n",
            "[Batch 6] Current Loss: 4.9439\n",
            "[Batch 7] Current Loss: 5.5297\n",
            "[Batch 8] Current Loss: 4.1407\n",
            "[Batch 9] Current Loss: 5.2574\n",
            "Ep 2 (Step 012400): Train loss 3.776, Val loss 5.189\n",
            "[Batch 0] Current Loss: 3.6024\n",
            "[Batch 1] Current Loss: 3.2078\n",
            "[Batch 2] Current Loss: 3.8868\n",
            "[Batch 3] Current Loss: 4.0672\n",
            "[Batch 4] Current Loss: 3.8176\n",
            "[Batch 5] Current Loss: 4.2964\n",
            "[Batch 6] Current Loss: 4.0043\n",
            "[Batch 7] Current Loss: 4.3770\n",
            "[Batch 8] Current Loss: 3.8455\n",
            "[Batch 9] Current Loss: 3.5419\n",
            "[Batch 0] Current Loss: 5.4718\n",
            "[Batch 1] Current Loss: 4.8612\n",
            "[Batch 2] Current Loss: 5.6045\n",
            "[Batch 3] Current Loss: 5.8691\n",
            "[Batch 4] Current Loss: 5.3523\n",
            "[Batch 5] Current Loss: 5.1600\n",
            "[Batch 6] Current Loss: 5.3948\n",
            "[Batch 7] Current Loss: 5.1748\n",
            "[Batch 8] Current Loss: 5.2058\n",
            "[Batch 9] Current Loss: 5.3098\n",
            "Ep 2 (Step 012420): Train loss 3.865, Val loss 5.340\n",
            "[Batch 0] Current Loss: 3.2020\n",
            "[Batch 1] Current Loss: 4.0795\n",
            "[Batch 2] Current Loss: 3.3499\n",
            "[Batch 3] Current Loss: 4.1935\n",
            "[Batch 4] Current Loss: 3.7933\n",
            "[Batch 5] Current Loss: 3.7868\n",
            "[Batch 6] Current Loss: 3.8080\n",
            "[Batch 7] Current Loss: 4.1078\n",
            "[Batch 8] Current Loss: 4.5447\n",
            "[Batch 9] Current Loss: 3.2887\n",
            "[Batch 0] Current Loss: 5.4252\n",
            "[Batch 1] Current Loss: 5.1110\n",
            "[Batch 2] Current Loss: 5.5348\n",
            "[Batch 3] Current Loss: 5.1273\n",
            "[Batch 4] Current Loss: 5.6064\n",
            "[Batch 5] Current Loss: 5.2655\n",
            "[Batch 6] Current Loss: 4.4841\n",
            "[Batch 7] Current Loss: 5.9001\n",
            "[Batch 8] Current Loss: 5.5657\n",
            "[Batch 9] Current Loss: 5.2158\n",
            "Ep 2 (Step 012440): Train loss 3.815, Val loss 5.324\n",
            "[Batch 0] Current Loss: 3.7075\n",
            "[Batch 1] Current Loss: 3.4565\n",
            "[Batch 2] Current Loss: 3.6398\n",
            "[Batch 3] Current Loss: 4.0995\n",
            "[Batch 4] Current Loss: 3.3991\n",
            "[Batch 5] Current Loss: 4.1804\n",
            "[Batch 6] Current Loss: 3.8282\n",
            "[Batch 7] Current Loss: 4.2269\n",
            "[Batch 8] Current Loss: 3.4078\n",
            "[Batch 9] Current Loss: 4.3250\n",
            "[Batch 0] Current Loss: 5.0266\n",
            "[Batch 1] Current Loss: 5.4585\n",
            "[Batch 2] Current Loss: 5.7177\n",
            "[Batch 3] Current Loss: 5.0260\n",
            "[Batch 4] Current Loss: 5.0305\n",
            "[Batch 5] Current Loss: 4.8472\n",
            "[Batch 6] Current Loss: 5.2740\n",
            "[Batch 7] Current Loss: 5.3368\n",
            "[Batch 8] Current Loss: 5.3382\n",
            "[Batch 9] Current Loss: 4.8141\n",
            "Ep 2 (Step 012460): Train loss 3.827, Val loss 5.187\n",
            "[Batch 0] Current Loss: 4.2613\n",
            "[Batch 1] Current Loss: 4.3522\n",
            "[Batch 2] Current Loss: 3.7914\n",
            "[Batch 3] Current Loss: 3.8103\n",
            "[Batch 4] Current Loss: 3.4349\n",
            "[Batch 5] Current Loss: 4.1333\n",
            "[Batch 6] Current Loss: 4.1116\n",
            "[Batch 7] Current Loss: 4.2122\n",
            "[Batch 8] Current Loss: 4.0243\n",
            "[Batch 9] Current Loss: 3.7238\n",
            "[Batch 0] Current Loss: 5.7032\n",
            "[Batch 1] Current Loss: 5.2677\n",
            "[Batch 2] Current Loss: 4.6396\n",
            "[Batch 3] Current Loss: 5.2570\n",
            "[Batch 4] Current Loss: 4.9269\n",
            "[Batch 5] Current Loss: 4.8341\n",
            "[Batch 6] Current Loss: 5.0313\n",
            "[Batch 7] Current Loss: 5.2818\n",
            "[Batch 8] Current Loss: 5.0155\n",
            "[Batch 9] Current Loss: 5.3662\n",
            "Ep 2 (Step 012480): Train loss 3.986, Val loss 5.132\n",
            "[Batch 0] Current Loss: 3.9421\n",
            "[Batch 1] Current Loss: 3.9651\n",
            "[Batch 2] Current Loss: 3.5287\n",
            "[Batch 3] Current Loss: 3.6482\n",
            "[Batch 4] Current Loss: 4.1419\n",
            "[Batch 5] Current Loss: 4.7061\n",
            "[Batch 6] Current Loss: 3.2546\n",
            "[Batch 7] Current Loss: 3.6616\n",
            "[Batch 8] Current Loss: 3.3759\n",
            "[Batch 9] Current Loss: 3.7876\n",
            "[Batch 0] Current Loss: 5.2863\n",
            "[Batch 1] Current Loss: 5.2192\n",
            "[Batch 2] Current Loss: 5.1934\n",
            "[Batch 3] Current Loss: 5.7255\n",
            "[Batch 4] Current Loss: 4.8615\n",
            "[Batch 5] Current Loss: 5.5466\n",
            "[Batch 6] Current Loss: 5.1961\n",
            "[Batch 7] Current Loss: 5.3257\n",
            "[Batch 8] Current Loss: 5.3067\n",
            "[Batch 9] Current Loss: 5.4829\n",
            "Ep 2 (Step 012500): Train loss 3.801, Val loss 5.314\n",
            "[Batch 0] Current Loss: 3.8333\n",
            "[Batch 1] Current Loss: 4.0983\n",
            "[Batch 2] Current Loss: 3.3724\n",
            "[Batch 3] Current Loss: 4.0606\n",
            "[Batch 4] Current Loss: 3.9102\n",
            "[Batch 5] Current Loss: 3.7540\n",
            "[Batch 6] Current Loss: 3.6776\n",
            "[Batch 7] Current Loss: 4.3119\n",
            "[Batch 8] Current Loss: 3.4768\n",
            "[Batch 9] Current Loss: 3.6287\n",
            "[Batch 0] Current Loss: 5.4319\n",
            "[Batch 1] Current Loss: 4.5672\n",
            "[Batch 2] Current Loss: 5.6845\n",
            "[Batch 3] Current Loss: 5.2773\n",
            "[Batch 4] Current Loss: 5.3721\n",
            "[Batch 5] Current Loss: 5.3973\n",
            "[Batch 6] Current Loss: 5.6455\n",
            "[Batch 7] Current Loss: 5.2863\n",
            "[Batch 8] Current Loss: 5.1099\n",
            "[Batch 9] Current Loss: 5.1131\n",
            "Ep 2 (Step 012520): Train loss 3.812, Val loss 5.289\n",
            "[Batch 0] Current Loss: 3.5964\n",
            "[Batch 1] Current Loss: 3.1668\n",
            "[Batch 2] Current Loss: 3.7458\n",
            "[Batch 3] Current Loss: 3.6584\n",
            "[Batch 4] Current Loss: 3.4255\n",
            "[Batch 5] Current Loss: 4.0057\n",
            "[Batch 6] Current Loss: 3.3410\n",
            "[Batch 7] Current Loss: 3.8481\n",
            "[Batch 8] Current Loss: 4.2997\n",
            "[Batch 9] Current Loss: 3.8713\n",
            "[Batch 0] Current Loss: 5.5869\n",
            "[Batch 1] Current Loss: 4.9786\n",
            "[Batch 2] Current Loss: 5.4585\n",
            "[Batch 3] Current Loss: 5.4193\n",
            "[Batch 4] Current Loss: 5.2987\n",
            "[Batch 5] Current Loss: 5.4638\n",
            "[Batch 6] Current Loss: 5.4642\n",
            "[Batch 7] Current Loss: 4.5620\n",
            "[Batch 8] Current Loss: 5.4247\n",
            "[Batch 9] Current Loss: 5.3564\n",
            "Ep 2 (Step 012540): Train loss 3.696, Val loss 5.301\n",
            "[Batch 0] Current Loss: 3.8421\n",
            "[Batch 1] Current Loss: 3.8128\n",
            "[Batch 2] Current Loss: 3.8506\n",
            "[Batch 3] Current Loss: 4.4222\n",
            "[Batch 4] Current Loss: 3.2964\n",
            "[Batch 5] Current Loss: 3.4408\n",
            "[Batch 6] Current Loss: 3.5087\n",
            "[Batch 7] Current Loss: 3.5568\n",
            "[Batch 8] Current Loss: 3.4210\n",
            "[Batch 9] Current Loss: 3.6688\n",
            "[Batch 0] Current Loss: 5.6847\n",
            "[Batch 1] Current Loss: 5.0199\n",
            "[Batch 2] Current Loss: 5.2774\n",
            "[Batch 3] Current Loss: 5.5350\n",
            "[Batch 4] Current Loss: 5.5026\n",
            "[Batch 5] Current Loss: 5.4618\n",
            "[Batch 6] Current Loss: 5.0339\n",
            "[Batch 7] Current Loss: 5.1609\n",
            "[Batch 8] Current Loss: 5.9392\n",
            "[Batch 9] Current Loss: 5.3585\n",
            "Ep 2 (Step 012560): Train loss 3.682, Val loss 5.397\n",
            "[Batch 0] Current Loss: 4.1522\n",
            "[Batch 1] Current Loss: 3.8740\n",
            "[Batch 2] Current Loss: 3.2534\n",
            "[Batch 3] Current Loss: 2.8019\n",
            "[Batch 4] Current Loss: 4.1331\n",
            "[Batch 5] Current Loss: 4.4300\n",
            "[Batch 6] Current Loss: 4.2526\n",
            "[Batch 7] Current Loss: 3.9371\n",
            "[Batch 8] Current Loss: 3.8125\n",
            "[Batch 9] Current Loss: 3.3332\n",
            "[Batch 0] Current Loss: 5.3535\n",
            "[Batch 1] Current Loss: 5.4243\n",
            "[Batch 2] Current Loss: 5.1802\n",
            "[Batch 3] Current Loss: 5.3767\n",
            "[Batch 4] Current Loss: 4.6790\n",
            "[Batch 5] Current Loss: 5.0386\n",
            "[Batch 6] Current Loss: 5.8586\n",
            "[Batch 7] Current Loss: 5.9248\n",
            "[Batch 8] Current Loss: 5.4422\n",
            "[Batch 9] Current Loss: 5.0943\n",
            "Ep 2 (Step 012580): Train loss 3.798, Val loss 5.337\n",
            "[Batch 0] Current Loss: 4.7131\n",
            "[Batch 1] Current Loss: 3.8155\n",
            "[Batch 2] Current Loss: 3.3691\n",
            "[Batch 3] Current Loss: 3.9866\n",
            "[Batch 4] Current Loss: 3.7483\n",
            "[Batch 5] Current Loss: 3.6781\n",
            "[Batch 6] Current Loss: 3.8006\n",
            "[Batch 7] Current Loss: 3.6324\n",
            "[Batch 8] Current Loss: 3.3466\n",
            "[Batch 9] Current Loss: 3.2490\n",
            "[Batch 0] Current Loss: 5.2040\n",
            "[Batch 1] Current Loss: 5.2847\n",
            "[Batch 2] Current Loss: 5.3656\n",
            "[Batch 3] Current Loss: 4.9714\n",
            "[Batch 4] Current Loss: 4.8915\n",
            "[Batch 5] Current Loss: 5.2183\n",
            "[Batch 6] Current Loss: 5.6936\n",
            "[Batch 7] Current Loss: 4.7751\n",
            "[Batch 8] Current Loss: 5.3387\n",
            "[Batch 9] Current Loss: 5.8625\n",
            "Ep 2 (Step 012600): Train loss 3.734, Val loss 5.261\n",
            "[Batch 0] Current Loss: 3.8613\n",
            "[Batch 1] Current Loss: 3.4384\n",
            "[Batch 2] Current Loss: 3.5940\n",
            "[Batch 3] Current Loss: 3.3010\n",
            "[Batch 4] Current Loss: 3.9538\n",
            "[Batch 5] Current Loss: 3.8848\n",
            "[Batch 6] Current Loss: 3.6577\n",
            "[Batch 7] Current Loss: 3.5909\n",
            "[Batch 8] Current Loss: 4.4604\n",
            "[Batch 9] Current Loss: 4.3083\n",
            "[Batch 0] Current Loss: 5.3531\n",
            "[Batch 1] Current Loss: 4.8266\n",
            "[Batch 2] Current Loss: 5.3312\n",
            "[Batch 3] Current Loss: 5.4287\n",
            "[Batch 4] Current Loss: 5.3776\n",
            "[Batch 5] Current Loss: 4.2652\n",
            "[Batch 6] Current Loss: 5.2959\n",
            "[Batch 7] Current Loss: 4.9034\n",
            "[Batch 8] Current Loss: 5.3134\n",
            "[Batch 9] Current Loss: 5.4991\n",
            "Ep 2 (Step 012620): Train loss 3.805, Val loss 5.159\n",
            "[Batch 0] Current Loss: 4.1432\n",
            "[Batch 1] Current Loss: 3.4702\n",
            "[Batch 2] Current Loss: 3.7483\n",
            "[Batch 3] Current Loss: 3.6084\n",
            "[Batch 4] Current Loss: 3.4132\n",
            "[Batch 5] Current Loss: 3.9495\n",
            "[Batch 6] Current Loss: 3.9683\n",
            "[Batch 7] Current Loss: 3.8170\n",
            "[Batch 8] Current Loss: 3.8046\n",
            "[Batch 9] Current Loss: 4.6254\n",
            "[Batch 0] Current Loss: 5.3697\n",
            "[Batch 1] Current Loss: 5.0877\n",
            "[Batch 2] Current Loss: 5.3262\n",
            "[Batch 3] Current Loss: 4.6039\n",
            "[Batch 4] Current Loss: 4.9125\n",
            "[Batch 5] Current Loss: 5.9236\n",
            "[Batch 6] Current Loss: 4.9484\n",
            "[Batch 7] Current Loss: 4.9760\n",
            "[Batch 8] Current Loss: 5.6843\n",
            "[Batch 9] Current Loss: 4.8779\n",
            "Ep 2 (Step 012640): Train loss 3.855, Val loss 5.171\n",
            "[Batch 0] Current Loss: 3.8126\n",
            "[Batch 1] Current Loss: 4.1527\n",
            "[Batch 2] Current Loss: 4.0772\n",
            "[Batch 3] Current Loss: 3.6575\n",
            "[Batch 4] Current Loss: 3.4620\n",
            "[Batch 5] Current Loss: 4.3481\n",
            "[Batch 6] Current Loss: 3.6581\n",
            "[Batch 7] Current Loss: 3.7427\n",
            "[Batch 8] Current Loss: 4.0296\n",
            "[Batch 9] Current Loss: 4.2635\n",
            "[Batch 0] Current Loss: 5.0415\n",
            "[Batch 1] Current Loss: 4.7707\n",
            "[Batch 2] Current Loss: 5.4428\n",
            "[Batch 3] Current Loss: 5.4183\n",
            "[Batch 4] Current Loss: 5.0910\n",
            "[Batch 5] Current Loss: 5.2013\n",
            "[Batch 6] Current Loss: 5.9363\n",
            "[Batch 7] Current Loss: 4.8179\n",
            "[Batch 8] Current Loss: 5.0111\n",
            "[Batch 9] Current Loss: 4.8908\n",
            "Ep 2 (Step 012660): Train loss 3.920, Val loss 5.162\n",
            "[Batch 0] Current Loss: 4.0800\n",
            "[Batch 1] Current Loss: 3.7437\n",
            "[Batch 2] Current Loss: 4.0944\n",
            "[Batch 3] Current Loss: 4.1287\n",
            "[Batch 4] Current Loss: 4.4875\n",
            "[Batch 5] Current Loss: 4.2235\n",
            "[Batch 6] Current Loss: 3.5229\n",
            "[Batch 7] Current Loss: 4.3462\n",
            "[Batch 8] Current Loss: 3.6499\n",
            "[Batch 9] Current Loss: 3.6999\n",
            "[Batch 0] Current Loss: 5.4463\n",
            "[Batch 1] Current Loss: 4.7759\n",
            "[Batch 2] Current Loss: 5.6334\n",
            "[Batch 3] Current Loss: 4.6865\n",
            "[Batch 4] Current Loss: 5.3184\n",
            "[Batch 5] Current Loss: 5.0743\n",
            "[Batch 6] Current Loss: 5.0860\n",
            "[Batch 7] Current Loss: 4.5985\n",
            "[Batch 8] Current Loss: 5.0381\n",
            "[Batch 9] Current Loss: 5.5452\n",
            "Ep 2 (Step 012680): Train loss 3.998, Val loss 5.120\n",
            "[Batch 0] Current Loss: 4.3605\n",
            "[Batch 1] Current Loss: 3.4539\n",
            "[Batch 2] Current Loss: 3.6801\n",
            "[Batch 3] Current Loss: 4.3268\n",
            "[Batch 4] Current Loss: 3.7206\n",
            "[Batch 5] Current Loss: 3.7549\n",
            "[Batch 6] Current Loss: 3.9817\n",
            "[Batch 7] Current Loss: 3.1599\n",
            "[Batch 8] Current Loss: 3.8361\n",
            "[Batch 9] Current Loss: 3.7418\n",
            "[Batch 0] Current Loss: 5.5393\n",
            "[Batch 1] Current Loss: 5.3554\n",
            "[Batch 2] Current Loss: 5.5188\n",
            "[Batch 3] Current Loss: 5.1793\n",
            "[Batch 4] Current Loss: 5.9476\n",
            "[Batch 5] Current Loss: 5.3147\n",
            "[Batch 6] Current Loss: 5.5728\n",
            "[Batch 7] Current Loss: 5.9683\n",
            "[Batch 8] Current Loss: 5.5136\n",
            "[Batch 9] Current Loss: 5.3420\n",
            "Ep 2 (Step 012700): Train loss 3.802, Val loss 5.525\n",
            "[Batch 0] Current Loss: 3.8963\n",
            "[Batch 1] Current Loss: 3.7881\n",
            "[Batch 2] Current Loss: 3.5487\n",
            "[Batch 3] Current Loss: 3.5564\n",
            "[Batch 4] Current Loss: 4.3584\n",
            "[Batch 5] Current Loss: 4.0213\n",
            "[Batch 6] Current Loss: 3.7373\n",
            "[Batch 7] Current Loss: 3.5508\n",
            "[Batch 8] Current Loss: 3.1053\n",
            "[Batch 9] Current Loss: 3.1066\n",
            "[Batch 0] Current Loss: 5.2285\n",
            "[Batch 1] Current Loss: 5.0129\n",
            "[Batch 2] Current Loss: 5.2154\n",
            "[Batch 3] Current Loss: 5.3884\n",
            "[Batch 4] Current Loss: 5.1910\n",
            "[Batch 5] Current Loss: 5.1003\n",
            "[Batch 6] Current Loss: 5.2480\n",
            "[Batch 7] Current Loss: 4.8897\n",
            "[Batch 8] Current Loss: 5.0226\n",
            "[Batch 9] Current Loss: 5.4141\n",
            "Ep 2 (Step 012720): Train loss 3.667, Val loss 5.171\n",
            "[Batch 0] Current Loss: 3.9987\n",
            "[Batch 1] Current Loss: 4.0555\n",
            "[Batch 2] Current Loss: 3.8306\n",
            "[Batch 3] Current Loss: 3.6654\n",
            "[Batch 4] Current Loss: 3.1338\n",
            "[Batch 5] Current Loss: 3.5190\n",
            "[Batch 6] Current Loss: 3.5544\n",
            "[Batch 7] Current Loss: 3.7194\n",
            "[Batch 8] Current Loss: 4.3023\n",
            "[Batch 9] Current Loss: 3.8716\n",
            "[Batch 0] Current Loss: 5.5805\n",
            "[Batch 1] Current Loss: 5.2904\n",
            "[Batch 2] Current Loss: 6.2409\n",
            "[Batch 3] Current Loss: 5.1273\n",
            "[Batch 4] Current Loss: 4.6316\n",
            "[Batch 5] Current Loss: 5.2482\n",
            "[Batch 6] Current Loss: 5.6520\n",
            "[Batch 7] Current Loss: 5.2550\n",
            "[Batch 8] Current Loss: 4.8965\n",
            "[Batch 9] Current Loss: 5.3712\n",
            "Ep 2 (Step 012740): Train loss 3.765, Val loss 5.329\n",
            "[Batch 0] Current Loss: 4.4974\n",
            "[Batch 1] Current Loss: 3.9837\n",
            "[Batch 2] Current Loss: 4.1925\n",
            "[Batch 3] Current Loss: 3.9153\n",
            "[Batch 4] Current Loss: 3.6594\n",
            "[Batch 5] Current Loss: 4.1221\n",
            "[Batch 6] Current Loss: 4.0417\n",
            "[Batch 7] Current Loss: 3.6059\n",
            "[Batch 8] Current Loss: 3.6903\n",
            "[Batch 9] Current Loss: 3.7094\n",
            "[Batch 0] Current Loss: 5.3940\n",
            "[Batch 1] Current Loss: 5.7229\n",
            "[Batch 2] Current Loss: 5.7688\n",
            "[Batch 3] Current Loss: 5.1032\n",
            "[Batch 4] Current Loss: 4.3281\n",
            "[Batch 5] Current Loss: 5.0990\n",
            "[Batch 6] Current Loss: 4.5115\n",
            "[Batch 7] Current Loss: 5.0837\n",
            "[Batch 8] Current Loss: 5.3965\n",
            "[Batch 9] Current Loss: 5.3563\n",
            "Ep 2 (Step 012760): Train loss 3.942, Val loss 5.176\n",
            "[Batch 0] Current Loss: 3.4981\n",
            "[Batch 1] Current Loss: 3.9585\n",
            "[Batch 2] Current Loss: 3.2772\n",
            "[Batch 3] Current Loss: 4.0996\n",
            "[Batch 4] Current Loss: 3.8014\n",
            "[Batch 5] Current Loss: 3.8441\n",
            "[Batch 6] Current Loss: 3.7610\n",
            "[Batch 7] Current Loss: 3.8153\n",
            "[Batch 8] Current Loss: 4.1695\n",
            "[Batch 9] Current Loss: 3.2120\n",
            "[Batch 0] Current Loss: 5.1902\n",
            "[Batch 1] Current Loss: 6.0369\n",
            "[Batch 2] Current Loss: 4.9652\n",
            "[Batch 3] Current Loss: 5.6640\n",
            "[Batch 4] Current Loss: 5.2423\n",
            "[Batch 5] Current Loss: 5.3828\n",
            "[Batch 6] Current Loss: 5.8167\n",
            "[Batch 7] Current Loss: 5.8061\n",
            "[Batch 8] Current Loss: 5.6067\n",
            "[Batch 9] Current Loss: 5.2002\n",
            "Ep 2 (Step 012780): Train loss 3.744, Val loss 5.491\n",
            "[Batch 0] Current Loss: 3.8501\n",
            "[Batch 1] Current Loss: 3.8241\n",
            "[Batch 2] Current Loss: 3.8123\n",
            "[Batch 3] Current Loss: 3.3945\n",
            "[Batch 4] Current Loss: 2.7972\n",
            "[Batch 5] Current Loss: 3.5085\n",
            "[Batch 6] Current Loss: 3.8051\n",
            "[Batch 7] Current Loss: 3.0277\n",
            "[Batch 8] Current Loss: 4.5465\n",
            "[Batch 9] Current Loss: 3.9703\n",
            "[Batch 0] Current Loss: 4.7481\n",
            "[Batch 1] Current Loss: 4.9857\n",
            "[Batch 2] Current Loss: 5.1014\n",
            "[Batch 3] Current Loss: 5.3759\n",
            "[Batch 4] Current Loss: 5.1697\n",
            "[Batch 5] Current Loss: 4.3373\n",
            "[Batch 6] Current Loss: 5.3957\n",
            "[Batch 7] Current Loss: 5.7531\n",
            "[Batch 8] Current Loss: 5.8872\n",
            "[Batch 9] Current Loss: 5.3280\n",
            "Ep 2 (Step 012800): Train loss 3.654, Val loss 5.208\n",
            "[Batch 0] Current Loss: 3.6334\n",
            "[Batch 1] Current Loss: 4.3387\n",
            "[Batch 2] Current Loss: 3.7960\n",
            "[Batch 3] Current Loss: 3.7968\n",
            "[Batch 4] Current Loss: 3.6760\n",
            "[Batch 5] Current Loss: 4.7738\n",
            "[Batch 6] Current Loss: 3.5772\n",
            "[Batch 7] Current Loss: 4.2255\n",
            "[Batch 8] Current Loss: 4.0676\n",
            "[Batch 9] Current Loss: 3.3100\n",
            "[Batch 0] Current Loss: 5.3507\n",
            "[Batch 1] Current Loss: 5.0434\n",
            "[Batch 2] Current Loss: 5.3424\n",
            "[Batch 3] Current Loss: 5.2016\n",
            "[Batch 4] Current Loss: 5.1692\n",
            "[Batch 5] Current Loss: 5.7836\n",
            "[Batch 6] Current Loss: 5.4878\n",
            "[Batch 7] Current Loss: 5.3053\n",
            "[Batch 8] Current Loss: 5.2793\n",
            "[Batch 9] Current Loss: 5.5351\n",
            "Ep 2 (Step 012820): Train loss 3.919, Val loss 5.350\n",
            "[Batch 0] Current Loss: 4.4301\n",
            "[Batch 1] Current Loss: 3.8192\n",
            "[Batch 2] Current Loss: 3.7086\n",
            "[Batch 3] Current Loss: 3.8947\n",
            "[Batch 4] Current Loss: 3.9627\n",
            "[Batch 5] Current Loss: 3.8271\n",
            "[Batch 6] Current Loss: 3.6968\n",
            "[Batch 7] Current Loss: 3.8510\n",
            "[Batch 8] Current Loss: 4.4833\n",
            "[Batch 9] Current Loss: 4.2010\n",
            "[Batch 0] Current Loss: 5.5241\n",
            "[Batch 1] Current Loss: 4.8843\n",
            "[Batch 2] Current Loss: 5.3266\n",
            "[Batch 3] Current Loss: 6.1284\n",
            "[Batch 4] Current Loss: 5.4656\n",
            "[Batch 5] Current Loss: 5.4474\n",
            "[Batch 6] Current Loss: 4.8504\n",
            "[Batch 7] Current Loss: 5.4308\n",
            "[Batch 8] Current Loss: 5.1560\n",
            "[Batch 9] Current Loss: 4.8763\n",
            "Ep 2 (Step 012840): Train loss 3.987, Val loss 5.309\n",
            "[Batch 0] Current Loss: 4.5798\n",
            "[Batch 1] Current Loss: 3.4080\n",
            "[Batch 2] Current Loss: 3.6558\n",
            "[Batch 3] Current Loss: 4.2346\n",
            "[Batch 4] Current Loss: 4.0344\n",
            "[Batch 5] Current Loss: 4.0447\n",
            "[Batch 6] Current Loss: 3.5928\n",
            "[Batch 7] Current Loss: 3.6871\n",
            "[Batch 8] Current Loss: 4.8439\n",
            "[Batch 9] Current Loss: 3.3502\n",
            "[Batch 0] Current Loss: 5.6477\n",
            "[Batch 1] Current Loss: 6.0586\n",
            "[Batch 2] Current Loss: 5.6359\n",
            "[Batch 3] Current Loss: 5.0765\n",
            "[Batch 4] Current Loss: 4.9275\n",
            "[Batch 5] Current Loss: 5.2556\n",
            "[Batch 6] Current Loss: 5.1940\n",
            "[Batch 7] Current Loss: 5.5678\n",
            "[Batch 8] Current Loss: 5.6347\n",
            "[Batch 9] Current Loss: 4.5689\n",
            "Ep 2 (Step 012860): Train loss 3.943, Val loss 5.357\n",
            "[Batch 0] Current Loss: 3.7384\n",
            "[Batch 1] Current Loss: 3.4996\n",
            "[Batch 2] Current Loss: 3.7642\n",
            "[Batch 3] Current Loss: 3.8067\n",
            "[Batch 4] Current Loss: 3.8413\n",
            "[Batch 5] Current Loss: 3.5255\n",
            "[Batch 6] Current Loss: 3.8949\n",
            "[Batch 7] Current Loss: 3.8371\n",
            "[Batch 8] Current Loss: 4.1283\n",
            "[Batch 9] Current Loss: 4.1253\n",
            "[Batch 0] Current Loss: 5.2231\n",
            "[Batch 1] Current Loss: 4.7865\n",
            "[Batch 2] Current Loss: 5.2992\n",
            "[Batch 3] Current Loss: 5.6172\n",
            "[Batch 4] Current Loss: 4.6102\n",
            "[Batch 5] Current Loss: 4.7654\n",
            "[Batch 6] Current Loss: 5.5250\n",
            "[Batch 7] Current Loss: 5.4718\n",
            "[Batch 8] Current Loss: 5.0587\n",
            "[Batch 9] Current Loss: 5.1396\n",
            "Ep 2 (Step 012880): Train loss 3.816, Val loss 5.150\n",
            "[Batch 0] Current Loss: 3.6527\n",
            "[Batch 1] Current Loss: 3.9707\n",
            "[Batch 2] Current Loss: 3.5507\n",
            "[Batch 3] Current Loss: 3.5719\n",
            "[Batch 4] Current Loss: 4.2559\n",
            "[Batch 5] Current Loss: 3.9845\n",
            "[Batch 6] Current Loss: 3.3589\n",
            "[Batch 7] Current Loss: 4.3240\n",
            "[Batch 8] Current Loss: 3.3618\n",
            "[Batch 9] Current Loss: 3.8875\n",
            "[Batch 0] Current Loss: 5.2712\n",
            "[Batch 1] Current Loss: 5.7053\n",
            "[Batch 2] Current Loss: 5.3805\n",
            "[Batch 3] Current Loss: 5.2848\n",
            "[Batch 4] Current Loss: 5.5163\n",
            "[Batch 5] Current Loss: 4.9987\n",
            "[Batch 6] Current Loss: 5.3040\n",
            "[Batch 7] Current Loss: 5.7329\n",
            "[Batch 8] Current Loss: 5.7484\n",
            "[Batch 9] Current Loss: 4.7607\n",
            "Ep 2 (Step 012900): Train loss 3.792, Val loss 5.370\n",
            "[Batch 0] Current Loss: 3.4009\n",
            "[Batch 1] Current Loss: 3.5118\n",
            "[Batch 2] Current Loss: 3.0355\n",
            "[Batch 3] Current Loss: 4.0023\n",
            "[Batch 4] Current Loss: 3.1153\n",
            "[Batch 5] Current Loss: 3.9784\n",
            "[Batch 6] Current Loss: 4.1486\n",
            "[Batch 7] Current Loss: 3.8893\n",
            "[Batch 8] Current Loss: 3.7983\n",
            "[Batch 9] Current Loss: 3.7568\n",
            "[Batch 0] Current Loss: 5.4836\n",
            "[Batch 1] Current Loss: 5.7174\n",
            "[Batch 2] Current Loss: 5.4523\n",
            "[Batch 3] Current Loss: 5.1040\n",
            "[Batch 4] Current Loss: 4.8758\n",
            "[Batch 5] Current Loss: 6.2186\n",
            "[Batch 6] Current Loss: 4.9426\n",
            "[Batch 7] Current Loss: 5.4373\n",
            "[Batch 8] Current Loss: 5.0373\n",
            "[Batch 9] Current Loss: 5.4923\n",
            "Ep 2 (Step 012920): Train loss 3.664, Val loss 5.376\n",
            "[Batch 0] Current Loss: 4.2614\n",
            "[Batch 1] Current Loss: 3.4742\n",
            "[Batch 2] Current Loss: 3.6185\n",
            "[Batch 3] Current Loss: 4.1858\n",
            "[Batch 4] Current Loss: 3.9919\n",
            "[Batch 5] Current Loss: 4.0081\n",
            "[Batch 6] Current Loss: 4.0119\n",
            "[Batch 7] Current Loss: 3.7756\n",
            "[Batch 8] Current Loss: 3.4918\n",
            "[Batch 9] Current Loss: 3.7520\n",
            "[Batch 0] Current Loss: 5.1801\n",
            "[Batch 1] Current Loss: 5.5215\n",
            "[Batch 2] Current Loss: 6.0535\n",
            "[Batch 3] Current Loss: 5.0047\n",
            "[Batch 4] Current Loss: 5.0031\n",
            "[Batch 5] Current Loss: 4.3584\n",
            "[Batch 6] Current Loss: 5.0691\n",
            "[Batch 7] Current Loss: 4.8836\n",
            "[Batch 8] Current Loss: 4.5335\n",
            "[Batch 9] Current Loss: 5.4647\n",
            "Ep 2 (Step 012940): Train loss 3.857, Val loss 5.107\n",
            "[Batch 0] Current Loss: 3.7455\n",
            "[Batch 1] Current Loss: 4.1005\n",
            "[Batch 2] Current Loss: 3.7533\n",
            "[Batch 3] Current Loss: 4.1860\n",
            "[Batch 4] Current Loss: 3.5240\n",
            "[Batch 5] Current Loss: 2.9760\n",
            "[Batch 6] Current Loss: 4.1349\n",
            "[Batch 7] Current Loss: 3.1258\n",
            "[Batch 8] Current Loss: 3.7498\n",
            "[Batch 9] Current Loss: 3.4377\n",
            "[Batch 0] Current Loss: 5.6737\n",
            "[Batch 1] Current Loss: 5.4267\n",
            "[Batch 2] Current Loss: 4.9879\n",
            "[Batch 3] Current Loss: 4.6756\n",
            "[Batch 4] Current Loss: 5.3078\n",
            "[Batch 5] Current Loss: 5.5634\n",
            "[Batch 6] Current Loss: 5.2617\n",
            "[Batch 7] Current Loss: 4.7042\n",
            "[Batch 8] Current Loss: 5.0032\n",
            "[Batch 9] Current Loss: 5.0704\n",
            "Ep 2 (Step 012960): Train loss 3.673, Val loss 5.167\n",
            "[Batch 0] Current Loss: 3.9588\n",
            "[Batch 1] Current Loss: 3.5819\n",
            "[Batch 2] Current Loss: 4.4404\n",
            "[Batch 3] Current Loss: 3.8061\n",
            "[Batch 4] Current Loss: 3.4793\n",
            "[Batch 5] Current Loss: 3.5166\n",
            "[Batch 6] Current Loss: 3.8493\n",
            "[Batch 7] Current Loss: 3.6837\n",
            "[Batch 8] Current Loss: 4.0703\n",
            "[Batch 9] Current Loss: 3.2596\n",
            "[Batch 0] Current Loss: 5.0253\n",
            "[Batch 1] Current Loss: 4.8039\n",
            "[Batch 2] Current Loss: 5.2052\n",
            "[Batch 3] Current Loss: 5.3263\n",
            "[Batch 4] Current Loss: 5.5963\n",
            "[Batch 5] Current Loss: 4.7948\n",
            "[Batch 6] Current Loss: 5.0025\n",
            "[Batch 7] Current Loss: 4.7792\n",
            "[Batch 8] Current Loss: 4.7571\n",
            "[Batch 9] Current Loss: 4.9100\n",
            "Ep 2 (Step 012980): Train loss 3.765, Val loss 5.020\n",
            "[Batch 0] Current Loss: 3.0574\n",
            "[Batch 1] Current Loss: 3.5976\n",
            "[Batch 2] Current Loss: 4.0708\n",
            "[Batch 3] Current Loss: 3.8403\n",
            "[Batch 4] Current Loss: 3.5198\n",
            "[Batch 5] Current Loss: 3.8656\n",
            "[Batch 6] Current Loss: 3.8946\n",
            "[Batch 7] Current Loss: 3.6775\n",
            "[Batch 8] Current Loss: 3.5941\n",
            "[Batch 9] Current Loss: 3.9892\n",
            "[Batch 0] Current Loss: 4.8611\n",
            "[Batch 1] Current Loss: 5.6445\n",
            "[Batch 2] Current Loss: 4.8458\n",
            "[Batch 3] Current Loss: 5.1883\n",
            "[Batch 4] Current Loss: 5.3686\n",
            "[Batch 5] Current Loss: 5.9833\n",
            "[Batch 6] Current Loss: 5.1540\n",
            "[Batch 7] Current Loss: 5.0756\n",
            "[Batch 8] Current Loss: 4.8393\n",
            "[Batch 9] Current Loss: 4.8982\n",
            "Ep 2 (Step 013000): Train loss 3.711, Val loss 5.186\n",
            "[Batch 0] Current Loss: 3.2939\n",
            "[Batch 1] Current Loss: 4.5441\n",
            "[Batch 2] Current Loss: 3.7235\n",
            "[Batch 3] Current Loss: 3.7297\n",
            "[Batch 4] Current Loss: 4.3018\n",
            "[Batch 5] Current Loss: 4.5739\n",
            "[Batch 6] Current Loss: 3.8249\n",
            "[Batch 7] Current Loss: 3.9666\n",
            "[Batch 8] Current Loss: 3.7279\n",
            "[Batch 9] Current Loss: 4.1834\n",
            "[Batch 0] Current Loss: 5.6261\n",
            "[Batch 1] Current Loss: 4.7637\n",
            "[Batch 2] Current Loss: 4.8650\n",
            "[Batch 3] Current Loss: 5.2555\n",
            "[Batch 4] Current Loss: 4.8207\n",
            "[Batch 5] Current Loss: 5.2173\n",
            "[Batch 6] Current Loss: 4.6594\n",
            "[Batch 7] Current Loss: 5.5265\n",
            "[Batch 8] Current Loss: 4.8944\n",
            "[Batch 9] Current Loss: 4.3382\n",
            "Ep 2 (Step 013020): Train loss 3.987, Val loss 4.997\n",
            "[Batch 0] Current Loss: 4.1866\n",
            "[Batch 1] Current Loss: 4.0395\n",
            "[Batch 2] Current Loss: 3.9725\n",
            "[Batch 3] Current Loss: 4.1911\n",
            "[Batch 4] Current Loss: 3.4996\n",
            "[Batch 5] Current Loss: 4.2380\n",
            "[Batch 6] Current Loss: 4.0010\n",
            "[Batch 7] Current Loss: 3.3640\n",
            "[Batch 8] Current Loss: 3.7359\n",
            "[Batch 9] Current Loss: 4.0577\n",
            "[Batch 0] Current Loss: 5.3403\n",
            "[Batch 1] Current Loss: 5.2251\n",
            "[Batch 2] Current Loss: 5.7099\n",
            "[Batch 3] Current Loss: 5.1943\n",
            "[Batch 4] Current Loss: 5.5041\n",
            "[Batch 5] Current Loss: 5.5530\n",
            "[Batch 6] Current Loss: 5.3439\n",
            "[Batch 7] Current Loss: 5.4410\n",
            "[Batch 8] Current Loss: 4.5564\n",
            "[Batch 9] Current Loss: 6.1555\n",
            "Ep 2 (Step 013040): Train loss 3.929, Val loss 5.402\n",
            "[Batch 0] Current Loss: 4.0162\n",
            "[Batch 1] Current Loss: 4.6980\n",
            "[Batch 2] Current Loss: 4.4605\n",
            "[Batch 3] Current Loss: 3.1593\n",
            "[Batch 4] Current Loss: 4.3430\n",
            "[Batch 5] Current Loss: 4.3759\n",
            "[Batch 6] Current Loss: 3.5793\n",
            "[Batch 7] Current Loss: 4.2216\n",
            "[Batch 8] Current Loss: 3.5703\n",
            "[Batch 9] Current Loss: 4.5180\n",
            "[Batch 0] Current Loss: 5.4930\n",
            "[Batch 1] Current Loss: 4.9431\n",
            "[Batch 2] Current Loss: 4.5495\n",
            "[Batch 3] Current Loss: 5.4043\n",
            "[Batch 4] Current Loss: 5.2049\n",
            "[Batch 5] Current Loss: 5.8373\n",
            "[Batch 6] Current Loss: 5.0834\n",
            "[Batch 7] Current Loss: 5.2628\n",
            "[Batch 8] Current Loss: 5.2544\n",
            "[Batch 9] Current Loss: 5.1961\n",
            "Ep 2 (Step 013060): Train loss 4.094, Val loss 5.223\n",
            "[Batch 0] Current Loss: 4.1531\n",
            "[Batch 1] Current Loss: 3.1796\n",
            "[Batch 2] Current Loss: 3.1664\n",
            "[Batch 3] Current Loss: 3.3861\n",
            "[Batch 4] Current Loss: 4.2217\n",
            "[Batch 5] Current Loss: 4.2874\n",
            "[Batch 6] Current Loss: 3.3157\n",
            "[Batch 7] Current Loss: 3.1634\n",
            "[Batch 8] Current Loss: 3.6039\n",
            "[Batch 9] Current Loss: 3.0507\n",
            "[Batch 0] Current Loss: 4.8725\n",
            "[Batch 1] Current Loss: 5.0572\n",
            "[Batch 2] Current Loss: 6.0780\n",
            "[Batch 3] Current Loss: 5.0878\n",
            "[Batch 4] Current Loss: 4.6297\n",
            "[Batch 5] Current Loss: 5.6259\n",
            "[Batch 6] Current Loss: 4.8898\n",
            "[Batch 7] Current Loss: 5.6362\n",
            "[Batch 8] Current Loss: 5.3975\n",
            "[Batch 9] Current Loss: 5.5690\n",
            "Ep 2 (Step 013080): Train loss 3.553, Val loss 5.284\n",
            "[Batch 0] Current Loss: 4.1292\n",
            "[Batch 1] Current Loss: 4.3069\n",
            "[Batch 2] Current Loss: 3.5262\n",
            "[Batch 3] Current Loss: 3.9863\n",
            "[Batch 4] Current Loss: 3.5356\n",
            "[Batch 5] Current Loss: 3.8184\n",
            "[Batch 6] Current Loss: 4.1461\n",
            "[Batch 7] Current Loss: 3.6044\n",
            "[Batch 8] Current Loss: 4.5733\n",
            "[Batch 9] Current Loss: 3.8966\n",
            "[Batch 0] Current Loss: 5.1010\n",
            "[Batch 1] Current Loss: 5.4041\n",
            "[Batch 2] Current Loss: 5.1182\n",
            "[Batch 3] Current Loss: 5.2204\n",
            "[Batch 4] Current Loss: 5.4933\n",
            "[Batch 5] Current Loss: 5.1546\n",
            "[Batch 6] Current Loss: 4.8630\n",
            "[Batch 7] Current Loss: 4.9004\n",
            "[Batch 8] Current Loss: 5.5208\n",
            "[Batch 9] Current Loss: 5.1657\n",
            "Ep 2 (Step 013100): Train loss 3.952, Val loss 5.194\n",
            "[Batch 0] Current Loss: 4.2172\n",
            "[Batch 1] Current Loss: 4.1857\n",
            "[Batch 2] Current Loss: 3.4336\n",
            "[Batch 3] Current Loss: 3.2462\n",
            "[Batch 4] Current Loss: 3.6609\n",
            "[Batch 5] Current Loss: 3.6499\n",
            "[Batch 6] Current Loss: 4.0306\n",
            "[Batch 7] Current Loss: 3.4430\n",
            "[Batch 8] Current Loss: 3.1362\n",
            "[Batch 9] Current Loss: 3.8576\n",
            "[Batch 0] Current Loss: 4.9220\n",
            "[Batch 1] Current Loss: 4.7853\n",
            "[Batch 2] Current Loss: 4.8553\n",
            "[Batch 3] Current Loss: 5.5220\n",
            "[Batch 4] Current Loss: 4.9053\n",
            "[Batch 5] Current Loss: 5.4105\n",
            "[Batch 6] Current Loss: 5.7146\n",
            "[Batch 7] Current Loss: 5.7333\n",
            "[Batch 8] Current Loss: 5.5288\n",
            "[Batch 9] Current Loss: 5.1825\n",
            "Ep 2 (Step 013120): Train loss 3.686, Val loss 5.256\n",
            "[Batch 0] Current Loss: 4.4791\n",
            "[Batch 1] Current Loss: 3.9100\n",
            "[Batch 2] Current Loss: 4.0859\n",
            "[Batch 3] Current Loss: 3.8651\n",
            "[Batch 4] Current Loss: 4.4699\n",
            "[Batch 5] Current Loss: 4.1314\n",
            "[Batch 6] Current Loss: 4.0702\n",
            "[Batch 7] Current Loss: 3.9592\n",
            "[Batch 8] Current Loss: 4.6277\n",
            "[Batch 9] Current Loss: 3.2203\n",
            "[Batch 0] Current Loss: 5.0645\n",
            "[Batch 1] Current Loss: 4.7156\n",
            "[Batch 2] Current Loss: 5.0235\n",
            "[Batch 3] Current Loss: 5.5706\n",
            "[Batch 4] Current Loss: 4.9909\n",
            "[Batch 5] Current Loss: 5.5714\n",
            "[Batch 6] Current Loss: 4.5370\n",
            "[Batch 7] Current Loss: 5.9047\n",
            "[Batch 8] Current Loss: 4.5900\n",
            "[Batch 9] Current Loss: 5.6022\n",
            "Ep 2 (Step 013140): Train loss 4.082, Val loss 5.157\n",
            "[Batch 0] Current Loss: 4.0660\n",
            "[Batch 1] Current Loss: 3.9844\n",
            "[Batch 2] Current Loss: 3.8487\n",
            "[Batch 3] Current Loss: 4.2403\n",
            "[Batch 4] Current Loss: 4.1864\n",
            "[Batch 5] Current Loss: 3.9730\n",
            "[Batch 6] Current Loss: 4.0564\n",
            "[Batch 7] Current Loss: 3.6644\n",
            "[Batch 8] Current Loss: 3.8270\n",
            "[Batch 9] Current Loss: 3.2239\n",
            "[Batch 0] Current Loss: 5.3076\n",
            "[Batch 1] Current Loss: 4.7015\n",
            "[Batch 2] Current Loss: 5.1453\n",
            "[Batch 3] Current Loss: 5.1607\n",
            "[Batch 4] Current Loss: 4.9413\n",
            "[Batch 5] Current Loss: 4.8381\n",
            "[Batch 6] Current Loss: 5.0686\n",
            "[Batch 7] Current Loss: 5.6686\n",
            "[Batch 8] Current Loss: 5.5786\n",
            "[Batch 9] Current Loss: 5.0815\n",
            "Ep 2 (Step 013160): Train loss 3.907, Val loss 5.149\n",
            "[Batch 0] Current Loss: 3.5634\n",
            "[Batch 1] Current Loss: 4.1252\n",
            "[Batch 2] Current Loss: 3.5675\n",
            "[Batch 3] Current Loss: 4.0270\n",
            "[Batch 4] Current Loss: 4.1459\n",
            "[Batch 5] Current Loss: 3.5069\n",
            "[Batch 6] Current Loss: 3.8702\n",
            "[Batch 7] Current Loss: 3.0941\n",
            "[Batch 8] Current Loss: 4.3163\n",
            "[Batch 9] Current Loss: 3.8668\n",
            "[Batch 0] Current Loss: 4.9616\n",
            "[Batch 1] Current Loss: 5.4948\n",
            "[Batch 2] Current Loss: 5.4212\n",
            "[Batch 3] Current Loss: 5.3711\n",
            "[Batch 4] Current Loss: 4.6887\n",
            "[Batch 5] Current Loss: 4.9366\n",
            "[Batch 6] Current Loss: 5.3693\n",
            "[Batch 7] Current Loss: 5.2764\n",
            "[Batch 8] Current Loss: 5.1662\n",
            "[Batch 9] Current Loss: 4.8096\n",
            "Ep 2 (Step 013180): Train loss 3.808, Val loss 5.150\n",
            "[Batch 0] Current Loss: 3.6913\n",
            "[Batch 1] Current Loss: 4.1347\n",
            "[Batch 2] Current Loss: 4.3125\n",
            "[Batch 3] Current Loss: 3.8619\n",
            "[Batch 4] Current Loss: 3.7194\n",
            "[Batch 5] Current Loss: 4.1003\n",
            "[Batch 6] Current Loss: 3.7153\n",
            "[Batch 7] Current Loss: 3.8266\n",
            "[Batch 8] Current Loss: 3.8483\n",
            "[Batch 9] Current Loss: 3.6062\n",
            "[Batch 0] Current Loss: 5.5079\n",
            "[Batch 1] Current Loss: 4.7990\n",
            "[Batch 2] Current Loss: 5.2513\n",
            "[Batch 3] Current Loss: 4.9777\n",
            "[Batch 4] Current Loss: 5.9038\n",
            "[Batch 5] Current Loss: 5.0883\n",
            "[Batch 6] Current Loss: 5.0304\n",
            "[Batch 7] Current Loss: 4.4969\n",
            "[Batch 8] Current Loss: 5.7219\n",
            "[Batch 9] Current Loss: 5.2627\n",
            "Ep 2 (Step 013200): Train loss 3.882, Val loss 5.204\n",
            "[Batch 0] Current Loss: 3.9688\n",
            "[Batch 1] Current Loss: 3.7191\n",
            "[Batch 2] Current Loss: 3.8558\n",
            "[Batch 3] Current Loss: 4.5287\n",
            "[Batch 4] Current Loss: 3.7325\n",
            "[Batch 5] Current Loss: 3.0050\n",
            "[Batch 6] Current Loss: 3.8503\n",
            "[Batch 7] Current Loss: 4.1472\n",
            "[Batch 8] Current Loss: 4.1491\n",
            "[Batch 9] Current Loss: 3.9291\n",
            "[Batch 0] Current Loss: 5.4234\n",
            "[Batch 1] Current Loss: 5.6166\n",
            "[Batch 2] Current Loss: 5.0859\n",
            "[Batch 3] Current Loss: 5.0677\n",
            "[Batch 4] Current Loss: 4.7534\n",
            "[Batch 5] Current Loss: 5.6346\n",
            "[Batch 6] Current Loss: 5.5877\n",
            "[Batch 7] Current Loss: 5.0566\n",
            "[Batch 8] Current Loss: 4.8835\n",
            "[Batch 9] Current Loss: 5.0653\n",
            "Ep 2 (Step 013220): Train loss 3.889, Val loss 5.217\n",
            "[Batch 0] Current Loss: 4.0952\n",
            "[Batch 1] Current Loss: 3.6919\n",
            "[Batch 2] Current Loss: 3.7750\n",
            "[Batch 3] Current Loss: 3.4530\n",
            "[Batch 4] Current Loss: 3.8002\n",
            "[Batch 5] Current Loss: 3.8713\n",
            "[Batch 6] Current Loss: 3.8919\n",
            "[Batch 7] Current Loss: 3.7550\n",
            "[Batch 8] Current Loss: 3.8156\n",
            "[Batch 9] Current Loss: 4.3734\n",
            "[Batch 0] Current Loss: 5.3115\n",
            "[Batch 1] Current Loss: 5.9682\n",
            "[Batch 2] Current Loss: 5.3622\n",
            "[Batch 3] Current Loss: 5.2814\n",
            "[Batch 4] Current Loss: 5.1852\n",
            "[Batch 5] Current Loss: 4.8832\n",
            "[Batch 6] Current Loss: 5.7597\n",
            "[Batch 7] Current Loss: 4.4646\n",
            "[Batch 8] Current Loss: 5.0233\n",
            "[Batch 9] Current Loss: 5.8364\n",
            "Ep 2 (Step 013240): Train loss 3.852, Val loss 5.308\n",
            "[Batch 0] Current Loss: 3.9598\n",
            "[Batch 1] Current Loss: 3.4986\n",
            "[Batch 2] Current Loss: 3.5667\n",
            "[Batch 3] Current Loss: 3.3785\n",
            "[Batch 4] Current Loss: 4.2351\n",
            "[Batch 5] Current Loss: 3.7819\n",
            "[Batch 6] Current Loss: 2.9192\n",
            "[Batch 7] Current Loss: 3.4299\n",
            "[Batch 8] Current Loss: 3.7392\n",
            "[Batch 9] Current Loss: 3.5907\n",
            "[Batch 0] Current Loss: 4.5212\n",
            "[Batch 1] Current Loss: 4.9697\n",
            "[Batch 2] Current Loss: 5.0852\n",
            "[Batch 3] Current Loss: 5.3873\n",
            "[Batch 4] Current Loss: 5.6319\n",
            "[Batch 5] Current Loss: 4.8428\n",
            "[Batch 6] Current Loss: 5.1756\n",
            "[Batch 7] Current Loss: 5.5778\n",
            "[Batch 8] Current Loss: 4.8201\n",
            "[Batch 9] Current Loss: 4.7416\n",
            "Ep 2 (Step 013260): Train loss 3.610, Val loss 5.075\n",
            "[Batch 0] Current Loss: 3.3731\n",
            "[Batch 1] Current Loss: 4.2326\n",
            "[Batch 2] Current Loss: 3.7570\n",
            "[Batch 3] Current Loss: 4.0997\n",
            "[Batch 4] Current Loss: 3.8400\n",
            "[Batch 5] Current Loss: 3.6331\n",
            "[Batch 6] Current Loss: 3.3100\n",
            "[Batch 7] Current Loss: 3.9496\n",
            "[Batch 8] Current Loss: 3.6578\n",
            "[Batch 9] Current Loss: 4.0915\n",
            "[Batch 0] Current Loss: 5.2000\n",
            "[Batch 1] Current Loss: 5.4166\n",
            "[Batch 2] Current Loss: 5.0999\n",
            "[Batch 3] Current Loss: 5.4132\n",
            "[Batch 4] Current Loss: 5.2491\n",
            "[Batch 5] Current Loss: 6.0150\n",
            "[Batch 6] Current Loss: 4.3877\n",
            "[Batch 7] Current Loss: 5.4955\n",
            "[Batch 8] Current Loss: 5.1403\n",
            "[Batch 9] Current Loss: 4.9015\n",
            "Ep 2 (Step 013280): Train loss 3.794, Val loss 5.232\n",
            "[Batch 0] Current Loss: 3.7639\n",
            "[Batch 1] Current Loss: 3.4236\n",
            "[Batch 2] Current Loss: 3.5262\n",
            "[Batch 3] Current Loss: 3.7422\n",
            "[Batch 4] Current Loss: 3.7787\n",
            "[Batch 5] Current Loss: 4.2830\n",
            "[Batch 6] Current Loss: 3.9643\n",
            "[Batch 7] Current Loss: 4.5513\n",
            "[Batch 8] Current Loss: 3.9682\n",
            "[Batch 9] Current Loss: 3.7002\n",
            "[Batch 0] Current Loss: 5.1592\n",
            "[Batch 1] Current Loss: 5.4541\n",
            "[Batch 2] Current Loss: 5.5780\n",
            "[Batch 3] Current Loss: 5.4280\n",
            "[Batch 4] Current Loss: 5.0531\n",
            "[Batch 5] Current Loss: 5.6881\n",
            "[Batch 6] Current Loss: 5.6882\n",
            "[Batch 7] Current Loss: 5.1651\n",
            "[Batch 8] Current Loss: 5.4145\n",
            "[Batch 9] Current Loss: 5.1809\n",
            "Ep 2 (Step 013300): Train loss 3.870, Val loss 5.381\n",
            "[Batch 0] Current Loss: 3.6079\n",
            "[Batch 1] Current Loss: 3.7973\n",
            "[Batch 2] Current Loss: 3.5219\n",
            "[Batch 3] Current Loss: 4.1628\n",
            "[Batch 4] Current Loss: 3.8915\n",
            "[Batch 5] Current Loss: 3.1850\n",
            "[Batch 6] Current Loss: 3.4234\n",
            "[Batch 7] Current Loss: 3.8756\n",
            "[Batch 8] Current Loss: 3.6024\n",
            "[Batch 9] Current Loss: 3.0125\n",
            "[Batch 0] Current Loss: 5.6411\n",
            "[Batch 1] Current Loss: 5.4947\n",
            "[Batch 2] Current Loss: 4.9612\n",
            "[Batch 3] Current Loss: 5.3929\n",
            "[Batch 4] Current Loss: 5.2587\n",
            "[Batch 5] Current Loss: 5.1085\n",
            "[Batch 6] Current Loss: 5.6551\n",
            "[Batch 7] Current Loss: 5.2261\n",
            "[Batch 8] Current Loss: 5.5679\n",
            "[Batch 9] Current Loss: 5.2103\n",
            "Ep 2 (Step 013320): Train loss 3.608, Val loss 5.352\n",
            "[Batch 0] Current Loss: 3.6966\n",
            "[Batch 1] Current Loss: 3.3066\n",
            "[Batch 2] Current Loss: 4.1424\n",
            "[Batch 3] Current Loss: 3.4558\n",
            "[Batch 4] Current Loss: 4.4709\n",
            "[Batch 5] Current Loss: 4.2240\n",
            "[Batch 6] Current Loss: 3.6083\n",
            "[Batch 7] Current Loss: 3.2313\n",
            "[Batch 8] Current Loss: 3.9828\n",
            "[Batch 9] Current Loss: 3.3025\n",
            "[Batch 0] Current Loss: 5.4798\n",
            "[Batch 1] Current Loss: 5.2200\n",
            "[Batch 2] Current Loss: 5.0559\n",
            "[Batch 3] Current Loss: 5.1000\n",
            "[Batch 4] Current Loss: 5.2772\n",
            "[Batch 5] Current Loss: 5.2950\n",
            "[Batch 6] Current Loss: 5.8170\n",
            "[Batch 7] Current Loss: 4.9706\n",
            "[Batch 8] Current Loss: 4.9161\n",
            "[Batch 9] Current Loss: 4.8327\n",
            "Ep 2 (Step 013340): Train loss 3.742, Val loss 5.196\n",
            "[Batch 0] Current Loss: 3.9286\n",
            "[Batch 1] Current Loss: 3.3933\n",
            "[Batch 2] Current Loss: 3.5951\n",
            "[Batch 3] Current Loss: 3.9268\n",
            "[Batch 4] Current Loss: 3.8179\n",
            "[Batch 5] Current Loss: 3.9318\n",
            "[Batch 6] Current Loss: 3.9642\n",
            "[Batch 7] Current Loss: 3.3728\n",
            "[Batch 8] Current Loss: 4.4671\n",
            "[Batch 9] Current Loss: 3.5280\n",
            "[Batch 0] Current Loss: 5.5176\n",
            "[Batch 1] Current Loss: 5.4133\n",
            "[Batch 2] Current Loss: 5.9440\n",
            "[Batch 3] Current Loss: 4.7730\n",
            "[Batch 4] Current Loss: 4.8081\n",
            "[Batch 5] Current Loss: 4.7167\n",
            "[Batch 6] Current Loss: 5.2067\n",
            "[Batch 7] Current Loss: 5.2621\n",
            "[Batch 8] Current Loss: 4.5252\n",
            "[Batch 9] Current Loss: 5.2890\n",
            "Ep 2 (Step 013360): Train loss 3.793, Val loss 5.146\n",
            "[Batch 0] Current Loss: 3.7947\n",
            "[Batch 1] Current Loss: 3.0141\n",
            "[Batch 2] Current Loss: 3.6345\n",
            "[Batch 3] Current Loss: 4.3099\n",
            "[Batch 4] Current Loss: 3.7646\n",
            "[Batch 5] Current Loss: 3.1632\n",
            "[Batch 6] Current Loss: 3.2911\n",
            "[Batch 7] Current Loss: 4.0540\n",
            "[Batch 8] Current Loss: 3.7374\n",
            "[Batch 9] Current Loss: 3.9520\n",
            "[Batch 0] Current Loss: 4.8505\n",
            "[Batch 1] Current Loss: 5.2899\n",
            "[Batch 2] Current Loss: 4.9855\n",
            "[Batch 3] Current Loss: 4.8243\n",
            "[Batch 4] Current Loss: 5.3450\n",
            "[Batch 5] Current Loss: 4.4278\n",
            "[Batch 6] Current Loss: 4.6088\n",
            "[Batch 7] Current Loss: 5.4171\n",
            "[Batch 8] Current Loss: 5.1090\n",
            "[Batch 9] Current Loss: 5.2168\n",
            "Ep 2 (Step 013380): Train loss 3.672, Val loss 5.007\n",
            "[Batch 0] Current Loss: 3.8498\n",
            "[Batch 1] Current Loss: 3.7930\n",
            "[Batch 2] Current Loss: 3.5753\n",
            "[Batch 3] Current Loss: 3.3865\n",
            "[Batch 4] Current Loss: 3.7375\n",
            "[Batch 5] Current Loss: 3.4486\n",
            "[Batch 6] Current Loss: 4.0903\n",
            "[Batch 7] Current Loss: 3.6399\n",
            "[Batch 8] Current Loss: 4.1495\n",
            "[Batch 9] Current Loss: 3.7126\n",
            "[Batch 0] Current Loss: 5.1077\n",
            "[Batch 1] Current Loss: 5.6439\n",
            "[Batch 2] Current Loss: 5.4724\n",
            "[Batch 3] Current Loss: 5.5930\n",
            "[Batch 4] Current Loss: 4.9104\n",
            "[Batch 5] Current Loss: 5.2342\n",
            "[Batch 6] Current Loss: 4.5884\n",
            "[Batch 7] Current Loss: 5.6108\n",
            "[Batch 8] Current Loss: 4.5512\n",
            "[Batch 9] Current Loss: 5.4306\n",
            "Ep 2 (Step 013400): Train loss 3.738, Val loss 5.214\n",
            "[Batch 0] Current Loss: 3.6821\n",
            "[Batch 1] Current Loss: 3.8067\n",
            "[Batch 2] Current Loss: 3.3507\n",
            "[Batch 3] Current Loss: 4.0672\n",
            "[Batch 4] Current Loss: 3.8059\n",
            "[Batch 5] Current Loss: 4.2493\n",
            "[Batch 6] Current Loss: 3.5359\n",
            "[Batch 7] Current Loss: 3.9555\n",
            "[Batch 8] Current Loss: 3.4070\n",
            "[Batch 9] Current Loss: 3.8871\n",
            "[Batch 0] Current Loss: 5.6202\n",
            "[Batch 1] Current Loss: 5.6674\n",
            "[Batch 2] Current Loss: 5.0626\n",
            "[Batch 3] Current Loss: 5.8601\n",
            "[Batch 4] Current Loss: 5.2946\n",
            "[Batch 5] Current Loss: 4.2099\n",
            "[Batch 6] Current Loss: 5.0131\n",
            "[Batch 7] Current Loss: 4.7963\n",
            "[Batch 8] Current Loss: 4.9642\n",
            "[Batch 9] Current Loss: 5.2242\n",
            "Ep 2 (Step 013420): Train loss 3.775, Val loss 5.171\n",
            "[Batch 0] Current Loss: 4.0576\n",
            "[Batch 1] Current Loss: 3.8066\n",
            "[Batch 2] Current Loss: 2.9593\n",
            "[Batch 3] Current Loss: 3.8675\n",
            "[Batch 4] Current Loss: 3.7119\n",
            "[Batch 5] Current Loss: 4.0676\n",
            "[Batch 6] Current Loss: 3.4606\n",
            "[Batch 7] Current Loss: 3.8078\n",
            "[Batch 8] Current Loss: 3.9411\n",
            "[Batch 9] Current Loss: 3.9452\n",
            "[Batch 0] Current Loss: 5.0129\n",
            "[Batch 1] Current Loss: 5.0636\n",
            "[Batch 2] Current Loss: 5.1878\n",
            "[Batch 3] Current Loss: 5.0383\n",
            "[Batch 4] Current Loss: 5.4830\n",
            "[Batch 5] Current Loss: 5.3725\n",
            "[Batch 6] Current Loss: 5.3898\n",
            "[Batch 7] Current Loss: 5.1906\n",
            "[Batch 8] Current Loss: 5.7950\n",
            "[Batch 9] Current Loss: 5.4591\n",
            "Ep 2 (Step 013440): Train loss 3.763, Val loss 5.299\n",
            "[Batch 0] Current Loss: 3.7534\n",
            "[Batch 1] Current Loss: 3.0783\n",
            "[Batch 2] Current Loss: 4.2835\n",
            "[Batch 3] Current Loss: 3.9634\n",
            "[Batch 4] Current Loss: 4.1679\n",
            "[Batch 5] Current Loss: 3.7357\n",
            "[Batch 6] Current Loss: 3.9736\n",
            "[Batch 7] Current Loss: 4.3519\n",
            "[Batch 8] Current Loss: 3.2743\n",
            "[Batch 9] Current Loss: 3.3313\n",
            "[Batch 0] Current Loss: 5.5077\n",
            "[Batch 1] Current Loss: 4.8102\n",
            "[Batch 2] Current Loss: 4.6423\n",
            "[Batch 3] Current Loss: 4.6136\n",
            "[Batch 4] Current Loss: 5.0801\n",
            "[Batch 5] Current Loss: 5.8561\n",
            "[Batch 6] Current Loss: 5.3331\n",
            "[Batch 7] Current Loss: 4.6434\n",
            "[Batch 8] Current Loss: 5.1104\n",
            "[Batch 9] Current Loss: 5.5023\n",
            "Ep 2 (Step 013460): Train loss 3.791, Val loss 5.110\n",
            "[Batch 0] Current Loss: 3.3517\n",
            "[Batch 1] Current Loss: 3.3918\n",
            "[Batch 2] Current Loss: 3.1562\n",
            "[Batch 3] Current Loss: 3.4367\n",
            "[Batch 4] Current Loss: 4.7332\n",
            "[Batch 5] Current Loss: 3.9808\n",
            "[Batch 6] Current Loss: 3.8147\n",
            "[Batch 7] Current Loss: 3.5161\n",
            "[Batch 8] Current Loss: 3.8503\n",
            "[Batch 9] Current Loss: 3.7742\n",
            "[Batch 0] Current Loss: 5.6111\n",
            "[Batch 1] Current Loss: 5.3019\n",
            "[Batch 2] Current Loss: 5.1589\n",
            "[Batch 3] Current Loss: 5.1783\n",
            "[Batch 4] Current Loss: 5.6401\n",
            "[Batch 5] Current Loss: 4.9429\n",
            "[Batch 6] Current Loss: 5.5606\n",
            "[Batch 7] Current Loss: 4.4121\n",
            "[Batch 8] Current Loss: 5.2980\n",
            "[Batch 9] Current Loss: 5.6989\n",
            "Ep 2 (Step 013480): Train loss 3.701, Val loss 5.280\n",
            "[Batch 0] Current Loss: 3.0231\n",
            "[Batch 1] Current Loss: 4.1355\n",
            "[Batch 2] Current Loss: 3.4637\n",
            "[Batch 3] Current Loss: 4.2553\n",
            "[Batch 4] Current Loss: 4.1424\n",
            "[Batch 5] Current Loss: 3.8108\n",
            "[Batch 6] Current Loss: 3.9907\n",
            "[Batch 7] Current Loss: 4.4396\n",
            "[Batch 8] Current Loss: 4.5350\n",
            "[Batch 9] Current Loss: 3.9022\n",
            "[Batch 0] Current Loss: 5.1084\n",
            "[Batch 1] Current Loss: 5.5860\n",
            "[Batch 2] Current Loss: 4.4538\n",
            "[Batch 3] Current Loss: 5.7352\n",
            "[Batch 4] Current Loss: 5.5947\n",
            "[Batch 5] Current Loss: 4.8508\n",
            "[Batch 6] Current Loss: 6.0548\n",
            "[Batch 7] Current Loss: 5.2972\n",
            "[Batch 8] Current Loss: 5.2181\n",
            "[Batch 9] Current Loss: 5.4530\n",
            "Ep 2 (Step 013500): Train loss 3.970, Val loss 5.335\n",
            "[Batch 0] Current Loss: 3.8392\n",
            "[Batch 1] Current Loss: 4.5433\n",
            "[Batch 2] Current Loss: 3.7018\n",
            "[Batch 3] Current Loss: 3.7022\n",
            "[Batch 4] Current Loss: 3.5194\n",
            "[Batch 5] Current Loss: 3.5306\n",
            "[Batch 6] Current Loss: 3.7116\n",
            "[Batch 7] Current Loss: 4.0244\n",
            "[Batch 8] Current Loss: 3.7126\n",
            "[Batch 9] Current Loss: 4.4426\n",
            "[Batch 0] Current Loss: 5.5518\n",
            "[Batch 1] Current Loss: 5.1564\n",
            "[Batch 2] Current Loss: 5.4330\n",
            "[Batch 3] Current Loss: 5.4302\n",
            "[Batch 4] Current Loss: 5.6349\n",
            "[Batch 5] Current Loss: 5.3960\n",
            "[Batch 6] Current Loss: 4.9898\n",
            "[Batch 7] Current Loss: 5.6562\n",
            "[Batch 8] Current Loss: 5.9093\n",
            "[Batch 9] Current Loss: 4.8863\n",
            "Ep 2 (Step 013520): Train loss 3.873, Val loss 5.404\n",
            "[Batch 0] Current Loss: 3.4207\n",
            "[Batch 1] Current Loss: 3.9868\n",
            "[Batch 2] Current Loss: 3.6759\n",
            "[Batch 3] Current Loss: 3.2675\n",
            "[Batch 4] Current Loss: 3.4803\n",
            "[Batch 5] Current Loss: 4.0547\n",
            "[Batch 6] Current Loss: 3.8409\n",
            "[Batch 7] Current Loss: 3.6496\n",
            "[Batch 8] Current Loss: 3.5109\n",
            "[Batch 9] Current Loss: 4.1039\n",
            "[Batch 0] Current Loss: 4.9529\n",
            "[Batch 1] Current Loss: 5.2473\n",
            "[Batch 2] Current Loss: 4.9786\n",
            "[Batch 3] Current Loss: 4.6134\n",
            "[Batch 4] Current Loss: 5.1547\n",
            "[Batch 5] Current Loss: 4.7977\n",
            "[Batch 6] Current Loss: 5.3258\n",
            "[Batch 7] Current Loss: 5.7442\n",
            "[Batch 8] Current Loss: 5.0283\n",
            "[Batch 9] Current Loss: 5.6309\n",
            "Ep 2 (Step 013540): Train loss 3.699, Val loss 5.147\n",
            "[Batch 0] Current Loss: 3.6986\n",
            "[Batch 1] Current Loss: 3.9065\n",
            "[Batch 2] Current Loss: 3.2698\n",
            "[Batch 3] Current Loss: 3.5652\n",
            "[Batch 4] Current Loss: 3.5043\n",
            "[Batch 5] Current Loss: 4.1542\n",
            "[Batch 6] Current Loss: 3.6560\n",
            "[Batch 7] Current Loss: 3.4233\n",
            "[Batch 8] Current Loss: 3.2207\n",
            "[Batch 9] Current Loss: 3.7496\n",
            "[Batch 0] Current Loss: 4.7931\n",
            "[Batch 1] Current Loss: 4.5624\n",
            "[Batch 2] Current Loss: 5.7087\n",
            "[Batch 3] Current Loss: 4.8673\n",
            "[Batch 4] Current Loss: 4.8992\n",
            "[Batch 5] Current Loss: 4.6994\n",
            "[Batch 6] Current Loss: 5.2934\n",
            "[Batch 7] Current Loss: 5.3579\n",
            "[Batch 8] Current Loss: 5.3201\n",
            "[Batch 9] Current Loss: 5.0279\n",
            "Ep 2 (Step 013560): Train loss 3.615, Val loss 5.053\n",
            "[Batch 0] Current Loss: 4.6413\n",
            "[Batch 1] Current Loss: 3.8006\n",
            "[Batch 2] Current Loss: 4.3090\n",
            "[Batch 3] Current Loss: 4.0147\n",
            "[Batch 4] Current Loss: 3.2353\n",
            "[Batch 5] Current Loss: 3.5708\n",
            "[Batch 6] Current Loss: 3.6646\n",
            "[Batch 7] Current Loss: 3.0313\n",
            "[Batch 8] Current Loss: 3.7933\n",
            "[Batch 9] Current Loss: 3.6534\n",
            "[Batch 0] Current Loss: 5.3330\n",
            "[Batch 1] Current Loss: 5.5703\n",
            "[Batch 2] Current Loss: 5.2868\n",
            "[Batch 3] Current Loss: 5.2981\n",
            "[Batch 4] Current Loss: 5.4640\n",
            "[Batch 5] Current Loss: 5.1581\n",
            "[Batch 6] Current Loss: 5.6476\n",
            "[Batch 7] Current Loss: 5.9491\n",
            "[Batch 8] Current Loss: 4.7810\n",
            "[Batch 9] Current Loss: 4.6589\n",
            "Ep 2 (Step 013580): Train loss 3.771, Val loss 5.315\n",
            "[Batch 0] Current Loss: 4.0778\n",
            "[Batch 1] Current Loss: 3.5255\n",
            "[Batch 2] Current Loss: 3.5987\n",
            "[Batch 3] Current Loss: 3.5183\n",
            "[Batch 4] Current Loss: 4.2159\n",
            "[Batch 5] Current Loss: 3.7194\n",
            "[Batch 6] Current Loss: 3.6367\n",
            "[Batch 7] Current Loss: 3.6841\n",
            "[Batch 8] Current Loss: 3.7185\n",
            "[Batch 9] Current Loss: 3.6862\n",
            "[Batch 0] Current Loss: 5.8922\n",
            "[Batch 1] Current Loss: 5.2040\n",
            "[Batch 2] Current Loss: 5.2896\n",
            "[Batch 3] Current Loss: 5.3817\n",
            "[Batch 4] Current Loss: 4.6276\n",
            "[Batch 5] Current Loss: 5.3084\n",
            "[Batch 6] Current Loss: 5.0474\n",
            "[Batch 7] Current Loss: 5.1016\n",
            "[Batch 8] Current Loss: 4.7125\n",
            "[Batch 9] Current Loss: 5.2762\n",
            "Ep 2 (Step 013600): Train loss 3.738, Val loss 5.184\n",
            "[Batch 0] Current Loss: 4.1391\n",
            "[Batch 1] Current Loss: 4.5283\n",
            "[Batch 2] Current Loss: 3.8159\n",
            "[Batch 3] Current Loss: 3.5111\n",
            "[Batch 4] Current Loss: 4.1848\n",
            "[Batch 5] Current Loss: 3.8449\n",
            "[Batch 6] Current Loss: 3.2230\n",
            "[Batch 7] Current Loss: 3.8432\n",
            "[Batch 8] Current Loss: 3.6494\n",
            "[Batch 9] Current Loss: 3.8098\n",
            "[Batch 0] Current Loss: 4.6510\n",
            "[Batch 1] Current Loss: 5.4170\n",
            "[Batch 2] Current Loss: 5.1463\n",
            "[Batch 3] Current Loss: 5.3288\n",
            "[Batch 4] Current Loss: 5.5275\n",
            "[Batch 5] Current Loss: 5.3109\n",
            "[Batch 6] Current Loss: 5.4946\n",
            "[Batch 7] Current Loss: 5.2595\n",
            "[Batch 8] Current Loss: 4.8294\n",
            "[Batch 9] Current Loss: 5.4262\n",
            "Ep 2 (Step 013620): Train loss 3.855, Val loss 5.239\n",
            "[Batch 0] Current Loss: 4.1413\n",
            "[Batch 1] Current Loss: 3.6433\n",
            "[Batch 2] Current Loss: 3.4950\n",
            "[Batch 3] Current Loss: 3.6188\n",
            "[Batch 4] Current Loss: 3.4759\n",
            "[Batch 5] Current Loss: 4.1640\n",
            "[Batch 6] Current Loss: 3.6888\n",
            "[Batch 7] Current Loss: 3.9432\n",
            "[Batch 8] Current Loss: 4.2027\n",
            "[Batch 9] Current Loss: 3.2272\n",
            "[Batch 0] Current Loss: 5.0534\n",
            "[Batch 1] Current Loss: 5.1164\n",
            "[Batch 2] Current Loss: 5.3605\n",
            "[Batch 3] Current Loss: 4.9793\n",
            "[Batch 4] Current Loss: 5.2700\n",
            "[Batch 5] Current Loss: 5.0717\n",
            "[Batch 6] Current Loss: 5.5786\n",
            "[Batch 7] Current Loss: 5.0057\n",
            "[Batch 8] Current Loss: 5.3954\n",
            "[Batch 9] Current Loss: 5.3076\n",
            "Ep 2 (Step 013640): Train loss 3.760, Val loss 5.214\n",
            "[Batch 0] Current Loss: 3.3441\n",
            "[Batch 1] Current Loss: 3.9847\n",
            "[Batch 2] Current Loss: 3.5922\n",
            "[Batch 3] Current Loss: 3.8858\n",
            "[Batch 4] Current Loss: 4.0918\n",
            "[Batch 5] Current Loss: 3.5621\n",
            "[Batch 6] Current Loss: 3.3178\n",
            "[Batch 7] Current Loss: 4.3781\n",
            "[Batch 8] Current Loss: 3.6737\n",
            "[Batch 9] Current Loss: 3.7759\n",
            "[Batch 0] Current Loss: 5.7148\n",
            "[Batch 1] Current Loss: 5.4432\n",
            "[Batch 2] Current Loss: 5.8359\n",
            "[Batch 3] Current Loss: 5.6869\n",
            "[Batch 4] Current Loss: 4.9957\n",
            "[Batch 5] Current Loss: 5.8536\n",
            "[Batch 6] Current Loss: 5.1589\n",
            "[Batch 7] Current Loss: 5.3509\n",
            "[Batch 8] Current Loss: 5.3627\n",
            "[Batch 9] Current Loss: 4.8992\n",
            "Ep 2 (Step 013660): Train loss 3.761, Val loss 5.430\n",
            "[Batch 0] Current Loss: 3.8595\n",
            "[Batch 1] Current Loss: 4.0869\n",
            "[Batch 2] Current Loss: 3.8721\n",
            "[Batch 3] Current Loss: 3.8147\n",
            "[Batch 4] Current Loss: 3.4506\n",
            "[Batch 5] Current Loss: 3.5474\n",
            "[Batch 6] Current Loss: 3.8353\n",
            "[Batch 7] Current Loss: 3.4089\n",
            "[Batch 8] Current Loss: 3.3248\n",
            "[Batch 9] Current Loss: 3.8189\n",
            "[Batch 0] Current Loss: 5.2528\n",
            "[Batch 1] Current Loss: 6.0118\n",
            "[Batch 2] Current Loss: 5.4550\n",
            "[Batch 3] Current Loss: 5.0036\n",
            "[Batch 4] Current Loss: 5.1968\n",
            "[Batch 5] Current Loss: 5.2531\n",
            "[Batch 6] Current Loss: 5.2677\n",
            "[Batch 7] Current Loss: 4.4730\n",
            "[Batch 8] Current Loss: 4.9928\n",
            "[Batch 9] Current Loss: 5.5386\n",
            "Ep 2 (Step 013680): Train loss 3.702, Val loss 5.245\n",
            "[Batch 0] Current Loss: 3.3951\n",
            "[Batch 1] Current Loss: 3.5792\n",
            "[Batch 2] Current Loss: 3.5186\n",
            "[Batch 3] Current Loss: 3.4156\n",
            "[Batch 4] Current Loss: 4.3199\n",
            "[Batch 5] Current Loss: 3.6932\n",
            "[Batch 6] Current Loss: 3.8270\n",
            "[Batch 7] Current Loss: 3.7968\n",
            "[Batch 8] Current Loss: 3.6102\n",
            "[Batch 9] Current Loss: 4.3887\n",
            "[Batch 0] Current Loss: 5.8604\n",
            "[Batch 1] Current Loss: 5.5154\n",
            "[Batch 2] Current Loss: 4.8096\n",
            "[Batch 3] Current Loss: 5.4456\n",
            "[Batch 4] Current Loss: 5.2928\n",
            "[Batch 5] Current Loss: 4.4721\n",
            "[Batch 6] Current Loss: 5.7820\n",
            "[Batch 7] Current Loss: 5.4476\n",
            "[Batch 8] Current Loss: 4.9779\n",
            "[Batch 9] Current Loss: 4.5453\n",
            "Ep 2 (Step 013700): Train loss 3.754, Val loss 5.215\n",
            "[Batch 0] Current Loss: 3.1873\n",
            "[Batch 1] Current Loss: 3.5838\n",
            "[Batch 2] Current Loss: 3.9420\n",
            "[Batch 3] Current Loss: 4.0578\n",
            "[Batch 4] Current Loss: 3.9425\n",
            "[Batch 5] Current Loss: 3.0177\n",
            "[Batch 6] Current Loss: 4.0852\n",
            "[Batch 7] Current Loss: 3.0429\n",
            "[Batch 8] Current Loss: 3.8977\n",
            "[Batch 9] Current Loss: 3.5046\n",
            "[Batch 0] Current Loss: 5.3218\n",
            "[Batch 1] Current Loss: 4.6871\n",
            "[Batch 2] Current Loss: 4.9891\n",
            "[Batch 3] Current Loss: 5.3804\n",
            "[Batch 4] Current Loss: 5.7028\n",
            "[Batch 5] Current Loss: 5.0317\n",
            "[Batch 6] Current Loss: 5.1823\n",
            "[Batch 7] Current Loss: 5.5051\n",
            "[Batch 8] Current Loss: 4.8296\n",
            "[Batch 9] Current Loss: 4.6014\n",
            "Ep 2 (Step 013720): Train loss 3.626, Val loss 5.123\n",
            "[Batch 0] Current Loss: 3.8248\n",
            "[Batch 1] Current Loss: 3.4070\n",
            "[Batch 2] Current Loss: 3.4028\n",
            "[Batch 3] Current Loss: 3.7703\n",
            "[Batch 4] Current Loss: 3.9500\n",
            "[Batch 5] Current Loss: 4.0076\n",
            "[Batch 6] Current Loss: 3.3182\n",
            "[Batch 7] Current Loss: 3.7152\n",
            "[Batch 8] Current Loss: 3.9008\n",
            "[Batch 9] Current Loss: 4.0741\n",
            "[Batch 0] Current Loss: 4.8125\n",
            "[Batch 1] Current Loss: 5.1345\n",
            "[Batch 2] Current Loss: 5.5052\n",
            "[Batch 3] Current Loss: 4.7548\n",
            "[Batch 4] Current Loss: 5.8594\n",
            "[Batch 5] Current Loss: 4.8888\n",
            "[Batch 6] Current Loss: 5.5092\n",
            "[Batch 7] Current Loss: 4.7633\n",
            "[Batch 8] Current Loss: 5.5449\n",
            "[Batch 9] Current Loss: 4.5895\n",
            "Ep 2 (Step 013740): Train loss 3.737, Val loss 5.136\n",
            "[Batch 0] Current Loss: 3.8375\n",
            "[Batch 1] Current Loss: 4.7849\n",
            "[Batch 2] Current Loss: 4.0042\n",
            "[Batch 3] Current Loss: 3.6578\n",
            "[Batch 4] Current Loss: 4.3714\n",
            "[Batch 5] Current Loss: 3.9837\n",
            "[Batch 6] Current Loss: 3.8842\n",
            "[Batch 7] Current Loss: 4.2710\n",
            "[Batch 8] Current Loss: 3.2157\n",
            "[Batch 9] Current Loss: 3.9573\n",
            "[Batch 0] Current Loss: 5.1965\n",
            "[Batch 1] Current Loss: 5.3834\n",
            "[Batch 2] Current Loss: 5.1892\n",
            "[Batch 3] Current Loss: 4.9689\n",
            "[Batch 4] Current Loss: 5.1261\n",
            "[Batch 5] Current Loss: 5.1483\n",
            "[Batch 6] Current Loss: 5.3503\n",
            "[Batch 7] Current Loss: 4.9246\n",
            "[Batch 8] Current Loss: 5.5987\n",
            "[Batch 9] Current Loss: 5.2589\n",
            "Ep 2 (Step 013760): Train loss 3.997, Val loss 5.214\n",
            "[Batch 0] Current Loss: 3.8829\n",
            "[Batch 1] Current Loss: 4.2707\n",
            "[Batch 2] Current Loss: 3.3440\n",
            "[Batch 3] Current Loss: 3.8892\n",
            "[Batch 4] Current Loss: 3.6621\n",
            "[Batch 5] Current Loss: 3.5255\n",
            "[Batch 6] Current Loss: 3.3930\n",
            "[Batch 7] Current Loss: 3.9352\n",
            "[Batch 8] Current Loss: 3.8671\n",
            "[Batch 9] Current Loss: 4.0600\n",
            "[Batch 0] Current Loss: 5.6278\n",
            "[Batch 1] Current Loss: 5.0238\n",
            "[Batch 2] Current Loss: 5.3495\n",
            "[Batch 3] Current Loss: 5.0229\n",
            "[Batch 4] Current Loss: 5.0870\n",
            "[Batch 5] Current Loss: 4.5521\n",
            "[Batch 6] Current Loss: 4.9752\n",
            "[Batch 7] Current Loss: 5.4000\n",
            "[Batch 8] Current Loss: 4.9840\n",
            "[Batch 9] Current Loss: 5.5863\n",
            "Ep 2 (Step 013780): Train loss 3.783, Val loss 5.161\n",
            "[Batch 0] Current Loss: 3.6801\n",
            "[Batch 1] Current Loss: 4.0504\n",
            "[Batch 2] Current Loss: 3.4303\n",
            "[Batch 3] Current Loss: 3.1540\n",
            "[Batch 4] Current Loss: 3.5530\n",
            "[Batch 5] Current Loss: 3.3111\n",
            "[Batch 6] Current Loss: 3.9794\n",
            "[Batch 7] Current Loss: 3.6471\n",
            "[Batch 8] Current Loss: 3.8724\n",
            "[Batch 9] Current Loss: 3.8011\n",
            "[Batch 0] Current Loss: 5.0441\n",
            "[Batch 1] Current Loss: 5.1339\n",
            "[Batch 2] Current Loss: 5.9091\n",
            "[Batch 3] Current Loss: 5.4355\n",
            "[Batch 4] Current Loss: 4.5656\n",
            "[Batch 5] Current Loss: 4.4095\n",
            "[Batch 6] Current Loss: 5.2663\n",
            "[Batch 7] Current Loss: 5.3111\n",
            "[Batch 8] Current Loss: 4.8403\n",
            "[Batch 9] Current Loss: 4.9810\n",
            "Ep 2 (Step 013800): Train loss 3.648, Val loss 5.090\n",
            "[Batch 0] Current Loss: 3.6150\n",
            "[Batch 1] Current Loss: 4.1413\n",
            "[Batch 2] Current Loss: 3.8937\n",
            "[Batch 3] Current Loss: 3.3628\n",
            "[Batch 4] Current Loss: 2.9739\n",
            "[Batch 5] Current Loss: 3.7654\n",
            "[Batch 6] Current Loss: 4.0855\n",
            "[Batch 7] Current Loss: 3.6101\n",
            "[Batch 8] Current Loss: 3.6831\n",
            "[Batch 9] Current Loss: 4.3341\n",
            "[Batch 0] Current Loss: 5.6975\n",
            "[Batch 1] Current Loss: 5.4261\n",
            "[Batch 2] Current Loss: 4.9814\n",
            "[Batch 3] Current Loss: 4.9516\n",
            "[Batch 4] Current Loss: 5.1059\n",
            "[Batch 5] Current Loss: 4.0437\n",
            "[Batch 6] Current Loss: 5.3073\n",
            "[Batch 7] Current Loss: 5.3066\n",
            "[Batch 8] Current Loss: 5.3610\n",
            "[Batch 9] Current Loss: 5.6946\n",
            "Ep 2 (Step 013820): Train loss 3.746, Val loss 5.188\n",
            "[Batch 0] Current Loss: 3.6849\n",
            "[Batch 1] Current Loss: 3.9591\n",
            "[Batch 2] Current Loss: 3.1428\n",
            "[Batch 3] Current Loss: 3.4450\n",
            "[Batch 4] Current Loss: 4.4308\n",
            "[Batch 5] Current Loss: 3.5568\n",
            "[Batch 6] Current Loss: 3.6462\n",
            "[Batch 7] Current Loss: 4.0858\n",
            "[Batch 8] Current Loss: 3.5890\n",
            "[Batch 9] Current Loss: 4.0029\n",
            "[Batch 0] Current Loss: 5.0738\n",
            "[Batch 1] Current Loss: 5.0755\n",
            "[Batch 2] Current Loss: 5.3831\n",
            "[Batch 3] Current Loss: 5.0834\n",
            "[Batch 4] Current Loss: 4.8461\n",
            "[Batch 5] Current Loss: 4.8341\n",
            "[Batch 6] Current Loss: 5.7656\n",
            "[Batch 7] Current Loss: 4.9340\n",
            "[Batch 8] Current Loss: 5.0491\n",
            "[Batch 9] Current Loss: 5.1935\n",
            "Ep 2 (Step 013840): Train loss 3.754, Val loss 5.124\n",
            "[Batch 0] Current Loss: 3.7188\n",
            "[Batch 1] Current Loss: 3.3334\n",
            "[Batch 2] Current Loss: 3.6802\n",
            "[Batch 3] Current Loss: 3.7080\n",
            "[Batch 4] Current Loss: 3.5904\n",
            "[Batch 5] Current Loss: 3.6940\n",
            "[Batch 6] Current Loss: 3.7910\n",
            "[Batch 7] Current Loss: 3.6564\n",
            "[Batch 8] Current Loss: 4.2567\n",
            "[Batch 9] Current Loss: 3.3313\n",
            "[Batch 0] Current Loss: 5.2563\n",
            "[Batch 1] Current Loss: 3.9449\n",
            "[Batch 2] Current Loss: 5.4710\n",
            "[Batch 3] Current Loss: 5.6240\n",
            "[Batch 4] Current Loss: 5.2505\n",
            "[Batch 5] Current Loss: 5.0897\n",
            "[Batch 6] Current Loss: 5.8361\n",
            "[Batch 7] Current Loss: 4.5038\n",
            "[Batch 8] Current Loss: 5.1402\n",
            "[Batch 9] Current Loss: 5.0399\n",
            "Ep 2 (Step 013860): Train loss 3.676, Val loss 5.116\n",
            "[Batch 0] Current Loss: 3.7292\n",
            "[Batch 1] Current Loss: 4.2733\n",
            "[Batch 2] Current Loss: 3.8393\n",
            "[Batch 3] Current Loss: 4.0373\n",
            "[Batch 4] Current Loss: 3.3030\n",
            "[Batch 5] Current Loss: 3.8942\n",
            "[Batch 6] Current Loss: 3.7088\n",
            "[Batch 7] Current Loss: 3.5280\n",
            "[Batch 8] Current Loss: 3.5328\n",
            "[Batch 9] Current Loss: 3.7829\n",
            "[Batch 0] Current Loss: 5.1888\n",
            "[Batch 1] Current Loss: 4.9896\n",
            "[Batch 2] Current Loss: 4.9418\n",
            "[Batch 3] Current Loss: 5.2241\n",
            "[Batch 4] Current Loss: 4.8623\n",
            "[Batch 5] Current Loss: 5.9411\n",
            "[Batch 6] Current Loss: 5.3941\n",
            "[Batch 7] Current Loss: 5.0208\n",
            "[Batch 8] Current Loss: 4.9295\n",
            "[Batch 9] Current Loss: 4.6809\n",
            "Ep 2 (Step 013880): Train loss 3.763, Val loss 5.117\n",
            "[Batch 0] Current Loss: 3.3160\n",
            "[Batch 1] Current Loss: 3.7384\n",
            "[Batch 2] Current Loss: 3.8260\n",
            "[Batch 3] Current Loss: 4.4852\n",
            "[Batch 4] Current Loss: 3.2689\n",
            "[Batch 5] Current Loss: 4.0132\n",
            "[Batch 6] Current Loss: 3.2676\n",
            "[Batch 7] Current Loss: 3.9782\n",
            "[Batch 8] Current Loss: 3.9406\n",
            "[Batch 9] Current Loss: 3.5638\n",
            "[Batch 0] Current Loss: 5.6794\n",
            "[Batch 1] Current Loss: 5.0822\n",
            "[Batch 2] Current Loss: 6.0012\n",
            "[Batch 3] Current Loss: 5.7304\n",
            "[Batch 4] Current Loss: 5.2266\n",
            "[Batch 5] Current Loss: 5.3100\n",
            "[Batch 6] Current Loss: 5.0122\n",
            "[Batch 7] Current Loss: 5.3151\n",
            "[Batch 8] Current Loss: 4.9702\n",
            "[Batch 9] Current Loss: 5.3633\n",
            "Ep 2 (Step 013900): Train loss 3.740, Val loss 5.369\n",
            "[Batch 0] Current Loss: 4.0450\n",
            "[Batch 1] Current Loss: 4.1868\n",
            "[Batch 2] Current Loss: 3.9320\n",
            "[Batch 3] Current Loss: 3.1587\n",
            "[Batch 4] Current Loss: 3.8784\n",
            "[Batch 5] Current Loss: 3.9356\n",
            "[Batch 6] Current Loss: 3.6928\n",
            "[Batch 7] Current Loss: 3.3351\n",
            "[Batch 8] Current Loss: 3.5392\n",
            "[Batch 9] Current Loss: 4.2255\n",
            "[Batch 0] Current Loss: 5.2266\n",
            "[Batch 1] Current Loss: 5.4134\n",
            "[Batch 2] Current Loss: 4.5174\n",
            "[Batch 3] Current Loss: 5.7551\n",
            "[Batch 4] Current Loss: 5.5850\n",
            "[Batch 5] Current Loss: 5.1417\n",
            "[Batch 6] Current Loss: 5.5378\n",
            "[Batch 7] Current Loss: 5.2445\n",
            "[Batch 8] Current Loss: 5.5572\n",
            "[Batch 9] Current Loss: 5.2695\n",
            "Ep 2 (Step 013920): Train loss 3.793, Val loss 5.325\n",
            "[Batch 0] Current Loss: 3.3628\n",
            "[Batch 1] Current Loss: 3.8583\n",
            "[Batch 2] Current Loss: 4.4779\n",
            "[Batch 3] Current Loss: 3.4736\n",
            "[Batch 4] Current Loss: 4.2470\n",
            "[Batch 5] Current Loss: 4.0531\n",
            "[Batch 6] Current Loss: 3.6335\n",
            "[Batch 7] Current Loss: 4.0428\n",
            "[Batch 8] Current Loss: 3.9355\n",
            "[Batch 9] Current Loss: 4.3281\n",
            "[Batch 0] Current Loss: 5.1880\n",
            "[Batch 1] Current Loss: 5.9404\n",
            "[Batch 2] Current Loss: 5.4862\n",
            "[Batch 3] Current Loss: 5.8147\n",
            "[Batch 4] Current Loss: 4.9904\n",
            "[Batch 5] Current Loss: 5.5581\n",
            "[Batch 6] Current Loss: 4.9235\n",
            "[Batch 7] Current Loss: 4.9020\n",
            "[Batch 8] Current Loss: 5.7318\n",
            "[Batch 9] Current Loss: 4.7926\n",
            "Ep 2 (Step 013940): Train loss 3.941, Val loss 5.333\n",
            "[Batch 0] Current Loss: 4.0991\n",
            "[Batch 1] Current Loss: 4.3961\n",
            "[Batch 2] Current Loss: 3.5971\n",
            "[Batch 3] Current Loss: 4.3462\n",
            "[Batch 4] Current Loss: 3.7353\n",
            "[Batch 5] Current Loss: 3.7526\n",
            "[Batch 6] Current Loss: 3.8497\n",
            "[Batch 7] Current Loss: 3.6128\n",
            "[Batch 8] Current Loss: 4.2333\n",
            "[Batch 9] Current Loss: 3.6905\n",
            "[Batch 0] Current Loss: 5.6190\n",
            "[Batch 1] Current Loss: 4.8467\n",
            "[Batch 2] Current Loss: 5.3790\n",
            "[Batch 3] Current Loss: 5.1142\n",
            "[Batch 4] Current Loss: 4.9911\n",
            "[Batch 5] Current Loss: 4.8907\n",
            "[Batch 6] Current Loss: 5.1239\n",
            "[Batch 7] Current Loss: 5.1918\n",
            "[Batch 8] Current Loss: 4.5084\n",
            "[Batch 9] Current Loss: 5.2592\n",
            "Ep 2 (Step 013960): Train loss 3.931, Val loss 5.092\n",
            "[Batch 0] Current Loss: 3.7635\n",
            "[Batch 1] Current Loss: 3.2649\n",
            "[Batch 2] Current Loss: 3.8542\n",
            "[Batch 3] Current Loss: 4.1525\n",
            "[Batch 4] Current Loss: 3.3010\n",
            "[Batch 5] Current Loss: 4.0204\n",
            "[Batch 6] Current Loss: 4.2345\n",
            "[Batch 7] Current Loss: 3.4146\n",
            "[Batch 8] Current Loss: 3.3232\n",
            "[Batch 9] Current Loss: 4.1842\n",
            "[Batch 0] Current Loss: 5.5934\n",
            "[Batch 1] Current Loss: 5.0246\n",
            "[Batch 2] Current Loss: 4.7942\n",
            "[Batch 3] Current Loss: 5.5419\n",
            "[Batch 4] Current Loss: 4.8945\n",
            "[Batch 5] Current Loss: 5.5177\n",
            "[Batch 6] Current Loss: 4.9681\n",
            "[Batch 7] Current Loss: 4.9713\n",
            "[Batch 8] Current Loss: 5.0925\n",
            "[Batch 9] Current Loss: 5.5192\n",
            "Ep 2 (Step 013980): Train loss 3.751, Val loss 5.192\n",
            "[Batch 0] Current Loss: 3.9356\n",
            "[Batch 1] Current Loss: 3.8091\n",
            "[Batch 2] Current Loss: 3.7243\n",
            "[Batch 3] Current Loss: 4.0177\n",
            "[Batch 4] Current Loss: 3.6196\n",
            "[Batch 5] Current Loss: 3.1507\n",
            "[Batch 6] Current Loss: 3.9649\n",
            "[Batch 7] Current Loss: 3.7469\n",
            "[Batch 8] Current Loss: 3.7412\n",
            "[Batch 9] Current Loss: 3.9307\n",
            "[Batch 0] Current Loss: 5.0698\n",
            "[Batch 1] Current Loss: 5.8444\n",
            "[Batch 2] Current Loss: 5.4484\n",
            "[Batch 3] Current Loss: 5.2129\n",
            "[Batch 4] Current Loss: 5.3262\n",
            "[Batch 5] Current Loss: 5.7240\n",
            "[Batch 6] Current Loss: 5.3598\n",
            "[Batch 7] Current Loss: 5.5432\n",
            "[Batch 8] Current Loss: 5.1763\n",
            "[Batch 9] Current Loss: 4.9578\n",
            "Ep 2 (Step 014000): Train loss 3.764, Val loss 5.366\n",
            "[Batch 0] Current Loss: 4.2084\n",
            "[Batch 1] Current Loss: 3.9868\n",
            "[Batch 2] Current Loss: 3.6725\n",
            "[Batch 3] Current Loss: 3.9319\n",
            "[Batch 4] Current Loss: 3.6975\n",
            "[Batch 5] Current Loss: 2.9428\n",
            "[Batch 6] Current Loss: 3.7589\n",
            "[Batch 7] Current Loss: 4.1788\n",
            "[Batch 8] Current Loss: 4.0879\n",
            "[Batch 9] Current Loss: 3.4604\n",
            "[Batch 0] Current Loss: 5.4645\n",
            "[Batch 1] Current Loss: 4.9271\n",
            "[Batch 2] Current Loss: 6.1168\n",
            "[Batch 3] Current Loss: 6.5632\n",
            "[Batch 4] Current Loss: 5.1342\n",
            "[Batch 5] Current Loss: 4.8552\n",
            "[Batch 6] Current Loss: 4.5463\n",
            "[Batch 7] Current Loss: 5.0477\n",
            "[Batch 8] Current Loss: 5.1060\n",
            "[Batch 9] Current Loss: 5.4369\n",
            "Ep 2 (Step 014020): Train loss 3.793, Val loss 5.320\n",
            "[Batch 0] Current Loss: 3.6087\n",
            "[Batch 1] Current Loss: 3.6697\n",
            "[Batch 2] Current Loss: 3.5431\n",
            "[Batch 3] Current Loss: 3.4089\n",
            "[Batch 4] Current Loss: 3.7327\n",
            "[Batch 5] Current Loss: 3.7579\n",
            "[Batch 6] Current Loss: 3.3742\n",
            "[Batch 7] Current Loss: 4.1930\n",
            "[Batch 8] Current Loss: 3.8146\n",
            "[Batch 9] Current Loss: 3.7870\n",
            "[Batch 0] Current Loss: 5.2464\n",
            "[Batch 1] Current Loss: 4.9890\n",
            "[Batch 2] Current Loss: 5.4921\n",
            "[Batch 3] Current Loss: 4.6568\n",
            "[Batch 4] Current Loss: 4.5717\n",
            "[Batch 5] Current Loss: 5.2263\n",
            "[Batch 6] Current Loss: 4.8159\n",
            "[Batch 7] Current Loss: 5.1238\n",
            "[Batch 8] Current Loss: 5.3592\n",
            "[Batch 9] Current Loss: 5.1030\n",
            "Ep 2 (Step 014040): Train loss 3.689, Val loss 5.058\n",
            "[Batch 0] Current Loss: 4.2759\n",
            "[Batch 1] Current Loss: 3.6008\n",
            "[Batch 2] Current Loss: 3.4508\n",
            "[Batch 3] Current Loss: 3.9029\n",
            "[Batch 4] Current Loss: 3.4550\n",
            "[Batch 5] Current Loss: 4.1305\n",
            "[Batch 6] Current Loss: 2.9376\n",
            "[Batch 7] Current Loss: 3.9495\n",
            "[Batch 8] Current Loss: 3.4300\n",
            "[Batch 9] Current Loss: 3.9086\n",
            "[Batch 0] Current Loss: 4.6122\n",
            "[Batch 1] Current Loss: 5.0657\n",
            "[Batch 2] Current Loss: 5.4936\n",
            "[Batch 3] Current Loss: 4.6553\n",
            "[Batch 4] Current Loss: 4.6269\n",
            "[Batch 5] Current Loss: 5.1792\n",
            "[Batch 6] Current Loss: 5.6138\n",
            "[Batch 7] Current Loss: 5.2327\n",
            "[Batch 8] Current Loss: 5.0243\n",
            "[Batch 9] Current Loss: 5.2377\n",
            "Ep 2 (Step 014060): Train loss 3.704, Val loss 5.074\n",
            "[Batch 0] Current Loss: 3.5638\n",
            "[Batch 1] Current Loss: 4.0595\n",
            "[Batch 2] Current Loss: 4.3576\n",
            "[Batch 3] Current Loss: 3.6406\n",
            "[Batch 4] Current Loss: 3.5784\n",
            "[Batch 5] Current Loss: 4.3048\n",
            "[Batch 6] Current Loss: 3.3808\n",
            "[Batch 7] Current Loss: 3.5495\n",
            "[Batch 8] Current Loss: 3.6043\n",
            "[Batch 9] Current Loss: 4.4683\n",
            "[Batch 0] Current Loss: 4.9010\n",
            "[Batch 1] Current Loss: 5.1878\n",
            "[Batch 2] Current Loss: 5.2781\n",
            "[Batch 3] Current Loss: 5.4644\n",
            "[Batch 4] Current Loss: 4.9037\n",
            "[Batch 5] Current Loss: 4.8650\n",
            "[Batch 6] Current Loss: 5.9203\n",
            "[Batch 7] Current Loss: 4.9410\n",
            "[Batch 8] Current Loss: 5.0008\n",
            "[Batch 9] Current Loss: 5.0188\n",
            "Ep 2 (Step 014080): Train loss 3.851, Val loss 5.148\n",
            "[Batch 0] Current Loss: 3.5496\n",
            "[Batch 1] Current Loss: 3.1236\n",
            "[Batch 2] Current Loss: 3.9079\n",
            "[Batch 3] Current Loss: 3.6176\n",
            "[Batch 4] Current Loss: 3.1177\n",
            "[Batch 5] Current Loss: 4.1971\n",
            "[Batch 6] Current Loss: 3.4577\n",
            "[Batch 7] Current Loss: 3.9375\n",
            "[Batch 8] Current Loss: 3.4727\n",
            "[Batch 9] Current Loss: 2.8904\n",
            "[Batch 0] Current Loss: 4.8417\n",
            "[Batch 1] Current Loss: 5.8032\n",
            "[Batch 2] Current Loss: 3.8590\n",
            "[Batch 3] Current Loss: 5.6965\n",
            "[Batch 4] Current Loss: 5.5659\n",
            "[Batch 5] Current Loss: 5.4682\n",
            "[Batch 6] Current Loss: 4.9313\n",
            "[Batch 7] Current Loss: 4.6339\n",
            "[Batch 8] Current Loss: 5.0220\n",
            "[Batch 9] Current Loss: 5.9410\n",
            "Ep 2 (Step 014100): Train loss 3.527, Val loss 5.176\n",
            "[Batch 0] Current Loss: 3.8413\n",
            "[Batch 1] Current Loss: 3.4811\n",
            "[Batch 2] Current Loss: 3.9841\n",
            "[Batch 3] Current Loss: 3.7573\n",
            "[Batch 4] Current Loss: 4.0318\n",
            "[Batch 5] Current Loss: 3.5862\n",
            "[Batch 6] Current Loss: 3.6760\n",
            "[Batch 7] Current Loss: 3.3440\n",
            "[Batch 8] Current Loss: 3.5281\n",
            "[Batch 9] Current Loss: 3.7723\n",
            "[Batch 0] Current Loss: 4.9345\n",
            "[Batch 1] Current Loss: 5.1753\n",
            "[Batch 2] Current Loss: 5.4887\n",
            "[Batch 3] Current Loss: 4.2612\n",
            "[Batch 4] Current Loss: 4.6860\n",
            "[Batch 5] Current Loss: 5.4377\n",
            "[Batch 6] Current Loss: 5.7044\n",
            "[Batch 7] Current Loss: 5.0704\n",
            "[Batch 8] Current Loss: 5.4410\n",
            "[Batch 9] Current Loss: 5.7559\n",
            "Ep 2 (Step 014120): Train loss 3.700, Val loss 5.195\n",
            "[Batch 0] Current Loss: 3.3822\n",
            "[Batch 1] Current Loss: 3.6417\n",
            "[Batch 2] Current Loss: 3.1634\n",
            "[Batch 3] Current Loss: 3.7089\n",
            "[Batch 4] Current Loss: 3.0146\n",
            "[Batch 5] Current Loss: 3.8170\n",
            "[Batch 6] Current Loss: 3.3174\n",
            "[Batch 7] Current Loss: 3.7626\n",
            "[Batch 8] Current Loss: 4.0179\n",
            "[Batch 9] Current Loss: 3.5796\n",
            "[Batch 0] Current Loss: 5.0052\n",
            "[Batch 1] Current Loss: 5.4845\n",
            "[Batch 2] Current Loss: 4.7512\n",
            "[Batch 3] Current Loss: 4.8312\n",
            "[Batch 4] Current Loss: 5.1317\n",
            "[Batch 5] Current Loss: 5.1897\n",
            "[Batch 6] Current Loss: 4.9804\n",
            "[Batch 7] Current Loss: 5.7753\n",
            "[Batch 8] Current Loss: 5.6391\n",
            "[Batch 9] Current Loss: 5.0894\n",
            "Ep 2 (Step 014140): Train loss 3.541, Val loss 5.188\n",
            "[Batch 0] Current Loss: 3.8999\n",
            "[Batch 1] Current Loss: 4.0448\n",
            "[Batch 2] Current Loss: 3.6113\n",
            "[Batch 3] Current Loss: 3.6816\n",
            "[Batch 4] Current Loss: 3.4423\n",
            "[Batch 5] Current Loss: 3.6073\n",
            "[Batch 6] Current Loss: 3.6897\n",
            "[Batch 7] Current Loss: 3.5567\n",
            "[Batch 8] Current Loss: 3.5757\n",
            "[Batch 9] Current Loss: 3.8210\n",
            "[Batch 0] Current Loss: 5.4575\n",
            "[Batch 1] Current Loss: 5.1321\n",
            "[Batch 2] Current Loss: 5.4132\n",
            "[Batch 3] Current Loss: 4.3359\n",
            "[Batch 4] Current Loss: 5.4491\n",
            "[Batch 5] Current Loss: 5.6221\n",
            "[Batch 6] Current Loss: 5.5868\n",
            "[Batch 7] Current Loss: 5.3036\n",
            "[Batch 8] Current Loss: 6.1028\n",
            "[Batch 9] Current Loss: 4.4561\n",
            "Ep 2 (Step 014160): Train loss 3.693, Val loss 5.286\n",
            "[Batch 0] Current Loss: 4.0123\n",
            "[Batch 1] Current Loss: 3.4410\n",
            "[Batch 2] Current Loss: 3.5028\n",
            "[Batch 3] Current Loss: 3.6569\n",
            "[Batch 4] Current Loss: 3.9189\n",
            "[Batch 5] Current Loss: 3.9535\n",
            "[Batch 6] Current Loss: 3.8711\n",
            "[Batch 7] Current Loss: 3.7109\n",
            "[Batch 8] Current Loss: 3.5480\n",
            "[Batch 9] Current Loss: 3.7323\n",
            "[Batch 0] Current Loss: 5.1528\n",
            "[Batch 1] Current Loss: 5.1554\n",
            "[Batch 2] Current Loss: 5.4350\n",
            "[Batch 3] Current Loss: 5.2776\n",
            "[Batch 4] Current Loss: 5.5866\n",
            "[Batch 5] Current Loss: 4.9958\n",
            "[Batch 6] Current Loss: 4.7486\n",
            "[Batch 7] Current Loss: 5.5027\n",
            "[Batch 8] Current Loss: 5.9360\n",
            "[Batch 9] Current Loss: 5.3342\n",
            "Ep 2 (Step 014180): Train loss 3.735, Val loss 5.312\n",
            "[Batch 0] Current Loss: 3.7045\n",
            "[Batch 1] Current Loss: 4.1571\n",
            "[Batch 2] Current Loss: 4.1745\n",
            "[Batch 3] Current Loss: 3.4470\n",
            "[Batch 4] Current Loss: 3.5580\n",
            "[Batch 5] Current Loss: 3.6497\n",
            "[Batch 6] Current Loss: 4.1299\n",
            "[Batch 7] Current Loss: 3.6514\n",
            "[Batch 8] Current Loss: 4.0800\n",
            "[Batch 9] Current Loss: 3.6477\n",
            "[Batch 0] Current Loss: 4.8133\n",
            "[Batch 1] Current Loss: 5.0527\n",
            "[Batch 2] Current Loss: 5.4048\n",
            "[Batch 3] Current Loss: 5.3162\n",
            "[Batch 4] Current Loss: 4.9785\n",
            "[Batch 5] Current Loss: 5.0461\n",
            "[Batch 6] Current Loss: 5.0682\n",
            "[Batch 7] Current Loss: 4.6964\n",
            "[Batch 8] Current Loss: 5.2934\n",
            "[Batch 9] Current Loss: 5.5421\n",
            "Ep 2 (Step 014200): Train loss 3.820, Val loss 5.121\n",
            "[Batch 0] Current Loss: 4.0218\n",
            "[Batch 1] Current Loss: 4.1763\n",
            "[Batch 2] Current Loss: 4.3520\n",
            "[Batch 3] Current Loss: 4.2410\n",
            "[Batch 4] Current Loss: 3.5990\n",
            "[Batch 5] Current Loss: 3.6403\n",
            "[Batch 6] Current Loss: 3.8048\n",
            "[Batch 7] Current Loss: 3.9097\n",
            "[Batch 8] Current Loss: 3.3055\n",
            "[Batch 9] Current Loss: 3.5591\n",
            "[Batch 0] Current Loss: 4.2101\n",
            "[Batch 1] Current Loss: 4.9950\n",
            "[Batch 2] Current Loss: 5.1701\n",
            "[Batch 3] Current Loss: 4.9790\n",
            "[Batch 4] Current Loss: 5.0327\n",
            "[Batch 5] Current Loss: 5.7972\n",
            "[Batch 6] Current Loss: 5.1473\n",
            "[Batch 7] Current Loss: 4.5708\n",
            "[Batch 8] Current Loss: 4.9573\n",
            "[Batch 9] Current Loss: 5.4653\n",
            "Ep 2 (Step 014220): Train loss 3.861, Val loss 5.032\n",
            "[Batch 0] Current Loss: 3.4756\n",
            "[Batch 1] Current Loss: 3.3874\n",
            "[Batch 2] Current Loss: 3.4551\n",
            "[Batch 3] Current Loss: 3.8363\n",
            "[Batch 4] Current Loss: 3.5625\n",
            "[Batch 5] Current Loss: 3.3384\n",
            "[Batch 6] Current Loss: 3.4885\n",
            "[Batch 7] Current Loss: 3.4580\n",
            "[Batch 8] Current Loss: 3.4142\n",
            "[Batch 9] Current Loss: 3.9816\n",
            "[Batch 0] Current Loss: 5.3429\n",
            "[Batch 1] Current Loss: 5.3585\n",
            "[Batch 2] Current Loss: 5.9438\n",
            "[Batch 3] Current Loss: 4.8577\n",
            "[Batch 4] Current Loss: 5.5246\n",
            "[Batch 5] Current Loss: 5.5206\n",
            "[Batch 6] Current Loss: 5.0317\n",
            "[Batch 7] Current Loss: 4.6840\n",
            "[Batch 8] Current Loss: 5.4753\n",
            "[Batch 9] Current Loss: 4.8471\n",
            "Ep 2 (Step 014240): Train loss 3.540, Val loss 5.259\n",
            "[Batch 0] Current Loss: 4.1246\n",
            "[Batch 1] Current Loss: 4.4090\n",
            "[Batch 2] Current Loss: 3.6873\n",
            "[Batch 3] Current Loss: 3.3811\n",
            "[Batch 4] Current Loss: 3.7397\n",
            "[Batch 5] Current Loss: 3.5927\n",
            "[Batch 6] Current Loss: 3.8088\n",
            "[Batch 7] Current Loss: 3.7812\n",
            "[Batch 8] Current Loss: 3.6918\n",
            "[Batch 9] Current Loss: 3.4347\n",
            "[Batch 0] Current Loss: 5.5682\n",
            "[Batch 1] Current Loss: 4.6766\n",
            "[Batch 2] Current Loss: 5.9407\n",
            "[Batch 3] Current Loss: 5.1043\n",
            "[Batch 4] Current Loss: 5.7209\n",
            "[Batch 5] Current Loss: 5.4609\n",
            "[Batch 6] Current Loss: 4.8500\n",
            "[Batch 7] Current Loss: 5.5415\n",
            "[Batch 8] Current Loss: 5.1138\n",
            "[Batch 9] Current Loss: 4.8678\n",
            "Ep 2 (Step 014260): Train loss 3.765, Val loss 5.284\n",
            "[Batch 0] Current Loss: 3.3004\n",
            "[Batch 1] Current Loss: 3.2567\n",
            "[Batch 2] Current Loss: 4.1404\n",
            "[Batch 3] Current Loss: 4.0122\n",
            "[Batch 4] Current Loss: 3.5505\n",
            "[Batch 5] Current Loss: 3.8545\n",
            "[Batch 6] Current Loss: 3.5557\n",
            "[Batch 7] Current Loss: 3.3085\n",
            "[Batch 8] Current Loss: 3.3989\n",
            "[Batch 9] Current Loss: 3.5216\n",
            "[Batch 0] Current Loss: 6.0116\n",
            "[Batch 1] Current Loss: 5.1500\n",
            "[Batch 2] Current Loss: 4.9723\n",
            "[Batch 3] Current Loss: 5.1640\n",
            "[Batch 4] Current Loss: 5.1296\n",
            "[Batch 5] Current Loss: 5.7545\n",
            "[Batch 6] Current Loss: 5.3335\n",
            "[Batch 7] Current Loss: 3.9538\n",
            "[Batch 8] Current Loss: 5.4174\n",
            "[Batch 9] Current Loss: 5.3983\n",
            "Ep 2 (Step 014280): Train loss 3.590, Val loss 5.228\n",
            "[Batch 0] Current Loss: 3.7639\n",
            "[Batch 1] Current Loss: 3.6046\n",
            "[Batch 2] Current Loss: 3.5844\n",
            "[Batch 3] Current Loss: 3.8047\n",
            "[Batch 4] Current Loss: 3.3195\n",
            "[Batch 5] Current Loss: 3.4246\n",
            "[Batch 6] Current Loss: 3.8131\n",
            "[Batch 7] Current Loss: 3.7786\n",
            "[Batch 8] Current Loss: 4.0120\n",
            "[Batch 9] Current Loss: 3.7623\n",
            "[Batch 0] Current Loss: 5.4701\n",
            "[Batch 1] Current Loss: 5.3221\n",
            "[Batch 2] Current Loss: 5.1858\n",
            "[Batch 3] Current Loss: 5.2179\n",
            "[Batch 4] Current Loss: 6.1598\n",
            "[Batch 5] Current Loss: 5.5685\n",
            "[Batch 6] Current Loss: 4.7558\n",
            "[Batch 7] Current Loss: 4.3940\n",
            "[Batch 8] Current Loss: 5.2343\n",
            "[Batch 9] Current Loss: 5.6954\n",
            "Ep 2 (Step 014300): Train loss 3.687, Val loss 5.300\n",
            "[Batch 0] Current Loss: 4.3025\n",
            "[Batch 1] Current Loss: 3.9918\n",
            "[Batch 2] Current Loss: 3.7470\n",
            "[Batch 3] Current Loss: 3.6507\n",
            "[Batch 4] Current Loss: 3.1158\n",
            "[Batch 5] Current Loss: 3.6164\n",
            "[Batch 6] Current Loss: 3.7569\n",
            "[Batch 7] Current Loss: 3.9139\n",
            "[Batch 8] Current Loss: 3.2422\n",
            "[Batch 9] Current Loss: 2.8946\n",
            "[Batch 0] Current Loss: 5.0358\n",
            "[Batch 1] Current Loss: 4.7999\n",
            "[Batch 2] Current Loss: 5.4067\n",
            "[Batch 3] Current Loss: 5.2148\n",
            "[Batch 4] Current Loss: 4.8815\n",
            "[Batch 5] Current Loss: 5.1555\n",
            "[Batch 6] Current Loss: 4.3471\n",
            "[Batch 7] Current Loss: 4.9903\n",
            "[Batch 8] Current Loss: 5.2562\n",
            "[Batch 9] Current Loss: 4.7536\n",
            "Ep 2 (Step 014320): Train loss 3.623, Val loss 4.984\n",
            "[Batch 0] Current Loss: 3.7223\n",
            "[Batch 1] Current Loss: 4.1283\n",
            "[Batch 2] Current Loss: 3.4829\n",
            "[Batch 3] Current Loss: 3.7357\n",
            "[Batch 4] Current Loss: 3.7207\n",
            "[Batch 5] Current Loss: 3.7180\n",
            "[Batch 6] Current Loss: 3.6222\n",
            "[Batch 7] Current Loss: 3.6312\n",
            "[Batch 8] Current Loss: 3.8078\n",
            "[Batch 9] Current Loss: 3.7016\n",
            "[Batch 0] Current Loss: 5.0816\n",
            "[Batch 1] Current Loss: 5.4027\n",
            "[Batch 2] Current Loss: 5.3144\n",
            "[Batch 3] Current Loss: 5.5192\n",
            "[Batch 4] Current Loss: 5.0327\n",
            "[Batch 5] Current Loss: 5.3422\n",
            "[Batch 6] Current Loss: 5.1753\n",
            "[Batch 7] Current Loss: 5.6709\n",
            "[Batch 8] Current Loss: 5.5779\n",
            "[Batch 9] Current Loss: 5.2899\n",
            "Ep 2 (Step 014340): Train loss 3.727, Val loss 5.341\n",
            "[Batch 0] Current Loss: 3.2238\n",
            "[Batch 1] Current Loss: 3.3544\n",
            "[Batch 2] Current Loss: 3.7055\n",
            "[Batch 3] Current Loss: 3.4483\n",
            "[Batch 4] Current Loss: 3.5411\n",
            "[Batch 5] Current Loss: 3.8324\n",
            "[Batch 6] Current Loss: 3.9520\n",
            "[Batch 7] Current Loss: 3.9012\n",
            "[Batch 8] Current Loss: 3.7825\n",
            "[Batch 9] Current Loss: 3.6248\n",
            "[Batch 0] Current Loss: 4.9107\n",
            "[Batch 1] Current Loss: 5.5192\n",
            "[Batch 2] Current Loss: 5.1277\n",
            "[Batch 3] Current Loss: 5.0595\n",
            "[Batch 4] Current Loss: 4.9589\n",
            "[Batch 5] Current Loss: 4.7187\n",
            "[Batch 6] Current Loss: 5.0153\n",
            "[Batch 7] Current Loss: 5.2168\n",
            "[Batch 8] Current Loss: 6.2835\n",
            "[Batch 9] Current Loss: 5.4284\n",
            "Ep 2 (Step 014360): Train loss 3.637, Val loss 5.224\n",
            "[Batch 0] Current Loss: 3.9220\n",
            "[Batch 1] Current Loss: 3.6739\n",
            "[Batch 2] Current Loss: 3.7825\n",
            "[Batch 3] Current Loss: 3.7383\n",
            "[Batch 4] Current Loss: 3.9889\n",
            "[Batch 5] Current Loss: 3.1455\n",
            "[Batch 6] Current Loss: 4.0017\n",
            "[Batch 7] Current Loss: 3.5315\n",
            "[Batch 8] Current Loss: 3.1348\n",
            "[Batch 9] Current Loss: 3.6208\n",
            "[Batch 0] Current Loss: 5.6764\n",
            "[Batch 1] Current Loss: 4.7149\n",
            "[Batch 2] Current Loss: 5.6175\n",
            "[Batch 3] Current Loss: 4.9229\n",
            "[Batch 4] Current Loss: 4.4664\n",
            "[Batch 5] Current Loss: 5.0052\n",
            "[Batch 6] Current Loss: 4.8612\n",
            "[Batch 7] Current Loss: 4.9298\n",
            "[Batch 8] Current Loss: 4.8365\n",
            "[Batch 9] Current Loss: 5.7570\n",
            "Ep 2 (Step 014380): Train loss 3.654, Val loss 5.079\n",
            "[Batch 0] Current Loss: 3.8609\n",
            "[Batch 1] Current Loss: 3.2023\n",
            "[Batch 2] Current Loss: 3.1861\n",
            "[Batch 3] Current Loss: 4.1458\n",
            "[Batch 4] Current Loss: 3.9892\n",
            "[Batch 5] Current Loss: 4.1062\n",
            "[Batch 6] Current Loss: 3.1545\n",
            "[Batch 7] Current Loss: 2.5798\n",
            "[Batch 8] Current Loss: 3.8891\n",
            "[Batch 9] Current Loss: 4.1477\n",
            "[Batch 0] Current Loss: 5.5034\n",
            "[Batch 1] Current Loss: 4.7586\n",
            "[Batch 2] Current Loss: 5.4117\n",
            "[Batch 3] Current Loss: 5.2245\n",
            "[Batch 4] Current Loss: 5.8882\n",
            "[Batch 5] Current Loss: 4.5505\n",
            "[Batch 6] Current Loss: 5.0060\n",
            "[Batch 7] Current Loss: 5.0517\n",
            "[Batch 8] Current Loss: 5.7275\n",
            "[Batch 9] Current Loss: 5.3290\n",
            "Ep 2 (Step 014400): Train loss 3.626, Val loss 5.245\n",
            "[Batch 0] Current Loss: 3.5065\n",
            "[Batch 1] Current Loss: 4.0496\n",
            "[Batch 2] Current Loss: 3.8757\n",
            "[Batch 3] Current Loss: 3.7245\n",
            "[Batch 4] Current Loss: 4.1009\n",
            "[Batch 5] Current Loss: 3.5063\n",
            "[Batch 6] Current Loss: 4.5144\n",
            "[Batch 7] Current Loss: 3.6218\n",
            "[Batch 8] Current Loss: 3.4041\n",
            "[Batch 9] Current Loss: 3.5245\n",
            "[Batch 0] Current Loss: 5.0463\n",
            "[Batch 1] Current Loss: 5.8659\n",
            "[Batch 2] Current Loss: 4.8321\n",
            "[Batch 3] Current Loss: 4.7098\n",
            "[Batch 4] Current Loss: 5.3042\n",
            "[Batch 5] Current Loss: 5.4974\n",
            "[Batch 6] Current Loss: 5.4019\n",
            "[Batch 7] Current Loss: 5.3439\n",
            "[Batch 8] Current Loss: 5.5934\n",
            "[Batch 9] Current Loss: 5.4192\n",
            "Ep 2 (Step 014420): Train loss 3.783, Val loss 5.301\n",
            "[Batch 0] Current Loss: 3.2854\n",
            "[Batch 1] Current Loss: 4.3292\n",
            "[Batch 2] Current Loss: 4.0817\n",
            "[Batch 3] Current Loss: 4.1321\n",
            "[Batch 4] Current Loss: 3.1632\n",
            "[Batch 5] Current Loss: 4.2409\n",
            "[Batch 6] Current Loss: 3.6832\n",
            "[Batch 7] Current Loss: 3.3213\n",
            "[Batch 8] Current Loss: 3.6359\n",
            "[Batch 9] Current Loss: 3.2428\n",
            "[Batch 0] Current Loss: 5.4118\n",
            "[Batch 1] Current Loss: 5.0332\n",
            "[Batch 2] Current Loss: 5.1373\n",
            "[Batch 3] Current Loss: 4.9842\n",
            "[Batch 4] Current Loss: 4.9575\n",
            "[Batch 5] Current Loss: 5.4066\n",
            "[Batch 6] Current Loss: 5.0598\n",
            "[Batch 7] Current Loss: 5.1926\n",
            "[Batch 8] Current Loss: 5.1590\n",
            "[Batch 9] Current Loss: 5.3864\n",
            "Ep 2 (Step 014440): Train loss 3.712, Val loss 5.173\n",
            "[Batch 0] Current Loss: 3.8944\n",
            "[Batch 1] Current Loss: 4.1200\n",
            "[Batch 2] Current Loss: 3.7301\n",
            "[Batch 3] Current Loss: 3.5575\n",
            "[Batch 4] Current Loss: 3.9678\n",
            "[Batch 5] Current Loss: 3.4842\n",
            "[Batch 6] Current Loss: 3.5368\n",
            "[Batch 7] Current Loss: 3.6921\n",
            "[Batch 8] Current Loss: 3.7290\n",
            "[Batch 9] Current Loss: 3.4014\n",
            "[Batch 0] Current Loss: 5.0896\n",
            "[Batch 1] Current Loss: 5.8862\n",
            "[Batch 2] Current Loss: 5.7164\n",
            "[Batch 3] Current Loss: 5.1687\n",
            "[Batch 4] Current Loss: 5.3204\n",
            "[Batch 5] Current Loss: 4.7829\n",
            "[Batch 6] Current Loss: 5.2006\n",
            "[Batch 7] Current Loss: 4.0865\n",
            "[Batch 8] Current Loss: 5.1591\n",
            "[Batch 9] Current Loss: 4.9370\n",
            "Ep 2 (Step 014460): Train loss 3.711, Val loss 5.135\n",
            "[Batch 0] Current Loss: 2.9769\n",
            "[Batch 1] Current Loss: 2.8926\n",
            "[Batch 2] Current Loss: 3.8127\n",
            "[Batch 3] Current Loss: 3.7119\n",
            "[Batch 4] Current Loss: 3.9708\n",
            "[Batch 5] Current Loss: 4.0049\n",
            "[Batch 6] Current Loss: 2.9010\n",
            "[Batch 7] Current Loss: 3.9108\n",
            "[Batch 8] Current Loss: 3.2661\n",
            "[Batch 9] Current Loss: 3.4521\n",
            "[Batch 0] Current Loss: 5.7102\n",
            "[Batch 1] Current Loss: 4.5595\n",
            "[Batch 2] Current Loss: 5.4446\n",
            "[Batch 3] Current Loss: 4.8536\n",
            "[Batch 4] Current Loss: 5.5670\n",
            "[Batch 5] Current Loss: 5.4560\n",
            "[Batch 6] Current Loss: 5.3220\n",
            "[Batch 7] Current Loss: 4.5810\n",
            "[Batch 8] Current Loss: 4.7345\n",
            "[Batch 9] Current Loss: 4.6537\n",
            "Ep 2 (Step 014480): Train loss 3.490, Val loss 5.088\n",
            "[Batch 0] Current Loss: 2.6823\n",
            "[Batch 1] Current Loss: 3.2066\n",
            "[Batch 2] Current Loss: 3.3080\n",
            "[Batch 3] Current Loss: 4.2214\n",
            "[Batch 4] Current Loss: 3.7728\n",
            "[Batch 5] Current Loss: 2.7628\n",
            "[Batch 6] Current Loss: 3.9098\n",
            "[Batch 7] Current Loss: 3.3635\n",
            "[Batch 8] Current Loss: 3.4484\n",
            "[Batch 9] Current Loss: 3.1648\n",
            "[Batch 0] Current Loss: 5.0312\n",
            "[Batch 1] Current Loss: 5.0629\n",
            "[Batch 2] Current Loss: 5.1825\n",
            "[Batch 3] Current Loss: 5.6388\n",
            "[Batch 4] Current Loss: 5.6779\n",
            "[Batch 5] Current Loss: 5.2187\n",
            "[Batch 6] Current Loss: 5.3670\n",
            "[Batch 7] Current Loss: 5.3000\n",
            "[Batch 8] Current Loss: 5.5076\n",
            "[Batch 9] Current Loss: 4.9055\n",
            "Ep 2 (Step 014500): Train loss 3.384, Val loss 5.289\n",
            "[Batch 0] Current Loss: 3.9665\n",
            "[Batch 1] Current Loss: 3.4623\n",
            "[Batch 2] Current Loss: 2.9187\n",
            "[Batch 3] Current Loss: 3.6396\n",
            "[Batch 4] Current Loss: 3.7490\n",
            "[Batch 5] Current Loss: 3.7749\n",
            "[Batch 6] Current Loss: 3.2119\n",
            "[Batch 7] Current Loss: 4.0020\n",
            "[Batch 8] Current Loss: 3.7544\n",
            "[Batch 9] Current Loss: 3.3550\n",
            "[Batch 0] Current Loss: 5.0184\n",
            "[Batch 1] Current Loss: 5.3215\n",
            "[Batch 2] Current Loss: 4.8644\n",
            "[Batch 3] Current Loss: 4.7503\n",
            "[Batch 4] Current Loss: 5.6404\n",
            "[Batch 5] Current Loss: 5.8305\n",
            "[Batch 6] Current Loss: 5.1888\n",
            "[Batch 7] Current Loss: 5.0918\n",
            "[Batch 8] Current Loss: 5.5366\n",
            "[Batch 9] Current Loss: 4.7682\n",
            "Ep 2 (Step 014520): Train loss 3.583, Val loss 5.201\n",
            "[Batch 0] Current Loss: 3.8098\n",
            "[Batch 1] Current Loss: 3.1345\n",
            "[Batch 2] Current Loss: 3.5357\n",
            "[Batch 3] Current Loss: 4.3734\n",
            "[Batch 4] Current Loss: 3.8873\n",
            "[Batch 5] Current Loss: 3.7935\n",
            "[Batch 6] Current Loss: 3.5935\n",
            "[Batch 7] Current Loss: 3.4333\n",
            "[Batch 8] Current Loss: 3.2227\n",
            "[Batch 9] Current Loss: 3.6573\n",
            "[Batch 0] Current Loss: 5.1569\n",
            "[Batch 1] Current Loss: 5.1347\n",
            "[Batch 2] Current Loss: 5.1742\n",
            "[Batch 3] Current Loss: 4.9773\n",
            "[Batch 4] Current Loss: 5.1797\n",
            "[Batch 5] Current Loss: 5.1436\n",
            "[Batch 6] Current Loss: 5.6639\n",
            "[Batch 7] Current Loss: 5.2594\n",
            "[Batch 8] Current Loss: 5.0247\n",
            "[Batch 9] Current Loss: 5.6076\n",
            "Ep 2 (Step 014540): Train loss 3.644, Val loss 5.232\n",
            "[Batch 0] Current Loss: 4.0733\n",
            "[Batch 1] Current Loss: 4.1006\n",
            "[Batch 2] Current Loss: 3.7443\n",
            "[Batch 3] Current Loss: 3.5467\n",
            "[Batch 4] Current Loss: 3.6409\n",
            "[Batch 5] Current Loss: 4.1670\n",
            "[Batch 6] Current Loss: 3.9927\n",
            "[Batch 7] Current Loss: 3.7667\n",
            "[Batch 8] Current Loss: 3.4361\n",
            "[Batch 9] Current Loss: 3.6600\n",
            "[Batch 0] Current Loss: 5.2556\n",
            "[Batch 1] Current Loss: 5.5276\n",
            "[Batch 2] Current Loss: 5.0782\n",
            "[Batch 3] Current Loss: 4.7319\n",
            "[Batch 4] Current Loss: 4.5833\n",
            "[Batch 5] Current Loss: 4.9619\n",
            "[Batch 6] Current Loss: 5.3233\n",
            "[Batch 7] Current Loss: 5.9659\n",
            "[Batch 8] Current Loss: 5.1638\n",
            "[Batch 9] Current Loss: 4.9878\n",
            "Ep 2 (Step 014560): Train loss 3.813, Val loss 5.158\n",
            "[Batch 0] Current Loss: 3.9114\n",
            "[Batch 1] Current Loss: 3.0186\n",
            "[Batch 2] Current Loss: 3.8504\n",
            "[Batch 3] Current Loss: 4.1635\n",
            "[Batch 4] Current Loss: 2.8047\n",
            "[Batch 5] Current Loss: 2.6705\n",
            "[Batch 6] Current Loss: 3.9998\n",
            "[Batch 7] Current Loss: 3.5153\n",
            "[Batch 8] Current Loss: 3.5636\n",
            "[Batch 9] Current Loss: 3.6460\n",
            "[Batch 0] Current Loss: 4.9173\n",
            "[Batch 1] Current Loss: 5.7048\n",
            "[Batch 2] Current Loss: 4.7386\n",
            "[Batch 3] Current Loss: 5.2579\n",
            "[Batch 4] Current Loss: 4.9566\n",
            "[Batch 5] Current Loss: 4.9424\n",
            "[Batch 6] Current Loss: 5.1129\n",
            "[Batch 7] Current Loss: 5.3562\n",
            "[Batch 8] Current Loss: 5.8820\n",
            "[Batch 9] Current Loss: 5.6910\n",
            "Ep 2 (Step 014580): Train loss 3.514, Val loss 5.256\n",
            "[Batch 0] Current Loss: 3.7736\n",
            "[Batch 1] Current Loss: 4.0188\n",
            "[Batch 2] Current Loss: 3.4506\n",
            "[Batch 3] Current Loss: 3.4934\n",
            "[Batch 4] Current Loss: 4.0762\n",
            "[Batch 5] Current Loss: 3.4454\n",
            "[Batch 6] Current Loss: 3.7439\n",
            "[Batch 7] Current Loss: 3.4446\n",
            "[Batch 8] Current Loss: 3.8395\n",
            "[Batch 9] Current Loss: 3.8500\n",
            "[Batch 0] Current Loss: 5.1102\n",
            "[Batch 1] Current Loss: 5.5130\n",
            "[Batch 2] Current Loss: 4.5174\n",
            "[Batch 3] Current Loss: 4.6651\n",
            "[Batch 4] Current Loss: 5.7859\n",
            "[Batch 5] Current Loss: 4.8046\n",
            "[Batch 6] Current Loss: 4.9484\n",
            "[Batch 7] Current Loss: 4.8339\n",
            "[Batch 8] Current Loss: 5.0124\n",
            "[Batch 9] Current Loss: 5.2324\n",
            "Ep 2 (Step 014600): Train loss 3.714, Val loss 5.042\n",
            "[Batch 0] Current Loss: 3.3124\n",
            "[Batch 1] Current Loss: 4.0724\n",
            "[Batch 2] Current Loss: 3.2899\n",
            "[Batch 3] Current Loss: 3.6838\n",
            "[Batch 4] Current Loss: 3.5963\n",
            "[Batch 5] Current Loss: 3.3881\n",
            "[Batch 6] Current Loss: 3.2582\n",
            "[Batch 7] Current Loss: 3.9424\n",
            "[Batch 8] Current Loss: 4.2614\n",
            "[Batch 9] Current Loss: 3.9374\n",
            "[Batch 0] Current Loss: 4.9272\n",
            "[Batch 1] Current Loss: 4.8250\n",
            "[Batch 2] Current Loss: 5.2062\n",
            "[Batch 3] Current Loss: 5.1051\n",
            "[Batch 4] Current Loss: 5.0101\n",
            "[Batch 5] Current Loss: 5.6120\n",
            "[Batch 6] Current Loss: 5.7644\n",
            "[Batch 7] Current Loss: 5.3560\n",
            "[Batch 8] Current Loss: 5.2616\n",
            "[Batch 9] Current Loss: 5.1385\n",
            "Ep 2 (Step 014620): Train loss 3.674, Val loss 5.221\n",
            "[Batch 0] Current Loss: 3.9108\n",
            "[Batch 1] Current Loss: 3.7076\n",
            "[Batch 2] Current Loss: 3.7588\n",
            "[Batch 3] Current Loss: 3.5238\n",
            "[Batch 4] Current Loss: 3.8179\n",
            "[Batch 5] Current Loss: 3.7409\n",
            "[Batch 6] Current Loss: 3.3688\n",
            "[Batch 7] Current Loss: 3.5210\n",
            "[Batch 8] Current Loss: 4.1171\n",
            "[Batch 9] Current Loss: 3.8596\n",
            "[Batch 0] Current Loss: 5.0797\n",
            "[Batch 1] Current Loss: 5.5206\n",
            "[Batch 2] Current Loss: 5.9666\n",
            "[Batch 3] Current Loss: 4.3273\n",
            "[Batch 4] Current Loss: 5.0282\n",
            "[Batch 5] Current Loss: 4.7786\n",
            "[Batch 6] Current Loss: 5.0157\n",
            "[Batch 7] Current Loss: 5.6594\n",
            "[Batch 8] Current Loss: 5.6168\n",
            "[Batch 9] Current Loss: 5.0606\n",
            "Ep 2 (Step 014640): Train loss 3.733, Val loss 5.205\n",
            "[Batch 0] Current Loss: 3.4497\n",
            "[Batch 1] Current Loss: 4.0979\n",
            "[Batch 2] Current Loss: 3.8463\n",
            "[Batch 3] Current Loss: 2.9912\n",
            "[Batch 4] Current Loss: 3.3513\n",
            "[Batch 5] Current Loss: 3.6131\n",
            "[Batch 6] Current Loss: 3.7868\n",
            "[Batch 7] Current Loss: 3.3639\n",
            "[Batch 8] Current Loss: 3.7213\n",
            "[Batch 9] Current Loss: 3.8675\n",
            "[Batch 0] Current Loss: 5.4522\n",
            "[Batch 1] Current Loss: 5.5137\n",
            "[Batch 2] Current Loss: 5.2574\n",
            "[Batch 3] Current Loss: 5.0961\n",
            "[Batch 4] Current Loss: 5.9703\n",
            "[Batch 5] Current Loss: 5.6963\n",
            "[Batch 6] Current Loss: 4.8854\n",
            "[Batch 7] Current Loss: 5.3615\n",
            "[Batch 8] Current Loss: 4.5829\n",
            "[Batch 9] Current Loss: 4.8147\n",
            "Ep 2 (Step 014660): Train loss 3.609, Val loss 5.263\n",
            "[Batch 0] Current Loss: 3.7656\n",
            "[Batch 1] Current Loss: 3.0435\n",
            "[Batch 2] Current Loss: 3.6769\n",
            "[Batch 3] Current Loss: 3.3436\n",
            "[Batch 4] Current Loss: 3.9092\n",
            "[Batch 5] Current Loss: 3.4064\n",
            "[Batch 6] Current Loss: 3.6562\n",
            "[Batch 7] Current Loss: 3.5212\n",
            "[Batch 8] Current Loss: 4.1406\n",
            "[Batch 9] Current Loss: 4.2608\n",
            "[Batch 0] Current Loss: 5.2176\n",
            "[Batch 1] Current Loss: 4.5517\n",
            "[Batch 2] Current Loss: 5.9526\n",
            "[Batch 3] Current Loss: 4.9896\n",
            "[Batch 4] Current Loss: 4.8901\n",
            "[Batch 5] Current Loss: 5.4038\n",
            "[Batch 6] Current Loss: 4.6168\n",
            "[Batch 7] Current Loss: 4.7293\n",
            "[Batch 8] Current Loss: 5.0630\n",
            "[Batch 9] Current Loss: 5.2576\n",
            "Ep 2 (Step 014680): Train loss 3.672, Val loss 5.067\n",
            "[Batch 0] Current Loss: 3.9916\n",
            "[Batch 1] Current Loss: 3.8506\n",
            "[Batch 2] Current Loss: 4.0157\n",
            "[Batch 3] Current Loss: 3.9558\n",
            "[Batch 4] Current Loss: 3.7762\n",
            "[Batch 5] Current Loss: 3.1156\n",
            "[Batch 6] Current Loss: 3.4786\n",
            "[Batch 7] Current Loss: 4.1799\n",
            "[Batch 8] Current Loss: 3.6651\n",
            "[Batch 9] Current Loss: 3.5373\n",
            "[Batch 0] Current Loss: 4.6192\n",
            "[Batch 1] Current Loss: 5.1208\n",
            "[Batch 2] Current Loss: 5.0102\n",
            "[Batch 3] Current Loss: 5.5185\n",
            "[Batch 4] Current Loss: 5.7168\n",
            "[Batch 5] Current Loss: 5.1570\n",
            "[Batch 6] Current Loss: 5.8913\n",
            "[Batch 7] Current Loss: 5.7233\n",
            "[Batch 8] Current Loss: 5.2560\n",
            "[Batch 9] Current Loss: 4.8519\n",
            "Ep 2 (Step 014700): Train loss 3.757, Val loss 5.286\n",
            "[Batch 0] Current Loss: 3.9693\n",
            "[Batch 1] Current Loss: 3.9407\n",
            "[Batch 2] Current Loss: 2.5271\n",
            "[Batch 3] Current Loss: 4.1474\n",
            "[Batch 4] Current Loss: 3.3328\n",
            "[Batch 5] Current Loss: 3.5695\n",
            "[Batch 6] Current Loss: 3.5300\n",
            "[Batch 7] Current Loss: 3.7517\n",
            "[Batch 8] Current Loss: 3.8252\n",
            "[Batch 9] Current Loss: 4.0514\n",
            "[Batch 0] Current Loss: 4.8794\n",
            "[Batch 1] Current Loss: 5.7575\n",
            "[Batch 2] Current Loss: 5.4557\n",
            "[Batch 3] Current Loss: 5.7409\n",
            "[Batch 4] Current Loss: 5.6587\n",
            "[Batch 5] Current Loss: 4.6942\n",
            "[Batch 6] Current Loss: 5.1564\n",
            "[Batch 7] Current Loss: 5.4699\n",
            "[Batch 8] Current Loss: 5.2199\n",
            "[Batch 9] Current Loss: 5.5157\n",
            "Ep 2 (Step 014720): Train loss 3.665, Val loss 5.355\n",
            "[Batch 0] Current Loss: 3.9855\n",
            "[Batch 1] Current Loss: 3.7597\n",
            "[Batch 2] Current Loss: 4.2780\n",
            "[Batch 3] Current Loss: 2.9080\n",
            "[Batch 4] Current Loss: 3.8830\n",
            "[Batch 5] Current Loss: 3.5313\n",
            "[Batch 6] Current Loss: 3.8755\n",
            "[Batch 7] Current Loss: 3.5846\n",
            "[Batch 8] Current Loss: 3.8148\n",
            "[Batch 9] Current Loss: 4.2093\n",
            "[Batch 0] Current Loss: 5.4136\n",
            "[Batch 1] Current Loss: 5.5222\n",
            "[Batch 2] Current Loss: 5.1945\n",
            "[Batch 3] Current Loss: 5.3723\n",
            "[Batch 4] Current Loss: 4.3634\n",
            "[Batch 5] Current Loss: 5.0591\n",
            "[Batch 6] Current Loss: 5.0849\n",
            "[Batch 7] Current Loss: 5.2758\n",
            "[Batch 8] Current Loss: 4.6197\n",
            "[Batch 9] Current Loss: 5.7385\n",
            "Ep 2 (Step 014740): Train loss 3.783, Val loss 5.164\n",
            "[Batch 0] Current Loss: 3.6197\n",
            "[Batch 1] Current Loss: 3.5252\n",
            "[Batch 2] Current Loss: 3.5387\n",
            "[Batch 3] Current Loss: 3.7241\n",
            "[Batch 4] Current Loss: 2.8701\n",
            "[Batch 5] Current Loss: 3.5822\n",
            "[Batch 6] Current Loss: 3.5757\n",
            "[Batch 7] Current Loss: 4.0649\n",
            "[Batch 8] Current Loss: 4.0315\n",
            "[Batch 9] Current Loss: 4.4144\n",
            "[Batch 0] Current Loss: 5.6287\n",
            "[Batch 1] Current Loss: 5.0420\n",
            "[Batch 2] Current Loss: 5.0367\n",
            "[Batch 3] Current Loss: 5.5368\n",
            "[Batch 4] Current Loss: 5.4015\n",
            "[Batch 5] Current Loss: 5.5299\n",
            "[Batch 6] Current Loss: 5.1823\n",
            "[Batch 7] Current Loss: 5.1506\n",
            "[Batch 8] Current Loss: 5.1279\n",
            "[Batch 9] Current Loss: 5.0754\n",
            "Ep 2 (Step 014760): Train loss 3.695, Val loss 5.271\n",
            "[Batch 0] Current Loss: 3.3690\n",
            "[Batch 1] Current Loss: 3.2864\n",
            "[Batch 2] Current Loss: 3.6383\n",
            "[Batch 3] Current Loss: 3.6220\n",
            "[Batch 4] Current Loss: 4.0140\n",
            "[Batch 5] Current Loss: 3.5443\n",
            "[Batch 6] Current Loss: 3.6908\n",
            "[Batch 7] Current Loss: 3.8158\n",
            "[Batch 8] Current Loss: 3.3868\n",
            "[Batch 9] Current Loss: 3.4680\n",
            "[Batch 0] Current Loss: 5.6009\n",
            "[Batch 1] Current Loss: 5.4987\n",
            "[Batch 2] Current Loss: 4.9559\n",
            "[Batch 3] Current Loss: 5.0822\n",
            "[Batch 4] Current Loss: 5.4608\n",
            "[Batch 5] Current Loss: 4.9701\n",
            "[Batch 6] Current Loss: 5.7751\n",
            "[Batch 7] Current Loss: 5.4921\n",
            "[Batch 8] Current Loss: 5.5886\n",
            "[Batch 9] Current Loss: 5.5711\n",
            "Ep 2 (Step 014780): Train loss 3.584, Val loss 5.400\n",
            "[Batch 0] Current Loss: 3.4262\n",
            "[Batch 1] Current Loss: 3.8953\n",
            "[Batch 2] Current Loss: 3.6587\n",
            "[Batch 3] Current Loss: 3.0298\n",
            "[Batch 4] Current Loss: 3.7488\n",
            "[Batch 5] Current Loss: 3.6774\n",
            "[Batch 6] Current Loss: 3.8926\n",
            "[Batch 7] Current Loss: 3.7846\n",
            "[Batch 8] Current Loss: 3.8474\n",
            "[Batch 9] Current Loss: 4.1007\n",
            "[Batch 0] Current Loss: 5.0734\n",
            "[Batch 1] Current Loss: 5.3774\n",
            "[Batch 2] Current Loss: 5.0745\n",
            "[Batch 3] Current Loss: 4.9201\n",
            "[Batch 4] Current Loss: 5.0103\n",
            "[Batch 5] Current Loss: 5.4527\n",
            "[Batch 6] Current Loss: 5.4443\n",
            "[Batch 7] Current Loss: 5.2787\n",
            "[Batch 8] Current Loss: 4.9095\n",
            "[Batch 9] Current Loss: 4.6327\n",
            "Ep 2 (Step 014800): Train loss 3.706, Val loss 5.117\n",
            "[Batch 0] Current Loss: 3.5764\n",
            "[Batch 1] Current Loss: 3.6541\n",
            "[Batch 2] Current Loss: 3.1221\n",
            "[Batch 3] Current Loss: 3.1319\n",
            "[Batch 4] Current Loss: 3.2551\n",
            "[Batch 5] Current Loss: 3.6700\n",
            "[Batch 6] Current Loss: 4.1812\n",
            "[Batch 7] Current Loss: 3.3958\n",
            "[Batch 8] Current Loss: 3.9237\n",
            "[Batch 9] Current Loss: 3.2239\n",
            "[Batch 0] Current Loss: 5.4636\n",
            "[Batch 1] Current Loss: 5.0036\n",
            "[Batch 2] Current Loss: 5.5558\n",
            "[Batch 3] Current Loss: 4.6099\n",
            "[Batch 4] Current Loss: 4.4777\n",
            "[Batch 5] Current Loss: 5.2027\n",
            "[Batch 6] Current Loss: 4.6868\n",
            "[Batch 7] Current Loss: 4.3694\n",
            "[Batch 8] Current Loss: 4.6099\n",
            "[Batch 9] Current Loss: 5.2610\n",
            "Ep 2 (Step 014820): Train loss 3.513, Val loss 4.924\n",
            "[Batch 0] Current Loss: 3.8886\n",
            "[Batch 1] Current Loss: 3.3423\n",
            "[Batch 2] Current Loss: 3.7679\n",
            "[Batch 3] Current Loss: 3.4466\n",
            "[Batch 4] Current Loss: 3.8838\n",
            "[Batch 5] Current Loss: 3.5833\n",
            "[Batch 6] Current Loss: 2.8378\n",
            "[Batch 7] Current Loss: 3.3371\n",
            "[Batch 8] Current Loss: 3.6331\n",
            "[Batch 9] Current Loss: 3.6709\n",
            "[Batch 0] Current Loss: 5.2339\n",
            "[Batch 1] Current Loss: 4.6422\n",
            "[Batch 2] Current Loss: 5.3591\n",
            "[Batch 3] Current Loss: 4.7484\n",
            "[Batch 4] Current Loss: 5.1656\n",
            "[Batch 5] Current Loss: 4.8784\n",
            "[Batch 6] Current Loss: 5.2187\n",
            "[Batch 7] Current Loss: 4.9751\n",
            "[Batch 8] Current Loss: 4.8417\n",
            "[Batch 9] Current Loss: 5.7143\n",
            "Ep 2 (Step 014840): Train loss 3.539, Val loss 5.078\n",
            "[Batch 0] Current Loss: 3.8911\n",
            "[Batch 1] Current Loss: 3.1732\n",
            "[Batch 2] Current Loss: 3.5488\n",
            "[Batch 3] Current Loss: 3.9676\n",
            "[Batch 4] Current Loss: 3.6211\n",
            "[Batch 5] Current Loss: 3.3840\n",
            "[Batch 6] Current Loss: 2.9134\n",
            "[Batch 7] Current Loss: 3.6033\n",
            "[Batch 8] Current Loss: 3.9060\n",
            "[Batch 9] Current Loss: 3.9659\n",
            "[Batch 0] Current Loss: 5.4616\n",
            "[Batch 1] Current Loss: 5.7378\n",
            "[Batch 2] Current Loss: 5.5678\n",
            "[Batch 3] Current Loss: 4.9347\n",
            "[Batch 4] Current Loss: 4.9199\n",
            "[Batch 5] Current Loss: 5.3565\n",
            "[Batch 6] Current Loss: 5.2091\n",
            "[Batch 7] Current Loss: 4.9135\n",
            "[Batch 8] Current Loss: 5.6889\n",
            "[Batch 9] Current Loss: 5.5935\n",
            "Ep 2 (Step 014860): Train loss 3.597, Val loss 5.338\n",
            "[Batch 0] Current Loss: 3.3266\n",
            "[Batch 1] Current Loss: 3.4169\n",
            "[Batch 2] Current Loss: 3.5812\n",
            "[Batch 3] Current Loss: 3.5835\n",
            "[Batch 4] Current Loss: 3.7493\n",
            "[Batch 5] Current Loss: 3.3336\n",
            "[Batch 6] Current Loss: 3.8497\n",
            "[Batch 7] Current Loss: 4.0474\n",
            "[Batch 8] Current Loss: 3.4063\n",
            "[Batch 9] Current Loss: 4.0745\n",
            "[Batch 0] Current Loss: 5.0110\n",
            "[Batch 1] Current Loss: 5.6647\n",
            "[Batch 2] Current Loss: 5.4555\n",
            "[Batch 3] Current Loss: 5.6465\n",
            "[Batch 4] Current Loss: 5.1818\n",
            "[Batch 5] Current Loss: 5.0021\n",
            "[Batch 6] Current Loss: 5.4561\n",
            "[Batch 7] Current Loss: 5.3241\n",
            "[Batch 8] Current Loss: 5.0323\n",
            "[Batch 9] Current Loss: 4.5377\n",
            "Ep 2 (Step 014880): Train loss 3.637, Val loss 5.231\n",
            "[Batch 0] Current Loss: 3.8984\n",
            "[Batch 1] Current Loss: 4.2234\n",
            "[Batch 2] Current Loss: 3.9501\n",
            "[Batch 3] Current Loss: 3.6573\n",
            "[Batch 4] Current Loss: 3.8010\n",
            "[Batch 5] Current Loss: 3.8213\n",
            "[Batch 6] Current Loss: 3.5219\n",
            "[Batch 7] Current Loss: 2.9349\n",
            "[Batch 8] Current Loss: 4.1120\n",
            "[Batch 9] Current Loss: 3.8436\n",
            "[Batch 0] Current Loss: 5.5012\n",
            "[Batch 1] Current Loss: 5.2640\n",
            "[Batch 2] Current Loss: 4.7827\n",
            "[Batch 3] Current Loss: 5.5255\n",
            "[Batch 4] Current Loss: 5.5917\n",
            "[Batch 5] Current Loss: 4.7425\n",
            "[Batch 6] Current Loss: 5.1259\n",
            "[Batch 7] Current Loss: 5.6983\n",
            "[Batch 8] Current Loss: 5.4221\n",
            "[Batch 9] Current Loss: 5.5455\n",
            "Ep 2 (Step 014900): Train loss 3.776, Val loss 5.320\n",
            "[Batch 0] Current Loss: 3.5009\n",
            "[Batch 1] Current Loss: 3.4904\n",
            "[Batch 2] Current Loss: 3.9715\n",
            "[Batch 3] Current Loss: 3.7785\n",
            "[Batch 4] Current Loss: 3.4214\n",
            "[Batch 5] Current Loss: 3.1650\n",
            "[Batch 6] Current Loss: 4.0127\n",
            "[Batch 7] Current Loss: 3.6790\n",
            "[Batch 8] Current Loss: 3.3740\n",
            "[Batch 9] Current Loss: 3.4790\n",
            "[Batch 0] Current Loss: 5.6254\n",
            "[Batch 1] Current Loss: 4.6967\n",
            "[Batch 2] Current Loss: 4.3102\n",
            "[Batch 3] Current Loss: 5.5032\n",
            "[Batch 4] Current Loss: 5.3355\n",
            "[Batch 5] Current Loss: 5.5007\n",
            "[Batch 6] Current Loss: 5.4731\n",
            "[Batch 7] Current Loss: 5.4741\n",
            "[Batch 8] Current Loss: 5.7312\n",
            "[Batch 9] Current Loss: 5.5461\n",
            "Ep 2 (Step 014920): Train loss 3.587, Val loss 5.320\n",
            "[Batch 0] Current Loss: 4.2566\n",
            "[Batch 1] Current Loss: 4.1387\n",
            "[Batch 2] Current Loss: 3.2208\n",
            "[Batch 3] Current Loss: 3.1500\n",
            "[Batch 4] Current Loss: 3.8243\n",
            "[Batch 5] Current Loss: 4.0999\n",
            "[Batch 6] Current Loss: 3.7745\n",
            "[Batch 7] Current Loss: 3.9973\n",
            "[Batch 8] Current Loss: 3.5568\n",
            "[Batch 9] Current Loss: 3.6322\n",
            "[Batch 0] Current Loss: 4.8963\n",
            "[Batch 1] Current Loss: 5.8573\n",
            "[Batch 2] Current Loss: 4.8717\n",
            "[Batch 3] Current Loss: 4.9325\n",
            "[Batch 4] Current Loss: 5.2762\n",
            "[Batch 5] Current Loss: 5.0918\n",
            "[Batch 6] Current Loss: 5.2427\n",
            "[Batch 7] Current Loss: 5.0723\n",
            "[Batch 8] Current Loss: 5.0300\n",
            "[Batch 9] Current Loss: 5.8614\n",
            "Ep 2 (Step 014940): Train loss 3.765, Val loss 5.213\n",
            "[Batch 0] Current Loss: 4.1410\n",
            "[Batch 1] Current Loss: 3.7097\n",
            "[Batch 2] Current Loss: 4.1585\n",
            "[Batch 3] Current Loss: 3.7820\n",
            "[Batch 4] Current Loss: 3.6518\n",
            "[Batch 5] Current Loss: 3.6891\n",
            "[Batch 6] Current Loss: 3.5264\n",
            "[Batch 7] Current Loss: 3.9679\n",
            "[Batch 8] Current Loss: 3.5572\n",
            "[Batch 9] Current Loss: 3.4320\n",
            "[Batch 0] Current Loss: 4.5461\n",
            "[Batch 1] Current Loss: 4.4236\n",
            "[Batch 2] Current Loss: 5.1018\n",
            "[Batch 3] Current Loss: 5.4762\n",
            "[Batch 4] Current Loss: 5.5460\n",
            "[Batch 5] Current Loss: 5.1749\n",
            "[Batch 6] Current Loss: 5.1786\n",
            "[Batch 7] Current Loss: 4.7261\n",
            "[Batch 8] Current Loss: 5.0788\n",
            "[Batch 9] Current Loss: 5.1760\n",
            "Ep 2 (Step 014960): Train loss 3.762, Val loss 5.043\n",
            "[Batch 0] Current Loss: 3.5453\n",
            "[Batch 1] Current Loss: 3.7556\n",
            "[Batch 2] Current Loss: 3.8340\n",
            "[Batch 3] Current Loss: 3.8155\n",
            "[Batch 4] Current Loss: 4.1100\n",
            "[Batch 5] Current Loss: 3.6006\n",
            "[Batch 6] Current Loss: 3.3477\n",
            "[Batch 7] Current Loss: 3.6118\n",
            "[Batch 8] Current Loss: 3.5448\n",
            "[Batch 9] Current Loss: 3.1819\n",
            "[Batch 0] Current Loss: 5.5456\n",
            "[Batch 1] Current Loss: 4.9248\n",
            "[Batch 2] Current Loss: 5.1618\n",
            "[Batch 3] Current Loss: 5.9207\n",
            "[Batch 4] Current Loss: 5.0062\n",
            "[Batch 5] Current Loss: 5.1728\n",
            "[Batch 6] Current Loss: 5.4614\n",
            "[Batch 7] Current Loss: 5.6515\n",
            "[Batch 8] Current Loss: 5.5540\n",
            "[Batch 9] Current Loss: 5.0979\n",
            "Ep 2 (Step 014980): Train loss 3.635, Val loss 5.350\n",
            "[Batch 0] Current Loss: 3.3202\n",
            "[Batch 1] Current Loss: 4.1020\n",
            "[Batch 2] Current Loss: 3.7221\n",
            "[Batch 3] Current Loss: 3.8414\n",
            "[Batch 4] Current Loss: 3.8479\n",
            "[Batch 5] Current Loss: 3.4336\n",
            "[Batch 6] Current Loss: 3.6196\n",
            "[Batch 7] Current Loss: 4.1338\n",
            "[Batch 8] Current Loss: 3.9283\n",
            "[Batch 9] Current Loss: 3.6661\n",
            "[Batch 0] Current Loss: 5.2346\n",
            "[Batch 1] Current Loss: 4.6894\n",
            "[Batch 2] Current Loss: 5.1554\n",
            "[Batch 3] Current Loss: 5.2142\n",
            "[Batch 4] Current Loss: 4.7448\n",
            "[Batch 5] Current Loss: 5.3659\n",
            "[Batch 6] Current Loss: 5.0296\n",
            "[Batch 7] Current Loss: 5.8354\n",
            "[Batch 8] Current Loss: 5.4276\n",
            "[Batch 9] Current Loss: 5.4529\n",
            "Ep 2 (Step 015000): Train loss 3.761, Val loss 5.215\n",
            "[Batch 0] Current Loss: 3.2386\n",
            "[Batch 1] Current Loss: 3.4229\n",
            "[Batch 2] Current Loss: 3.4267\n",
            "[Batch 3] Current Loss: 3.5662\n",
            "[Batch 4] Current Loss: 3.1852\n",
            "[Batch 5] Current Loss: 3.7211\n",
            "[Batch 6] Current Loss: 3.2439\n",
            "[Batch 7] Current Loss: 3.5680\n",
            "[Batch 8] Current Loss: 3.3766\n",
            "[Batch 9] Current Loss: 3.6022\n",
            "[Batch 0] Current Loss: 5.3201\n",
            "[Batch 1] Current Loss: 4.7086\n",
            "[Batch 2] Current Loss: 5.0072\n",
            "[Batch 3] Current Loss: 5.4622\n",
            "[Batch 4] Current Loss: 5.1456\n",
            "[Batch 5] Current Loss: 5.7991\n",
            "[Batch 6] Current Loss: 5.7823\n",
            "[Batch 7] Current Loss: 5.2765\n",
            "[Batch 8] Current Loss: 5.1645\n",
            "[Batch 9] Current Loss: 5.3708\n",
            "Ep 2 (Step 015020): Train loss 3.435, Val loss 5.304\n",
            "[Batch 0] Current Loss: 3.2026\n",
            "[Batch 1] Current Loss: 3.4590\n",
            "[Batch 2] Current Loss: 3.4266\n",
            "[Batch 3] Current Loss: 3.1275\n",
            "[Batch 4] Current Loss: 3.7669\n",
            "[Batch 5] Current Loss: 3.5185\n",
            "[Batch 6] Current Loss: 3.6913\n",
            "[Batch 7] Current Loss: 3.3205\n",
            "[Batch 8] Current Loss: 4.0405\n",
            "[Batch 9] Current Loss: 3.8846\n",
            "[Batch 0] Current Loss: 4.7275\n",
            "[Batch 1] Current Loss: 5.5794\n",
            "[Batch 2] Current Loss: 4.3681\n",
            "[Batch 3] Current Loss: 5.4272\n",
            "[Batch 4] Current Loss: 4.9772\n",
            "[Batch 5] Current Loss: 5.4656\n",
            "[Batch 6] Current Loss: 5.3376\n",
            "[Batch 7] Current Loss: 4.9878\n",
            "[Batch 8] Current Loss: 5.3230\n",
            "[Batch 9] Current Loss: 4.5962\n",
            "Ep 2 (Step 015040): Train loss 3.544, Val loss 5.079\n",
            "[Batch 0] Current Loss: 4.2170\n",
            "[Batch 1] Current Loss: 4.0807\n",
            "[Batch 2] Current Loss: 3.8697\n",
            "[Batch 3] Current Loss: 3.3638\n",
            "[Batch 4] Current Loss: 3.8326\n",
            "[Batch 5] Current Loss: 3.3937\n",
            "[Batch 6] Current Loss: 3.4868\n",
            "[Batch 7] Current Loss: 3.4450\n",
            "[Batch 8] Current Loss: 3.7397\n",
            "[Batch 9] Current Loss: 4.0857\n",
            "[Batch 0] Current Loss: 5.4566\n",
            "[Batch 1] Current Loss: 5.6243\n",
            "[Batch 2] Current Loss: 4.7846\n",
            "[Batch 3] Current Loss: 5.5862\n",
            "[Batch 4] Current Loss: 5.3188\n",
            "[Batch 5] Current Loss: 4.8852\n",
            "[Batch 6] Current Loss: 5.0900\n",
            "[Batch 7] Current Loss: 5.6678\n",
            "[Batch 8] Current Loss: 5.6080\n",
            "[Batch 9] Current Loss: 5.0885\n",
            "Ep 2 (Step 015060): Train loss 3.751, Val loss 5.311\n",
            "[Batch 0] Current Loss: 3.1920\n",
            "[Batch 1] Current Loss: 2.8464\n",
            "[Batch 2] Current Loss: 3.3458\n",
            "[Batch 3] Current Loss: 3.4037\n",
            "[Batch 4] Current Loss: 4.6888\n",
            "[Batch 5] Current Loss: 4.0379\n",
            "[Batch 6] Current Loss: 3.7101\n",
            "[Batch 7] Current Loss: 3.2748\n",
            "[Batch 8] Current Loss: 3.3344\n",
            "[Batch 9] Current Loss: 3.6227\n",
            "[Batch 0] Current Loss: 5.8124\n",
            "[Batch 1] Current Loss: 5.2355\n",
            "[Batch 2] Current Loss: 5.5145\n",
            "[Batch 3] Current Loss: 4.9865\n",
            "[Batch 4] Current Loss: 5.6431\n",
            "[Batch 5] Current Loss: 5.1452\n",
            "[Batch 6] Current Loss: 5.1841\n",
            "[Batch 7] Current Loss: 5.2435\n",
            "[Batch 8] Current Loss: 5.5671\n",
            "[Batch 9] Current Loss: 5.2194\n",
            "Ep 2 (Step 015080): Train loss 3.546, Val loss 5.355\n",
            "[Batch 0] Current Loss: 3.3928\n",
            "[Batch 1] Current Loss: 3.5316\n",
            "[Batch 2] Current Loss: 3.6407\n",
            "[Batch 3] Current Loss: 3.9466\n",
            "[Batch 4] Current Loss: 3.9217\n",
            "[Batch 5] Current Loss: 3.8721\n",
            "[Batch 6] Current Loss: 3.4912\n",
            "[Batch 7] Current Loss: 3.8610\n",
            "[Batch 8] Current Loss: 3.8002\n",
            "[Batch 9] Current Loss: 2.8575\n",
            "[Batch 0] Current Loss: 5.7690\n",
            "[Batch 1] Current Loss: 5.1378\n",
            "[Batch 2] Current Loss: 5.2288\n",
            "[Batch 3] Current Loss: 5.2311\n",
            "[Batch 4] Current Loss: 5.0677\n",
            "[Batch 5] Current Loss: 4.4045\n",
            "[Batch 6] Current Loss: 4.7696\n",
            "[Batch 7] Current Loss: 4.8746\n",
            "[Batch 8] Current Loss: 5.5206\n",
            "[Batch 9] Current Loss: 5.3088\n",
            "Ep 2 (Step 015100): Train loss 3.632, Val loss 5.131\n",
            "[Batch 0] Current Loss: 3.4865\n",
            "[Batch 1] Current Loss: 3.3820\n",
            "[Batch 2] Current Loss: 3.8713\n",
            "[Batch 3] Current Loss: 3.7687\n",
            "[Batch 4] Current Loss: 3.9084\n",
            "[Batch 5] Current Loss: 4.1109\n",
            "[Batch 6] Current Loss: 3.6296\n",
            "[Batch 7] Current Loss: 3.2919\n",
            "[Batch 8] Current Loss: 4.5514\n",
            "[Batch 9] Current Loss: 3.8571\n",
            "[Batch 0] Current Loss: 5.2032\n",
            "[Batch 1] Current Loss: 5.2155\n",
            "[Batch 2] Current Loss: 4.6242\n",
            "[Batch 3] Current Loss: 5.2054\n",
            "[Batch 4] Current Loss: 5.3337\n",
            "[Batch 5] Current Loss: 4.7962\n",
            "[Batch 6] Current Loss: 4.7698\n",
            "[Batch 7] Current Loss: 4.9647\n",
            "[Batch 8] Current Loss: 5.5858\n",
            "[Batch 9] Current Loss: 4.7904\n",
            "Ep 2 (Step 015120): Train loss 3.786, Val loss 5.049\n",
            "[Batch 0] Current Loss: 3.9375\n",
            "[Batch 1] Current Loss: 3.9746\n",
            "[Batch 2] Current Loss: 4.4401\n",
            "[Batch 3] Current Loss: 3.5794\n",
            "[Batch 4] Current Loss: 3.6945\n",
            "[Batch 5] Current Loss: 3.9339\n",
            "[Batch 6] Current Loss: 4.4771\n",
            "[Batch 7] Current Loss: 3.3712\n",
            "[Batch 8] Current Loss: 3.7092\n",
            "[Batch 9] Current Loss: 3.4053\n",
            "[Batch 0] Current Loss: 5.0766\n",
            "[Batch 1] Current Loss: 6.0043\n",
            "[Batch 2] Current Loss: 5.6270\n",
            "[Batch 3] Current Loss: 4.5685\n",
            "[Batch 4] Current Loss: 5.1899\n",
            "[Batch 5] Current Loss: 5.1381\n",
            "[Batch 6] Current Loss: 5.6778\n",
            "[Batch 7] Current Loss: 5.2410\n",
            "[Batch 8] Current Loss: 5.0748\n",
            "[Batch 9] Current Loss: 5.1569\n",
            "Ep 2 (Step 015140): Train loss 3.852, Val loss 5.275\n",
            "[Batch 0] Current Loss: 3.4126\n",
            "[Batch 1] Current Loss: 2.5914\n",
            "[Batch 2] Current Loss: 3.9274\n",
            "[Batch 3] Current Loss: 4.0473\n",
            "[Batch 4] Current Loss: 3.1585\n",
            "[Batch 5] Current Loss: 3.8069\n",
            "[Batch 6] Current Loss: 3.8058\n",
            "[Batch 7] Current Loss: 3.6546\n",
            "[Batch 8] Current Loss: 3.1449\n",
            "[Batch 9] Current Loss: 4.1667\n",
            "[Batch 0] Current Loss: 5.2401\n",
            "[Batch 1] Current Loss: 4.6273\n",
            "[Batch 2] Current Loss: 5.7594\n",
            "[Batch 3] Current Loss: 4.2982\n",
            "[Batch 4] Current Loss: 5.3240\n",
            "[Batch 5] Current Loss: 4.4965\n",
            "[Batch 6] Current Loss: 5.0551\n",
            "[Batch 7] Current Loss: 5.4329\n",
            "[Batch 8] Current Loss: 5.2405\n",
            "[Batch 9] Current Loss: 6.1236\n",
            "Ep 2 (Step 015160): Train loss 3.572, Val loss 5.160\n",
            "[Batch 0] Current Loss: 3.4584\n",
            "[Batch 1] Current Loss: 4.0976\n",
            "[Batch 2] Current Loss: 3.0360\n",
            "[Batch 3] Current Loss: 4.0611\n",
            "[Batch 4] Current Loss: 4.0051\n",
            "[Batch 5] Current Loss: 3.3544\n",
            "[Batch 6] Current Loss: 3.8647\n",
            "[Batch 7] Current Loss: 2.9010\n",
            "[Batch 8] Current Loss: 3.6782\n",
            "[Batch 9] Current Loss: 3.5585\n",
            "[Batch 0] Current Loss: 5.3433\n",
            "[Batch 1] Current Loss: 5.1804\n",
            "[Batch 2] Current Loss: 4.6164\n",
            "[Batch 3] Current Loss: 4.9177\n",
            "[Batch 4] Current Loss: 5.0958\n",
            "[Batch 5] Current Loss: 5.2305\n",
            "[Batch 6] Current Loss: 5.4932\n",
            "[Batch 7] Current Loss: 5.3918\n",
            "[Batch 8] Current Loss: 5.4117\n",
            "[Batch 9] Current Loss: 5.3619\n",
            "Ep 2 (Step 015180): Train loss 3.602, Val loss 5.204\n",
            "[Batch 0] Current Loss: 4.1089\n",
            "[Batch 1] Current Loss: 4.1345\n",
            "[Batch 2] Current Loss: 3.6167\n",
            "[Batch 3] Current Loss: 3.8823\n",
            "[Batch 4] Current Loss: 3.3950\n",
            "[Batch 5] Current Loss: 3.9714\n",
            "[Batch 6] Current Loss: 3.1803\n",
            "[Batch 7] Current Loss: 3.5179\n",
            "[Batch 8] Current Loss: 3.6770\n",
            "[Batch 9] Current Loss: 3.8014\n",
            "[Batch 0] Current Loss: 5.5372\n",
            "[Batch 1] Current Loss: 4.9620\n",
            "[Batch 2] Current Loss: 5.8260\n",
            "[Batch 3] Current Loss: 6.1483\n",
            "[Batch 4] Current Loss: 4.8771\n",
            "[Batch 5] Current Loss: 5.5015\n",
            "[Batch 6] Current Loss: 5.3345\n",
            "[Batch 7] Current Loss: 5.5373\n",
            "[Batch 8] Current Loss: 5.0961\n",
            "[Batch 9] Current Loss: 5.1777\n",
            "Ep 2 (Step 015200): Train loss 3.729, Val loss 5.400\n",
            "[Batch 0] Current Loss: 3.4764\n",
            "[Batch 1] Current Loss: 3.4529\n",
            "[Batch 2] Current Loss: 3.8256\n",
            "[Batch 3] Current Loss: 3.6803\n",
            "[Batch 4] Current Loss: 4.0833\n",
            "[Batch 5] Current Loss: 3.5231\n",
            "[Batch 6] Current Loss: 4.0802\n",
            "[Batch 7] Current Loss: 3.2532\n",
            "[Batch 8] Current Loss: 3.8832\n",
            "[Batch 9] Current Loss: 3.5998\n",
            "[Batch 0] Current Loss: 5.5801\n",
            "[Batch 1] Current Loss: 5.8367\n",
            "[Batch 2] Current Loss: 5.2193\n",
            "[Batch 3] Current Loss: 5.0584\n",
            "[Batch 4] Current Loss: 5.4258\n",
            "[Batch 5] Current Loss: 5.2307\n",
            "[Batch 6] Current Loss: 5.5583\n",
            "[Batch 7] Current Loss: 5.0410\n",
            "[Batch 8] Current Loss: 5.1634\n",
            "[Batch 9] Current Loss: 5.3367\n",
            "Ep 2 (Step 015220): Train loss 3.686, Val loss 5.345\n",
            "[Batch 0] Current Loss: 3.4352\n",
            "[Batch 1] Current Loss: 3.2268\n",
            "[Batch 2] Current Loss: 3.5237\n",
            "[Batch 3] Current Loss: 3.8668\n",
            "[Batch 4] Current Loss: 3.3973\n",
            "[Batch 5] Current Loss: 3.3791\n",
            "[Batch 6] Current Loss: 3.7924\n",
            "[Batch 7] Current Loss: 3.4924\n",
            "[Batch 8] Current Loss: 3.5082\n",
            "[Batch 9] Current Loss: 3.4740\n",
            "[Batch 0] Current Loss: 4.9871\n",
            "[Batch 1] Current Loss: 5.2534\n",
            "[Batch 2] Current Loss: 4.2363\n",
            "[Batch 3] Current Loss: 5.6050\n",
            "[Batch 4] Current Loss: 5.4841\n",
            "[Batch 5] Current Loss: 4.3898\n",
            "[Batch 6] Current Loss: 5.0186\n",
            "[Batch 7] Current Loss: 5.0691\n",
            "[Batch 8] Current Loss: 4.9440\n",
            "[Batch 9] Current Loss: 5.2898\n",
            "Ep 2 (Step 015240): Train loss 3.510, Val loss 5.028\n",
            "[Batch 0] Current Loss: 3.9111\n",
            "[Batch 1] Current Loss: 3.7037\n",
            "[Batch 2] Current Loss: 3.6665\n",
            "[Batch 3] Current Loss: 3.7362\n",
            "[Batch 4] Current Loss: 3.3005\n",
            "[Batch 5] Current Loss: 3.8210\n",
            "[Batch 6] Current Loss: 4.0025\n",
            "[Batch 7] Current Loss: 3.6605\n",
            "[Batch 8] Current Loss: 3.4755\n",
            "[Batch 9] Current Loss: 3.8153\n",
            "[Batch 0] Current Loss: 5.8334\n",
            "[Batch 1] Current Loss: 4.8304\n",
            "[Batch 2] Current Loss: 5.0163\n",
            "[Batch 3] Current Loss: 4.5762\n",
            "[Batch 4] Current Loss: 5.4597\n",
            "[Batch 5] Current Loss: 5.4601\n",
            "[Batch 6] Current Loss: 5.1062\n",
            "[Batch 7] Current Loss: 5.5885\n",
            "[Batch 8] Current Loss: 4.8570\n",
            "[Batch 9] Current Loss: 4.5842\n",
            "Ep 2 (Step 015260): Train loss 3.709, Val loss 5.131\n",
            "[Batch 0] Current Loss: 3.5369\n",
            "[Batch 1] Current Loss: 2.7812\n",
            "[Batch 2] Current Loss: 3.3367\n",
            "[Batch 3] Current Loss: 3.2503\n",
            "[Batch 4] Current Loss: 3.8562\n",
            "[Batch 5] Current Loss: 3.6889\n",
            "[Batch 6] Current Loss: 4.1029\n",
            "[Batch 7] Current Loss: 3.6806\n",
            "[Batch 8] Current Loss: 4.0003\n",
            "[Batch 9] Current Loss: 3.5009\n",
            "[Batch 0] Current Loss: 5.4114\n",
            "[Batch 1] Current Loss: 5.3402\n",
            "[Batch 2] Current Loss: 5.6629\n",
            "[Batch 3] Current Loss: 5.1746\n",
            "[Batch 4] Current Loss: 4.9770\n",
            "[Batch 5] Current Loss: 4.6448\n",
            "[Batch 6] Current Loss: 4.8206\n",
            "[Batch 7] Current Loss: 5.3755\n",
            "[Batch 8] Current Loss: 5.4489\n",
            "[Batch 9] Current Loss: 4.5711\n",
            "Ep 2 (Step 015280): Train loss 3.573, Val loss 5.143\n",
            "[Batch 0] Current Loss: 3.7893\n",
            "[Batch 1] Current Loss: 3.8667\n",
            "[Batch 2] Current Loss: 3.8679\n",
            "[Batch 3] Current Loss: 2.3782\n",
            "[Batch 4] Current Loss: 3.3930\n",
            "[Batch 5] Current Loss: 3.0382\n",
            "[Batch 6] Current Loss: 4.0029\n",
            "[Batch 7] Current Loss: 3.6377\n",
            "[Batch 8] Current Loss: 3.4438\n",
            "[Batch 9] Current Loss: 3.6792\n",
            "[Batch 0] Current Loss: 5.4530\n",
            "[Batch 1] Current Loss: 5.1202\n",
            "[Batch 2] Current Loss: 5.8984\n",
            "[Batch 3] Current Loss: 5.2005\n",
            "[Batch 4] Current Loss: 5.3636\n",
            "[Batch 5] Current Loss: 4.6879\n",
            "[Batch 6] Current Loss: 5.0419\n",
            "[Batch 7] Current Loss: 4.3544\n",
            "[Batch 8] Current Loss: 5.2114\n",
            "[Batch 9] Current Loss: 5.1281\n",
            "Ep 2 (Step 015300): Train loss 3.510, Val loss 5.146\n",
            "[Batch 0] Current Loss: 3.0515\n",
            "[Batch 1] Current Loss: 3.0465\n",
            "[Batch 2] Current Loss: 3.0930\n",
            "[Batch 3] Current Loss: 3.0506\n",
            "[Batch 4] Current Loss: 3.1060\n",
            "[Batch 5] Current Loss: 3.4702\n",
            "[Batch 6] Current Loss: 2.9062\n",
            "[Batch 7] Current Loss: 3.0743\n",
            "[Batch 8] Current Loss: 3.8314\n",
            "[Batch 9] Current Loss: 3.6736\n",
            "[Batch 0] Current Loss: 5.1028\n",
            "[Batch 1] Current Loss: 5.5964\n",
            "[Batch 2] Current Loss: 5.1031\n",
            "[Batch 3] Current Loss: 4.9500\n",
            "[Batch 4] Current Loss: 5.4250\n",
            "[Batch 5] Current Loss: 5.4870\n",
            "[Batch 6] Current Loss: 5.4648\n",
            "[Batch 7] Current Loss: 4.9989\n",
            "[Batch 8] Current Loss: 4.8551\n",
            "[Batch 9] Current Loss: 4.7932\n",
            "Ep 2 (Step 015320): Train loss 3.230, Val loss 5.178\n",
            "[Batch 0] Current Loss: 4.1018\n",
            "[Batch 1] Current Loss: 3.9446\n",
            "[Batch 2] Current Loss: 4.4486\n",
            "[Batch 3] Current Loss: 3.4859\n",
            "[Batch 4] Current Loss: 3.6169\n",
            "[Batch 5] Current Loss: 3.0988\n",
            "[Batch 6] Current Loss: 3.7845\n",
            "[Batch 7] Current Loss: 4.2650\n",
            "[Batch 8] Current Loss: 4.0479\n",
            "[Batch 9] Current Loss: 3.6218\n",
            "[Batch 0] Current Loss: 4.7540\n",
            "[Batch 1] Current Loss: 5.6645\n",
            "[Batch 2] Current Loss: 4.9867\n",
            "[Batch 3] Current Loss: 4.6716\n",
            "[Batch 4] Current Loss: 5.1935\n",
            "[Batch 5] Current Loss: 4.8422\n",
            "[Batch 6] Current Loss: 5.8297\n",
            "[Batch 7] Current Loss: 6.2491\n",
            "[Batch 8] Current Loss: 4.2155\n",
            "[Batch 9] Current Loss: 4.9083\n",
            "Ep 2 (Step 015340): Train loss 3.842, Val loss 5.132\n",
            "[Batch 0] Current Loss: 4.0046\n",
            "[Batch 1] Current Loss: 3.8679\n",
            "[Batch 2] Current Loss: 3.6039\n",
            "[Batch 3] Current Loss: 3.6137\n",
            "[Batch 4] Current Loss: 3.3281\n",
            "[Batch 5] Current Loss: 3.7337\n",
            "[Batch 6] Current Loss: 3.3358\n",
            "[Batch 7] Current Loss: 3.6254\n",
            "[Batch 8] Current Loss: 3.2038\n",
            "[Batch 9] Current Loss: 3.5953\n",
            "[Batch 0] Current Loss: 4.8917\n",
            "[Batch 1] Current Loss: 4.6672\n",
            "[Batch 2] Current Loss: 4.8705\n",
            "[Batch 3] Current Loss: 4.8812\n",
            "[Batch 4] Current Loss: 4.9693\n",
            "[Batch 5] Current Loss: 5.3179\n",
            "[Batch 6] Current Loss: 5.3988\n",
            "[Batch 7] Current Loss: 5.5388\n",
            "[Batch 8] Current Loss: 4.3300\n",
            "[Batch 9] Current Loss: 5.2971\n",
            "Ep 2 (Step 015360): Train loss 3.591, Val loss 5.016\n",
            "[Batch 0] Current Loss: 3.9709\n",
            "[Batch 1] Current Loss: 3.5624\n",
            "[Batch 2] Current Loss: 3.3760\n",
            "[Batch 3] Current Loss: 3.3641\n",
            "[Batch 4] Current Loss: 3.6996\n",
            "[Batch 5] Current Loss: 3.2163\n",
            "[Batch 6] Current Loss: 3.5627\n",
            "[Batch 7] Current Loss: 3.2989\n",
            "[Batch 8] Current Loss: 3.8557\n",
            "[Batch 9] Current Loss: 2.8625\n",
            "[Batch 0] Current Loss: 5.6123\n",
            "[Batch 1] Current Loss: 4.6392\n",
            "[Batch 2] Current Loss: 5.1567\n",
            "[Batch 3] Current Loss: 5.3742\n",
            "[Batch 4] Current Loss: 4.7700\n",
            "[Batch 5] Current Loss: 5.4476\n",
            "[Batch 6] Current Loss: 5.2377\n",
            "[Batch 7] Current Loss: 5.2287\n",
            "[Batch 8] Current Loss: 5.3810\n",
            "[Batch 9] Current Loss: 5.3118\n",
            "Ep 2 (Step 015380): Train loss 3.477, Val loss 5.216\n",
            "[Batch 0] Current Loss: 3.7406\n",
            "[Batch 1] Current Loss: 3.2380\n",
            "[Batch 2] Current Loss: 3.7642\n",
            "[Batch 3] Current Loss: 3.6106\n",
            "[Batch 4] Current Loss: 3.7665\n",
            "[Batch 5] Current Loss: 3.5649\n",
            "[Batch 6] Current Loss: 2.9976\n",
            "[Batch 7] Current Loss: 3.5013\n",
            "[Batch 8] Current Loss: 3.9763\n",
            "[Batch 9] Current Loss: 3.4133\n",
            "[Batch 0] Current Loss: 5.3941\n",
            "[Batch 1] Current Loss: 4.6580\n",
            "[Batch 2] Current Loss: 5.4786\n",
            "[Batch 3] Current Loss: 5.7959\n",
            "[Batch 4] Current Loss: 5.3083\n",
            "[Batch 5] Current Loss: 4.7777\n",
            "[Batch 6] Current Loss: 5.1172\n",
            "[Batch 7] Current Loss: 5.2138\n",
            "[Batch 8] Current Loss: 4.8585\n",
            "[Batch 9] Current Loss: 5.3735\n",
            "Ep 2 (Step 015400): Train loss 3.557, Val loss 5.198\n",
            "[Batch 0] Current Loss: 3.5783\n",
            "[Batch 1] Current Loss: 3.7818\n",
            "[Batch 2] Current Loss: 4.0285\n",
            "[Batch 3] Current Loss: 3.3165\n",
            "[Batch 4] Current Loss: 3.8371\n",
            "[Batch 5] Current Loss: 3.1379\n",
            "[Batch 6] Current Loss: 3.4439\n",
            "[Batch 7] Current Loss: 3.4180\n",
            "[Batch 8] Current Loss: 3.7730\n",
            "[Batch 9] Current Loss: 3.4665\n",
            "[Batch 0] Current Loss: 5.0361\n",
            "[Batch 1] Current Loss: 5.2476\n",
            "[Batch 2] Current Loss: 5.6441\n",
            "[Batch 3] Current Loss: 5.8225\n",
            "[Batch 4] Current Loss: 5.7898\n",
            "[Batch 5] Current Loss: 5.2296\n",
            "[Batch 6] Current Loss: 4.7737\n",
            "[Batch 7] Current Loss: 4.9418\n",
            "[Batch 8] Current Loss: 4.9703\n",
            "[Batch 9] Current Loss: 4.4465\n",
            "Ep 2 (Step 015420): Train loss 3.578, Val loss 5.190\n",
            "[Batch 0] Current Loss: 3.6938\n",
            "[Batch 1] Current Loss: 3.7302\n",
            "[Batch 2] Current Loss: 3.7976\n",
            "[Batch 3] Current Loss: 3.3717\n",
            "[Batch 4] Current Loss: 3.2790\n",
            "[Batch 5] Current Loss: 3.5527\n",
            "[Batch 6] Current Loss: 2.9947\n",
            "[Batch 7] Current Loss: 3.8719\n",
            "[Batch 8] Current Loss: 3.8859\n",
            "[Batch 9] Current Loss: 3.2639\n",
            "[Batch 0] Current Loss: 5.3307\n",
            "[Batch 1] Current Loss: 5.2085\n",
            "[Batch 2] Current Loss: 5.4003\n",
            "[Batch 3] Current Loss: 4.8037\n",
            "[Batch 4] Current Loss: 5.0830\n",
            "[Batch 5] Current Loss: 5.0735\n",
            "[Batch 6] Current Loss: 5.2233\n",
            "[Batch 7] Current Loss: 4.6847\n",
            "[Batch 8] Current Loss: 5.1284\n",
            "[Batch 9] Current Loss: 5.2742\n",
            "Ep 2 (Step 015440): Train loss 3.544, Val loss 5.121\n",
            "[Batch 0] Current Loss: 3.4838\n",
            "[Batch 1] Current Loss: 3.8104\n",
            "[Batch 2] Current Loss: 3.1288\n",
            "[Batch 3] Current Loss: 3.5521\n",
            "[Batch 4] Current Loss: 3.2651\n",
            "[Batch 5] Current Loss: 3.7659\n",
            "[Batch 6] Current Loss: 3.4997\n",
            "[Batch 7] Current Loss: 3.9110\n",
            "[Batch 8] Current Loss: 3.0126\n",
            "[Batch 9] Current Loss: 3.4771\n",
            "[Batch 0] Current Loss: 4.3760\n",
            "[Batch 1] Current Loss: 6.1015\n",
            "[Batch 2] Current Loss: 4.6491\n",
            "[Batch 3] Current Loss: 5.0445\n",
            "[Batch 4] Current Loss: 4.3652\n",
            "[Batch 5] Current Loss: 5.1623\n",
            "[Batch 6] Current Loss: 5.0558\n",
            "[Batch 7] Current Loss: 4.9545\n",
            "[Batch 8] Current Loss: 5.2787\n",
            "[Batch 9] Current Loss: 4.7346\n",
            "Ep 2 (Step 015460): Train loss 3.491, Val loss 4.972\n",
            "[Batch 0] Current Loss: 4.0787\n",
            "[Batch 1] Current Loss: 4.4631\n",
            "[Batch 2] Current Loss: 3.6978\n",
            "[Batch 3] Current Loss: 3.6876\n",
            "[Batch 4] Current Loss: 3.6508\n",
            "[Batch 5] Current Loss: 4.1808\n",
            "[Batch 6] Current Loss: 3.9327\n",
            "[Batch 7] Current Loss: 3.6112\n",
            "[Batch 8] Current Loss: 3.2436\n",
            "[Batch 9] Current Loss: 3.7797\n",
            "[Batch 0] Current Loss: 4.7669\n",
            "[Batch 1] Current Loss: 5.6322\n",
            "[Batch 2] Current Loss: 5.5029\n",
            "[Batch 3] Current Loss: 4.9142\n",
            "[Batch 4] Current Loss: 5.6070\n",
            "[Batch 5] Current Loss: 4.6288\n",
            "[Batch 6] Current Loss: 5.7128\n",
            "[Batch 7] Current Loss: 4.8681\n",
            "[Batch 8] Current Loss: 4.9087\n",
            "[Batch 9] Current Loss: 5.6859\n",
            "Ep 2 (Step 015480): Train loss 3.833, Val loss 5.223\n",
            "[Batch 0] Current Loss: 3.2214\n",
            "[Batch 1] Current Loss: 3.7884\n",
            "[Batch 2] Current Loss: 3.4978\n",
            "[Batch 3] Current Loss: 3.5897\n",
            "[Batch 4] Current Loss: 3.1095\n",
            "[Batch 5] Current Loss: 3.7126\n",
            "[Batch 6] Current Loss: 3.4331\n",
            "[Batch 7] Current Loss: 3.5653\n",
            "[Batch 8] Current Loss: 3.2674\n",
            "[Batch 9] Current Loss: 3.1684\n",
            "[Batch 0] Current Loss: 5.2698\n",
            "[Batch 1] Current Loss: 5.6003\n",
            "[Batch 2] Current Loss: 5.1629\n",
            "[Batch 3] Current Loss: 4.8627\n",
            "[Batch 4] Current Loss: 5.0525\n",
            "[Batch 5] Current Loss: 5.1953\n",
            "[Batch 6] Current Loss: 4.8498\n",
            "[Batch 7] Current Loss: 5.2605\n",
            "[Batch 8] Current Loss: 5.3293\n",
            "[Batch 9] Current Loss: 4.8027\n",
            "Ep 2 (Step 015500): Train loss 3.435, Val loss 5.139\n",
            "[Batch 0] Current Loss: 3.5623\n",
            "[Batch 1] Current Loss: 3.7727\n",
            "[Batch 2] Current Loss: 3.4037\n",
            "[Batch 3] Current Loss: 3.6806\n",
            "[Batch 4] Current Loss: 3.4060\n",
            "[Batch 5] Current Loss: 3.0146\n",
            "[Batch 6] Current Loss: 3.9944\n",
            "[Batch 7] Current Loss: 3.0136\n",
            "[Batch 8] Current Loss: 3.1887\n",
            "[Batch 9] Current Loss: 3.7555\n",
            "[Batch 0] Current Loss: 4.9875\n",
            "[Batch 1] Current Loss: 5.3409\n",
            "[Batch 2] Current Loss: 5.3911\n",
            "[Batch 3] Current Loss: 4.8262\n",
            "[Batch 4] Current Loss: 5.7938\n",
            "[Batch 5] Current Loss: 5.9333\n",
            "[Batch 6] Current Loss: 4.9486\n",
            "[Batch 7] Current Loss: 5.0426\n",
            "[Batch 8] Current Loss: 5.4556\n",
            "[Batch 9] Current Loss: 5.3022\n",
            "Ep 2 (Step 015520): Train loss 3.479, Val loss 5.302\n",
            "[Batch 0] Current Loss: 3.0120\n",
            "[Batch 1] Current Loss: 3.7869\n",
            "[Batch 2] Current Loss: 3.6226\n",
            "[Batch 3] Current Loss: 3.3297\n",
            "[Batch 4] Current Loss: 4.0527\n",
            "[Batch 5] Current Loss: 3.4455\n",
            "[Batch 6] Current Loss: 4.0511\n",
            "[Batch 7] Current Loss: 3.3314\n",
            "[Batch 8] Current Loss: 3.4857\n",
            "[Batch 9] Current Loss: 3.9401\n",
            "[Batch 0] Current Loss: 5.5739\n",
            "[Batch 1] Current Loss: 5.3647\n",
            "[Batch 2] Current Loss: 4.2176\n",
            "[Batch 3] Current Loss: 5.2415\n",
            "[Batch 4] Current Loss: 5.7587\n",
            "[Batch 5] Current Loss: 4.6968\n",
            "[Batch 6] Current Loss: 4.8130\n",
            "[Batch 7] Current Loss: 4.9239\n",
            "[Batch 8] Current Loss: 4.3111\n",
            "[Batch 9] Current Loss: 5.4905\n",
            "Ep 2 (Step 015540): Train loss 3.606, Val loss 5.039\n",
            "[Batch 0] Current Loss: 3.3589\n",
            "[Batch 1] Current Loss: 3.8609\n",
            "[Batch 2] Current Loss: 3.7739\n",
            "[Batch 3] Current Loss: 3.8710\n",
            "[Batch 4] Current Loss: 3.3022\n",
            "[Batch 5] Current Loss: 3.9324\n",
            "[Batch 6] Current Loss: 3.7080\n",
            "[Batch 7] Current Loss: 3.6483\n",
            "[Batch 8] Current Loss: 3.7467\n",
            "[Batch 9] Current Loss: 4.4653\n",
            "[Batch 0] Current Loss: 5.3920\n",
            "[Batch 1] Current Loss: 5.8610\n",
            "[Batch 2] Current Loss: 4.9148\n",
            "[Batch 3] Current Loss: 5.6878\n",
            "[Batch 4] Current Loss: 4.1745\n",
            "[Batch 5] Current Loss: 6.1594\n",
            "[Batch 6] Current Loss: 5.3259\n",
            "[Batch 7] Current Loss: 5.6829\n",
            "[Batch 8] Current Loss: 4.5494\n",
            "[Batch 9] Current Loss: 5.3706\n",
            "Ep 2 (Step 015560): Train loss 3.767, Val loss 5.312\n",
            "[Batch 0] Current Loss: 3.4969\n",
            "[Batch 1] Current Loss: 3.2134\n",
            "[Batch 2] Current Loss: 3.5301\n",
            "[Batch 3] Current Loss: 3.3656\n",
            "[Batch 4] Current Loss: 3.6040\n",
            "[Batch 5] Current Loss: 3.3919\n",
            "[Batch 6] Current Loss: 3.0939\n",
            "[Batch 7] Current Loss: 3.5468\n",
            "[Batch 8] Current Loss: 3.6294\n",
            "[Batch 9] Current Loss: 3.9363\n",
            "[Batch 0] Current Loss: 5.6744\n",
            "[Batch 1] Current Loss: 4.8363\n",
            "[Batch 2] Current Loss: 5.5927\n",
            "[Batch 3] Current Loss: 5.4447\n",
            "[Batch 4] Current Loss: 4.8199\n",
            "[Batch 5] Current Loss: 4.2793\n",
            "[Batch 6] Current Loss: 5.4291\n",
            "[Batch 7] Current Loss: 5.3511\n",
            "[Batch 8] Current Loss: 5.6571\n",
            "[Batch 9] Current Loss: 5.4909\n",
            "Ep 2 (Step 015580): Train loss 3.481, Val loss 5.258\n",
            "[Batch 0] Current Loss: 3.7133\n",
            "[Batch 1] Current Loss: 3.6655\n",
            "[Batch 2] Current Loss: 3.6483\n",
            "[Batch 3] Current Loss: 3.4586\n",
            "[Batch 4] Current Loss: 3.6349\n",
            "[Batch 5] Current Loss: 3.6198\n",
            "[Batch 6] Current Loss: 3.5265\n",
            "[Batch 7] Current Loss: 3.5421\n",
            "[Batch 8] Current Loss: 3.5285\n",
            "[Batch 9] Current Loss: 3.4746\n",
            "[Batch 0] Current Loss: 5.3702\n",
            "[Batch 1] Current Loss: 4.8777\n",
            "[Batch 2] Current Loss: 5.6983\n",
            "[Batch 3] Current Loss: 4.6159\n",
            "[Batch 4] Current Loss: 5.2784\n",
            "[Batch 5] Current Loss: 4.8390\n",
            "[Batch 6] Current Loss: 5.3147\n",
            "[Batch 7] Current Loss: 5.6151\n",
            "[Batch 8] Current Loss: 5.2286\n",
            "[Batch 9] Current Loss: 4.9733\n",
            "Ep 2 (Step 015600): Train loss 3.581, Val loss 5.181\n",
            "[Batch 0] Current Loss: 3.8448\n",
            "[Batch 1] Current Loss: 3.5635\n",
            "[Batch 2] Current Loss: 3.3515\n",
            "[Batch 3] Current Loss: 3.5908\n",
            "[Batch 4] Current Loss: 3.7966\n",
            "[Batch 5] Current Loss: 3.8585\n",
            "[Batch 6] Current Loss: 3.6732\n",
            "[Batch 7] Current Loss: 3.2602\n",
            "[Batch 8] Current Loss: 3.8590\n",
            "[Batch 9] Current Loss: 4.0211\n",
            "[Batch 0] Current Loss: 4.8764\n",
            "[Batch 1] Current Loss: 5.2907\n",
            "[Batch 2] Current Loss: 4.6679\n",
            "[Batch 3] Current Loss: 5.5271\n",
            "[Batch 4] Current Loss: 5.4886\n",
            "[Batch 5] Current Loss: 4.6024\n",
            "[Batch 6] Current Loss: 4.0353\n",
            "[Batch 7] Current Loss: 4.6392\n",
            "[Batch 8] Current Loss: 5.6163\n",
            "[Batch 9] Current Loss: 4.7750\n",
            "Ep 2 (Step 015620): Train loss 3.682, Val loss 4.952\n",
            "[Batch 0] Current Loss: 3.7623\n",
            "[Batch 1] Current Loss: 3.9193\n",
            "[Batch 2] Current Loss: 3.0206\n",
            "[Batch 3] Current Loss: 4.1295\n",
            "[Batch 4] Current Loss: 3.4642\n",
            "[Batch 5] Current Loss: 3.5956\n",
            "[Batch 6] Current Loss: 3.3571\n",
            "[Batch 7] Current Loss: 3.4942\n",
            "[Batch 8] Current Loss: 4.1261\n",
            "[Batch 9] Current Loss: 3.9233\n",
            "[Batch 0] Current Loss: 5.7429\n",
            "[Batch 1] Current Loss: 5.2927\n",
            "[Batch 2] Current Loss: 5.3665\n",
            "[Batch 3] Current Loss: 5.1781\n",
            "[Batch 4] Current Loss: 5.6847\n",
            "[Batch 5] Current Loss: 5.3022\n",
            "[Batch 6] Current Loss: 5.5722\n",
            "[Batch 7] Current Loss: 4.4823\n",
            "[Batch 8] Current Loss: 5.6675\n",
            "[Batch 9] Current Loss: 5.1268\n",
            "Ep 2 (Step 015640): Train loss 3.679, Val loss 5.342\n",
            "[Batch 0] Current Loss: 3.4038\n",
            "[Batch 1] Current Loss: 3.3350\n",
            "[Batch 2] Current Loss: 3.8346\n",
            "[Batch 3] Current Loss: 3.4240\n",
            "[Batch 4] Current Loss: 3.6995\n",
            "[Batch 5] Current Loss: 2.9966\n",
            "[Batch 6] Current Loss: 3.1637\n",
            "[Batch 7] Current Loss: 3.7222\n",
            "[Batch 8] Current Loss: 3.5364\n",
            "[Batch 9] Current Loss: 3.9145\n",
            "[Batch 0] Current Loss: 5.2568\n",
            "[Batch 1] Current Loss: 5.4681\n",
            "[Batch 2] Current Loss: 5.7621\n",
            "[Batch 3] Current Loss: 5.0863\n",
            "[Batch 4] Current Loss: 4.7145\n",
            "[Batch 5] Current Loss: 5.1065\n",
            "[Batch 6] Current Loss: 4.3133\n",
            "[Batch 7] Current Loss: 5.6501\n",
            "[Batch 8] Current Loss: 5.4551\n",
            "[Batch 9] Current Loss: 5.6018\n",
            "Ep 2 (Step 015660): Train loss 3.503, Val loss 5.241\n",
            "[Batch 0] Current Loss: 3.7200\n",
            "[Batch 1] Current Loss: 2.7771\n",
            "[Batch 2] Current Loss: 3.5137\n",
            "[Batch 3] Current Loss: 4.2066\n",
            "[Batch 4] Current Loss: 3.5062\n",
            "[Batch 5] Current Loss: 3.5093\n",
            "[Batch 6] Current Loss: 3.6872\n",
            "[Batch 7] Current Loss: 3.1008\n",
            "[Batch 8] Current Loss: 3.2890\n",
            "[Batch 9] Current Loss: 3.2101\n",
            "[Batch 0] Current Loss: 5.0336\n",
            "[Batch 1] Current Loss: 4.7621\n",
            "[Batch 2] Current Loss: 4.9895\n",
            "[Batch 3] Current Loss: 5.8055\n",
            "[Batch 4] Current Loss: 4.8747\n",
            "[Batch 5] Current Loss: 5.4989\n",
            "[Batch 6] Current Loss: 4.9691\n",
            "[Batch 7] Current Loss: 5.3829\n",
            "[Batch 8] Current Loss: 4.8540\n",
            "[Batch 9] Current Loss: 5.3429\n",
            "Ep 2 (Step 015680): Train loss 3.452, Val loss 5.151\n",
            "[Batch 0] Current Loss: 3.4130\n",
            "[Batch 1] Current Loss: 3.6149\n",
            "[Batch 2] Current Loss: 3.6090\n",
            "[Batch 3] Current Loss: 3.4243\n",
            "[Batch 4] Current Loss: 3.2737\n",
            "[Batch 5] Current Loss: 3.9880\n",
            "[Batch 6] Current Loss: 3.7651\n",
            "[Batch 7] Current Loss: 3.4191\n",
            "[Batch 8] Current Loss: 3.8870\n",
            "[Batch 9] Current Loss: 3.6972\n",
            "[Batch 0] Current Loss: 5.6833\n",
            "[Batch 1] Current Loss: 4.9988\n",
            "[Batch 2] Current Loss: 5.6401\n",
            "[Batch 3] Current Loss: 5.3050\n",
            "[Batch 4] Current Loss: 4.6278\n",
            "[Batch 5] Current Loss: 5.0149\n",
            "[Batch 6] Current Loss: 5.2158\n",
            "[Batch 7] Current Loss: 5.2968\n",
            "[Batch 8] Current Loss: 5.2530\n",
            "[Batch 9] Current Loss: 5.6367\n",
            "Ep 2 (Step 015700): Train loss 3.609, Val loss 5.267\n",
            "[Batch 0] Current Loss: 3.4007\n",
            "[Batch 1] Current Loss: 4.1836\n",
            "[Batch 2] Current Loss: 3.7872\n",
            "[Batch 3] Current Loss: 3.5654\n",
            "[Batch 4] Current Loss: 3.9129\n",
            "[Batch 5] Current Loss: 2.8278\n",
            "[Batch 6] Current Loss: 3.6483\n",
            "[Batch 7] Current Loss: 3.3572\n",
            "[Batch 8] Current Loss: 3.4979\n",
            "[Batch 9] Current Loss: 3.3640\n",
            "[Batch 0] Current Loss: 5.1268\n",
            "[Batch 1] Current Loss: 4.9624\n",
            "[Batch 2] Current Loss: 4.7805\n",
            "[Batch 3] Current Loss: 5.1454\n",
            "[Batch 4] Current Loss: 5.4502\n",
            "[Batch 5] Current Loss: 5.5058\n",
            "[Batch 6] Current Loss: 5.0400\n",
            "[Batch 7] Current Loss: 5.5081\n",
            "[Batch 8] Current Loss: 5.0165\n",
            "[Batch 9] Current Loss: 5.3384\n",
            "Ep 2 (Step 015720): Train loss 3.555, Val loss 5.187\n",
            "[Batch 0] Current Loss: 3.7530\n",
            "[Batch 1] Current Loss: 3.8210\n",
            "[Batch 2] Current Loss: 3.4703\n",
            "[Batch 3] Current Loss: 3.4244\n",
            "[Batch 4] Current Loss: 3.4862\n",
            "[Batch 5] Current Loss: 3.3206\n",
            "[Batch 6] Current Loss: 3.8696\n",
            "[Batch 7] Current Loss: 3.0651\n",
            "[Batch 8] Current Loss: 4.0723\n",
            "[Batch 9] Current Loss: 3.4963\n",
            "[Batch 0] Current Loss: 5.5765\n",
            "[Batch 1] Current Loss: 5.1481\n",
            "[Batch 2] Current Loss: 5.8337\n",
            "[Batch 3] Current Loss: 5.1861\n",
            "[Batch 4] Current Loss: 5.9833\n",
            "[Batch 5] Current Loss: 5.8928\n",
            "[Batch 6] Current Loss: 5.0786\n",
            "[Batch 7] Current Loss: 5.5743\n",
            "[Batch 8] Current Loss: 4.4885\n",
            "[Batch 9] Current Loss: 5.5948\n",
            "Ep 2 (Step 015740): Train loss 3.578, Val loss 5.436\n",
            "[Batch 0] Current Loss: 4.1414\n",
            "[Batch 1] Current Loss: 4.1686\n",
            "[Batch 2] Current Loss: 3.7185\n",
            "[Batch 3] Current Loss: 2.9174\n",
            "[Batch 4] Current Loss: 3.5179\n",
            "[Batch 5] Current Loss: 3.7301\n",
            "[Batch 6] Current Loss: 3.2774\n",
            "[Batch 7] Current Loss: 3.2216\n",
            "[Batch 8] Current Loss: 3.8336\n",
            "[Batch 9] Current Loss: 3.7117\n",
            "[Batch 0] Current Loss: 5.5109\n",
            "[Batch 1] Current Loss: 5.4410\n",
            "[Batch 2] Current Loss: 5.3485\n",
            "[Batch 3] Current Loss: 4.8526\n",
            "[Batch 4] Current Loss: 5.3396\n",
            "[Batch 5] Current Loss: 5.0647\n",
            "[Batch 6] Current Loss: 5.2399\n",
            "[Batch 7] Current Loss: 6.0832\n",
            "[Batch 8] Current Loss: 4.7622\n",
            "[Batch 9] Current Loss: 5.8056\n",
            "Ep 2 (Step 015760): Train loss 3.624, Val loss 5.345\n",
            "[Batch 0] Current Loss: 3.2336\n",
            "[Batch 1] Current Loss: 3.8280\n",
            "[Batch 2] Current Loss: 3.2653\n",
            "[Batch 3] Current Loss: 3.5498\n",
            "[Batch 4] Current Loss: 3.2729\n",
            "[Batch 5] Current Loss: 3.6797\n",
            "[Batch 6] Current Loss: 3.2887\n",
            "[Batch 7] Current Loss: 3.5284\n",
            "[Batch 8] Current Loss: 3.8157\n",
            "[Batch 9] Current Loss: 3.7832\n",
            "[Batch 0] Current Loss: 5.0564\n",
            "[Batch 1] Current Loss: 5.2013\n",
            "[Batch 2] Current Loss: 5.3631\n",
            "[Batch 3] Current Loss: 4.7223\n",
            "[Batch 4] Current Loss: 4.9179\n",
            "[Batch 5] Current Loss: 5.0800\n",
            "[Batch 6] Current Loss: 4.3458\n",
            "[Batch 7] Current Loss: 5.7288\n",
            "[Batch 8] Current Loss: 5.3581\n",
            "[Batch 9] Current Loss: 5.2488\n",
            "Ep 2 (Step 015780): Train loss 3.525, Val loss 5.102\n",
            "[Batch 0] Current Loss: 2.9091\n",
            "[Batch 1] Current Loss: 3.2166\n",
            "[Batch 2] Current Loss: 3.7073\n",
            "[Batch 3] Current Loss: 3.9733\n",
            "[Batch 4] Current Loss: 3.6419\n",
            "[Batch 5] Current Loss: 3.4360\n",
            "[Batch 6] Current Loss: 4.0898\n",
            "[Batch 7] Current Loss: 3.4565\n",
            "[Batch 8] Current Loss: 3.9136\n",
            "[Batch 9] Current Loss: 3.2674\n",
            "[Batch 0] Current Loss: 4.8603\n",
            "[Batch 1] Current Loss: 4.9516\n",
            "[Batch 2] Current Loss: 5.3812\n",
            "[Batch 3] Current Loss: 5.1945\n",
            "[Batch 4] Current Loss: 5.0622\n",
            "[Batch 5] Current Loss: 5.2881\n",
            "[Batch 6] Current Loss: 4.9842\n",
            "[Batch 7] Current Loss: 5.4804\n",
            "[Batch 8] Current Loss: 5.0222\n",
            "[Batch 9] Current Loss: 4.7629\n",
            "Ep 2 (Step 015800): Train loss 3.561, Val loss 5.099\n",
            "[Batch 0] Current Loss: 4.5180\n",
            "[Batch 1] Current Loss: 3.7406\n",
            "[Batch 2] Current Loss: 3.7687\n",
            "[Batch 3] Current Loss: 3.3411\n",
            "[Batch 4] Current Loss: 4.0945\n",
            "[Batch 5] Current Loss: 3.6578\n",
            "[Batch 6] Current Loss: 3.2059\n",
            "[Batch 7] Current Loss: 3.5480\n",
            "[Batch 8] Current Loss: 3.8384\n",
            "[Batch 9] Current Loss: 4.2027\n",
            "[Batch 0] Current Loss: 5.4896\n",
            "[Batch 1] Current Loss: 4.7908\n",
            "[Batch 2] Current Loss: 5.3975\n",
            "[Batch 3] Current Loss: 4.8526\n",
            "[Batch 4] Current Loss: 5.0691\n",
            "[Batch 5] Current Loss: 5.7588\n",
            "[Batch 6] Current Loss: 4.7272\n",
            "[Batch 7] Current Loss: 5.6554\n",
            "[Batch 8] Current Loss: 5.0642\n",
            "[Batch 9] Current Loss: 5.2395\n",
            "Ep 2 (Step 015820): Train loss 3.792, Val loss 5.204\n",
            "[Batch 0] Current Loss: 3.6369\n",
            "[Batch 1] Current Loss: 3.2318\n",
            "[Batch 2] Current Loss: 3.2892\n",
            "[Batch 3] Current Loss: 3.7527\n",
            "[Batch 4] Current Loss: 4.4779\n",
            "[Batch 5] Current Loss: 3.2727\n",
            "[Batch 6] Current Loss: 2.9696\n",
            "[Batch 7] Current Loss: 3.4155\n",
            "[Batch 8] Current Loss: 3.5083\n",
            "[Batch 9] Current Loss: 3.5999\n",
            "[Batch 0] Current Loss: 4.9532\n",
            "[Batch 1] Current Loss: 5.1419\n",
            "[Batch 2] Current Loss: 5.4898\n",
            "[Batch 3] Current Loss: 5.4332\n",
            "[Batch 4] Current Loss: 4.9515\n",
            "[Batch 5] Current Loss: 5.1635\n",
            "[Batch 6] Current Loss: 5.4001\n",
            "[Batch 7] Current Loss: 4.5909\n",
            "[Batch 8] Current Loss: 5.4251\n",
            "[Batch 9] Current Loss: 4.9460\n",
            "Ep 2 (Step 015840): Train loss 3.515, Val loss 5.150\n",
            "[Batch 0] Current Loss: 3.6929\n",
            "[Batch 1] Current Loss: 3.2669\n",
            "[Batch 2] Current Loss: 3.5247\n",
            "[Batch 3] Current Loss: 3.8644\n",
            "[Batch 4] Current Loss: 3.0888\n",
            "[Batch 5] Current Loss: 3.9571\n",
            "[Batch 6] Current Loss: 4.0476\n",
            "[Batch 7] Current Loss: 3.6365\n",
            "[Batch 8] Current Loss: 3.6820\n",
            "[Batch 9] Current Loss: 3.0994\n",
            "[Batch 0] Current Loss: 5.9282\n",
            "[Batch 1] Current Loss: 4.9706\n",
            "[Batch 2] Current Loss: 5.3050\n",
            "[Batch 3] Current Loss: 5.6742\n",
            "[Batch 4] Current Loss: 5.6767\n",
            "[Batch 5] Current Loss: 5.4479\n",
            "[Batch 6] Current Loss: 5.0927\n",
            "[Batch 7] Current Loss: 4.8882\n",
            "[Batch 8] Current Loss: 5.3328\n",
            "[Batch 9] Current Loss: 5.2078\n",
            "Ep 2 (Step 015860): Train loss 3.586, Val loss 5.352\n",
            "[Batch 0] Current Loss: 3.3334\n",
            "[Batch 1] Current Loss: 3.4738\n",
            "[Batch 2] Current Loss: 3.1655\n",
            "[Batch 3] Current Loss: 3.4189\n",
            "[Batch 4] Current Loss: 4.1014\n",
            "[Batch 5] Current Loss: 3.8844\n",
            "[Batch 6] Current Loss: 3.4436\n",
            "[Batch 7] Current Loss: 3.6541\n",
            "[Batch 8] Current Loss: 3.8633\n",
            "[Batch 9] Current Loss: 3.8259\n",
            "[Batch 0] Current Loss: 4.5840\n",
            "[Batch 1] Current Loss: 4.5044\n",
            "[Batch 2] Current Loss: 6.1526\n",
            "[Batch 3] Current Loss: 4.9415\n",
            "[Batch 4] Current Loss: 5.0151\n",
            "[Batch 5] Current Loss: 5.3520\n",
            "[Batch 6] Current Loss: 5.4145\n",
            "[Batch 7] Current Loss: 5.0014\n",
            "[Batch 8] Current Loss: 5.2700\n",
            "[Batch 9] Current Loss: 4.8848\n",
            "Ep 2 (Step 015880): Train loss 3.616, Val loss 5.112\n",
            "[Batch 0] Current Loss: 3.9787\n",
            "[Batch 1] Current Loss: 3.2219\n",
            "[Batch 2] Current Loss: 3.9269\n",
            "[Batch 3] Current Loss: 3.6024\n",
            "[Batch 4] Current Loss: 3.9610\n",
            "[Batch 5] Current Loss: 4.0264\n",
            "[Batch 6] Current Loss: 3.5810\n",
            "[Batch 7] Current Loss: 3.1838\n",
            "[Batch 8] Current Loss: 3.4429\n",
            "[Batch 9] Current Loss: 2.9735\n",
            "[Batch 0] Current Loss: 5.4426\n",
            "[Batch 1] Current Loss: 5.4613\n",
            "[Batch 2] Current Loss: 4.8393\n",
            "[Batch 3] Current Loss: 5.0998\n",
            "[Batch 4] Current Loss: 5.6403\n",
            "[Batch 5] Current Loss: 4.7209\n",
            "[Batch 6] Current Loss: 5.2989\n",
            "[Batch 7] Current Loss: 5.0326\n",
            "[Batch 8] Current Loss: 4.8031\n",
            "[Batch 9] Current Loss: 4.8952\n",
            "Ep 2 (Step 015900): Train loss 3.590, Val loss 5.123\n",
            "[Batch 0] Current Loss: 4.1663\n",
            "[Batch 1] Current Loss: 3.8163\n",
            "[Batch 2] Current Loss: 3.6782\n",
            "[Batch 3] Current Loss: 3.6472\n",
            "[Batch 4] Current Loss: 3.6595\n",
            "[Batch 5] Current Loss: 4.0762\n",
            "[Batch 6] Current Loss: 3.4286\n",
            "[Batch 7] Current Loss: 3.6699\n",
            "[Batch 8] Current Loss: 3.3841\n",
            "[Batch 9] Current Loss: 4.0895\n",
            "[Batch 0] Current Loss: 5.6568\n",
            "[Batch 1] Current Loss: 6.0512\n",
            "[Batch 2] Current Loss: 5.3459\n",
            "[Batch 3] Current Loss: 5.0069\n",
            "[Batch 4] Current Loss: 5.5129\n",
            "[Batch 5] Current Loss: 4.7176\n",
            "[Batch 6] Current Loss: 4.9185\n",
            "[Batch 7] Current Loss: 5.2355\n",
            "[Batch 8] Current Loss: 5.7267\n",
            "[Batch 9] Current Loss: 4.9240\n",
            "Ep 2 (Step 015920): Train loss 3.762, Val loss 5.310\n",
            "[Batch 0] Current Loss: 4.2828\n",
            "[Batch 1] Current Loss: 3.9335\n",
            "[Batch 2] Current Loss: 3.3814\n",
            "[Batch 3] Current Loss: 3.3160\n",
            "[Batch 4] Current Loss: 3.4309\n",
            "[Batch 5] Current Loss: 3.7301\n",
            "[Batch 6] Current Loss: 3.8398\n",
            "[Batch 7] Current Loss: 3.7257\n",
            "[Batch 8] Current Loss: 3.6155\n",
            "[Batch 9] Current Loss: 3.8579\n",
            "[Batch 0] Current Loss: 5.5323\n",
            "[Batch 1] Current Loss: 5.4917\n",
            "[Batch 2] Current Loss: 4.9532\n",
            "[Batch 3] Current Loss: 4.7007\n",
            "[Batch 4] Current Loss: 5.2319\n",
            "[Batch 5] Current Loss: 4.7391\n",
            "[Batch 6] Current Loss: 4.9091\n",
            "[Batch 7] Current Loss: 5.4983\n",
            "[Batch 8] Current Loss: 5.4496\n",
            "[Batch 9] Current Loss: 5.2718\n",
            "Ep 2 (Step 015940): Train loss 3.711, Val loss 5.178\n",
            "[Batch 0] Current Loss: 3.6127\n",
            "[Batch 1] Current Loss: 3.3140\n",
            "[Batch 2] Current Loss: 3.3666\n",
            "[Batch 3] Current Loss: 3.8742\n",
            "[Batch 4] Current Loss: 3.4666\n",
            "[Batch 5] Current Loss: 3.9381\n",
            "[Batch 6] Current Loss: 3.0926\n",
            "[Batch 7] Current Loss: 3.5664\n",
            "[Batch 8] Current Loss: 3.2283\n",
            "[Batch 9] Current Loss: 3.1086\n",
            "[Batch 0] Current Loss: 5.4451\n",
            "[Batch 1] Current Loss: 5.7356\n",
            "[Batch 2] Current Loss: 4.8957\n",
            "[Batch 3] Current Loss: 4.8442\n",
            "[Batch 4] Current Loss: 4.5624\n",
            "[Batch 5] Current Loss: 5.6845\n",
            "[Batch 6] Current Loss: 5.3124\n",
            "[Batch 7] Current Loss: 5.3600\n",
            "[Batch 8] Current Loss: 5.4293\n",
            "[Batch 9] Current Loss: 5.3726\n",
            "Ep 2 (Step 015960): Train loss 3.457, Val loss 5.264\n",
            "[Batch 0] Current Loss: 2.8257\n",
            "[Batch 1] Current Loss: 3.5152\n",
            "[Batch 2] Current Loss: 3.5111\n",
            "[Batch 3] Current Loss: 3.1935\n",
            "[Batch 4] Current Loss: 3.1929\n",
            "[Batch 5] Current Loss: 3.4547\n",
            "[Batch 6] Current Loss: 3.5609\n",
            "[Batch 7] Current Loss: 3.1589\n",
            "[Batch 8] Current Loss: 3.9250\n",
            "[Batch 9] Current Loss: 3.3139\n",
            "[Batch 0] Current Loss: 5.2320\n",
            "[Batch 1] Current Loss: 5.3139\n",
            "[Batch 2] Current Loss: 5.7151\n",
            "[Batch 3] Current Loss: 4.6704\n",
            "[Batch 4] Current Loss: 4.7038\n",
            "[Batch 5] Current Loss: 4.8676\n",
            "[Batch 6] Current Loss: 5.1923\n",
            "[Batch 7] Current Loss: 5.0502\n",
            "[Batch 8] Current Loss: 5.5333\n",
            "[Batch 9] Current Loss: 5.5631\n",
            "Ep 2 (Step 015980): Train loss 3.365, Val loss 5.184\n",
            "[Batch 0] Current Loss: 3.1779\n",
            "[Batch 1] Current Loss: 3.5723\n",
            "[Batch 2] Current Loss: 2.7958\n",
            "[Batch 3] Current Loss: 3.4148\n",
            "[Batch 4] Current Loss: 3.4746\n",
            "[Batch 5] Current Loss: 3.6324\n",
            "[Batch 6] Current Loss: 3.3694\n",
            "[Batch 7] Current Loss: 3.3359\n",
            "[Batch 8] Current Loss: 3.1015\n",
            "[Batch 9] Current Loss: 3.6095\n",
            "[Batch 0] Current Loss: 5.1149\n",
            "[Batch 1] Current Loss: 5.0031\n",
            "[Batch 2] Current Loss: 5.3255\n",
            "[Batch 3] Current Loss: 5.6203\n",
            "[Batch 4] Current Loss: 5.4606\n",
            "[Batch 5] Current Loss: 5.0623\n",
            "[Batch 6] Current Loss: 5.2271\n",
            "[Batch 7] Current Loss: 4.7470\n",
            "[Batch 8] Current Loss: 5.0381\n",
            "[Batch 9] Current Loss: 5.6598\n",
            "Ep 2 (Step 016000): Train loss 3.348, Val loss 5.226\n",
            "[Batch 0] Current Loss: 3.4085\n",
            "[Batch 1] Current Loss: 3.3439\n",
            "[Batch 2] Current Loss: 3.9299\n",
            "[Batch 3] Current Loss: 3.4285\n",
            "[Batch 4] Current Loss: 3.0761\n",
            "[Batch 5] Current Loss: 3.8588\n",
            "[Batch 6] Current Loss: 3.8233\n",
            "[Batch 7] Current Loss: 3.9832\n",
            "[Batch 8] Current Loss: 2.8052\n",
            "[Batch 9] Current Loss: 3.0822\n",
            "[Batch 0] Current Loss: 4.8983\n",
            "[Batch 1] Current Loss: 5.2799\n",
            "[Batch 2] Current Loss: 5.6298\n",
            "[Batch 3] Current Loss: 4.9716\n",
            "[Batch 4] Current Loss: 4.0325\n",
            "[Batch 5] Current Loss: 5.4324\n",
            "[Batch 6] Current Loss: 5.0413\n",
            "[Batch 7] Current Loss: 4.8528\n",
            "[Batch 8] Current Loss: 5.1314\n",
            "[Batch 9] Current Loss: 5.4863\n",
            "Ep 2 (Step 016020): Train loss 3.474, Val loss 5.076\n",
            "[Batch 0] Current Loss: 3.5164\n",
            "[Batch 1] Current Loss: 3.4944\n",
            "[Batch 2] Current Loss: 3.6495\n",
            "[Batch 3] Current Loss: 3.1952\n",
            "[Batch 4] Current Loss: 3.9397\n",
            "[Batch 5] Current Loss: 3.4327\n",
            "[Batch 6] Current Loss: 3.7463\n",
            "[Batch 7] Current Loss: 4.0463\n",
            "[Batch 8] Current Loss: 3.6331\n",
            "[Batch 9] Current Loss: 3.0420\n",
            "[Batch 0] Current Loss: 5.0347\n",
            "[Batch 1] Current Loss: 5.0527\n",
            "[Batch 2] Current Loss: 5.2578\n",
            "[Batch 3] Current Loss: 4.9049\n",
            "[Batch 4] Current Loss: 5.3449\n",
            "[Batch 5] Current Loss: 5.0558\n",
            "[Batch 6] Current Loss: 5.3572\n",
            "[Batch 7] Current Loss: 5.6487\n",
            "[Batch 8] Current Loss: 5.1264\n",
            "[Batch 9] Current Loss: 5.5399\n",
            "Ep 2 (Step 016040): Train loss 3.570, Val loss 5.232\n",
            "[Batch 0] Current Loss: 3.9080\n",
            "[Batch 1] Current Loss: 3.6404\n",
            "[Batch 2] Current Loss: 3.1924\n",
            "[Batch 3] Current Loss: 4.2917\n",
            "[Batch 4] Current Loss: 3.6429\n",
            "[Batch 5] Current Loss: 3.3759\n",
            "[Batch 6] Current Loss: 3.9104\n",
            "[Batch 7] Current Loss: 3.9336\n",
            "[Batch 8] Current Loss: 3.3430\n",
            "[Batch 9] Current Loss: 3.3406\n",
            "[Batch 0] Current Loss: 5.2619\n",
            "[Batch 1] Current Loss: 5.8133\n",
            "[Batch 2] Current Loss: 4.9904\n",
            "[Batch 3] Current Loss: 5.0726\n",
            "[Batch 4] Current Loss: 5.2505\n",
            "[Batch 5] Current Loss: 5.3639\n",
            "[Batch 6] Current Loss: 5.2189\n",
            "[Batch 7] Current Loss: 5.2192\n",
            "[Batch 8] Current Loss: 4.6901\n",
            "[Batch 9] Current Loss: 5.4609\n",
            "Ep 2 (Step 016060): Train loss 3.658, Val loss 5.234\n",
            "[Batch 0] Current Loss: 3.5739\n",
            "[Batch 1] Current Loss: 3.4926\n",
            "[Batch 2] Current Loss: 3.1928\n",
            "[Batch 3] Current Loss: 3.4594\n",
            "[Batch 4] Current Loss: 3.6657\n",
            "[Batch 5] Current Loss: 2.8338\n",
            "[Batch 6] Current Loss: 3.9125\n",
            "[Batch 7] Current Loss: 3.6120\n",
            "[Batch 8] Current Loss: 3.3672\n",
            "[Batch 9] Current Loss: 3.5866\n",
            "[Batch 0] Current Loss: 5.0023\n",
            "[Batch 1] Current Loss: 4.7161\n",
            "[Batch 2] Current Loss: 4.8892\n",
            "[Batch 3] Current Loss: 5.3432\n",
            "[Batch 4] Current Loss: 5.4942\n",
            "[Batch 5] Current Loss: 5.3548\n",
            "[Batch 6] Current Loss: 4.9186\n",
            "[Batch 7] Current Loss: 5.7113\n",
            "[Batch 8] Current Loss: 4.6270\n",
            "[Batch 9] Current Loss: 5.6580\n",
            "Ep 2 (Step 016080): Train loss 3.470, Val loss 5.171\n",
            "[Batch 0] Current Loss: 3.4558\n",
            "[Batch 1] Current Loss: 3.8089\n",
            "[Batch 2] Current Loss: 3.7661\n",
            "[Batch 3] Current Loss: 3.8233\n",
            "[Batch 4] Current Loss: 2.9965\n",
            "[Batch 5] Current Loss: 3.4978\n",
            "[Batch 6] Current Loss: 3.4941\n",
            "[Batch 7] Current Loss: 3.6771\n",
            "[Batch 8] Current Loss: 3.0835\n",
            "[Batch 9] Current Loss: 3.1802\n",
            "[Batch 0] Current Loss: 4.5530\n",
            "[Batch 1] Current Loss: 5.2355\n",
            "[Batch 2] Current Loss: 5.2712\n",
            "[Batch 3] Current Loss: 5.0426\n",
            "[Batch 4] Current Loss: 5.3438\n",
            "[Batch 5] Current Loss: 5.2482\n",
            "[Batch 6] Current Loss: 4.6653\n",
            "[Batch 7] Current Loss: 4.6438\n",
            "[Batch 8] Current Loss: 5.1153\n",
            "[Batch 9] Current Loss: 5.1107\n",
            "Ep 2 (Step 016100): Train loss 3.478, Val loss 5.023\n",
            "[Batch 0] Current Loss: 4.2697\n",
            "[Batch 1] Current Loss: 3.3593\n",
            "[Batch 2] Current Loss: 3.2509\n",
            "[Batch 3] Current Loss: 3.5481\n",
            "[Batch 4] Current Loss: 3.2837\n",
            "[Batch 5] Current Loss: 3.0693\n",
            "[Batch 6] Current Loss: 3.3690\n",
            "[Batch 7] Current Loss: 3.2967\n",
            "[Batch 8] Current Loss: 3.9620\n",
            "[Batch 9] Current Loss: 3.7748\n",
            "[Batch 0] Current Loss: 4.9630\n",
            "[Batch 1] Current Loss: 4.3395\n",
            "[Batch 2] Current Loss: 4.9303\n",
            "[Batch 3] Current Loss: 5.6415\n",
            "[Batch 4] Current Loss: 3.8998\n",
            "[Batch 5] Current Loss: 5.4981\n",
            "[Batch 6] Current Loss: 5.2380\n",
            "[Batch 7] Current Loss: 4.8267\n",
            "[Batch 8] Current Loss: 5.1973\n",
            "[Batch 9] Current Loss: 5.6430\n",
            "Ep 2 (Step 016120): Train loss 3.518, Val loss 5.018\n",
            "[Batch 0] Current Loss: 3.4521\n",
            "[Batch 1] Current Loss: 3.0893\n",
            "[Batch 2] Current Loss: 3.6486\n",
            "[Batch 3] Current Loss: 3.1581\n",
            "[Batch 4] Current Loss: 3.5968\n",
            "[Batch 5] Current Loss: 3.8290\n",
            "[Batch 6] Current Loss: 3.2090\n",
            "[Batch 7] Current Loss: 4.0039\n",
            "[Batch 8] Current Loss: 3.9028\n",
            "[Batch 9] Current Loss: 3.0624\n",
            "[Batch 0] Current Loss: 5.4746\n",
            "[Batch 1] Current Loss: 4.7639\n",
            "[Batch 2] Current Loss: 5.2714\n",
            "[Batch 3] Current Loss: 4.4154\n",
            "[Batch 4] Current Loss: 5.3155\n",
            "[Batch 5] Current Loss: 5.7025\n",
            "[Batch 6] Current Loss: 5.2074\n",
            "[Batch 7] Current Loss: 5.5325\n",
            "[Batch 8] Current Loss: 5.3576\n",
            "[Batch 9] Current Loss: 4.5042\n",
            "Ep 2 (Step 016140): Train loss 3.495, Val loss 5.154\n",
            "[Batch 0] Current Loss: 3.6368\n",
            "[Batch 1] Current Loss: 3.7775\n",
            "[Batch 2] Current Loss: 3.2450\n",
            "[Batch 3] Current Loss: 3.3137\n",
            "[Batch 4] Current Loss: 4.2083\n",
            "[Batch 5] Current Loss: 3.2807\n",
            "[Batch 6] Current Loss: 3.1086\n",
            "[Batch 7] Current Loss: 2.9028\n",
            "[Batch 8] Current Loss: 4.0891\n",
            "[Batch 9] Current Loss: 2.9307\n",
            "[Batch 0] Current Loss: 5.1423\n",
            "[Batch 1] Current Loss: 4.8589\n",
            "[Batch 2] Current Loss: 5.5159\n",
            "[Batch 3] Current Loss: 5.7915\n",
            "[Batch 4] Current Loss: 5.5109\n",
            "[Batch 5] Current Loss: 4.3456\n",
            "[Batch 6] Current Loss: 5.4423\n",
            "[Batch 7] Current Loss: 4.9836\n",
            "[Batch 8] Current Loss: 4.9190\n",
            "[Batch 9] Current Loss: 5.6922\n",
            "Ep 2 (Step 016160): Train loss 3.449, Val loss 5.220\n",
            "[Batch 0] Current Loss: 3.7465\n",
            "[Batch 1] Current Loss: 3.8499\n",
            "[Batch 2] Current Loss: 3.6878\n",
            "[Batch 3] Current Loss: 3.1029\n",
            "[Batch 4] Current Loss: 3.4001\n",
            "[Batch 5] Current Loss: 3.7238\n",
            "[Batch 6] Current Loss: 3.3433\n",
            "[Batch 7] Current Loss: 3.4633\n",
            "[Batch 8] Current Loss: 3.3033\n",
            "[Batch 9] Current Loss: 3.2590\n",
            "[Batch 0] Current Loss: 4.8924\n",
            "[Batch 1] Current Loss: 4.9502\n",
            "[Batch 2] Current Loss: 4.8441\n",
            "[Batch 3] Current Loss: 5.7621\n",
            "[Batch 4] Current Loss: 5.2709\n",
            "[Batch 5] Current Loss: 5.1813\n",
            "[Batch 6] Current Loss: 5.4451\n",
            "[Batch 7] Current Loss: 5.2518\n",
            "[Batch 8] Current Loss: 5.2395\n",
            "[Batch 9] Current Loss: 4.3747\n",
            "Ep 2 (Step 016180): Train loss 3.488, Val loss 5.121\n",
            "[Batch 0] Current Loss: 3.5501\n",
            "[Batch 1] Current Loss: 4.0115\n",
            "[Batch 2] Current Loss: 3.8220\n",
            "[Batch 3] Current Loss: 3.4295\n",
            "[Batch 4] Current Loss: 3.3785\n",
            "[Batch 5] Current Loss: 3.3344\n",
            "[Batch 6] Current Loss: 3.4050\n",
            "[Batch 7] Current Loss: 3.0782\n",
            "[Batch 8] Current Loss: 3.2564\n",
            "[Batch 9] Current Loss: 3.5334\n",
            "[Batch 0] Current Loss: 4.8995\n",
            "[Batch 1] Current Loss: 5.2171\n",
            "[Batch 2] Current Loss: 5.1088\n",
            "[Batch 3] Current Loss: 5.0237\n",
            "[Batch 4] Current Loss: 5.4751\n",
            "[Batch 5] Current Loss: 5.5073\n",
            "[Batch 6] Current Loss: 4.9107\n",
            "[Batch 7] Current Loss: 5.9366\n",
            "[Batch 8] Current Loss: 5.1633\n",
            "[Batch 9] Current Loss: 5.7176\n",
            "Ep 2 (Step 016200): Train loss 3.480, Val loss 5.296\n",
            "[Batch 0] Current Loss: 3.3457\n",
            "[Batch 1] Current Loss: 3.7230\n",
            "[Batch 2] Current Loss: 3.0413\n",
            "[Batch 3] Current Loss: 3.6352\n",
            "[Batch 4] Current Loss: 3.3938\n",
            "[Batch 5] Current Loss: 3.1377\n",
            "[Batch 6] Current Loss: 3.7922\n",
            "[Batch 7] Current Loss: 3.5501\n",
            "[Batch 8] Current Loss: 4.1530\n",
            "[Batch 9] Current Loss: 2.9653\n",
            "[Batch 0] Current Loss: 5.1221\n",
            "[Batch 1] Current Loss: 5.0593\n",
            "[Batch 2] Current Loss: 4.2239\n",
            "[Batch 3] Current Loss: 6.1547\n",
            "[Batch 4] Current Loss: 5.4094\n",
            "[Batch 5] Current Loss: 5.0848\n",
            "[Batch 6] Current Loss: 5.7026\n",
            "[Batch 7] Current Loss: 4.6237\n",
            "[Batch 8] Current Loss: 5.2895\n",
            "[Batch 9] Current Loss: 5.7820\n",
            "Ep 2 (Step 016220): Train loss 3.474, Val loss 5.245\n",
            "[Batch 0] Current Loss: 3.6623\n",
            "[Batch 1] Current Loss: 3.7034\n",
            "[Batch 2] Current Loss: 3.4147\n",
            "[Batch 3] Current Loss: 3.7808\n",
            "[Batch 4] Current Loss: 3.6181\n",
            "[Batch 5] Current Loss: 3.3522\n",
            "[Batch 6] Current Loss: 3.5238\n",
            "[Batch 7] Current Loss: 3.3155\n",
            "[Batch 8] Current Loss: 3.5399\n",
            "[Batch 9] Current Loss: 3.0996\n",
            "[Batch 0] Current Loss: 5.3599\n",
            "[Batch 1] Current Loss: 5.4288\n",
            "[Batch 2] Current Loss: 5.5748\n",
            "[Batch 3] Current Loss: 4.7714\n",
            "[Batch 4] Current Loss: 5.8771\n",
            "[Batch 5] Current Loss: 4.7637\n",
            "[Batch 6] Current Loss: 4.3367\n",
            "[Batch 7] Current Loss: 4.7114\n",
            "[Batch 8] Current Loss: 5.2923\n",
            "[Batch 9] Current Loss: 5.2570\n",
            "Ep 2 (Step 016240): Train loss 3.501, Val loss 5.137\n",
            "[Batch 0] Current Loss: 3.4527\n",
            "[Batch 1] Current Loss: 3.9517\n",
            "[Batch 2] Current Loss: 2.9009\n",
            "[Batch 3] Current Loss: 3.4769\n",
            "[Batch 4] Current Loss: 3.0956\n",
            "[Batch 5] Current Loss: 3.6185\n",
            "[Batch 6] Current Loss: 4.0700\n",
            "[Batch 7] Current Loss: 3.1949\n",
            "[Batch 8] Current Loss: 3.4756\n",
            "[Batch 9] Current Loss: 3.3370\n",
            "[Batch 0] Current Loss: 5.3671\n",
            "[Batch 1] Current Loss: 4.8877\n",
            "[Batch 2] Current Loss: 5.0164\n",
            "[Batch 3] Current Loss: 4.8101\n",
            "[Batch 4] Current Loss: 4.2377\n",
            "[Batch 5] Current Loss: 5.5194\n",
            "[Batch 6] Current Loss: 4.7228\n",
            "[Batch 7] Current Loss: 5.1266\n",
            "[Batch 8] Current Loss: 5.0148\n",
            "[Batch 9] Current Loss: 5.2339\n",
            "Ep 2 (Step 016260): Train loss 3.457, Val loss 4.994\n",
            "[Batch 0] Current Loss: 3.7781\n",
            "[Batch 1] Current Loss: 3.6866\n",
            "[Batch 2] Current Loss: 4.0765\n",
            "[Batch 3] Current Loss: 4.3948\n",
            "[Batch 4] Current Loss: 3.2580\n",
            "[Batch 5] Current Loss: 3.9039\n",
            "[Batch 6] Current Loss: 2.9673\n",
            "[Batch 7] Current Loss: 3.3509\n",
            "[Batch 8] Current Loss: 3.8187\n",
            "[Batch 9] Current Loss: 3.1281\n",
            "[Batch 0] Current Loss: 5.2552\n",
            "[Batch 1] Current Loss: 5.5141\n",
            "[Batch 2] Current Loss: 5.5536\n",
            "[Batch 3] Current Loss: 4.9092\n",
            "[Batch 4] Current Loss: 4.6358\n",
            "[Batch 5] Current Loss: 5.3457\n",
            "[Batch 6] Current Loss: 5.6535\n",
            "[Batch 7] Current Loss: 5.4083\n",
            "[Batch 8] Current Loss: 5.5446\n",
            "[Batch 9] Current Loss: 5.5722\n",
            "Ep 2 (Step 016280): Train loss 3.636, Val loss 5.339\n",
            "[Batch 0] Current Loss: 3.2694\n",
            "[Batch 1] Current Loss: 3.6170\n",
            "[Batch 2] Current Loss: 3.9802\n",
            "[Batch 3] Current Loss: 2.9991\n",
            "[Batch 4] Current Loss: 3.5654\n",
            "[Batch 5] Current Loss: 3.8502\n",
            "[Batch 6] Current Loss: 3.7760\n",
            "[Batch 7] Current Loss: 3.4345\n",
            "[Batch 8] Current Loss: 3.6993\n",
            "[Batch 9] Current Loss: 3.5204\n",
            "[Batch 0] Current Loss: 4.5245\n",
            "[Batch 1] Current Loss: 4.8427\n",
            "[Batch 2] Current Loss: 5.4614\n",
            "[Batch 3] Current Loss: 5.3588\n",
            "[Batch 4] Current Loss: 5.5485\n",
            "[Batch 5] Current Loss: 4.6082\n",
            "[Batch 6] Current Loss: 5.5920\n",
            "[Batch 7] Current Loss: 4.6672\n",
            "[Batch 8] Current Loss: 5.2317\n",
            "[Batch 9] Current Loss: 4.4850\n",
            "Ep 2 (Step 016300): Train loss 3.571, Val loss 5.032\n",
            "[Batch 0] Current Loss: 3.5514\n",
            "[Batch 1] Current Loss: 3.2113\n",
            "[Batch 2] Current Loss: 2.7655\n",
            "[Batch 3] Current Loss: 3.4890\n",
            "[Batch 4] Current Loss: 3.3974\n",
            "[Batch 5] Current Loss: 3.4948\n",
            "[Batch 6] Current Loss: 2.9597\n",
            "[Batch 7] Current Loss: 3.6991\n",
            "[Batch 8] Current Loss: 3.3235\n",
            "[Batch 9] Current Loss: 3.4094\n",
            "[Batch 0] Current Loss: 4.4931\n",
            "[Batch 1] Current Loss: 5.6009\n",
            "[Batch 2] Current Loss: 4.9519\n",
            "[Batch 3] Current Loss: 5.6558\n",
            "[Batch 4] Current Loss: 4.9161\n",
            "[Batch 5] Current Loss: 5.3675\n",
            "[Batch 6] Current Loss: 5.8867\n",
            "[Batch 7] Current Loss: 5.5146\n",
            "[Batch 8] Current Loss: 5.1303\n",
            "[Batch 9] Current Loss: 5.3112\n",
            "Ep 2 (Step 016320): Train loss 3.330, Val loss 5.283\n",
            "[Batch 0] Current Loss: 3.7969\n",
            "[Batch 1] Current Loss: 3.9598\n",
            "[Batch 2] Current Loss: 3.5604\n",
            "[Batch 3] Current Loss: 3.6068\n",
            "[Batch 4] Current Loss: 2.9427\n",
            "[Batch 5] Current Loss: 3.8367\n",
            "[Batch 6] Current Loss: 4.0209\n",
            "[Batch 7] Current Loss: 3.5454\n",
            "[Batch 8] Current Loss: 3.3387\n",
            "[Batch 9] Current Loss: 3.0636\n",
            "[Batch 0] Current Loss: 4.9461\n",
            "[Batch 1] Current Loss: 5.0611\n",
            "[Batch 2] Current Loss: 5.2062\n",
            "[Batch 3] Current Loss: 5.7482\n",
            "[Batch 4] Current Loss: 5.3080\n",
            "[Batch 5] Current Loss: 4.9523\n",
            "[Batch 6] Current Loss: 5.5121\n",
            "[Batch 7] Current Loss: 5.1096\n",
            "[Batch 8] Current Loss: 5.7117\n",
            "[Batch 9] Current Loss: 5.3462\n",
            "Ep 2 (Step 016340): Train loss 3.567, Val loss 5.290\n",
            "[Batch 0] Current Loss: 3.1670\n",
            "[Batch 1] Current Loss: 3.7493\n",
            "[Batch 2] Current Loss: 3.4751\n",
            "[Batch 3] Current Loss: 3.9126\n",
            "[Batch 4] Current Loss: 3.5420\n",
            "[Batch 5] Current Loss: 3.1183\n",
            "[Batch 6] Current Loss: 3.7931\n",
            "[Batch 7] Current Loss: 3.4501\n",
            "[Batch 8] Current Loss: 3.7473\n",
            "[Batch 9] Current Loss: 3.6912\n",
            "[Batch 0] Current Loss: 5.6815\n",
            "[Batch 1] Current Loss: 4.3312\n",
            "[Batch 2] Current Loss: 5.4517\n",
            "[Batch 3] Current Loss: 4.7062\n",
            "[Batch 4] Current Loss: 4.6776\n",
            "[Batch 5] Current Loss: 4.3861\n",
            "[Batch 6] Current Loss: 5.2535\n",
            "[Batch 7] Current Loss: 4.8606\n",
            "[Batch 8] Current Loss: 5.0687\n",
            "[Batch 9] Current Loss: 4.8729\n",
            "Ep 2 (Step 016360): Train loss 3.565, Val loss 4.929\n",
            "[Batch 0] Current Loss: 3.7642\n",
            "[Batch 1] Current Loss: 3.3473\n",
            "[Batch 2] Current Loss: 3.2659\n",
            "[Batch 3] Current Loss: 3.4244\n",
            "[Batch 4] Current Loss: 4.4148\n",
            "[Batch 5] Current Loss: 3.5337\n",
            "[Batch 6] Current Loss: 3.9637\n",
            "[Batch 7] Current Loss: 3.4090\n",
            "[Batch 8] Current Loss: 3.6103\n",
            "[Batch 9] Current Loss: 3.7359\n",
            "[Batch 0] Current Loss: 4.8302\n",
            "[Batch 1] Current Loss: 5.3609\n",
            "[Batch 2] Current Loss: 5.3986\n",
            "[Batch 3] Current Loss: 5.2542\n",
            "[Batch 4] Current Loss: 5.7820\n",
            "[Batch 5] Current Loss: 4.7046\n",
            "[Batch 6] Current Loss: 5.6210\n",
            "[Batch 7] Current Loss: 5.1739\n",
            "[Batch 8] Current Loss: 5.6584\n",
            "[Batch 9] Current Loss: 5.2827\n",
            "Ep 2 (Step 016380): Train loss 3.647, Val loss 5.307\n",
            "[Batch 0] Current Loss: 3.0022\n",
            "[Batch 1] Current Loss: 3.2420\n",
            "[Batch 2] Current Loss: 3.7751\n",
            "[Batch 3] Current Loss: 3.7886\n",
            "[Batch 4] Current Loss: 3.5925\n",
            "[Batch 5] Current Loss: 3.4377\n",
            "[Batch 6] Current Loss: 3.8855\n",
            "[Batch 7] Current Loss: 3.0687\n",
            "[Batch 8] Current Loss: 3.5330\n",
            "[Batch 9] Current Loss: 3.3530\n",
            "[Batch 0] Current Loss: 5.7197\n",
            "[Batch 1] Current Loss: 4.8545\n",
            "[Batch 2] Current Loss: 5.3516\n",
            "[Batch 3] Current Loss: 4.5005\n",
            "[Batch 4] Current Loss: 5.9148\n",
            "[Batch 5] Current Loss: 4.7516\n",
            "[Batch 6] Current Loss: 4.9877\n",
            "[Batch 7] Current Loss: 5.7511\n",
            "[Batch 8] Current Loss: 5.4303\n",
            "[Batch 9] Current Loss: 5.1372\n",
            "Ep 2 (Step 016400): Train loss 3.468, Val loss 5.240\n",
            "[Batch 0] Current Loss: 3.4219\n",
            "[Batch 1] Current Loss: 2.8787\n",
            "[Batch 2] Current Loss: 3.3998\n",
            "[Batch 3] Current Loss: 3.3886\n",
            "[Batch 4] Current Loss: 3.4251\n",
            "[Batch 5] Current Loss: 3.2193\n",
            "[Batch 6] Current Loss: 3.7667\n",
            "[Batch 7] Current Loss: 3.6964\n",
            "[Batch 8] Current Loss: 3.9103\n",
            "[Batch 9] Current Loss: 2.9351\n",
            "[Batch 0] Current Loss: 5.7631\n",
            "[Batch 1] Current Loss: 5.0593\n",
            "[Batch 2] Current Loss: 5.7865\n",
            "[Batch 3] Current Loss: 5.1951\n",
            "[Batch 4] Current Loss: 4.4638\n",
            "[Batch 5] Current Loss: 5.4131\n",
            "[Batch 6] Current Loss: 4.6638\n",
            "[Batch 7] Current Loss: 5.2645\n",
            "[Batch 8] Current Loss: 5.6299\n",
            "[Batch 9] Current Loss: 5.2114\n",
            "Ep 2 (Step 016420): Train loss 3.404, Val loss 5.245\n",
            "[Batch 0] Current Loss: 3.1398\n",
            "[Batch 1] Current Loss: 3.1005\n",
            "[Batch 2] Current Loss: 3.5957\n",
            "[Batch 3] Current Loss: 3.9995\n",
            "[Batch 4] Current Loss: 3.3037\n",
            "[Batch 5] Current Loss: 3.7513\n",
            "[Batch 6] Current Loss: 3.6641\n",
            "[Batch 7] Current Loss: 3.5131\n",
            "[Batch 8] Current Loss: 4.2382\n",
            "[Batch 9] Current Loss: 4.0890\n",
            "[Batch 0] Current Loss: 5.2863\n",
            "[Batch 1] Current Loss: 5.0905\n",
            "[Batch 2] Current Loss: 5.7997\n",
            "[Batch 3] Current Loss: 5.5777\n",
            "[Batch 4] Current Loss: 5.0736\n",
            "[Batch 5] Current Loss: 5.0525\n",
            "[Batch 6] Current Loss: 4.9921\n",
            "[Batch 7] Current Loss: 5.7232\n",
            "[Batch 8] Current Loss: 5.1747\n",
            "[Batch 9] Current Loss: 5.1878\n",
            "Ep 2 (Step 016440): Train loss 3.639, Val loss 5.296\n",
            "[Batch 0] Current Loss: 3.1829\n",
            "[Batch 1] Current Loss: 3.7380\n",
            "[Batch 2] Current Loss: 3.6594\n",
            "[Batch 3] Current Loss: 2.8954\n",
            "[Batch 4] Current Loss: 3.2890\n",
            "[Batch 5] Current Loss: 3.9462\n",
            "[Batch 6] Current Loss: 2.9680\n",
            "[Batch 7] Current Loss: 3.9365\n",
            "[Batch 8] Current Loss: 3.3534\n",
            "[Batch 9] Current Loss: 3.1922\n",
            "[Batch 0] Current Loss: 5.6591\n",
            "[Batch 1] Current Loss: 4.8351\n",
            "[Batch 2] Current Loss: 5.0563\n",
            "[Batch 3] Current Loss: 4.9083\n",
            "[Batch 4] Current Loss: 5.0015\n",
            "[Batch 5] Current Loss: 4.5751\n",
            "[Batch 6] Current Loss: 5.7261\n",
            "[Batch 7] Current Loss: 4.7815\n",
            "[Batch 8] Current Loss: 4.9839\n",
            "[Batch 9] Current Loss: 5.5000\n",
            "Ep 2 (Step 016460): Train loss 3.416, Val loss 5.103\n",
            "[Batch 0] Current Loss: 3.4404\n",
            "[Batch 1] Current Loss: 3.6420\n",
            "[Batch 2] Current Loss: 3.2112\n",
            "[Batch 3] Current Loss: 3.5100\n",
            "[Batch 4] Current Loss: 3.7403\n",
            "[Batch 5] Current Loss: 3.2521\n",
            "[Batch 6] Current Loss: 3.8913\n",
            "[Batch 7] Current Loss: 3.4978\n",
            "[Batch 8] Current Loss: 3.2156\n",
            "[Batch 9] Current Loss: 3.6248\n",
            "[Batch 0] Current Loss: 4.3443\n",
            "[Batch 1] Current Loss: 5.5237\n",
            "[Batch 2] Current Loss: 4.8651\n",
            "[Batch 3] Current Loss: 4.9367\n",
            "[Batch 4] Current Loss: 4.5639\n",
            "[Batch 5] Current Loss: 4.6064\n",
            "[Batch 6] Current Loss: 3.8266\n",
            "[Batch 7] Current Loss: 5.4883\n",
            "[Batch 8] Current Loss: 5.0768\n",
            "[Batch 9] Current Loss: 5.5035\n",
            "Ep 2 (Step 016480): Train loss 3.503, Val loss 4.874\n",
            "[Batch 0] Current Loss: 3.6385\n",
            "[Batch 1] Current Loss: 3.5407\n",
            "[Batch 2] Current Loss: 3.3165\n",
            "[Batch 3] Current Loss: 3.7586\n",
            "[Batch 4] Current Loss: 3.5375\n",
            "[Batch 5] Current Loss: 3.6683\n",
            "[Batch 6] Current Loss: 3.5664\n",
            "[Batch 7] Current Loss: 3.8503\n",
            "[Batch 8] Current Loss: 3.4039\n",
            "[Batch 9] Current Loss: 3.6054\n",
            "[Batch 0] Current Loss: 5.8710\n",
            "[Batch 1] Current Loss: 5.2229\n",
            "[Batch 2] Current Loss: 4.7933\n",
            "[Batch 3] Current Loss: 5.9492\n",
            "[Batch 4] Current Loss: 5.3727\n",
            "[Batch 5] Current Loss: 5.8303\n",
            "[Batch 6] Current Loss: 5.2383\n",
            "[Batch 7] Current Loss: 4.6722\n",
            "[Batch 8] Current Loss: 5.1356\n",
            "[Batch 9] Current Loss: 5.4152\n",
            "Ep 2 (Step 016500): Train loss 3.589, Val loss 5.350\n",
            "[Batch 0] Current Loss: 3.8689\n",
            "[Batch 1] Current Loss: 3.5338\n",
            "[Batch 2] Current Loss: 3.5068\n",
            "[Batch 3] Current Loss: 3.1838\n",
            "[Batch 4] Current Loss: 3.3811\n",
            "[Batch 5] Current Loss: 3.5030\n",
            "[Batch 6] Current Loss: 3.5126\n",
            "[Batch 7] Current Loss: 3.2577\n",
            "[Batch 8] Current Loss: 3.1595\n",
            "[Batch 9] Current Loss: 3.5363\n",
            "[Batch 0] Current Loss: 5.9034\n",
            "[Batch 1] Current Loss: 5.0367\n",
            "[Batch 2] Current Loss: 4.9955\n",
            "[Batch 3] Current Loss: 4.8901\n",
            "[Batch 4] Current Loss: 5.3506\n",
            "[Batch 5] Current Loss: 4.7244\n",
            "[Batch 6] Current Loss: 5.0672\n",
            "[Batch 7] Current Loss: 4.9005\n",
            "[Batch 8] Current Loss: 5.2038\n",
            "[Batch 9] Current Loss: 5.4207\n",
            "Ep 2 (Step 016520): Train loss 3.444, Val loss 5.149\n",
            "[Batch 0] Current Loss: 3.6930\n",
            "[Batch 1] Current Loss: 3.0131\n",
            "[Batch 2] Current Loss: 3.2691\n",
            "[Batch 3] Current Loss: 3.7810\n",
            "[Batch 4] Current Loss: 2.9985\n",
            "[Batch 5] Current Loss: 3.4248\n",
            "[Batch 6] Current Loss: 3.5380\n",
            "[Batch 7] Current Loss: 3.9838\n",
            "[Batch 8] Current Loss: 3.5232\n",
            "[Batch 9] Current Loss: 3.7463\n",
            "[Batch 0] Current Loss: 5.5414\n",
            "[Batch 1] Current Loss: 5.2896\n",
            "[Batch 2] Current Loss: 5.2484\n",
            "[Batch 3] Current Loss: 4.9138\n",
            "[Batch 4] Current Loss: 4.4321\n",
            "[Batch 5] Current Loss: 5.2978\n",
            "[Batch 6] Current Loss: 5.2514\n",
            "[Batch 7] Current Loss: 5.1264\n",
            "[Batch 8] Current Loss: 5.6296\n",
            "[Batch 9] Current Loss: 4.8729\n",
            "Ep 2 (Step 016540): Train loss 3.497, Val loss 5.160\n",
            "[Batch 0] Current Loss: 4.0248\n",
            "[Batch 1] Current Loss: 3.3691\n",
            "[Batch 2] Current Loss: 3.1415\n",
            "[Batch 3] Current Loss: 3.4737\n",
            "[Batch 4] Current Loss: 3.8036\n",
            "[Batch 5] Current Loss: 4.3460\n",
            "[Batch 6] Current Loss: 3.3511\n",
            "[Batch 7] Current Loss: 3.4586\n",
            "[Batch 8] Current Loss: 3.2699\n",
            "[Batch 9] Current Loss: 3.5706\n",
            "[Batch 0] Current Loss: 5.4427\n",
            "[Batch 1] Current Loss: 5.8954\n",
            "[Batch 2] Current Loss: 5.1119\n",
            "[Batch 3] Current Loss: 5.4313\n",
            "[Batch 4] Current Loss: 6.0646\n",
            "[Batch 5] Current Loss: 4.9829\n",
            "[Batch 6] Current Loss: 5.7820\n",
            "[Batch 7] Current Loss: 5.0410\n",
            "[Batch 8] Current Loss: 5.4370\n",
            "[Batch 9] Current Loss: 5.2439\n",
            "Ep 2 (Step 016560): Train loss 3.581, Val loss 5.443\n",
            "[Batch 0] Current Loss: 2.9473\n",
            "[Batch 1] Current Loss: 2.6558\n",
            "[Batch 2] Current Loss: 3.6693\n",
            "[Batch 3] Current Loss: 3.7357\n",
            "[Batch 4] Current Loss: 3.7658\n",
            "[Batch 5] Current Loss: 3.9079\n",
            "[Batch 6] Current Loss: 3.8620\n",
            "[Batch 7] Current Loss: 2.8807\n",
            "[Batch 8] Current Loss: 3.4898\n",
            "[Batch 9] Current Loss: 3.5075\n",
            "[Batch 0] Current Loss: 5.4749\n",
            "[Batch 1] Current Loss: 4.6435\n",
            "[Batch 2] Current Loss: 5.1379\n",
            "[Batch 3] Current Loss: 4.8584\n",
            "[Batch 4] Current Loss: 5.4379\n",
            "[Batch 5] Current Loss: 4.5826\n",
            "[Batch 6] Current Loss: 5.5076\n",
            "[Batch 7] Current Loss: 4.8724\n",
            "[Batch 8] Current Loss: 5.0952\n",
            "[Batch 9] Current Loss: 4.8061\n",
            "Ep 2 (Step 016580): Train loss 3.442, Val loss 5.042\n",
            "[Batch 0] Current Loss: 3.8751\n",
            "[Batch 1] Current Loss: 4.0325\n",
            "[Batch 2] Current Loss: 3.2623\n",
            "[Batch 3] Current Loss: 4.0152\n",
            "[Batch 4] Current Loss: 3.4515\n",
            "[Batch 5] Current Loss: 4.0445\n",
            "[Batch 6] Current Loss: 3.1729\n",
            "[Batch 7] Current Loss: 3.6041\n",
            "[Batch 8] Current Loss: 3.6720\n",
            "[Batch 9] Current Loss: 3.8032\n",
            "[Batch 0] Current Loss: 5.1304\n",
            "[Batch 1] Current Loss: 5.0751\n",
            "[Batch 2] Current Loss: 4.8227\n",
            "[Batch 3] Current Loss: 5.7614\n",
            "[Batch 4] Current Loss: 5.2008\n",
            "[Batch 5] Current Loss: 4.7768\n",
            "[Batch 6] Current Loss: 5.1750\n",
            "[Batch 7] Current Loss: 5.3529\n",
            "[Batch 8] Current Loss: 4.5716\n",
            "[Batch 9] Current Loss: 5.2110\n",
            "Ep 2 (Step 016600): Train loss 3.693, Val loss 5.108\n",
            "[Batch 0] Current Loss: 3.3874\n",
            "[Batch 1] Current Loss: 3.8844\n",
            "[Batch 2] Current Loss: 3.0689\n",
            "[Batch 3] Current Loss: 3.4265\n",
            "[Batch 4] Current Loss: 2.9178\n",
            "[Batch 5] Current Loss: 3.3208\n",
            "[Batch 6] Current Loss: 3.4005\n",
            "[Batch 7] Current Loss: 3.6673\n",
            "[Batch 8] Current Loss: 3.8775\n",
            "[Batch 9] Current Loss: 3.9139\n",
            "[Batch 0] Current Loss: 5.3066\n",
            "[Batch 1] Current Loss: 4.9515\n",
            "[Batch 2] Current Loss: 5.0555\n",
            "[Batch 3] Current Loss: 5.2143\n",
            "[Batch 4] Current Loss: 5.0192\n",
            "[Batch 5] Current Loss: 4.9494\n",
            "[Batch 6] Current Loss: 5.0311\n",
            "[Batch 7] Current Loss: 4.6486\n",
            "[Batch 8] Current Loss: 5.5594\n",
            "[Batch 9] Current Loss: 5.6316\n",
            "Ep 2 (Step 016620): Train loss 3.486, Val loss 5.137\n",
            "[Batch 0] Current Loss: 3.8839\n",
            "[Batch 1] Current Loss: 3.5589\n",
            "[Batch 2] Current Loss: 4.2598\n",
            "[Batch 3] Current Loss: 3.2139\n",
            "[Batch 4] Current Loss: 3.6226\n",
            "[Batch 5] Current Loss: 3.6354\n",
            "[Batch 6] Current Loss: 3.1263\n",
            "[Batch 7] Current Loss: 3.5629\n",
            "[Batch 8] Current Loss: 3.3326\n",
            "[Batch 9] Current Loss: 4.0517\n",
            "[Batch 0] Current Loss: 4.4216\n",
            "[Batch 1] Current Loss: 5.7025\n",
            "[Batch 2] Current Loss: 5.8325\n",
            "[Batch 3] Current Loss: 5.9470\n",
            "[Batch 4] Current Loss: 4.9157\n",
            "[Batch 5] Current Loss: 4.8877\n",
            "[Batch 6] Current Loss: 5.4436\n",
            "[Batch 7] Current Loss: 5.6388\n",
            "[Batch 8] Current Loss: 4.7316\n",
            "[Batch 9] Current Loss: 5.1944\n",
            "Ep 2 (Step 016640): Train loss 3.625, Val loss 5.272\n",
            "[Batch 0] Current Loss: 3.5406\n",
            "[Batch 1] Current Loss: 3.8241\n",
            "[Batch 2] Current Loss: 3.4472\n",
            "[Batch 3] Current Loss: 3.3578\n",
            "[Batch 4] Current Loss: 3.1436\n",
            "[Batch 5] Current Loss: 3.3842\n",
            "[Batch 6] Current Loss: 3.1698\n",
            "[Batch 7] Current Loss: 3.5623\n",
            "[Batch 8] Current Loss: 3.1412\n",
            "[Batch 9] Current Loss: 3.3846\n",
            "[Batch 0] Current Loss: 5.9053\n",
            "[Batch 1] Current Loss: 4.8281\n",
            "[Batch 2] Current Loss: 5.3372\n",
            "[Batch 3] Current Loss: 5.0813\n",
            "[Batch 4] Current Loss: 5.3956\n",
            "[Batch 5] Current Loss: 5.3489\n",
            "[Batch 6] Current Loss: 5.0610\n",
            "[Batch 7] Current Loss: 5.3652\n",
            "[Batch 8] Current Loss: 5.2275\n",
            "[Batch 9] Current Loss: 5.4745\n",
            "Ep 2 (Step 016660): Train loss 3.396, Val loss 5.302\n",
            "[Batch 0] Current Loss: 3.0978\n",
            "[Batch 1] Current Loss: 3.7403\n",
            "[Batch 2] Current Loss: 3.1979\n",
            "[Batch 3] Current Loss: 3.4364\n",
            "[Batch 4] Current Loss: 2.7595\n",
            "[Batch 5] Current Loss: 3.0001\n",
            "[Batch 6] Current Loss: 3.3687\n",
            "[Batch 7] Current Loss: 3.6602\n",
            "[Batch 8] Current Loss: 3.4610\n",
            "[Batch 9] Current Loss: 3.6428\n",
            "[Batch 0] Current Loss: 5.1478\n",
            "[Batch 1] Current Loss: 4.8970\n",
            "[Batch 2] Current Loss: 5.5542\n",
            "[Batch 3] Current Loss: 4.9797\n",
            "[Batch 4] Current Loss: 5.6726\n",
            "[Batch 5] Current Loss: 5.2997\n",
            "[Batch 6] Current Loss: 5.6159\n",
            "[Batch 7] Current Loss: 4.7689\n",
            "[Batch 8] Current Loss: 5.3389\n",
            "[Batch 9] Current Loss: 5.0645\n",
            "Ep 2 (Step 016680): Train loss 3.336, Val loss 5.234\n",
            "[Batch 0] Current Loss: 4.0018\n",
            "[Batch 1] Current Loss: 3.6641\n",
            "[Batch 2] Current Loss: 3.8049\n",
            "[Batch 3] Current Loss: 4.0024\n",
            "[Batch 4] Current Loss: 3.4052\n",
            "[Batch 5] Current Loss: 3.3767\n",
            "[Batch 6] Current Loss: 3.5968\n",
            "[Batch 7] Current Loss: 3.5972\n",
            "[Batch 8] Current Loss: 3.7743\n",
            "[Batch 9] Current Loss: 3.4660\n",
            "[Batch 0] Current Loss: 5.5296\n",
            "[Batch 1] Current Loss: 4.8633\n",
            "[Batch 2] Current Loss: 5.1812\n",
            "[Batch 3] Current Loss: 5.7701\n",
            "[Batch 4] Current Loss: 5.0249\n",
            "[Batch 5] Current Loss: 4.6263\n",
            "[Batch 6] Current Loss: 5.2282\n",
            "[Batch 7] Current Loss: 5.1298\n",
            "[Batch 8] Current Loss: 5.5353\n",
            "[Batch 9] Current Loss: 5.4529\n",
            "Ep 2 (Step 016700): Train loss 3.669, Val loss 5.234\n",
            "[Batch 0] Current Loss: 3.6162\n",
            "[Batch 1] Current Loss: 3.6178\n",
            "[Batch 2] Current Loss: 3.0576\n",
            "[Batch 3] Current Loss: 3.4999\n",
            "[Batch 4] Current Loss: 3.6354\n",
            "[Batch 5] Current Loss: 3.2213\n",
            "[Batch 6] Current Loss: 3.1544\n",
            "[Batch 7] Current Loss: 3.6641\n",
            "[Batch 8] Current Loss: 4.1318\n",
            "[Batch 9] Current Loss: 2.9548\n",
            "[Batch 0] Current Loss: 5.0611\n",
            "[Batch 1] Current Loss: 5.7062\n",
            "[Batch 2] Current Loss: 5.1904\n",
            "[Batch 3] Current Loss: 5.4807\n",
            "[Batch 4] Current Loss: 4.9444\n",
            "[Batch 5] Current Loss: 5.2607\n",
            "[Batch 6] Current Loss: 5.0257\n",
            "[Batch 7] Current Loss: 5.4033\n",
            "[Batch 8] Current Loss: 5.2569\n",
            "[Batch 9] Current Loss: 5.5527\n",
            "Ep 2 (Step 016720): Train loss 3.455, Val loss 5.288\n",
            "[Batch 0] Current Loss: 3.3242\n",
            "[Batch 1] Current Loss: 4.0644\n",
            "[Batch 2] Current Loss: 3.5873\n",
            "[Batch 3] Current Loss: 3.7611\n",
            "[Batch 4] Current Loss: 3.4046\n",
            "[Batch 5] Current Loss: 3.7488\n",
            "[Batch 6] Current Loss: 3.5717\n",
            "[Batch 7] Current Loss: 3.2094\n",
            "[Batch 8] Current Loss: 3.7071\n",
            "[Batch 9] Current Loss: 3.5772\n",
            "[Batch 0] Current Loss: 4.8114\n",
            "[Batch 1] Current Loss: 5.0425\n",
            "[Batch 2] Current Loss: 5.1593\n",
            "[Batch 3] Current Loss: 4.6850\n",
            "[Batch 4] Current Loss: 5.6123\n",
            "[Batch 5] Current Loss: 5.6585\n",
            "[Batch 6] Current Loss: 5.2494\n",
            "[Batch 7] Current Loss: 5.9729\n",
            "[Batch 8] Current Loss: 5.0899\n",
            "[Batch 9] Current Loss: 5.8385\n",
            "Ep 2 (Step 016740): Train loss 3.596, Val loss 5.312\n",
            "[Batch 0] Current Loss: 3.6434\n",
            "[Batch 1] Current Loss: 3.0894\n",
            "[Batch 2] Current Loss: 3.5234\n",
            "[Batch 3] Current Loss: 3.7162\n",
            "[Batch 4] Current Loss: 3.8486\n",
            "[Batch 5] Current Loss: 2.7983\n",
            "[Batch 6] Current Loss: 3.7778\n",
            "[Batch 7] Current Loss: 4.2006\n",
            "[Batch 8] Current Loss: 3.2519\n",
            "[Batch 9] Current Loss: 3.6337\n",
            "[Batch 0] Current Loss: 5.2378\n",
            "[Batch 1] Current Loss: 4.3473\n",
            "[Batch 2] Current Loss: 5.4762\n",
            "[Batch 3] Current Loss: 5.2449\n",
            "[Batch 4] Current Loss: 5.1165\n",
            "[Batch 5] Current Loss: 5.6383\n",
            "[Batch 6] Current Loss: 5.4746\n",
            "[Batch 7] Current Loss: 5.6772\n",
            "[Batch 8] Current Loss: 5.1820\n",
            "[Batch 9] Current Loss: 4.6763\n",
            "Ep 2 (Step 016760): Train loss 3.548, Val loss 5.207\n",
            "[Batch 0] Current Loss: 3.9047\n",
            "[Batch 1] Current Loss: 3.7081\n",
            "[Batch 2] Current Loss: 3.9358\n",
            "[Batch 3] Current Loss: 3.1831\n",
            "[Batch 4] Current Loss: 3.8142\n",
            "[Batch 5] Current Loss: 3.6637\n",
            "[Batch 6] Current Loss: 3.6297\n",
            "[Batch 7] Current Loss: 3.7744\n",
            "[Batch 8] Current Loss: 3.3727\n",
            "[Batch 9] Current Loss: 2.5328\n",
            "[Batch 0] Current Loss: 5.1562\n",
            "[Batch 1] Current Loss: 4.7476\n",
            "[Batch 2] Current Loss: 4.8547\n",
            "[Batch 3] Current Loss: 4.9322\n",
            "[Batch 4] Current Loss: 5.0034\n",
            "[Batch 5] Current Loss: 5.4139\n",
            "[Batch 6] Current Loss: 5.0446\n",
            "[Batch 7] Current Loss: 5.0992\n",
            "[Batch 8] Current Loss: 5.4643\n",
            "[Batch 9] Current Loss: 5.2245\n",
            "Ep 2 (Step 016780): Train loss 3.552, Val loss 5.094\n",
            "[Batch 0] Current Loss: 3.7098\n",
            "[Batch 1] Current Loss: 3.3242\n",
            "[Batch 2] Current Loss: 3.3879\n",
            "[Batch 3] Current Loss: 3.8391\n",
            "[Batch 4] Current Loss: 3.1923\n",
            "[Batch 5] Current Loss: 3.4428\n",
            "[Batch 6] Current Loss: 3.6653\n",
            "[Batch 7] Current Loss: 3.6866\n",
            "[Batch 8] Current Loss: 3.7703\n",
            "[Batch 9] Current Loss: 3.2217\n",
            "[Batch 0] Current Loss: 4.9629\n",
            "[Batch 1] Current Loss: 5.4286\n",
            "[Batch 2] Current Loss: 4.9638\n",
            "[Batch 3] Current Loss: 4.8873\n",
            "[Batch 4] Current Loss: 5.7830\n",
            "[Batch 5] Current Loss: 4.3001\n",
            "[Batch 6] Current Loss: 5.1982\n",
            "[Batch 7] Current Loss: 5.5885\n",
            "[Batch 8] Current Loss: 5.2978\n",
            "[Batch 9] Current Loss: 5.1478\n",
            "Ep 2 (Step 016800): Train loss 3.524, Val loss 5.156\n",
            "[Batch 0] Current Loss: 3.0898\n",
            "[Batch 1] Current Loss: 2.9843\n",
            "[Batch 2] Current Loss: 3.8429\n",
            "[Batch 3] Current Loss: 3.6173\n",
            "[Batch 4] Current Loss: 3.2101\n",
            "[Batch 5] Current Loss: 3.1406\n",
            "[Batch 6] Current Loss: 3.3057\n",
            "[Batch 7] Current Loss: 3.4271\n",
            "[Batch 8] Current Loss: 3.5013\n",
            "[Batch 9] Current Loss: 3.8472\n",
            "[Batch 0] Current Loss: 5.0535\n",
            "[Batch 1] Current Loss: 5.2468\n",
            "[Batch 2] Current Loss: 5.5524\n",
            "[Batch 3] Current Loss: 4.8506\n",
            "[Batch 4] Current Loss: 4.6527\n",
            "[Batch 5] Current Loss: 5.1469\n",
            "[Batch 6] Current Loss: 5.9477\n",
            "[Batch 7] Current Loss: 4.7727\n",
            "[Batch 8] Current Loss: 5.0875\n",
            "[Batch 9] Current Loss: 5.5204\n",
            "Ep 2 (Step 016820): Train loss 3.397, Val loss 5.183\n",
            "[Batch 0] Current Loss: 3.6577\n",
            "[Batch 1] Current Loss: 3.9132\n",
            "[Batch 2] Current Loss: 3.7715\n",
            "[Batch 3] Current Loss: 3.5015\n",
            "[Batch 4] Current Loss: 3.1102\n",
            "[Batch 5] Current Loss: 2.9692\n",
            "[Batch 6] Current Loss: 3.4597\n",
            "[Batch 7] Current Loss: 3.5595\n",
            "[Batch 8] Current Loss: 3.1403\n",
            "[Batch 9] Current Loss: 3.6930\n",
            "[Batch 0] Current Loss: 5.4135\n",
            "[Batch 1] Current Loss: 4.6843\n",
            "[Batch 2] Current Loss: 5.5935\n",
            "[Batch 3] Current Loss: 5.7152\n",
            "[Batch 4] Current Loss: 5.3588\n",
            "[Batch 5] Current Loss: 5.1526\n",
            "[Batch 6] Current Loss: 4.6955\n",
            "[Batch 7] Current Loss: 4.9325\n",
            "[Batch 8] Current Loss: 6.1547\n",
            "[Batch 9] Current Loss: 4.7445\n",
            "Ep 2 (Step 016840): Train loss 3.478, Val loss 5.244\n",
            "[Batch 0] Current Loss: 2.5228\n",
            "[Batch 1] Current Loss: 3.9682\n",
            "[Batch 2] Current Loss: 3.8110\n",
            "[Batch 3] Current Loss: 3.4406\n",
            "[Batch 4] Current Loss: 2.8135\n",
            "[Batch 5] Current Loss: 3.1919\n",
            "[Batch 6] Current Loss: 3.5006\n",
            "[Batch 7] Current Loss: 3.7005\n",
            "[Batch 8] Current Loss: 3.5799\n",
            "[Batch 9] Current Loss: 3.0878\n",
            "[Batch 0] Current Loss: 5.4341\n",
            "[Batch 1] Current Loss: 4.7886\n",
            "[Batch 2] Current Loss: 5.6621\n",
            "[Batch 3] Current Loss: 4.9076\n",
            "[Batch 4] Current Loss: 5.5459\n",
            "[Batch 5] Current Loss: 5.4010\n",
            "[Batch 6] Current Loss: 5.2277\n",
            "[Batch 7] Current Loss: 5.7861\n",
            "[Batch 8] Current Loss: 5.4776\n",
            "[Batch 9] Current Loss: 4.7196\n",
            "Ep 2 (Step 016860): Train loss 3.362, Val loss 5.295\n",
            "[Batch 0] Current Loss: 2.7578\n",
            "[Batch 1] Current Loss: 3.4387\n",
            "[Batch 2] Current Loss: 3.3044\n",
            "[Batch 3] Current Loss: 3.3036\n",
            "[Batch 4] Current Loss: 3.5197\n",
            "[Batch 5] Current Loss: 3.9215\n",
            "[Batch 6] Current Loss: 3.3688\n",
            "[Batch 7] Current Loss: 3.9365\n",
            "[Batch 8] Current Loss: 3.0996\n",
            "[Batch 9] Current Loss: 3.6921\n",
            "[Batch 0] Current Loss: 5.0497\n",
            "[Batch 1] Current Loss: 5.1054\n",
            "[Batch 2] Current Loss: 5.2099\n",
            "[Batch 3] Current Loss: 5.6353\n",
            "[Batch 4] Current Loss: 5.1883\n",
            "[Batch 5] Current Loss: 4.7394\n",
            "[Batch 6] Current Loss: 5.4621\n",
            "[Batch 7] Current Loss: 4.9284\n",
            "[Batch 8] Current Loss: 5.6021\n",
            "[Batch 9] Current Loss: 5.2171\n",
            "Ep 2 (Step 016880): Train loss 3.434, Val loss 5.214\n",
            "[Batch 0] Current Loss: 2.7734\n",
            "[Batch 1] Current Loss: 3.2521\n",
            "[Batch 2] Current Loss: 3.5813\n",
            "[Batch 3] Current Loss: 3.8389\n",
            "[Batch 4] Current Loss: 3.8011\n",
            "[Batch 5] Current Loss: 3.4923\n",
            "[Batch 6] Current Loss: 3.4891\n",
            "[Batch 7] Current Loss: 3.1252\n",
            "[Batch 8] Current Loss: 3.3070\n",
            "[Batch 9] Current Loss: 3.3507\n",
            "[Batch 0] Current Loss: 5.3682\n",
            "[Batch 1] Current Loss: 4.8879\n",
            "[Batch 2] Current Loss: 4.7746\n",
            "[Batch 3] Current Loss: 5.4420\n",
            "[Batch 4] Current Loss: 5.4366\n",
            "[Batch 5] Current Loss: 4.5925\n",
            "[Batch 6] Current Loss: 5.0396\n",
            "[Batch 7] Current Loss: 6.0965\n",
            "[Batch 8] Current Loss: 5.1939\n",
            "[Batch 9] Current Loss: 5.4085\n",
            "Ep 2 (Step 016900): Train loss 3.401, Val loss 5.224\n",
            "Every effort moves you can be a great way to achieve your life.  The difference between the two characters and the characters are a great way to find the story of the story. The story ends in the story, which is a story of the story. The story\n",
            "[Batch 0] Current Loss: 3.2705\n",
            "[Batch 1] Current Loss: 3.0104\n",
            "[Batch 2] Current Loss: 3.4018\n",
            "[Batch 3] Current Loss: 3.4393\n",
            "[Batch 4] Current Loss: 3.6997\n",
            "[Batch 5] Current Loss: 3.4447\n",
            "[Batch 6] Current Loss: 3.2738\n",
            "[Batch 7] Current Loss: 3.5390\n",
            "[Batch 8] Current Loss: 3.5844\n",
            "[Batch 9] Current Loss: 3.4046\n",
            "[Batch 0] Current Loss: 5.6041\n",
            "[Batch 1] Current Loss: 5.4996\n",
            "[Batch 2] Current Loss: 4.8199\n",
            "[Batch 3] Current Loss: 5.3146\n",
            "[Batch 4] Current Loss: 5.9625\n",
            "[Batch 5] Current Loss: 5.3501\n",
            "[Batch 6] Current Loss: 4.8858\n",
            "[Batch 7] Current Loss: 4.5928\n",
            "[Batch 8] Current Loss: 4.7034\n",
            "[Batch 9] Current Loss: 5.5741\n",
            "Ep 3 (Step 016920): Train loss 3.407, Val loss 5.231\n",
            "[Batch 0] Current Loss: 3.4540\n",
            "[Batch 1] Current Loss: 3.8321\n",
            "[Batch 2] Current Loss: 3.1208\n",
            "[Batch 3] Current Loss: 2.7481\n",
            "[Batch 4] Current Loss: 2.9119\n",
            "[Batch 5] Current Loss: 3.6698\n",
            "[Batch 6] Current Loss: 3.7659\n",
            "[Batch 7] Current Loss: 3.9795\n",
            "[Batch 8] Current Loss: 3.4565\n",
            "[Batch 9] Current Loss: 3.6322\n",
            "[Batch 0] Current Loss: 5.1080\n",
            "[Batch 1] Current Loss: 5.3432\n",
            "[Batch 2] Current Loss: 4.6160\n",
            "[Batch 3] Current Loss: 4.5490\n",
            "[Batch 4] Current Loss: 5.1456\n",
            "[Batch 5] Current Loss: 5.6542\n",
            "[Batch 6] Current Loss: 4.7312\n",
            "[Batch 7] Current Loss: 5.8720\n",
            "[Batch 8] Current Loss: 5.2632\n",
            "[Batch 9] Current Loss: 4.6675\n",
            "Ep 3 (Step 016940): Train loss 3.457, Val loss 5.095\n",
            "[Batch 0] Current Loss: 3.6024\n",
            "[Batch 1] Current Loss: 3.4493\n",
            "[Batch 2] Current Loss: 3.4668\n",
            "[Batch 3] Current Loss: 3.6857\n",
            "[Batch 4] Current Loss: 3.7613\n",
            "[Batch 5] Current Loss: 3.5564\n",
            "[Batch 6] Current Loss: 2.6785\n",
            "[Batch 7] Current Loss: 3.2668\n",
            "[Batch 8] Current Loss: 3.4212\n",
            "[Batch 9] Current Loss: 3.0072\n",
            "[Batch 0] Current Loss: 5.0766\n",
            "[Batch 1] Current Loss: 4.8067\n",
            "[Batch 2] Current Loss: 5.1098\n",
            "[Batch 3] Current Loss: 5.4825\n",
            "[Batch 4] Current Loss: 4.1771\n",
            "[Batch 5] Current Loss: 5.3803\n",
            "[Batch 6] Current Loss: 4.3191\n",
            "[Batch 7] Current Loss: 4.7799\n",
            "[Batch 8] Current Loss: 5.7576\n",
            "[Batch 9] Current Loss: 4.7118\n",
            "Ep 3 (Step 016960): Train loss 3.390, Val loss 4.960\n",
            "[Batch 0] Current Loss: 3.4032\n",
            "[Batch 1] Current Loss: 3.2835\n",
            "[Batch 2] Current Loss: 3.6820\n",
            "[Batch 3] Current Loss: 3.1263\n",
            "[Batch 4] Current Loss: 3.5882\n",
            "[Batch 5] Current Loss: 3.0664\n",
            "[Batch 6] Current Loss: 2.6227\n",
            "[Batch 7] Current Loss: 3.0199\n",
            "[Batch 8] Current Loss: 3.3197\n",
            "[Batch 9] Current Loss: 3.5550\n",
            "[Batch 0] Current Loss: 5.5267\n",
            "[Batch 1] Current Loss: 5.4375\n",
            "[Batch 2] Current Loss: 5.3228\n",
            "[Batch 3] Current Loss: 5.5490\n",
            "[Batch 4] Current Loss: 5.2179\n",
            "[Batch 5] Current Loss: 5.4064\n",
            "[Batch 6] Current Loss: 5.5684\n",
            "[Batch 7] Current Loss: 5.3067\n",
            "[Batch 8] Current Loss: 4.8544\n",
            "[Batch 9] Current Loss: 5.6531\n",
            "Ep 3 (Step 016980): Train loss 3.267, Val loss 5.384\n",
            "[Batch 0] Current Loss: 3.0258\n",
            "[Batch 1] Current Loss: 3.3440\n",
            "[Batch 2] Current Loss: 3.0436\n",
            "[Batch 3] Current Loss: 3.7353\n",
            "[Batch 4] Current Loss: 2.9532\n",
            "[Batch 5] Current Loss: 3.7493\n",
            "[Batch 6] Current Loss: 4.1706\n",
            "[Batch 7] Current Loss: 3.4971\n",
            "[Batch 8] Current Loss: 3.5241\n",
            "[Batch 9] Current Loss: 3.4738\n",
            "[Batch 0] Current Loss: 5.7844\n",
            "[Batch 1] Current Loss: 5.7518\n",
            "[Batch 2] Current Loss: 5.1428\n",
            "[Batch 3] Current Loss: 5.7835\n",
            "[Batch 4] Current Loss: 4.5648\n",
            "[Batch 5] Current Loss: 5.8994\n",
            "[Batch 6] Current Loss: 4.9293\n",
            "[Batch 7] Current Loss: 6.0441\n",
            "[Batch 8] Current Loss: 4.8987\n",
            "[Batch 9] Current Loss: 5.2078\n",
            "Ep 3 (Step 017000): Train loss 3.452, Val loss 5.401\n",
            "[Batch 0] Current Loss: 3.0424\n",
            "[Batch 1] Current Loss: 3.7815\n",
            "[Batch 2] Current Loss: 3.1016\n",
            "[Batch 3] Current Loss: 3.3335\n",
            "[Batch 4] Current Loss: 3.3970\n",
            "[Batch 5] Current Loss: 3.2271\n",
            "[Batch 6] Current Loss: 3.5879\n",
            "[Batch 7] Current Loss: 3.2241\n",
            "[Batch 8] Current Loss: 3.8840\n",
            "[Batch 9] Current Loss: 3.6633\n",
            "[Batch 0] Current Loss: 4.7640\n",
            "[Batch 1] Current Loss: 5.4351\n",
            "[Batch 2] Current Loss: 5.0777\n",
            "[Batch 3] Current Loss: 5.1010\n",
            "[Batch 4] Current Loss: 5.6399\n",
            "[Batch 5] Current Loss: 4.9701\n",
            "[Batch 6] Current Loss: 5.6277\n",
            "[Batch 7] Current Loss: 4.7555\n",
            "[Batch 8] Current Loss: 6.3384\n",
            "[Batch 9] Current Loss: 5.3612\n",
            "Ep 3 (Step 017020): Train loss 3.424, Val loss 5.307\n",
            "[Batch 0] Current Loss: 3.5896\n",
            "[Batch 1] Current Loss: 3.5792\n",
            "[Batch 2] Current Loss: 4.0018\n",
            "[Batch 3] Current Loss: 3.5904\n",
            "[Batch 4] Current Loss: 3.7204\n",
            "[Batch 5] Current Loss: 2.8471\n",
            "[Batch 6] Current Loss: 3.1766\n",
            "[Batch 7] Current Loss: 3.7212\n",
            "[Batch 8] Current Loss: 2.9735\n",
            "[Batch 9] Current Loss: 3.1677\n",
            "[Batch 0] Current Loss: 5.6895\n",
            "[Batch 1] Current Loss: 5.0835\n",
            "[Batch 2] Current Loss: 4.9649\n",
            "[Batch 3] Current Loss: 5.6573\n",
            "[Batch 4] Current Loss: 4.9672\n",
            "[Batch 5] Current Loss: 4.8861\n",
            "[Batch 6] Current Loss: 5.6308\n",
            "[Batch 7] Current Loss: 5.6273\n",
            "[Batch 8] Current Loss: 4.9489\n",
            "[Batch 9] Current Loss: 4.8061\n",
            "Ep 3 (Step 017040): Train loss 3.437, Val loss 5.226\n",
            "[Batch 0] Current Loss: 3.0017\n",
            "[Batch 1] Current Loss: 3.5032\n",
            "[Batch 2] Current Loss: 3.6398\n",
            "[Batch 3] Current Loss: 3.8332\n",
            "[Batch 4] Current Loss: 3.2671\n",
            "[Batch 5] Current Loss: 3.6802\n",
            "[Batch 6] Current Loss: 3.3950\n",
            "[Batch 7] Current Loss: 3.3058\n",
            "[Batch 8] Current Loss: 3.2530\n",
            "[Batch 9] Current Loss: 2.7883\n",
            "[Batch 0] Current Loss: 4.9538\n",
            "[Batch 1] Current Loss: 5.7201\n",
            "[Batch 2] Current Loss: 5.4549\n",
            "[Batch 3] Current Loss: 5.3369\n",
            "[Batch 4] Current Loss: 5.1793\n",
            "[Batch 5] Current Loss: 5.3900\n",
            "[Batch 6] Current Loss: 5.1861\n",
            "[Batch 7] Current Loss: 5.4343\n",
            "[Batch 8] Current Loss: 5.5941\n",
            "[Batch 9] Current Loss: 5.4196\n",
            "Ep 3 (Step 017060): Train loss 3.367, Val loss 5.367\n",
            "[Batch 0] Current Loss: 3.3342\n",
            "[Batch 1] Current Loss: 3.1081\n",
            "[Batch 2] Current Loss: 3.2098\n",
            "[Batch 3] Current Loss: 3.1176\n",
            "[Batch 4] Current Loss: 3.8217\n",
            "[Batch 5] Current Loss: 3.4826\n",
            "[Batch 6] Current Loss: 3.4531\n",
            "[Batch 7] Current Loss: 3.5432\n",
            "[Batch 8] Current Loss: 3.2763\n",
            "[Batch 9] Current Loss: 3.3601\n",
            "[Batch 0] Current Loss: 5.2784\n",
            "[Batch 1] Current Loss: 4.7490\n",
            "[Batch 2] Current Loss: 5.7212\n",
            "[Batch 3] Current Loss: 5.6199\n",
            "[Batch 4] Current Loss: 5.2864\n",
            "[Batch 5] Current Loss: 5.6295\n",
            "[Batch 6] Current Loss: 4.7717\n",
            "[Batch 7] Current Loss: 5.1555\n",
            "[Batch 8] Current Loss: 5.3374\n",
            "[Batch 9] Current Loss: 4.9421\n",
            "Ep 3 (Step 017080): Train loss 3.371, Val loss 5.249\n",
            "[Batch 0] Current Loss: 3.3767\n",
            "[Batch 1] Current Loss: 3.1085\n",
            "[Batch 2] Current Loss: 3.2669\n",
            "[Batch 3] Current Loss: 3.3705\n",
            "[Batch 4] Current Loss: 3.6640\n",
            "[Batch 5] Current Loss: 3.3345\n",
            "[Batch 6] Current Loss: 3.2812\n",
            "[Batch 7] Current Loss: 3.2371\n",
            "[Batch 8] Current Loss: 3.5635\n",
            "[Batch 9] Current Loss: 3.3528\n",
            "[Batch 0] Current Loss: 4.9861\n",
            "[Batch 1] Current Loss: 5.7053\n",
            "[Batch 2] Current Loss: 5.1840\n",
            "[Batch 3] Current Loss: 4.8410\n",
            "[Batch 4] Current Loss: 5.3876\n",
            "[Batch 5] Current Loss: 5.5209\n",
            "[Batch 6] Current Loss: 5.2346\n",
            "[Batch 7] Current Loss: 6.0006\n",
            "[Batch 8] Current Loss: 6.0182\n",
            "[Batch 9] Current Loss: 5.8089\n",
            "Ep 3 (Step 017100): Train loss 3.356, Val loss 5.469\n",
            "[Batch 0] Current Loss: 3.6160\n",
            "[Batch 1] Current Loss: 3.6995\n",
            "[Batch 2] Current Loss: 3.4018\n",
            "[Batch 3] Current Loss: 3.4567\n",
            "[Batch 4] Current Loss: 2.9370\n",
            "[Batch 5] Current Loss: 4.4175\n",
            "[Batch 6] Current Loss: 3.5303\n",
            "[Batch 7] Current Loss: 3.3005\n",
            "[Batch 8] Current Loss: 2.8125\n",
            "[Batch 9] Current Loss: 2.9092\n",
            "[Batch 0] Current Loss: 5.5337\n",
            "[Batch 1] Current Loss: 5.6319\n",
            "[Batch 2] Current Loss: 5.5709\n",
            "[Batch 3] Current Loss: 5.0872\n",
            "[Batch 4] Current Loss: 5.3601\n",
            "[Batch 5] Current Loss: 5.3391\n",
            "[Batch 6] Current Loss: 6.3746\n",
            "[Batch 7] Current Loss: 4.4076\n",
            "[Batch 8] Current Loss: 5.0097\n",
            "[Batch 9] Current Loss: 4.9374\n",
            "Ep 3 (Step 017120): Train loss 3.408, Val loss 5.325\n",
            "[Batch 0] Current Loss: 2.9128\n",
            "[Batch 1] Current Loss: 3.1042\n",
            "[Batch 2] Current Loss: 3.1531\n",
            "[Batch 3] Current Loss: 3.5849\n",
            "[Batch 4] Current Loss: 3.3437\n",
            "[Batch 5] Current Loss: 3.6666\n",
            "[Batch 6] Current Loss: 3.0534\n",
            "[Batch 7] Current Loss: 3.7259\n",
            "[Batch 8] Current Loss: 3.4836\n",
            "[Batch 9] Current Loss: 3.4106\n",
            "[Batch 0] Current Loss: 5.0806\n",
            "[Batch 1] Current Loss: 5.1379\n",
            "[Batch 2] Current Loss: 6.3044\n",
            "[Batch 3] Current Loss: 5.4514\n",
            "[Batch 4] Current Loss: 5.5420\n",
            "[Batch 5] Current Loss: 5.1193\n",
            "[Batch 6] Current Loss: 4.8489\n",
            "[Batch 7] Current Loss: 5.0221\n",
            "[Batch 8] Current Loss: 5.3401\n",
            "[Batch 9] Current Loss: 4.9059\n",
            "Ep 3 (Step 017140): Train loss 3.344, Val loss 5.275\n",
            "[Batch 0] Current Loss: 3.3355\n",
            "[Batch 1] Current Loss: 3.0517\n",
            "[Batch 2] Current Loss: 3.1672\n",
            "[Batch 3] Current Loss: 3.6388\n",
            "[Batch 4] Current Loss: 3.4987\n",
            "[Batch 5] Current Loss: 3.6930\n",
            "[Batch 6] Current Loss: 3.4867\n",
            "[Batch 7] Current Loss: 3.1856\n",
            "[Batch 8] Current Loss: 3.4743\n",
            "[Batch 9] Current Loss: 3.0727\n",
            "[Batch 0] Current Loss: 5.7997\n",
            "[Batch 1] Current Loss: 5.2194\n",
            "[Batch 2] Current Loss: 5.1336\n",
            "[Batch 3] Current Loss: 5.1262\n",
            "[Batch 4] Current Loss: 5.3004\n",
            "[Batch 5] Current Loss: 4.8603\n",
            "[Batch 6] Current Loss: 4.6198\n",
            "[Batch 7] Current Loss: 4.8207\n",
            "[Batch 8] Current Loss: 5.5839\n",
            "[Batch 9] Current Loss: 5.3865\n",
            "Ep 3 (Step 017160): Train loss 3.360, Val loss 5.185\n",
            "[Batch 0] Current Loss: 3.4728\n",
            "[Batch 1] Current Loss: 3.7455\n",
            "[Batch 2] Current Loss: 3.0598\n",
            "[Batch 3] Current Loss: 3.8176\n",
            "[Batch 4] Current Loss: 2.7459\n",
            "[Batch 5] Current Loss: 3.3945\n",
            "[Batch 6] Current Loss: 3.3353\n",
            "[Batch 7] Current Loss: 3.9446\n",
            "[Batch 8] Current Loss: 3.3374\n",
            "[Batch 9] Current Loss: 3.3467\n",
            "[Batch 0] Current Loss: 5.4551\n",
            "[Batch 1] Current Loss: 5.0699\n",
            "[Batch 2] Current Loss: 5.7920\n",
            "[Batch 3] Current Loss: 5.2097\n",
            "[Batch 4] Current Loss: 5.4532\n",
            "[Batch 5] Current Loss: 4.6597\n",
            "[Batch 6] Current Loss: 5.4109\n",
            "[Batch 7] Current Loss: 5.2754\n",
            "[Batch 8] Current Loss: 6.1610\n",
            "[Batch 9] Current Loss: 5.4133\n",
            "Ep 3 (Step 017180): Train loss 3.420, Val loss 5.390\n",
            "[Batch 0] Current Loss: 3.4988\n",
            "[Batch 1] Current Loss: 3.4214\n",
            "[Batch 2] Current Loss: 3.4505\n",
            "[Batch 3] Current Loss: 3.5985\n",
            "[Batch 4] Current Loss: 2.7037\n",
            "[Batch 5] Current Loss: 3.7483\n",
            "[Batch 6] Current Loss: 3.9455\n",
            "[Batch 7] Current Loss: 3.5053\n",
            "[Batch 8] Current Loss: 3.4012\n",
            "[Batch 9] Current Loss: 3.2607\n",
            "[Batch 0] Current Loss: 5.3215\n",
            "[Batch 1] Current Loss: 4.8922\n",
            "[Batch 2] Current Loss: 5.0650\n",
            "[Batch 3] Current Loss: 5.3501\n",
            "[Batch 4] Current Loss: 5.6049\n",
            "[Batch 5] Current Loss: 5.2027\n",
            "[Batch 6] Current Loss: 5.6080\n",
            "[Batch 7] Current Loss: 5.2848\n",
            "[Batch 8] Current Loss: 5.4195\n",
            "[Batch 9] Current Loss: 4.8507\n",
            "Ep 3 (Step 017200): Train loss 3.453, Val loss 5.260\n",
            "[Batch 0] Current Loss: 2.9811\n",
            "[Batch 1] Current Loss: 3.3287\n",
            "[Batch 2] Current Loss: 3.7541\n",
            "[Batch 3] Current Loss: 3.2456\n",
            "[Batch 4] Current Loss: 3.4714\n",
            "[Batch 5] Current Loss: 3.4127\n",
            "[Batch 6] Current Loss: 3.6639\n",
            "[Batch 7] Current Loss: 3.4775\n",
            "[Batch 8] Current Loss: 3.4400\n",
            "[Batch 9] Current Loss: 3.4433\n",
            "[Batch 0] Current Loss: 5.3287\n",
            "[Batch 1] Current Loss: 5.2930\n",
            "[Batch 2] Current Loss: 4.9814\n",
            "[Batch 3] Current Loss: 5.3745\n",
            "[Batch 4] Current Loss: 5.6294\n",
            "[Batch 5] Current Loss: 4.9749\n",
            "[Batch 6] Current Loss: 6.2884\n",
            "[Batch 7] Current Loss: 5.2344\n",
            "[Batch 8] Current Loss: 5.4548\n",
            "[Batch 9] Current Loss: 5.3959\n",
            "Ep 3 (Step 017220): Train loss 3.422, Val loss 5.396\n",
            "[Batch 0] Current Loss: 3.2751\n",
            "[Batch 1] Current Loss: 3.0749\n",
            "[Batch 2] Current Loss: 3.2717\n",
            "[Batch 3] Current Loss: 3.8693\n",
            "[Batch 4] Current Loss: 2.9488\n",
            "[Batch 5] Current Loss: 3.7194\n",
            "[Batch 6] Current Loss: 3.4349\n",
            "[Batch 7] Current Loss: 3.6930\n",
            "[Batch 8] Current Loss: 3.7187\n",
            "[Batch 9] Current Loss: 3.7493\n",
            "[Batch 0] Current Loss: 5.4522\n",
            "[Batch 1] Current Loss: 4.8145\n",
            "[Batch 2] Current Loss: 4.9883\n",
            "[Batch 3] Current Loss: 5.4941\n",
            "[Batch 4] Current Loss: 5.3457\n",
            "[Batch 5] Current Loss: 5.0156\n",
            "[Batch 6] Current Loss: 4.8724\n",
            "[Batch 7] Current Loss: 4.7897\n",
            "[Batch 8] Current Loss: 5.2414\n",
            "[Batch 9] Current Loss: 5.1794\n",
            "Ep 3 (Step 017240): Train loss 3.476, Val loss 5.119\n",
            "[Batch 0] Current Loss: 3.1027\n",
            "[Batch 1] Current Loss: 3.2496\n",
            "[Batch 2] Current Loss: 3.4437\n",
            "[Batch 3] Current Loss: 3.8299\n",
            "[Batch 4] Current Loss: 3.4443\n",
            "[Batch 5] Current Loss: 4.0749\n",
            "[Batch 6] Current Loss: 3.1701\n",
            "[Batch 7] Current Loss: 3.8323\n",
            "[Batch 8] Current Loss: 3.6559\n",
            "[Batch 9] Current Loss: 2.8355\n",
            "[Batch 0] Current Loss: 5.4783\n",
            "[Batch 1] Current Loss: 5.7187\n",
            "[Batch 2] Current Loss: 5.3733\n",
            "[Batch 3] Current Loss: 5.3174\n",
            "[Batch 4] Current Loss: 5.7839\n",
            "[Batch 5] Current Loss: 4.8455\n",
            "[Batch 6] Current Loss: 4.6668\n",
            "[Batch 7] Current Loss: 6.0021\n",
            "[Batch 8] Current Loss: 5.6092\n",
            "[Batch 9] Current Loss: 5.3769\n",
            "Ep 3 (Step 017260): Train loss 3.464, Val loss 5.417\n",
            "[Batch 0] Current Loss: 3.7060\n",
            "[Batch 1] Current Loss: 2.8685\n",
            "[Batch 2] Current Loss: 3.6098\n",
            "[Batch 3] Current Loss: 2.6007\n",
            "[Batch 4] Current Loss: 3.5922\n",
            "[Batch 5] Current Loss: 3.4895\n",
            "[Batch 6] Current Loss: 2.9757\n",
            "[Batch 7] Current Loss: 3.7919\n",
            "[Batch 8] Current Loss: 2.6232\n",
            "[Batch 9] Current Loss: 3.8901\n",
            "[Batch 0] Current Loss: 4.6212\n",
            "[Batch 1] Current Loss: 5.6002\n",
            "[Batch 2] Current Loss: 5.4263\n",
            "[Batch 3] Current Loss: 4.8794\n",
            "[Batch 4] Current Loss: 5.0563\n",
            "[Batch 5] Current Loss: 5.0292\n",
            "[Batch 6] Current Loss: 4.7884\n",
            "[Batch 7] Current Loss: 5.3989\n",
            "[Batch 8] Current Loss: 5.1341\n",
            "[Batch 9] Current Loss: 5.6076\n",
            "Ep 3 (Step 017280): Train loss 3.315, Val loss 5.154\n",
            "[Batch 0] Current Loss: 3.2774\n",
            "[Batch 1] Current Loss: 3.0271\n",
            "[Batch 2] Current Loss: 2.9631\n",
            "[Batch 3] Current Loss: 3.5101\n",
            "[Batch 4] Current Loss: 3.1211\n",
            "[Batch 5] Current Loss: 3.5878\n",
            "[Batch 6] Current Loss: 2.8462\n",
            "[Batch 7] Current Loss: 3.1162\n",
            "[Batch 8] Current Loss: 4.2720\n",
            "[Batch 9] Current Loss: 3.8666\n",
            "[Batch 0] Current Loss: 4.8507\n",
            "[Batch 1] Current Loss: 4.0820\n",
            "[Batch 2] Current Loss: 5.9348\n",
            "[Batch 3] Current Loss: 5.4508\n",
            "[Batch 4] Current Loss: 5.2350\n",
            "[Batch 5] Current Loss: 5.3032\n",
            "[Batch 6] Current Loss: 5.3520\n",
            "[Batch 7] Current Loss: 4.9662\n",
            "[Batch 8] Current Loss: 4.7262\n",
            "[Batch 9] Current Loss: 4.1472\n",
            "Ep 3 (Step 017300): Train loss 3.359, Val loss 5.005\n",
            "[Batch 0] Current Loss: 3.9931\n",
            "[Batch 1] Current Loss: 3.6224\n",
            "[Batch 2] Current Loss: 3.5155\n",
            "[Batch 3] Current Loss: 3.5917\n",
            "[Batch 4] Current Loss: 3.8514\n",
            "[Batch 5] Current Loss: 3.8377\n",
            "[Batch 6] Current Loss: 2.8428\n",
            "[Batch 7] Current Loss: 3.5621\n",
            "[Batch 8] Current Loss: 3.0216\n",
            "[Batch 9] Current Loss: 2.8628\n",
            "[Batch 0] Current Loss: 4.7464\n",
            "[Batch 1] Current Loss: 5.2505\n",
            "[Batch 2] Current Loss: 5.2027\n",
            "[Batch 3] Current Loss: 5.7456\n",
            "[Batch 4] Current Loss: 5.2935\n",
            "[Batch 5] Current Loss: 5.0734\n",
            "[Batch 6] Current Loss: 5.5004\n",
            "[Batch 7] Current Loss: 4.9770\n",
            "[Batch 8] Current Loss: 5.4417\n",
            "[Batch 9] Current Loss: 5.7269\n",
            "Ep 3 (Step 017320): Train loss 3.470, Val loss 5.296\n",
            "[Batch 0] Current Loss: 3.5238\n",
            "[Batch 1] Current Loss: 3.6815\n",
            "[Batch 2] Current Loss: 3.5318\n",
            "[Batch 3] Current Loss: 3.0189\n",
            "[Batch 4] Current Loss: 3.1627\n",
            "[Batch 5] Current Loss: 2.8023\n",
            "[Batch 6] Current Loss: 2.8081\n",
            "[Batch 7] Current Loss: 2.9020\n",
            "[Batch 8] Current Loss: 3.4483\n",
            "[Batch 9] Current Loss: 2.9779\n",
            "[Batch 0] Current Loss: 5.3246\n",
            "[Batch 1] Current Loss: 5.0708\n",
            "[Batch 2] Current Loss: 5.7621\n",
            "[Batch 3] Current Loss: 4.8717\n",
            "[Batch 4] Current Loss: 5.6072\n",
            "[Batch 5] Current Loss: 5.0399\n",
            "[Batch 6] Current Loss: 4.4978\n",
            "[Batch 7] Current Loss: 5.2499\n",
            "[Batch 8] Current Loss: 5.4910\n",
            "[Batch 9] Current Loss: 4.9668\n",
            "Ep 3 (Step 017340): Train loss 3.186, Val loss 5.188\n",
            "[Batch 0] Current Loss: 3.3399\n",
            "[Batch 1] Current Loss: 3.9529\n",
            "[Batch 2] Current Loss: 3.0520\n",
            "[Batch 3] Current Loss: 3.5904\n",
            "[Batch 4] Current Loss: 3.0544\n",
            "[Batch 5] Current Loss: 3.5347\n",
            "[Batch 6] Current Loss: 3.7247\n",
            "[Batch 7] Current Loss: 3.5066\n",
            "[Batch 8] Current Loss: 3.6363\n",
            "[Batch 9] Current Loss: 2.9930\n",
            "[Batch 0] Current Loss: 5.1036\n",
            "[Batch 1] Current Loss: 5.7185\n",
            "[Batch 2] Current Loss: 4.3632\n",
            "[Batch 3] Current Loss: 4.9621\n",
            "[Batch 4] Current Loss: 4.8903\n",
            "[Batch 5] Current Loss: 5.7402\n",
            "[Batch 6] Current Loss: 4.7936\n",
            "[Batch 7] Current Loss: 5.8236\n",
            "[Batch 8] Current Loss: 4.9200\n",
            "[Batch 9] Current Loss: 5.1314\n",
            "Ep 3 (Step 017360): Train loss 3.438, Val loss 5.145\n",
            "[Batch 0] Current Loss: 3.2386\n",
            "[Batch 1] Current Loss: 3.4193\n",
            "[Batch 2] Current Loss: 3.8954\n",
            "[Batch 3] Current Loss: 3.1640\n",
            "[Batch 4] Current Loss: 3.1547\n",
            "[Batch 5] Current Loss: 3.5391\n",
            "[Batch 6] Current Loss: 3.5776\n",
            "[Batch 7] Current Loss: 3.1420\n",
            "[Batch 8] Current Loss: 3.2306\n",
            "[Batch 9] Current Loss: 3.2275\n",
            "[Batch 0] Current Loss: 5.1612\n",
            "[Batch 1] Current Loss: 6.0573\n",
            "[Batch 2] Current Loss: 5.6578\n",
            "[Batch 3] Current Loss: 5.4091\n",
            "[Batch 4] Current Loss: 5.8664\n",
            "[Batch 5] Current Loss: 5.4184\n",
            "[Batch 6] Current Loss: 5.3417\n",
            "[Batch 7] Current Loss: 5.2440\n",
            "[Batch 8] Current Loss: 5.4267\n",
            "[Batch 9] Current Loss: 5.6491\n",
            "Ep 3 (Step 017380): Train loss 3.359, Val loss 5.523\n",
            "[Batch 0] Current Loss: 3.5656\n",
            "[Batch 1] Current Loss: 3.6655\n",
            "[Batch 2] Current Loss: 4.4623\n",
            "[Batch 3] Current Loss: 3.1567\n",
            "[Batch 4] Current Loss: 3.6226\n",
            "[Batch 5] Current Loss: 3.2863\n",
            "[Batch 6] Current Loss: 3.6265\n",
            "[Batch 7] Current Loss: 3.0967\n",
            "[Batch 8] Current Loss: 3.2730\n",
            "[Batch 9] Current Loss: 4.0973\n",
            "[Batch 0] Current Loss: 4.7016\n",
            "[Batch 1] Current Loss: 5.5581\n",
            "[Batch 2] Current Loss: 5.1873\n",
            "[Batch 3] Current Loss: 4.7129\n",
            "[Batch 4] Current Loss: 4.2816\n",
            "[Batch 5] Current Loss: 6.0441\n",
            "[Batch 6] Current Loss: 5.1388\n",
            "[Batch 7] Current Loss: 5.5233\n",
            "[Batch 8] Current Loss: 5.3913\n",
            "[Batch 9] Current Loss: 5.2453\n",
            "Ep 3 (Step 017400): Train loss 3.585, Val loss 5.178\n",
            "[Batch 0] Current Loss: 3.5906\n",
            "[Batch 1] Current Loss: 3.4653\n",
            "[Batch 2] Current Loss: 2.5582\n",
            "[Batch 3] Current Loss: 3.0259\n",
            "[Batch 4] Current Loss: 3.6366\n",
            "[Batch 5] Current Loss: 3.3663\n",
            "[Batch 6] Current Loss: 3.3153\n",
            "[Batch 7] Current Loss: 3.4170\n",
            "[Batch 8] Current Loss: 2.9366\n",
            "[Batch 9] Current Loss: 3.1301\n",
            "[Batch 0] Current Loss: 5.8969\n",
            "[Batch 1] Current Loss: 5.2054\n",
            "[Batch 2] Current Loss: 5.7097\n",
            "[Batch 3] Current Loss: 5.6024\n",
            "[Batch 4] Current Loss: 5.1760\n",
            "[Batch 5] Current Loss: 5.1814\n",
            "[Batch 6] Current Loss: 4.4824\n",
            "[Batch 7] Current Loss: 4.6152\n",
            "[Batch 8] Current Loss: 6.0247\n",
            "[Batch 9] Current Loss: 5.3540\n",
            "Ep 3 (Step 017420): Train loss 3.244, Val loss 5.325\n",
            "[Batch 0] Current Loss: 3.0857\n",
            "[Batch 1] Current Loss: 3.9486\n",
            "[Batch 2] Current Loss: 2.7355\n",
            "[Batch 3] Current Loss: 3.5126\n",
            "[Batch 4] Current Loss: 3.7071\n",
            "[Batch 5] Current Loss: 3.3090\n",
            "[Batch 6] Current Loss: 3.6583\n",
            "[Batch 7] Current Loss: 3.3909\n",
            "[Batch 8] Current Loss: 3.4741\n",
            "[Batch 9] Current Loss: 3.8226\n",
            "[Batch 0] Current Loss: 5.4231\n",
            "[Batch 1] Current Loss: 6.2592\n",
            "[Batch 2] Current Loss: 5.4559\n",
            "[Batch 3] Current Loss: 4.9179\n",
            "[Batch 4] Current Loss: 4.8643\n",
            "[Batch 5] Current Loss: 4.4455\n",
            "[Batch 6] Current Loss: 5.0999\n",
            "[Batch 7] Current Loss: 5.3960\n",
            "[Batch 8] Current Loss: 5.2981\n",
            "[Batch 9] Current Loss: 5.3875\n",
            "Ep 3 (Step 017440): Train loss 3.464, Val loss 5.255\n",
            "[Batch 0] Current Loss: 3.7280\n",
            "[Batch 1] Current Loss: 3.9075\n",
            "[Batch 2] Current Loss: 2.8462\n",
            "[Batch 3] Current Loss: 2.7813\n",
            "[Batch 4] Current Loss: 3.5217\n",
            "[Batch 5] Current Loss: 3.4535\n",
            "[Batch 6] Current Loss: 2.7680\n",
            "[Batch 7] Current Loss: 3.6693\n",
            "[Batch 8] Current Loss: 3.4018\n",
            "[Batch 9] Current Loss: 3.6126\n",
            "[Batch 0] Current Loss: 5.5905\n",
            "[Batch 1] Current Loss: 4.9900\n",
            "[Batch 2] Current Loss: 5.6948\n",
            "[Batch 3] Current Loss: 4.7706\n",
            "[Batch 4] Current Loss: 5.4493\n",
            "[Batch 5] Current Loss: 5.4986\n",
            "[Batch 6] Current Loss: 6.0781\n",
            "[Batch 7] Current Loss: 6.5796\n",
            "[Batch 8] Current Loss: 5.0655\n",
            "[Batch 9] Current Loss: 5.5999\n",
            "Ep 3 (Step 017460): Train loss 3.369, Val loss 5.532\n",
            "[Batch 0] Current Loss: 3.3230\n",
            "[Batch 1] Current Loss: 3.7776\n",
            "[Batch 2] Current Loss: 2.9344\n",
            "[Batch 3] Current Loss: 3.8284\n",
            "[Batch 4] Current Loss: 3.1069\n",
            "[Batch 5] Current Loss: 3.4850\n",
            "[Batch 6] Current Loss: 3.5196\n",
            "[Batch 7] Current Loss: 3.7422\n",
            "[Batch 8] Current Loss: 3.4977\n",
            "[Batch 9] Current Loss: 3.2814\n",
            "[Batch 0] Current Loss: 5.9963\n",
            "[Batch 1] Current Loss: 5.2791\n",
            "[Batch 2] Current Loss: 5.2837\n",
            "[Batch 3] Current Loss: 5.9439\n",
            "[Batch 4] Current Loss: 4.9893\n",
            "[Batch 5] Current Loss: 4.8147\n",
            "[Batch 6] Current Loss: 4.7239\n",
            "[Batch 7] Current Loss: 5.7213\n",
            "[Batch 8] Current Loss: 5.2323\n",
            "[Batch 9] Current Loss: 5.8547\n",
            "Ep 3 (Step 017480): Train loss 3.450, Val loss 5.384\n",
            "[Batch 0] Current Loss: 3.9484\n",
            "[Batch 1] Current Loss: 3.3808\n",
            "[Batch 2] Current Loss: 2.9973\n",
            "[Batch 3] Current Loss: 3.9567\n",
            "[Batch 4] Current Loss: 3.0055\n",
            "[Batch 5] Current Loss: 3.0332\n",
            "[Batch 6] Current Loss: 3.1933\n",
            "[Batch 7] Current Loss: 3.2297\n",
            "[Batch 8] Current Loss: 3.4607\n",
            "[Batch 9] Current Loss: 2.7401\n",
            "[Batch 0] Current Loss: 5.5711\n",
            "[Batch 1] Current Loss: 5.4191\n",
            "[Batch 2] Current Loss: 4.5552\n",
            "[Batch 3] Current Loss: 5.0181\n",
            "[Batch 4] Current Loss: 5.5484\n",
            "[Batch 5] Current Loss: 4.6662\n",
            "[Batch 6] Current Loss: 5.7565\n",
            "[Batch 7] Current Loss: 4.8041\n",
            "[Batch 8] Current Loss: 5.1232\n",
            "[Batch 9] Current Loss: 5.4803\n",
            "Ep 3 (Step 017500): Train loss 3.295, Val loss 5.194\n",
            "[Batch 0] Current Loss: 3.3462\n",
            "[Batch 1] Current Loss: 3.6075\n",
            "[Batch 2] Current Loss: 3.2688\n",
            "[Batch 3] Current Loss: 3.2657\n",
            "[Batch 4] Current Loss: 3.1307\n",
            "[Batch 5] Current Loss: 3.5420\n",
            "[Batch 6] Current Loss: 3.1178\n",
            "[Batch 7] Current Loss: 3.6995\n",
            "[Batch 8] Current Loss: 3.6376\n",
            "[Batch 9] Current Loss: 3.1943\n",
            "[Batch 0] Current Loss: 5.7551\n",
            "[Batch 1] Current Loss: 4.5141\n",
            "[Batch 2] Current Loss: 4.3639\n",
            "[Batch 3] Current Loss: 5.1317\n",
            "[Batch 4] Current Loss: 5.0020\n",
            "[Batch 5] Current Loss: 4.8220\n",
            "[Batch 6] Current Loss: 5.7615\n",
            "[Batch 7] Current Loss: 5.8607\n",
            "[Batch 8] Current Loss: 5.5190\n",
            "[Batch 9] Current Loss: 4.5807\n",
            "Ep 3 (Step 017520): Train loss 3.381, Val loss 5.131\n",
            "[Batch 0] Current Loss: 3.5781\n",
            "[Batch 1] Current Loss: 4.0704\n",
            "[Batch 2] Current Loss: 3.4235\n",
            "[Batch 3] Current Loss: 3.1444\n",
            "[Batch 4] Current Loss: 2.9874\n",
            "[Batch 5] Current Loss: 3.3242\n",
            "[Batch 6] Current Loss: 3.2813\n",
            "[Batch 7] Current Loss: 3.3929\n",
            "[Batch 8] Current Loss: 3.8657\n",
            "[Batch 9] Current Loss: 2.4500\n",
            "[Batch 0] Current Loss: 6.0112\n",
            "[Batch 1] Current Loss: 5.2150\n",
            "[Batch 2] Current Loss: 5.3985\n",
            "[Batch 3] Current Loss: 6.2420\n",
            "[Batch 4] Current Loss: 5.3993\n",
            "[Batch 5] Current Loss: 4.9563\n",
            "[Batch 6] Current Loss: 5.2456\n",
            "[Batch 7] Current Loss: 5.7087\n",
            "[Batch 8] Current Loss: 5.9342\n",
            "[Batch 9] Current Loss: 5.2526\n",
            "Ep 3 (Step 017540): Train loss 3.352, Val loss 5.536\n",
            "[Batch 0] Current Loss: 3.6788\n",
            "[Batch 1] Current Loss: 3.3793\n",
            "[Batch 2] Current Loss: 3.3718\n",
            "[Batch 3] Current Loss: 3.3229\n",
            "[Batch 4] Current Loss: 3.0352\n",
            "[Batch 5] Current Loss: 3.6971\n",
            "[Batch 6] Current Loss: 3.6873\n",
            "[Batch 7] Current Loss: 3.2290\n",
            "[Batch 8] Current Loss: 3.3629\n",
            "[Batch 9] Current Loss: 3.1282\n",
            "[Batch 0] Current Loss: 5.8169\n",
            "[Batch 1] Current Loss: 5.6329\n",
            "[Batch 2] Current Loss: 4.6966\n",
            "[Batch 3] Current Loss: 5.4252\n",
            "[Batch 4] Current Loss: 5.2350\n",
            "[Batch 5] Current Loss: 5.0604\n",
            "[Batch 6] Current Loss: 5.6705\n",
            "[Batch 7] Current Loss: 5.3296\n",
            "[Batch 8] Current Loss: 5.3534\n",
            "[Batch 9] Current Loss: 5.4257\n",
            "Ep 3 (Step 017560): Train loss 3.389, Val loss 5.365\n",
            "[Batch 0] Current Loss: 3.3245\n",
            "[Batch 1] Current Loss: 3.6984\n",
            "[Batch 2] Current Loss: 3.0511\n",
            "[Batch 3] Current Loss: 3.2575\n",
            "[Batch 4] Current Loss: 3.0289\n",
            "[Batch 5] Current Loss: 3.9734\n",
            "[Batch 6] Current Loss: 3.7442\n",
            "[Batch 7] Current Loss: 2.8690\n",
            "[Batch 8] Current Loss: 3.8831\n",
            "[Batch 9] Current Loss: 3.3930\n",
            "[Batch 0] Current Loss: 5.5376\n",
            "[Batch 1] Current Loss: 5.3337\n",
            "[Batch 2] Current Loss: 5.6189\n",
            "[Batch 3] Current Loss: 5.1728\n",
            "[Batch 4] Current Loss: 5.0196\n",
            "[Batch 5] Current Loss: 5.4571\n",
            "[Batch 6] Current Loss: 6.0176\n",
            "[Batch 7] Current Loss: 5.6448\n",
            "[Batch 8] Current Loss: 5.3757\n",
            "[Batch 9] Current Loss: 5.0011\n",
            "Ep 3 (Step 017580): Train loss 3.422, Val loss 5.418\n",
            "[Batch 0] Current Loss: 3.6275\n",
            "[Batch 1] Current Loss: 3.2855\n",
            "[Batch 2] Current Loss: 2.9574\n",
            "[Batch 3] Current Loss: 3.7473\n",
            "[Batch 4] Current Loss: 3.6714\n",
            "[Batch 5] Current Loss: 3.3015\n",
            "[Batch 6] Current Loss: 3.1392\n",
            "[Batch 7] Current Loss: 3.5861\n",
            "[Batch 8] Current Loss: 3.3730\n",
            "[Batch 9] Current Loss: 3.1182\n",
            "[Batch 0] Current Loss: 5.6041\n",
            "[Batch 1] Current Loss: 5.1134\n",
            "[Batch 2] Current Loss: 5.8994\n",
            "[Batch 3] Current Loss: 5.5775\n",
            "[Batch 4] Current Loss: 5.7416\n",
            "[Batch 5] Current Loss: 4.7682\n",
            "[Batch 6] Current Loss: 4.5439\n",
            "[Batch 7] Current Loss: 5.0569\n",
            "[Batch 8] Current Loss: 5.2002\n",
            "[Batch 9] Current Loss: 5.3677\n",
            "Ep 3 (Step 017600): Train loss 3.381, Val loss 5.287\n",
            "[Batch 0] Current Loss: 3.7314\n",
            "[Batch 1] Current Loss: 3.7039\n",
            "[Batch 2] Current Loss: 3.2786\n",
            "[Batch 3] Current Loss: 3.2965\n",
            "[Batch 4] Current Loss: 3.1620\n",
            "[Batch 5] Current Loss: 3.4090\n",
            "[Batch 6] Current Loss: 3.3133\n",
            "[Batch 7] Current Loss: 3.5403\n",
            "[Batch 8] Current Loss: 3.0708\n",
            "[Batch 9] Current Loss: 3.7414\n",
            "[Batch 0] Current Loss: 5.0932\n",
            "[Batch 1] Current Loss: 5.2905\n",
            "[Batch 2] Current Loss: 6.1813\n",
            "[Batch 3] Current Loss: 4.5022\n",
            "[Batch 4] Current Loss: 5.9190\n",
            "[Batch 5] Current Loss: 5.2980\n",
            "[Batch 6] Current Loss: 5.3099\n",
            "[Batch 7] Current Loss: 5.6910\n",
            "[Batch 8] Current Loss: 5.1355\n",
            "[Batch 9] Current Loss: 5.3244\n",
            "Ep 3 (Step 017620): Train loss 3.425, Val loss 5.374\n",
            "[Batch 0] Current Loss: 3.6159\n",
            "[Batch 1] Current Loss: 3.2713\n",
            "[Batch 2] Current Loss: 2.8448\n",
            "[Batch 3] Current Loss: 3.6208\n",
            "[Batch 4] Current Loss: 3.0650\n",
            "[Batch 5] Current Loss: 3.0150\n",
            "[Batch 6] Current Loss: 3.3876\n",
            "[Batch 7] Current Loss: 3.5246\n",
            "[Batch 8] Current Loss: 3.9024\n",
            "[Batch 9] Current Loss: 2.7118\n",
            "[Batch 0] Current Loss: 5.5855\n",
            "[Batch 1] Current Loss: 4.6501\n",
            "[Batch 2] Current Loss: 5.4601\n",
            "[Batch 3] Current Loss: 5.2919\n",
            "[Batch 4] Current Loss: 5.1610\n",
            "[Batch 5] Current Loss: 5.6476\n",
            "[Batch 6] Current Loss: 5.5321\n",
            "[Batch 7] Current Loss: 5.0937\n",
            "[Batch 8] Current Loss: 5.1694\n",
            "[Batch 9] Current Loss: 5.5013\n",
            "Ep 3 (Step 017640): Train loss 3.296, Val loss 5.309\n",
            "[Batch 0] Current Loss: 3.9402\n",
            "[Batch 1] Current Loss: 2.7109\n",
            "[Batch 2] Current Loss: 3.1679\n",
            "[Batch 3] Current Loss: 2.9866\n",
            "[Batch 4] Current Loss: 3.9498\n",
            "[Batch 5] Current Loss: 3.4681\n",
            "[Batch 6] Current Loss: 3.3961\n",
            "[Batch 7] Current Loss: 3.3914\n",
            "[Batch 8] Current Loss: 3.2587\n",
            "[Batch 9] Current Loss: 3.1340\n",
            "[Batch 0] Current Loss: 5.2766\n",
            "[Batch 1] Current Loss: 5.1890\n",
            "[Batch 2] Current Loss: 5.8444\n",
            "[Batch 3] Current Loss: 5.3098\n",
            "[Batch 4] Current Loss: 5.7028\n",
            "[Batch 5] Current Loss: 5.7830\n",
            "[Batch 6] Current Loss: 4.4306\n",
            "[Batch 7] Current Loss: 4.8480\n",
            "[Batch 8] Current Loss: 4.9287\n",
            "[Batch 9] Current Loss: 5.3265\n",
            "Ep 3 (Step 017660): Train loss 3.340, Val loss 5.264\n",
            "[Batch 0] Current Loss: 3.2380\n",
            "[Batch 1] Current Loss: 3.5267\n",
            "[Batch 2] Current Loss: 3.8647\n",
            "[Batch 3] Current Loss: 3.6208\n",
            "[Batch 4] Current Loss: 3.7069\n",
            "[Batch 5] Current Loss: 3.4261\n",
            "[Batch 6] Current Loss: 3.0862\n",
            "[Batch 7] Current Loss: 2.3800\n",
            "[Batch 8] Current Loss: 3.5735\n",
            "[Batch 9] Current Loss: 4.1052\n",
            "[Batch 0] Current Loss: 5.0564\n",
            "[Batch 1] Current Loss: 3.7505\n",
            "[Batch 2] Current Loss: 5.5254\n",
            "[Batch 3] Current Loss: 5.1352\n",
            "[Batch 4] Current Loss: 5.4069\n",
            "[Batch 5] Current Loss: 4.9744\n",
            "[Batch 6] Current Loss: 5.6380\n",
            "[Batch 7] Current Loss: 5.5330\n",
            "[Batch 8] Current Loss: 5.5605\n",
            "[Batch 9] Current Loss: 4.8192\n",
            "Ep 3 (Step 017680): Train loss 3.453, Val loss 5.140\n",
            "[Batch 0] Current Loss: 2.9333\n",
            "[Batch 1] Current Loss: 3.5956\n",
            "[Batch 2] Current Loss: 2.8321\n",
            "[Batch 3] Current Loss: 3.3681\n",
            "[Batch 4] Current Loss: 3.0682\n",
            "[Batch 5] Current Loss: 3.6638\n",
            "[Batch 6] Current Loss: 3.6325\n",
            "[Batch 7] Current Loss: 4.1412\n",
            "[Batch 8] Current Loss: 3.2164\n",
            "[Batch 9] Current Loss: 3.4441\n",
            "[Batch 0] Current Loss: 5.2095\n",
            "[Batch 1] Current Loss: 4.8843\n",
            "[Batch 2] Current Loss: 5.5621\n",
            "[Batch 3] Current Loss: 6.0007\n",
            "[Batch 4] Current Loss: 5.6883\n",
            "[Batch 5] Current Loss: 5.0430\n",
            "[Batch 6] Current Loss: 4.7651\n",
            "[Batch 7] Current Loss: 5.3262\n",
            "[Batch 8] Current Loss: 5.4173\n",
            "[Batch 9] Current Loss: 5.1378\n",
            "Ep 3 (Step 017700): Train loss 3.390, Val loss 5.303\n",
            "[Batch 0] Current Loss: 3.3890\n",
            "[Batch 1] Current Loss: 3.2171\n",
            "[Batch 2] Current Loss: 3.3639\n",
            "[Batch 3] Current Loss: 2.9577\n",
            "[Batch 4] Current Loss: 3.0955\n",
            "[Batch 5] Current Loss: 3.2337\n",
            "[Batch 6] Current Loss: 3.2229\n",
            "[Batch 7] Current Loss: 3.3099\n",
            "[Batch 8] Current Loss: 2.9452\n",
            "[Batch 9] Current Loss: 3.5080\n",
            "[Batch 0] Current Loss: 5.4354\n",
            "[Batch 1] Current Loss: 5.9223\n",
            "[Batch 2] Current Loss: 5.1385\n",
            "[Batch 3] Current Loss: 5.4739\n",
            "[Batch 4] Current Loss: 5.6328\n",
            "[Batch 5] Current Loss: 5.2989\n",
            "[Batch 6] Current Loss: 5.3008\n",
            "[Batch 7] Current Loss: 5.2415\n",
            "[Batch 8] Current Loss: 5.5544\n",
            "[Batch 9] Current Loss: 5.3803\n",
            "Ep 3 (Step 017720): Train loss 3.224, Val loss 5.438\n",
            "[Batch 0] Current Loss: 3.4270\n",
            "[Batch 1] Current Loss: 3.7292\n",
            "[Batch 2] Current Loss: 3.5673\n",
            "[Batch 3] Current Loss: 2.7550\n",
            "[Batch 4] Current Loss: 3.6994\n",
            "[Batch 5] Current Loss: 2.6819\n",
            "[Batch 6] Current Loss: 3.4806\n",
            "[Batch 7] Current Loss: 3.4212\n",
            "[Batch 8] Current Loss: 3.7261\n",
            "[Batch 9] Current Loss: 3.5713\n",
            "[Batch 0] Current Loss: 5.0712\n",
            "[Batch 1] Current Loss: 5.2808\n",
            "[Batch 2] Current Loss: 5.9261\n",
            "[Batch 3] Current Loss: 4.2566\n",
            "[Batch 4] Current Loss: 5.1514\n",
            "[Batch 5] Current Loss: 5.5655\n",
            "[Batch 6] Current Loss: 5.1395\n",
            "[Batch 7] Current Loss: 5.5047\n",
            "[Batch 8] Current Loss: 5.1379\n",
            "[Batch 9] Current Loss: 4.5985\n",
            "Ep 3 (Step 017740): Train loss 3.406, Val loss 5.163\n",
            "[Batch 0] Current Loss: 2.9988\n",
            "[Batch 1] Current Loss: 3.5021\n",
            "[Batch 2] Current Loss: 3.4043\n",
            "[Batch 3] Current Loss: 3.4341\n",
            "[Batch 4] Current Loss: 3.3983\n",
            "[Batch 5] Current Loss: 3.8033\n",
            "[Batch 6] Current Loss: 3.8053\n",
            "[Batch 7] Current Loss: 3.2459\n",
            "[Batch 8] Current Loss: 3.4262\n",
            "[Batch 9] Current Loss: 3.2052\n",
            "[Batch 0] Current Loss: 5.0754\n",
            "[Batch 1] Current Loss: 5.6217\n",
            "[Batch 2] Current Loss: 5.6393\n",
            "[Batch 3] Current Loss: 5.4473\n",
            "[Batch 4] Current Loss: 6.0562\n",
            "[Batch 5] Current Loss: 5.3432\n",
            "[Batch 6] Current Loss: 5.1547\n",
            "[Batch 7] Current Loss: 4.4841\n",
            "[Batch 8] Current Loss: 5.8336\n",
            "[Batch 9] Current Loss: 5.6826\n",
            "Ep 3 (Step 017760): Train loss 3.422, Val loss 5.434\n",
            "[Batch 0] Current Loss: 3.4828\n",
            "[Batch 1] Current Loss: 3.1116\n",
            "[Batch 2] Current Loss: 3.2761\n",
            "[Batch 3] Current Loss: 3.8391\n",
            "[Batch 4] Current Loss: 3.1277\n",
            "[Batch 5] Current Loss: 3.5224\n",
            "[Batch 6] Current Loss: 3.5283\n",
            "[Batch 7] Current Loss: 3.0820\n",
            "[Batch 8] Current Loss: 2.8593\n",
            "[Batch 9] Current Loss: 3.1216\n",
            "[Batch 0] Current Loss: 6.3420\n",
            "[Batch 1] Current Loss: 5.4153\n",
            "[Batch 2] Current Loss: 5.4072\n",
            "[Batch 3] Current Loss: 5.5948\n",
            "[Batch 4] Current Loss: 5.5219\n",
            "[Batch 5] Current Loss: 5.0120\n",
            "[Batch 6] Current Loss: 5.5359\n",
            "[Batch 7] Current Loss: 5.6906\n",
            "[Batch 8] Current Loss: 5.9012\n",
            "[Batch 9] Current Loss: 5.2834\n",
            "Ep 3 (Step 017780): Train loss 3.295, Val loss 5.570\n",
            "[Batch 0] Current Loss: 3.1186\n",
            "[Batch 1] Current Loss: 3.2146\n",
            "[Batch 2] Current Loss: 3.5338\n",
            "[Batch 3] Current Loss: 3.7479\n",
            "[Batch 4] Current Loss: 3.3422\n",
            "[Batch 5] Current Loss: 2.7873\n",
            "[Batch 6] Current Loss: 3.7684\n",
            "[Batch 7] Current Loss: 3.7933\n",
            "[Batch 8] Current Loss: 2.9159\n",
            "[Batch 9] Current Loss: 3.0423\n",
            "[Batch 0] Current Loss: 5.4502\n",
            "[Batch 1] Current Loss: 4.2968\n",
            "[Batch 2] Current Loss: 5.5193\n",
            "[Batch 3] Current Loss: 4.7396\n",
            "[Batch 4] Current Loss: 4.7314\n",
            "[Batch 5] Current Loss: 5.8256\n",
            "[Batch 6] Current Loss: 5.1041\n",
            "[Batch 7] Current Loss: 5.1197\n",
            "[Batch 8] Current Loss: 5.1138\n",
            "[Batch 9] Current Loss: 4.6800\n",
            "Ep 3 (Step 017800): Train loss 3.326, Val loss 5.058\n",
            "[Batch 0] Current Loss: 3.4867\n",
            "[Batch 1] Current Loss: 2.9280\n",
            "[Batch 2] Current Loss: 3.1706\n",
            "[Batch 3] Current Loss: 3.0273\n",
            "[Batch 4] Current Loss: 3.4199\n",
            "[Batch 5] Current Loss: 3.5622\n",
            "[Batch 6] Current Loss: 2.7429\n",
            "[Batch 7] Current Loss: 3.7751\n",
            "[Batch 8] Current Loss: 3.3264\n",
            "[Batch 9] Current Loss: 3.2898\n",
            "[Batch 0] Current Loss: 5.3185\n",
            "[Batch 1] Current Loss: 4.3233\n",
            "[Batch 2] Current Loss: 4.5839\n",
            "[Batch 3] Current Loss: 4.9532\n",
            "[Batch 4] Current Loss: 5.8606\n",
            "[Batch 5] Current Loss: 5.7486\n",
            "[Batch 6] Current Loss: 5.3709\n",
            "[Batch 7] Current Loss: 5.6196\n",
            "[Batch 8] Current Loss: 5.6738\n",
            "[Batch 9] Current Loss: 5.2721\n",
            "Ep 3 (Step 017820): Train loss 3.273, Val loss 5.272\n",
            "[Batch 0] Current Loss: 3.4908\n",
            "[Batch 1] Current Loss: 3.2661\n",
            "[Batch 2] Current Loss: 3.1978\n",
            "[Batch 3] Current Loss: 3.4828\n",
            "[Batch 4] Current Loss: 3.1945\n",
            "[Batch 5] Current Loss: 3.3893\n",
            "[Batch 6] Current Loss: 3.0125\n",
            "[Batch 7] Current Loss: 3.2006\n",
            "[Batch 8] Current Loss: 3.1802\n",
            "[Batch 9] Current Loss: 3.5803\n",
            "[Batch 0] Current Loss: 5.1630\n",
            "[Batch 1] Current Loss: 5.2671\n",
            "[Batch 2] Current Loss: 5.2704\n",
            "[Batch 3] Current Loss: 5.3316\n",
            "[Batch 4] Current Loss: 5.8470\n",
            "[Batch 5] Current Loss: 4.3474\n",
            "[Batch 6] Current Loss: 5.5432\n",
            "[Batch 7] Current Loss: 4.4944\n",
            "[Batch 8] Current Loss: 5.3815\n",
            "[Batch 9] Current Loss: 5.1416\n",
            "Ep 3 (Step 017840): Train loss 3.299, Val loss 5.179\n",
            "[Batch 0] Current Loss: 3.6487\n",
            "[Batch 1] Current Loss: 3.2779\n",
            "[Batch 2] Current Loss: 3.4627\n",
            "[Batch 3] Current Loss: 3.0502\n",
            "[Batch 4] Current Loss: 3.2654\n",
            "[Batch 5] Current Loss: 3.3276\n",
            "[Batch 6] Current Loss: 3.5020\n",
            "[Batch 7] Current Loss: 3.7029\n",
            "[Batch 8] Current Loss: 3.3146\n",
            "[Batch 9] Current Loss: 3.7198\n",
            "[Batch 0] Current Loss: 6.0871\n",
            "[Batch 1] Current Loss: 5.0432\n",
            "[Batch 2] Current Loss: 5.2659\n",
            "[Batch 3] Current Loss: 5.4495\n",
            "[Batch 4] Current Loss: 5.8962\n",
            "[Batch 5] Current Loss: 4.9931\n",
            "[Batch 6] Current Loss: 4.7065\n",
            "[Batch 7] Current Loss: 3.8225\n",
            "[Batch 8] Current Loss: 5.0738\n",
            "[Batch 9] Current Loss: 5.2294\n",
            "Ep 3 (Step 017860): Train loss 3.427, Val loss 5.157\n",
            "[Batch 0] Current Loss: 3.2803\n",
            "[Batch 1] Current Loss: 3.1595\n",
            "[Batch 2] Current Loss: 2.9313\n",
            "[Batch 3] Current Loss: 3.6350\n",
            "[Batch 4] Current Loss: 3.2254\n",
            "[Batch 5] Current Loss: 3.2440\n",
            "[Batch 6] Current Loss: 3.1697\n",
            "[Batch 7] Current Loss: 3.6327\n",
            "[Batch 8] Current Loss: 3.0754\n",
            "[Batch 9] Current Loss: 3.8521\n",
            "[Batch 0] Current Loss: 5.7320\n",
            "[Batch 1] Current Loss: 5.2449\n",
            "[Batch 2] Current Loss: 4.9442\n",
            "[Batch 3] Current Loss: 5.4544\n",
            "[Batch 4] Current Loss: 5.3846\n",
            "[Batch 5] Current Loss: 5.1855\n",
            "[Batch 6] Current Loss: 4.8698\n",
            "[Batch 7] Current Loss: 5.0821\n",
            "[Batch 8] Current Loss: 5.2580\n",
            "[Batch 9] Current Loss: 5.4963\n",
            "Ep 3 (Step 017880): Train loss 3.321, Val loss 5.265\n",
            "[Batch 0] Current Loss: 3.3761\n",
            "[Batch 1] Current Loss: 3.4178\n",
            "[Batch 2] Current Loss: 3.3398\n",
            "[Batch 3] Current Loss: 3.0883\n",
            "[Batch 4] Current Loss: 2.5447\n",
            "[Batch 5] Current Loss: 3.6861\n",
            "[Batch 6] Current Loss: 3.0346\n",
            "[Batch 7] Current Loss: 3.0006\n",
            "[Batch 8] Current Loss: 3.6304\n",
            "[Batch 9] Current Loss: 3.2054\n",
            "[Batch 0] Current Loss: 4.9381\n",
            "[Batch 1] Current Loss: 5.1160\n",
            "[Batch 2] Current Loss: 5.5124\n",
            "[Batch 3] Current Loss: 4.9024\n",
            "[Batch 4] Current Loss: 5.1954\n",
            "[Batch 5] Current Loss: 5.3744\n",
            "[Batch 6] Current Loss: 5.4520\n",
            "[Batch 7] Current Loss: 5.2813\n",
            "[Batch 8] Current Loss: 5.7607\n",
            "[Batch 9] Current Loss: 5.2672\n",
            "Ep 3 (Step 017900): Train loss 3.232, Val loss 5.280\n",
            "[Batch 0] Current Loss: 3.5239\n",
            "[Batch 1] Current Loss: 4.0490\n",
            "[Batch 2] Current Loss: 3.2343\n",
            "[Batch 3] Current Loss: 3.1810\n",
            "[Batch 4] Current Loss: 3.1836\n",
            "[Batch 5] Current Loss: 2.7781\n",
            "[Batch 6] Current Loss: 2.8778\n",
            "[Batch 7] Current Loss: 3.4613\n",
            "[Batch 8] Current Loss: 3.6601\n",
            "[Batch 9] Current Loss: 3.3133\n",
            "[Batch 0] Current Loss: 5.5307\n",
            "[Batch 1] Current Loss: 5.1434\n",
            "[Batch 2] Current Loss: 5.7534\n",
            "[Batch 3] Current Loss: 4.4799\n",
            "[Batch 4] Current Loss: 5.1384\n",
            "[Batch 5] Current Loss: 5.4000\n",
            "[Batch 6] Current Loss: 4.5453\n",
            "[Batch 7] Current Loss: 5.1876\n",
            "[Batch 8] Current Loss: 5.7291\n",
            "[Batch 9] Current Loss: 5.8262\n",
            "Ep 3 (Step 017920): Train loss 3.326, Val loss 5.273\n",
            "[Batch 0] Current Loss: 3.1675\n",
            "[Batch 1] Current Loss: 3.2175\n",
            "[Batch 2] Current Loss: 3.5740\n",
            "[Batch 3] Current Loss: 3.7094\n",
            "[Batch 4] Current Loss: 3.0103\n",
            "[Batch 5] Current Loss: 3.5371\n",
            "[Batch 6] Current Loss: 3.5261\n",
            "[Batch 7] Current Loss: 3.7236\n",
            "[Batch 8] Current Loss: 2.8628\n",
            "[Batch 9] Current Loss: 2.9974\n",
            "[Batch 0] Current Loss: 5.5019\n",
            "[Batch 1] Current Loss: 5.5270\n",
            "[Batch 2] Current Loss: 4.9673\n",
            "[Batch 3] Current Loss: 5.1003\n",
            "[Batch 4] Current Loss: 4.7274\n",
            "[Batch 5] Current Loss: 6.2753\n",
            "[Batch 6] Current Loss: 5.1201\n",
            "[Batch 7] Current Loss: 5.2205\n",
            "[Batch 8] Current Loss: 5.8810\n",
            "[Batch 9] Current Loss: 4.9965\n",
            "Ep 3 (Step 017940): Train loss 3.333, Val loss 5.332\n",
            "[Batch 0] Current Loss: 3.1129\n",
            "[Batch 1] Current Loss: 4.0630\n",
            "[Batch 2] Current Loss: 3.3997\n",
            "[Batch 3] Current Loss: 2.9710\n",
            "[Batch 4] Current Loss: 3.5372\n",
            "[Batch 5] Current Loss: 3.5074\n",
            "[Batch 6] Current Loss: 3.5572\n",
            "[Batch 7] Current Loss: 3.4314\n",
            "[Batch 8] Current Loss: 3.8762\n",
            "[Batch 9] Current Loss: 3.4611\n",
            "[Batch 0] Current Loss: 5.0299\n",
            "[Batch 1] Current Loss: 5.6188\n",
            "[Batch 2] Current Loss: 5.3595\n",
            "[Batch 3] Current Loss: 4.4384\n",
            "[Batch 4] Current Loss: 5.0610\n",
            "[Batch 5] Current Loss: 5.4342\n",
            "[Batch 6] Current Loss: 5.3772\n",
            "[Batch 7] Current Loss: 5.3838\n",
            "[Batch 8] Current Loss: 4.5746\n",
            "[Batch 9] Current Loss: 5.2676\n",
            "Ep 3 (Step 017960): Train loss 3.492, Val loss 5.154\n",
            "[Batch 0] Current Loss: 3.0744\n",
            "[Batch 1] Current Loss: 3.7988\n",
            "[Batch 2] Current Loss: 3.6523\n",
            "[Batch 3] Current Loss: 3.6835\n",
            "[Batch 4] Current Loss: 3.3383\n",
            "[Batch 5] Current Loss: 3.0850\n",
            "[Batch 6] Current Loss: 3.1044\n",
            "[Batch 7] Current Loss: 3.3178\n",
            "[Batch 8] Current Loss: 3.8768\n",
            "[Batch 9] Current Loss: 3.1251\n",
            "[Batch 0] Current Loss: 4.9853\n",
            "[Batch 1] Current Loss: 5.0000\n",
            "[Batch 2] Current Loss: 5.0348\n",
            "[Batch 3] Current Loss: 5.5325\n",
            "[Batch 4] Current Loss: 5.4727\n",
            "[Batch 5] Current Loss: 4.9347\n",
            "[Batch 6] Current Loss: 5.5066\n",
            "[Batch 7] Current Loss: 4.8041\n",
            "[Batch 8] Current Loss: 5.2852\n",
            "[Batch 9] Current Loss: 5.4533\n",
            "Ep 3 (Step 017980): Train loss 3.406, Val loss 5.201\n",
            "[Batch 0] Current Loss: 3.7054\n",
            "[Batch 1] Current Loss: 3.4658\n",
            "[Batch 2] Current Loss: 3.3720\n",
            "[Batch 3] Current Loss: 2.7613\n",
            "[Batch 4] Current Loss: 3.0477\n",
            "[Batch 5] Current Loss: 3.7721\n",
            "[Batch 6] Current Loss: 3.2032\n",
            "[Batch 7] Current Loss: 2.5945\n",
            "[Batch 8] Current Loss: 3.1670\n",
            "[Batch 9] Current Loss: 3.3790\n",
            "[Batch 0] Current Loss: 5.0329\n",
            "[Batch 1] Current Loss: 5.3928\n",
            "[Batch 2] Current Loss: 5.0404\n",
            "[Batch 3] Current Loss: 5.7591\n",
            "[Batch 4] Current Loss: 5.1028\n",
            "[Batch 5] Current Loss: 5.5297\n",
            "[Batch 6] Current Loss: 5.3178\n",
            "[Batch 7] Current Loss: 5.3396\n",
            "[Batch 8] Current Loss: 4.9435\n",
            "[Batch 9] Current Loss: 4.9677\n",
            "Ep 3 (Step 018000): Train loss 3.247, Val loss 5.243\n",
            "[Batch 0] Current Loss: 3.7777\n",
            "[Batch 1] Current Loss: 3.2043\n",
            "[Batch 2] Current Loss: 3.1519\n",
            "[Batch 3] Current Loss: 3.2349\n",
            "[Batch 4] Current Loss: 3.5611\n",
            "[Batch 5] Current Loss: 3.0587\n",
            "[Batch 6] Current Loss: 3.3149\n",
            "[Batch 7] Current Loss: 3.3654\n",
            "[Batch 8] Current Loss: 4.1319\n",
            "[Batch 9] Current Loss: 3.5197\n",
            "[Batch 0] Current Loss: 5.1999\n",
            "[Batch 1] Current Loss: 5.6835\n",
            "[Batch 2] Current Loss: 5.0904\n",
            "[Batch 3] Current Loss: 5.7761\n",
            "[Batch 4] Current Loss: 5.0121\n",
            "[Batch 5] Current Loss: 5.3634\n",
            "[Batch 6] Current Loss: 5.4225\n",
            "[Batch 7] Current Loss: 5.0398\n",
            "[Batch 8] Current Loss: 4.6768\n",
            "[Batch 9] Current Loss: 5.5196\n",
            "Ep 3 (Step 018020): Train loss 3.432, Val loss 5.278\n",
            "[Batch 0] Current Loss: 2.9456\n",
            "[Batch 1] Current Loss: 3.3479\n",
            "[Batch 2] Current Loss: 2.4280\n",
            "[Batch 3] Current Loss: 3.4264\n",
            "[Batch 4] Current Loss: 2.8947\n",
            "[Batch 5] Current Loss: 3.1981\n",
            "[Batch 6] Current Loss: 2.9863\n",
            "[Batch 7] Current Loss: 3.6090\n",
            "[Batch 8] Current Loss: 3.6994\n",
            "[Batch 9] Current Loss: 3.5156\n",
            "[Batch 0] Current Loss: 4.8805\n",
            "[Batch 1] Current Loss: 5.6199\n",
            "[Batch 2] Current Loss: 5.6601\n",
            "[Batch 3] Current Loss: 4.4948\n",
            "[Batch 4] Current Loss: 5.4303\n",
            "[Batch 5] Current Loss: 5.6997\n",
            "[Batch 6] Current Loss: 5.8656\n",
            "[Batch 7] Current Loss: 4.4207\n",
            "[Batch 8] Current Loss: 5.7047\n",
            "[Batch 9] Current Loss: 5.1233\n",
            "Ep 3 (Step 018040): Train loss 3.205, Val loss 5.290\n",
            "[Batch 0] Current Loss: 3.1072\n",
            "[Batch 1] Current Loss: 3.3523\n",
            "[Batch 2] Current Loss: 3.5224\n",
            "[Batch 3] Current Loss: 3.5308\n",
            "[Batch 4] Current Loss: 2.9280\n",
            "[Batch 5] Current Loss: 3.4041\n",
            "[Batch 6] Current Loss: 3.2497\n",
            "[Batch 7] Current Loss: 3.1170\n",
            "[Batch 8] Current Loss: 3.3718\n",
            "[Batch 9] Current Loss: 2.6403\n",
            "[Batch 0] Current Loss: 5.2050\n",
            "[Batch 1] Current Loss: 6.1346\n",
            "[Batch 2] Current Loss: 5.6392\n",
            "[Batch 3] Current Loss: 5.0380\n",
            "[Batch 4] Current Loss: 5.6398\n",
            "[Batch 5] Current Loss: 5.0568\n",
            "[Batch 6] Current Loss: 5.2560\n",
            "[Batch 7] Current Loss: 5.6370\n",
            "[Batch 8] Current Loss: 5.2053\n",
            "[Batch 9] Current Loss: 5.5591\n",
            "Ep 3 (Step 018060): Train loss 3.222, Val loss 5.437\n",
            "[Batch 0] Current Loss: 3.6762\n",
            "[Batch 1] Current Loss: 3.4479\n",
            "[Batch 2] Current Loss: 3.1509\n",
            "[Batch 3] Current Loss: 2.9088\n",
            "[Batch 4] Current Loss: 3.2350\n",
            "[Batch 5] Current Loss: 3.5874\n",
            "[Batch 6] Current Loss: 3.5608\n",
            "[Batch 7] Current Loss: 2.2639\n",
            "[Batch 8] Current Loss: 2.8933\n",
            "[Batch 9] Current Loss: 3.4071\n",
            "[Batch 0] Current Loss: 5.0161\n",
            "[Batch 1] Current Loss: 5.4366\n",
            "[Batch 2] Current Loss: 4.7707\n",
            "[Batch 3] Current Loss: 5.0996\n",
            "[Batch 4] Current Loss: 5.1273\n",
            "[Batch 5] Current Loss: 5.1713\n",
            "[Batch 6] Current Loss: 4.6664\n",
            "[Batch 7] Current Loss: 5.9010\n",
            "[Batch 8] Current Loss: 5.1820\n",
            "[Batch 9] Current Loss: 5.4458\n",
            "Ep 3 (Step 018080): Train loss 3.213, Val loss 5.182\n",
            "[Batch 0] Current Loss: 3.3987\n",
            "[Batch 1] Current Loss: 3.1572\n",
            "[Batch 2] Current Loss: 2.9641\n",
            "[Batch 3] Current Loss: 2.8951\n",
            "[Batch 4] Current Loss: 3.2747\n",
            "[Batch 5] Current Loss: 3.8787\n",
            "[Batch 6] Current Loss: 3.3277\n",
            "[Batch 7] Current Loss: 3.5532\n",
            "[Batch 8] Current Loss: 4.1560\n",
            "[Batch 9] Current Loss: 2.8779\n",
            "[Batch 0] Current Loss: 5.6230\n",
            "[Batch 1] Current Loss: 5.6086\n",
            "[Batch 2] Current Loss: 5.5893\n",
            "[Batch 3] Current Loss: 5.5331\n",
            "[Batch 4] Current Loss: 5.3068\n",
            "[Batch 5] Current Loss: 5.6660\n",
            "[Batch 6] Current Loss: 4.5805\n",
            "[Batch 7] Current Loss: 4.7327\n",
            "[Batch 8] Current Loss: 4.8654\n",
            "[Batch 9] Current Loss: 5.3221\n",
            "Ep 3 (Step 018100): Train loss 3.348, Val loss 5.283\n",
            "[Batch 0] Current Loss: 3.4941\n",
            "[Batch 1] Current Loss: 3.0649\n",
            "[Batch 2] Current Loss: 2.8832\n",
            "[Batch 3] Current Loss: 3.1125\n",
            "[Batch 4] Current Loss: 3.4171\n",
            "[Batch 5] Current Loss: 3.3165\n",
            "[Batch 6] Current Loss: 3.5236\n",
            "[Batch 7] Current Loss: 3.4425\n",
            "[Batch 8] Current Loss: 3.5489\n",
            "[Batch 9] Current Loss: 3.2044\n",
            "[Batch 0] Current Loss: 5.4131\n",
            "[Batch 1] Current Loss: 5.2287\n",
            "[Batch 2] Current Loss: 4.7902\n",
            "[Batch 3] Current Loss: 5.7570\n",
            "[Batch 4] Current Loss: 4.9055\n",
            "[Batch 5] Current Loss: 5.3978\n",
            "[Batch 6] Current Loss: 5.5216\n",
            "[Batch 7] Current Loss: 5.1125\n",
            "[Batch 8] Current Loss: 5.6206\n",
            "[Batch 9] Current Loss: 4.0421\n",
            "Ep 3 (Step 018120): Train loss 3.301, Val loss 5.179\n",
            "[Batch 0] Current Loss: 3.3204\n",
            "[Batch 1] Current Loss: 3.1579\n",
            "[Batch 2] Current Loss: 3.2912\n",
            "[Batch 3] Current Loss: 3.1997\n",
            "[Batch 4] Current Loss: 3.9590\n",
            "[Batch 5] Current Loss: 3.1217\n",
            "[Batch 6] Current Loss: 3.4917\n",
            "[Batch 7] Current Loss: 3.2692\n",
            "[Batch 8] Current Loss: 3.8766\n",
            "[Batch 9] Current Loss: 3.3841\n",
            "[Batch 0] Current Loss: 6.0039\n",
            "[Batch 1] Current Loss: 5.3613\n",
            "[Batch 2] Current Loss: 5.4418\n",
            "[Batch 3] Current Loss: 5.5981\n",
            "[Batch 4] Current Loss: 5.0070\n",
            "[Batch 5] Current Loss: 5.6578\n",
            "[Batch 6] Current Loss: 5.0529\n",
            "[Batch 7] Current Loss: 5.6342\n",
            "[Batch 8] Current Loss: 5.7535\n",
            "[Batch 9] Current Loss: 5.0921\n",
            "Ep 3 (Step 018140): Train loss 3.407, Val loss 5.460\n",
            "[Batch 0] Current Loss: 3.4001\n",
            "[Batch 1] Current Loss: 3.2403\n",
            "[Batch 2] Current Loss: 3.8949\n",
            "[Batch 3] Current Loss: 3.2349\n",
            "[Batch 4] Current Loss: 4.0671\n",
            "[Batch 5] Current Loss: 3.6760\n",
            "[Batch 6] Current Loss: 3.5301\n",
            "[Batch 7] Current Loss: 3.0002\n",
            "[Batch 8] Current Loss: 3.3837\n",
            "[Batch 9] Current Loss: 3.6021\n",
            "[Batch 0] Current Loss: 5.8083\n",
            "[Batch 1] Current Loss: 5.5813\n",
            "[Batch 2] Current Loss: 4.3583\n",
            "[Batch 3] Current Loss: 5.7849\n",
            "[Batch 4] Current Loss: 5.3754\n",
            "[Batch 5] Current Loss: 5.8736\n",
            "[Batch 6] Current Loss: 4.9136\n",
            "[Batch 7] Current Loss: 5.5943\n",
            "[Batch 8] Current Loss: 4.6705\n",
            "[Batch 9] Current Loss: 5.2818\n",
            "Ep 3 (Step 018160): Train loss 3.503, Val loss 5.324\n",
            "[Batch 0] Current Loss: 3.1773\n",
            "[Batch 1] Current Loss: 3.3634\n",
            "[Batch 2] Current Loss: 3.0645\n",
            "[Batch 3] Current Loss: 2.6969\n",
            "[Batch 4] Current Loss: 3.3971\n",
            "[Batch 5] Current Loss: 2.9973\n",
            "[Batch 6] Current Loss: 3.3764\n",
            "[Batch 7] Current Loss: 3.2262\n",
            "[Batch 8] Current Loss: 3.6211\n",
            "[Batch 9] Current Loss: 2.5907\n",
            "[Batch 0] Current Loss: 5.1061\n",
            "[Batch 1] Current Loss: 5.5428\n",
            "[Batch 2] Current Loss: 5.6286\n",
            "[Batch 3] Current Loss: 5.3700\n",
            "[Batch 4] Current Loss: 6.0656\n",
            "[Batch 5] Current Loss: 5.9130\n",
            "[Batch 6] Current Loss: 5.5237\n",
            "[Batch 7] Current Loss: 5.1511\n",
            "[Batch 8] Current Loss: 5.5849\n",
            "[Batch 9] Current Loss: 5.4815\n",
            "Ep 3 (Step 018180): Train loss 3.151, Val loss 5.537\n",
            "[Batch 0] Current Loss: 3.7830\n",
            "[Batch 1] Current Loss: 3.6764\n",
            "[Batch 2] Current Loss: 3.2583\n",
            "[Batch 3] Current Loss: 3.4437\n",
            "[Batch 4] Current Loss: 3.4264\n",
            "[Batch 5] Current Loss: 3.1837\n",
            "[Batch 6] Current Loss: 3.2096\n",
            "[Batch 7] Current Loss: 3.3650\n",
            "[Batch 8] Current Loss: 3.1061\n",
            "[Batch 9] Current Loss: 3.6482\n",
            "[Batch 0] Current Loss: 5.5134\n",
            "[Batch 1] Current Loss: 5.4350\n",
            "[Batch 2] Current Loss: 5.8135\n",
            "[Batch 3] Current Loss: 5.9093\n",
            "[Batch 4] Current Loss: 5.4331\n",
            "[Batch 5] Current Loss: 5.6076\n",
            "[Batch 6] Current Loss: 4.8742\n",
            "[Batch 7] Current Loss: 5.3620\n",
            "[Batch 8] Current Loss: 4.6055\n",
            "[Batch 9] Current Loss: 5.1474\n",
            "Ep 3 (Step 018200): Train loss 3.410, Val loss 5.370\n",
            "[Batch 0] Current Loss: 3.0517\n",
            "[Batch 1] Current Loss: 3.3323\n",
            "[Batch 2] Current Loss: 3.3812\n",
            "[Batch 3] Current Loss: 2.5234\n",
            "[Batch 4] Current Loss: 2.6489\n",
            "[Batch 5] Current Loss: 3.1706\n",
            "[Batch 6] Current Loss: 3.1462\n",
            "[Batch 7] Current Loss: 2.9976\n",
            "[Batch 8] Current Loss: 3.5543\n",
            "[Batch 9] Current Loss: 2.6786\n",
            "[Batch 0] Current Loss: 5.4505\n",
            "[Batch 1] Current Loss: 5.4705\n",
            "[Batch 2] Current Loss: 6.0379\n",
            "[Batch 3] Current Loss: 5.3063\n",
            "[Batch 4] Current Loss: 4.7970\n",
            "[Batch 5] Current Loss: 5.1808\n",
            "[Batch 6] Current Loss: 5.2480\n",
            "[Batch 7] Current Loss: 5.2329\n",
            "[Batch 8] Current Loss: 6.0262\n",
            "[Batch 9] Current Loss: 5.3061\n",
            "Ep 3 (Step 018220): Train loss 3.048, Val loss 5.406\n",
            "[Batch 0] Current Loss: 3.3500\n",
            "[Batch 1] Current Loss: 4.0298\n",
            "[Batch 2] Current Loss: 3.5069\n",
            "[Batch 3] Current Loss: 3.1545\n",
            "[Batch 4] Current Loss: 2.9892\n",
            "[Batch 5] Current Loss: 3.4421\n",
            "[Batch 6] Current Loss: 3.1506\n",
            "[Batch 7] Current Loss: 3.1800\n",
            "[Batch 8] Current Loss: 3.7869\n",
            "[Batch 9] Current Loss: 3.1830\n",
            "[Batch 0] Current Loss: 4.8845\n",
            "[Batch 1] Current Loss: 5.8889\n",
            "[Batch 2] Current Loss: 4.5327\n",
            "[Batch 3] Current Loss: 5.2059\n",
            "[Batch 4] Current Loss: 5.5667\n",
            "[Batch 5] Current Loss: 4.8450\n",
            "[Batch 6] Current Loss: 5.5339\n",
            "[Batch 7] Current Loss: 6.1000\n",
            "[Batch 8] Current Loss: 4.7175\n",
            "[Batch 9] Current Loss: 5.7035\n",
            "Ep 3 (Step 018240): Train loss 3.377, Val loss 5.298\n",
            "[Batch 0] Current Loss: 3.3458\n",
            "[Batch 1] Current Loss: 3.0599\n",
            "[Batch 2] Current Loss: 2.9381\n",
            "[Batch 3] Current Loss: 3.6473\n",
            "[Batch 4] Current Loss: 3.8571\n",
            "[Batch 5] Current Loss: 3.1329\n",
            "[Batch 6] Current Loss: 3.3106\n",
            "[Batch 7] Current Loss: 3.3493\n",
            "[Batch 8] Current Loss: 2.9884\n",
            "[Batch 9] Current Loss: 3.3538\n",
            "[Batch 0] Current Loss: 5.9910\n",
            "[Batch 1] Current Loss: 6.1620\n",
            "[Batch 2] Current Loss: 5.0149\n",
            "[Batch 3] Current Loss: 5.7757\n",
            "[Batch 4] Current Loss: 5.5909\n",
            "[Batch 5] Current Loss: 5.5404\n",
            "[Batch 6] Current Loss: 5.7796\n",
            "[Batch 7] Current Loss: 5.2425\n",
            "[Batch 8] Current Loss: 5.5845\n",
            "[Batch 9] Current Loss: 5.1938\n",
            "Ep 3 (Step 018260): Train loss 3.298, Val loss 5.588\n",
            "[Batch 0] Current Loss: 3.1262\n",
            "[Batch 1] Current Loss: 3.2991\n",
            "[Batch 2] Current Loss: 2.7838\n",
            "[Batch 3] Current Loss: 3.3825\n",
            "[Batch 4] Current Loss: 2.6160\n",
            "[Batch 5] Current Loss: 3.3518\n",
            "[Batch 6] Current Loss: 3.1944\n",
            "[Batch 7] Current Loss: 3.1690\n",
            "[Batch 8] Current Loss: 3.6622\n",
            "[Batch 9] Current Loss: 3.2320\n",
            "[Batch 0] Current Loss: 4.8292\n",
            "[Batch 1] Current Loss: 5.6179\n",
            "[Batch 2] Current Loss: 5.7318\n",
            "[Batch 3] Current Loss: 5.3498\n",
            "[Batch 4] Current Loss: 5.5675\n",
            "[Batch 5] Current Loss: 4.7921\n",
            "[Batch 6] Current Loss: 5.4939\n",
            "[Batch 7] Current Loss: 5.5916\n",
            "[Batch 8] Current Loss: 5.1729\n",
            "[Batch 9] Current Loss: 5.6514\n",
            "Ep 3 (Step 018280): Train loss 3.182, Val loss 5.380\n",
            "[Batch 0] Current Loss: 3.1797\n",
            "[Batch 1] Current Loss: 3.3909\n",
            "[Batch 2] Current Loss: 3.9287\n",
            "[Batch 3] Current Loss: 3.5020\n",
            "[Batch 4] Current Loss: 2.6883\n",
            "[Batch 5] Current Loss: 2.9422\n",
            "[Batch 6] Current Loss: 3.6766\n",
            "[Batch 7] Current Loss: 3.6080\n",
            "[Batch 8] Current Loss: 3.5626\n",
            "[Batch 9] Current Loss: 3.5053\n",
            "[Batch 0] Current Loss: 5.0050\n",
            "[Batch 1] Current Loss: 4.8382\n",
            "[Batch 2] Current Loss: 5.8727\n",
            "[Batch 3] Current Loss: 5.2472\n",
            "[Batch 4] Current Loss: 5.1971\n",
            "[Batch 5] Current Loss: 4.2061\n",
            "[Batch 6] Current Loss: 5.5811\n",
            "[Batch 7] Current Loss: 5.2975\n",
            "[Batch 8] Current Loss: 5.4481\n",
            "[Batch 9] Current Loss: 4.6537\n",
            "Ep 3 (Step 018300): Train loss 3.398, Val loss 5.135\n",
            "[Batch 0] Current Loss: 2.7354\n",
            "[Batch 1] Current Loss: 3.4241\n",
            "[Batch 2] Current Loss: 3.0514\n",
            "[Batch 3] Current Loss: 4.0141\n",
            "[Batch 4] Current Loss: 2.7228\n",
            "[Batch 5] Current Loss: 3.3587\n",
            "[Batch 6] Current Loss: 3.4702\n",
            "[Batch 7] Current Loss: 2.7584\n",
            "[Batch 8] Current Loss: 3.8378\n",
            "[Batch 9] Current Loss: 3.6086\n",
            "[Batch 0] Current Loss: 5.5687\n",
            "[Batch 1] Current Loss: 4.9727\n",
            "[Batch 2] Current Loss: 5.7799\n",
            "[Batch 3] Current Loss: 5.6032\n",
            "[Batch 4] Current Loss: 4.7221\n",
            "[Batch 5] Current Loss: 5.2273\n",
            "[Batch 6] Current Loss: 5.2960\n",
            "[Batch 7] Current Loss: 5.8067\n",
            "[Batch 8] Current Loss: 5.7869\n",
            "[Batch 9] Current Loss: 5.4768\n",
            "Ep 3 (Step 018320): Train loss 3.298, Val loss 5.424\n",
            "[Batch 0] Current Loss: 3.3249\n",
            "[Batch 1] Current Loss: 3.3366\n",
            "[Batch 2] Current Loss: 2.8845\n",
            "[Batch 3] Current Loss: 3.6921\n",
            "[Batch 4] Current Loss: 3.5901\n",
            "[Batch 5] Current Loss: 3.7121\n",
            "[Batch 6] Current Loss: 3.2910\n",
            "[Batch 7] Current Loss: 3.4264\n",
            "[Batch 8] Current Loss: 3.6033\n",
            "[Batch 9] Current Loss: 3.1954\n",
            "[Batch 0] Current Loss: 5.0600\n",
            "[Batch 1] Current Loss: 5.4364\n",
            "[Batch 2] Current Loss: 5.0732\n",
            "[Batch 3] Current Loss: 5.6241\n",
            "[Batch 4] Current Loss: 5.0426\n",
            "[Batch 5] Current Loss: 5.6452\n",
            "[Batch 6] Current Loss: 5.5296\n",
            "[Batch 7] Current Loss: 5.8484\n",
            "[Batch 8] Current Loss: 5.9191\n",
            "[Batch 9] Current Loss: 5.3584\n",
            "Ep 3 (Step 018340): Train loss 3.406, Val loss 5.454\n",
            "[Batch 0] Current Loss: 3.1215\n",
            "[Batch 1] Current Loss: 3.7866\n",
            "[Batch 2] Current Loss: 3.9273\n",
            "[Batch 3] Current Loss: 3.2767\n",
            "[Batch 4] Current Loss: 3.1073\n",
            "[Batch 5] Current Loss: 3.3577\n",
            "[Batch 6] Current Loss: 2.9540\n",
            "[Batch 7] Current Loss: 3.1258\n",
            "[Batch 8] Current Loss: 2.6128\n",
            "[Batch 9] Current Loss: 3.5457\n",
            "[Batch 0] Current Loss: 5.0289\n",
            "[Batch 1] Current Loss: 4.6506\n",
            "[Batch 2] Current Loss: 5.4097\n",
            "[Batch 3] Current Loss: 5.5863\n",
            "[Batch 4] Current Loss: 5.8920\n",
            "[Batch 5] Current Loss: 5.2164\n",
            "[Batch 6] Current Loss: 6.3142\n",
            "[Batch 7] Current Loss: 4.8487\n",
            "[Batch 8] Current Loss: 5.0193\n",
            "[Batch 9] Current Loss: 5.5893\n",
            "Ep 3 (Step 018360): Train loss 3.282, Val loss 5.356\n",
            "[Batch 0] Current Loss: 3.5732\n",
            "[Batch 1] Current Loss: 3.2724\n",
            "[Batch 2] Current Loss: 3.8532\n",
            "[Batch 3] Current Loss: 3.2656\n",
            "[Batch 4] Current Loss: 3.8053\n",
            "[Batch 5] Current Loss: 3.5396\n",
            "[Batch 6] Current Loss: 3.5437\n",
            "[Batch 7] Current Loss: 3.7043\n",
            "[Batch 8] Current Loss: 2.8258\n",
            "[Batch 9] Current Loss: 3.3960\n",
            "[Batch 0] Current Loss: 5.1871\n",
            "[Batch 1] Current Loss: 5.2402\n",
            "[Batch 2] Current Loss: 5.2214\n",
            "[Batch 3] Current Loss: 4.9537\n",
            "[Batch 4] Current Loss: 4.4370\n",
            "[Batch 5] Current Loss: 5.5094\n",
            "[Batch 6] Current Loss: 5.7922\n",
            "[Batch 7] Current Loss: 5.2487\n",
            "[Batch 8] Current Loss: 5.5537\n",
            "[Batch 9] Current Loss: 5.3489\n",
            "Ep 3 (Step 018380): Train loss 3.478, Val loss 5.249\n",
            "[Batch 0] Current Loss: 2.8220\n",
            "[Batch 1] Current Loss: 3.2788\n",
            "[Batch 2] Current Loss: 3.5141\n",
            "[Batch 3] Current Loss: 3.8679\n",
            "[Batch 4] Current Loss: 3.8071\n",
            "[Batch 5] Current Loss: 3.2453\n",
            "[Batch 6] Current Loss: 3.6341\n",
            "[Batch 7] Current Loss: 3.0275\n",
            "[Batch 8] Current Loss: 3.2148\n",
            "[Batch 9] Current Loss: 2.9883\n",
            "[Batch 0] Current Loss: 5.5974\n",
            "[Batch 1] Current Loss: 5.9898\n",
            "[Batch 2] Current Loss: 5.2848\n",
            "[Batch 3] Current Loss: 4.7166\n",
            "[Batch 4] Current Loss: 5.3297\n",
            "[Batch 5] Current Loss: 5.1638\n",
            "[Batch 6] Current Loss: 5.5377\n",
            "[Batch 7] Current Loss: 5.7543\n",
            "[Batch 8] Current Loss: 5.4264\n",
            "[Batch 9] Current Loss: 4.8006\n",
            "Ep 3 (Step 018400): Train loss 3.340, Val loss 5.360\n",
            "[Batch 0] Current Loss: 3.1192\n",
            "[Batch 1] Current Loss: 3.3311\n",
            "[Batch 2] Current Loss: 3.3961\n",
            "[Batch 3] Current Loss: 3.3605\n",
            "[Batch 4] Current Loss: 3.3729\n",
            "[Batch 5] Current Loss: 2.9233\n",
            "[Batch 6] Current Loss: 3.5761\n",
            "[Batch 7] Current Loss: 2.5346\n",
            "[Batch 8] Current Loss: 3.8245\n",
            "[Batch 9] Current Loss: 3.8429\n",
            "[Batch 0] Current Loss: 5.1308\n",
            "[Batch 1] Current Loss: 5.3114\n",
            "[Batch 2] Current Loss: 5.3386\n",
            "[Batch 3] Current Loss: 5.2795\n",
            "[Batch 4] Current Loss: 5.4239\n",
            "[Batch 5] Current Loss: 5.7876\n",
            "[Batch 6] Current Loss: 5.7909\n",
            "[Batch 7] Current Loss: 5.5176\n",
            "[Batch 8] Current Loss: 4.9406\n",
            "[Batch 9] Current Loss: 5.1718\n",
            "Ep 3 (Step 018420): Train loss 3.328, Val loss 5.369\n",
            "[Batch 0] Current Loss: 3.2896\n",
            "[Batch 1] Current Loss: 3.3113\n",
            "[Batch 2] Current Loss: 3.0944\n",
            "[Batch 3] Current Loss: 3.4327\n",
            "[Batch 4] Current Loss: 2.9270\n",
            "[Batch 5] Current Loss: 2.6734\n",
            "[Batch 6] Current Loss: 3.6607\n",
            "[Batch 7] Current Loss: 2.9959\n",
            "[Batch 8] Current Loss: 3.6228\n",
            "[Batch 9] Current Loss: 3.2850\n",
            "[Batch 0] Current Loss: 5.2143\n",
            "[Batch 1] Current Loss: 4.6098\n",
            "[Batch 2] Current Loss: 5.2386\n",
            "[Batch 3] Current Loss: 5.1008\n",
            "[Batch 4] Current Loss: 5.2350\n",
            "[Batch 5] Current Loss: 5.2602\n",
            "[Batch 6] Current Loss: 5.8442\n",
            "[Batch 7] Current Loss: 5.0560\n",
            "[Batch 8] Current Loss: 4.9305\n",
            "[Batch 9] Current Loss: 5.4307\n",
            "Ep 3 (Step 018440): Train loss 3.229, Val loss 5.192\n",
            "[Batch 0] Current Loss: 3.2388\n",
            "[Batch 1] Current Loss: 2.8991\n",
            "[Batch 2] Current Loss: 3.7455\n",
            "[Batch 3] Current Loss: 3.0224\n",
            "[Batch 4] Current Loss: 3.7130\n",
            "[Batch 5] Current Loss: 2.8240\n",
            "[Batch 6] Current Loss: 2.7754\n",
            "[Batch 7] Current Loss: 3.3367\n",
            "[Batch 8] Current Loss: 3.5120\n",
            "[Batch 9] Current Loss: 3.1335\n",
            "[Batch 0] Current Loss: 5.3525\n",
            "[Batch 1] Current Loss: 5.2008\n",
            "[Batch 2] Current Loss: 4.8957\n",
            "[Batch 3] Current Loss: 5.5869\n",
            "[Batch 4] Current Loss: 5.6797\n",
            "[Batch 5] Current Loss: 6.0016\n",
            "[Batch 6] Current Loss: 5.3951\n",
            "[Batch 7] Current Loss: 5.0158\n",
            "[Batch 8] Current Loss: 4.8430\n",
            "[Batch 9] Current Loss: 5.3326\n",
            "Ep 3 (Step 018460): Train loss 3.220, Val loss 5.330\n",
            "[Batch 0] Current Loss: 3.2093\n",
            "[Batch 1] Current Loss: 3.2543\n",
            "[Batch 2] Current Loss: 3.8247\n",
            "[Batch 3] Current Loss: 3.2094\n",
            "[Batch 4] Current Loss: 3.5762\n",
            "[Batch 5] Current Loss: 3.7128\n",
            "[Batch 6] Current Loss: 3.9386\n",
            "[Batch 7] Current Loss: 2.8990\n",
            "[Batch 8] Current Loss: 3.3321\n",
            "[Batch 9] Current Loss: 3.7468\n",
            "[Batch 0] Current Loss: 5.3890\n",
            "[Batch 1] Current Loss: 5.3282\n",
            "[Batch 2] Current Loss: 5.9493\n",
            "[Batch 3] Current Loss: 4.3914\n",
            "[Batch 4] Current Loss: 5.2964\n",
            "[Batch 5] Current Loss: 5.6245\n",
            "[Batch 6] Current Loss: 4.8586\n",
            "[Batch 7] Current Loss: 6.1874\n",
            "[Batch 8] Current Loss: 5.7251\n",
            "[Batch 9] Current Loss: 5.4070\n",
            "Ep 3 (Step 018480): Train loss 3.470, Val loss 5.416\n",
            "[Batch 0] Current Loss: 3.5379\n",
            "[Batch 1] Current Loss: 3.2937\n",
            "[Batch 2] Current Loss: 3.3557\n",
            "[Batch 3] Current Loss: 2.5274\n",
            "[Batch 4] Current Loss: 3.0894\n",
            "[Batch 5] Current Loss: 3.6758\n",
            "[Batch 6] Current Loss: 2.9444\n",
            "[Batch 7] Current Loss: 3.0535\n",
            "[Batch 8] Current Loss: 2.8376\n",
            "[Batch 9] Current Loss: 3.5053\n",
            "[Batch 0] Current Loss: 5.3924\n",
            "[Batch 1] Current Loss: 6.0268\n",
            "[Batch 2] Current Loss: 4.7564\n",
            "[Batch 3] Current Loss: 5.8132\n",
            "[Batch 4] Current Loss: 5.5752\n",
            "[Batch 5] Current Loss: 5.1105\n",
            "[Batch 6] Current Loss: 5.5398\n",
            "[Batch 7] Current Loss: 4.7989\n",
            "[Batch 8] Current Loss: 6.0914\n",
            "[Batch 9] Current Loss: 5.6908\n",
            "Ep 3 (Step 018500): Train loss 3.182, Val loss 5.480\n",
            "[Batch 0] Current Loss: 2.8675\n",
            "[Batch 1] Current Loss: 3.2123\n",
            "[Batch 2] Current Loss: 2.6505\n",
            "[Batch 3] Current Loss: 2.7145\n",
            "[Batch 4] Current Loss: 3.3563\n",
            "[Batch 5] Current Loss: 3.4018\n",
            "[Batch 6] Current Loss: 3.4803\n",
            "[Batch 7] Current Loss: 3.8932\n",
            "[Batch 8] Current Loss: 2.5036\n",
            "[Batch 9] Current Loss: 3.0548\n",
            "[Batch 0] Current Loss: 5.6755\n",
            "[Batch 1] Current Loss: 5.2743\n",
            "[Batch 2] Current Loss: 5.0659\n",
            "[Batch 3] Current Loss: 5.2039\n",
            "[Batch 4] Current Loss: 4.9959\n",
            "[Batch 5] Current Loss: 5.6890\n",
            "[Batch 6] Current Loss: 5.4089\n",
            "[Batch 7] Current Loss: 5.2775\n",
            "[Batch 8] Current Loss: 5.4914\n",
            "[Batch 9] Current Loss: 5.1118\n",
            "Ep 3 (Step 018520): Train loss 3.113, Val loss 5.319\n",
            "[Batch 0] Current Loss: 3.5423\n",
            "[Batch 1] Current Loss: 2.9695\n",
            "[Batch 2] Current Loss: 3.7556\n",
            "[Batch 3] Current Loss: 3.2832\n",
            "[Batch 4] Current Loss: 3.9065\n",
            "[Batch 5] Current Loss: 2.5417\n",
            "[Batch 6] Current Loss: 2.8866\n",
            "[Batch 7] Current Loss: 2.3793\n",
            "[Batch 8] Current Loss: 3.4592\n",
            "[Batch 9] Current Loss: 3.7450\n",
            "[Batch 0] Current Loss: 5.4057\n",
            "[Batch 1] Current Loss: 4.8843\n",
            "[Batch 2] Current Loss: 5.5473\n",
            "[Batch 3] Current Loss: 5.1717\n",
            "[Batch 4] Current Loss: 5.4652\n",
            "[Batch 5] Current Loss: 5.2563\n",
            "[Batch 6] Current Loss: 6.1310\n",
            "[Batch 7] Current Loss: 6.0283\n",
            "[Batch 8] Current Loss: 4.3744\n",
            "[Batch 9] Current Loss: 5.2441\n",
            "Ep 3 (Step 018540): Train loss 3.247, Val loss 5.351\n",
            "[Batch 0] Current Loss: 3.6475\n",
            "[Batch 1] Current Loss: 3.0633\n",
            "[Batch 2] Current Loss: 3.3431\n",
            "[Batch 3] Current Loss: 3.5297\n",
            "[Batch 4] Current Loss: 3.3591\n",
            "[Batch 5] Current Loss: 2.7994\n",
            "[Batch 6] Current Loss: 3.1871\n",
            "[Batch 7] Current Loss: 3.0001\n",
            "[Batch 8] Current Loss: 3.4116\n",
            "[Batch 9] Current Loss: 2.9601\n",
            "[Batch 0] Current Loss: 4.3755\n",
            "[Batch 1] Current Loss: 5.5615\n",
            "[Batch 2] Current Loss: 5.4297\n",
            "[Batch 3] Current Loss: 4.9462\n",
            "[Batch 4] Current Loss: 4.4378\n",
            "[Batch 5] Current Loss: 5.4974\n",
            "[Batch 6] Current Loss: 5.7310\n",
            "[Batch 7] Current Loss: 5.5060\n",
            "[Batch 8] Current Loss: 5.3927\n",
            "[Batch 9] Current Loss: 5.6772\n",
            "Ep 3 (Step 018560): Train loss 3.230, Val loss 5.256\n",
            "[Batch 0] Current Loss: 3.6683\n",
            "[Batch 1] Current Loss: 2.9602\n",
            "[Batch 2] Current Loss: 2.9338\n",
            "[Batch 3] Current Loss: 3.3165\n",
            "[Batch 4] Current Loss: 2.9281\n",
            "[Batch 5] Current Loss: 2.7447\n",
            "[Batch 6] Current Loss: 3.0883\n",
            "[Batch 7] Current Loss: 3.3406\n",
            "[Batch 8] Current Loss: 3.1728\n",
            "[Batch 9] Current Loss: 2.9989\n",
            "[Batch 0] Current Loss: 5.4407\n",
            "[Batch 1] Current Loss: 5.2039\n",
            "[Batch 2] Current Loss: 4.9890\n",
            "[Batch 3] Current Loss: 5.7359\n",
            "[Batch 4] Current Loss: 4.8756\n",
            "[Batch 5] Current Loss: 4.9579\n",
            "[Batch 6] Current Loss: 5.4630\n",
            "[Batch 7] Current Loss: 5.4199\n",
            "[Batch 8] Current Loss: 5.5262\n",
            "[Batch 9] Current Loss: 5.1921\n",
            "Ep 3 (Step 018580): Train loss 3.115, Val loss 5.280\n",
            "[Batch 0] Current Loss: 3.8956\n",
            "[Batch 1] Current Loss: 2.8655\n",
            "[Batch 2] Current Loss: 3.0074\n",
            "[Batch 3] Current Loss: 3.6354\n",
            "[Batch 4] Current Loss: 3.0090\n",
            "[Batch 5] Current Loss: 3.0095\n",
            "[Batch 6] Current Loss: 3.3550\n",
            "[Batch 7] Current Loss: 3.4885\n",
            "[Batch 8] Current Loss: 3.0937\n",
            "[Batch 9] Current Loss: 3.4390\n",
            "[Batch 0] Current Loss: 5.7307\n",
            "[Batch 1] Current Loss: 5.4016\n",
            "[Batch 2] Current Loss: 5.4652\n",
            "[Batch 3] Current Loss: 5.0131\n",
            "[Batch 4] Current Loss: 4.8332\n",
            "[Batch 5] Current Loss: 5.1110\n",
            "[Batch 6] Current Loss: 5.8140\n",
            "[Batch 7] Current Loss: 4.9329\n",
            "[Batch 8] Current Loss: 6.0818\n",
            "[Batch 9] Current Loss: 5.3532\n",
            "Ep 3 (Step 018600): Train loss 3.280, Val loss 5.374\n",
            "[Batch 0] Current Loss: 3.1134\n",
            "[Batch 1] Current Loss: 3.6222\n",
            "[Batch 2] Current Loss: 3.0317\n",
            "[Batch 3] Current Loss: 3.2750\n",
            "[Batch 4] Current Loss: 3.6089\n",
            "[Batch 5] Current Loss: 3.2724\n",
            "[Batch 6] Current Loss: 3.3788\n",
            "[Batch 7] Current Loss: 3.5600\n",
            "[Batch 8] Current Loss: 3.1494\n",
            "[Batch 9] Current Loss: 3.0882\n",
            "[Batch 0] Current Loss: 5.9206\n",
            "[Batch 1] Current Loss: 5.0125\n",
            "[Batch 2] Current Loss: 5.7630\n",
            "[Batch 3] Current Loss: 4.9665\n",
            "[Batch 4] Current Loss: 4.7480\n",
            "[Batch 5] Current Loss: 6.2005\n",
            "[Batch 6] Current Loss: 4.3553\n",
            "[Batch 7] Current Loss: 5.7842\n",
            "[Batch 8] Current Loss: 5.4786\n",
            "[Batch 9] Current Loss: 5.2319\n",
            "Ep 3 (Step 018620): Train loss 3.310, Val loss 5.346\n",
            "[Batch 0] Current Loss: 2.8699\n",
            "[Batch 1] Current Loss: 3.4765\n",
            "[Batch 2] Current Loss: 3.8677\n",
            "[Batch 3] Current Loss: 3.3551\n",
            "[Batch 4] Current Loss: 2.5181\n",
            "[Batch 5] Current Loss: 3.6260\n",
            "[Batch 6] Current Loss: 3.6335\n",
            "[Batch 7] Current Loss: 3.6601\n",
            "[Batch 8] Current Loss: 2.8437\n",
            "[Batch 9] Current Loss: 3.5874\n",
            "[Batch 0] Current Loss: 5.4216\n",
            "[Batch 1] Current Loss: 4.8757\n",
            "[Batch 2] Current Loss: 5.6533\n",
            "[Batch 3] Current Loss: 5.0393\n",
            "[Batch 4] Current Loss: 5.4080\n",
            "[Batch 5] Current Loss: 5.4813\n",
            "[Batch 6] Current Loss: 5.6542\n",
            "[Batch 7] Current Loss: 5.6773\n",
            "[Batch 8] Current Loss: 5.6470\n",
            "[Batch 9] Current Loss: 4.8169\n",
            "Ep 3 (Step 018640): Train loss 3.344, Val loss 5.367\n",
            "[Batch 0] Current Loss: 3.2868\n",
            "[Batch 1] Current Loss: 3.8423\n",
            "[Batch 2] Current Loss: 2.9821\n",
            "[Batch 3] Current Loss: 3.1946\n",
            "[Batch 4] Current Loss: 4.1166\n",
            "[Batch 5] Current Loss: 2.9830\n",
            "[Batch 6] Current Loss: 4.1100\n",
            "[Batch 7] Current Loss: 3.3582\n",
            "[Batch 8] Current Loss: 3.0592\n",
            "[Batch 9] Current Loss: 3.4668\n",
            "[Batch 0] Current Loss: 4.7566\n",
            "[Batch 1] Current Loss: 4.8927\n",
            "[Batch 2] Current Loss: 4.8923\n",
            "[Batch 3] Current Loss: 5.5621\n",
            "[Batch 4] Current Loss: 4.5921\n",
            "[Batch 5] Current Loss: 5.2027\n",
            "[Batch 6] Current Loss: 5.9785\n",
            "[Batch 7] Current Loss: 5.3206\n",
            "[Batch 8] Current Loss: 5.4787\n",
            "[Batch 9] Current Loss: 4.9904\n",
            "Ep 3 (Step 018660): Train loss 3.440, Val loss 5.167\n",
            "[Batch 0] Current Loss: 2.8811\n",
            "[Batch 1] Current Loss: 3.3568\n",
            "[Batch 2] Current Loss: 3.3061\n",
            "[Batch 3] Current Loss: 2.5723\n",
            "[Batch 4] Current Loss: 3.6929\n",
            "[Batch 5] Current Loss: 2.9768\n",
            "[Batch 6] Current Loss: 3.2440\n",
            "[Batch 7] Current Loss: 3.8286\n",
            "[Batch 8] Current Loss: 3.4363\n",
            "[Batch 9] Current Loss: 3.9046\n",
            "[Batch 0] Current Loss: 5.5605\n",
            "[Batch 1] Current Loss: 5.0603\n",
            "[Batch 2] Current Loss: 5.6960\n",
            "[Batch 3] Current Loss: 5.6525\n",
            "[Batch 4] Current Loss: 5.6656\n",
            "[Batch 5] Current Loss: 5.2099\n",
            "[Batch 6] Current Loss: 5.2838\n",
            "[Batch 7] Current Loss: 5.7924\n",
            "[Batch 8] Current Loss: 4.7473\n",
            "[Batch 9] Current Loss: 4.7568\n",
            "Ep 3 (Step 018680): Train loss 3.320, Val loss 5.343\n",
            "[Batch 0] Current Loss: 3.2261\n",
            "[Batch 1] Current Loss: 3.3169\n",
            "[Batch 2] Current Loss: 3.0749\n",
            "[Batch 3] Current Loss: 3.2852\n",
            "[Batch 4] Current Loss: 3.3383\n",
            "[Batch 5] Current Loss: 2.7610\n",
            "[Batch 6] Current Loss: 3.8631\n",
            "[Batch 7] Current Loss: 3.1682\n",
            "[Batch 8] Current Loss: 2.7631\n",
            "[Batch 9] Current Loss: 2.8230\n",
            "[Batch 0] Current Loss: 5.5384\n",
            "[Batch 1] Current Loss: 4.9945\n",
            "[Batch 2] Current Loss: 5.2104\n",
            "[Batch 3] Current Loss: 5.0521\n",
            "[Batch 4] Current Loss: 5.0912\n",
            "[Batch 5] Current Loss: 4.7579\n",
            "[Batch 6] Current Loss: 4.9772\n",
            "[Batch 7] Current Loss: 5.2987\n",
            "[Batch 8] Current Loss: 5.4537\n",
            "[Batch 9] Current Loss: 4.7908\n",
            "Ep 3 (Step 018700): Train loss 3.162, Val loss 5.116\n",
            "[Batch 0] Current Loss: 2.8379\n",
            "[Batch 1] Current Loss: 3.5033\n",
            "[Batch 2] Current Loss: 3.2231\n",
            "[Batch 3] Current Loss: 3.8035\n",
            "[Batch 4] Current Loss: 2.9438\n",
            "[Batch 5] Current Loss: 3.8073\n",
            "[Batch 6] Current Loss: 2.7618\n",
            "[Batch 7] Current Loss: 3.5851\n",
            "[Batch 8] Current Loss: 3.8424\n",
            "[Batch 9] Current Loss: 2.7155\n",
            "[Batch 0] Current Loss: 5.2250\n",
            "[Batch 1] Current Loss: 4.6666\n",
            "[Batch 2] Current Loss: 5.1136\n",
            "[Batch 3] Current Loss: 6.0358\n",
            "[Batch 4] Current Loss: 4.5760\n",
            "[Batch 5] Current Loss: 5.4724\n",
            "[Batch 6] Current Loss: 5.4473\n",
            "[Batch 7] Current Loss: 4.6298\n",
            "[Batch 8] Current Loss: 5.3018\n",
            "[Batch 9] Current Loss: 4.4127\n",
            "Ep 3 (Step 018720): Train loss 3.302, Val loss 5.088\n",
            "[Batch 0] Current Loss: 3.2475\n",
            "[Batch 1] Current Loss: 3.1540\n",
            "[Batch 2] Current Loss: 3.1139\n",
            "[Batch 3] Current Loss: 3.2482\n",
            "[Batch 4] Current Loss: 3.0550\n",
            "[Batch 5] Current Loss: 3.2246\n",
            "[Batch 6] Current Loss: 3.1087\n",
            "[Batch 7] Current Loss: 4.0568\n",
            "[Batch 8] Current Loss: 3.7228\n",
            "[Batch 9] Current Loss: 3.7242\n",
            "[Batch 0] Current Loss: 4.9798\n",
            "[Batch 1] Current Loss: 5.6666\n",
            "[Batch 2] Current Loss: 5.2819\n",
            "[Batch 3] Current Loss: 5.9695\n",
            "[Batch 4] Current Loss: 5.3386\n",
            "[Batch 5] Current Loss: 5.0850\n",
            "[Batch 6] Current Loss: 4.6117\n",
            "[Batch 7] Current Loss: 5.3551\n",
            "[Batch 8] Current Loss: 5.8728\n",
            "[Batch 9] Current Loss: 5.6148\n",
            "Ep 3 (Step 018740): Train loss 3.366, Val loss 5.378\n",
            "[Batch 0] Current Loss: 3.8172\n",
            "[Batch 1] Current Loss: 2.9778\n",
            "[Batch 2] Current Loss: 3.6075\n",
            "[Batch 3] Current Loss: 3.1286\n",
            "[Batch 4] Current Loss: 3.0319\n",
            "[Batch 5] Current Loss: 3.4828\n",
            "[Batch 6] Current Loss: 3.5343\n",
            "[Batch 7] Current Loss: 3.7646\n",
            "[Batch 8] Current Loss: 3.7268\n",
            "[Batch 9] Current Loss: 2.7227\n",
            "[Batch 0] Current Loss: 5.1001\n",
            "[Batch 1] Current Loss: 4.6408\n",
            "[Batch 2] Current Loss: 5.0180\n",
            "[Batch 3] Current Loss: 5.6159\n",
            "[Batch 4] Current Loss: 5.4066\n",
            "[Batch 5] Current Loss: 4.9435\n",
            "[Batch 6] Current Loss: 4.9578\n",
            "[Batch 7] Current Loss: 5.2239\n",
            "[Batch 8] Current Loss: 5.3357\n",
            "[Batch 9] Current Loss: 4.6822\n",
            "Ep 3 (Step 018760): Train loss 3.379, Val loss 5.092\n",
            "[Batch 0] Current Loss: 3.2295\n",
            "[Batch 1] Current Loss: 3.6203\n",
            "[Batch 2] Current Loss: 3.1397\n",
            "[Batch 3] Current Loss: 2.9253\n",
            "[Batch 4] Current Loss: 3.0539\n",
            "[Batch 5] Current Loss: 3.5155\n",
            "[Batch 6] Current Loss: 3.9010\n",
            "[Batch 7] Current Loss: 3.4372\n",
            "[Batch 8] Current Loss: 2.9146\n",
            "[Batch 9] Current Loss: 2.6972\n",
            "[Batch 0] Current Loss: 5.0415\n",
            "[Batch 1] Current Loss: 5.8406\n",
            "[Batch 2] Current Loss: 6.0450\n",
            "[Batch 3] Current Loss: 6.2558\n",
            "[Batch 4] Current Loss: 5.0364\n",
            "[Batch 5] Current Loss: 5.8863\n",
            "[Batch 6] Current Loss: 5.9250\n",
            "[Batch 7] Current Loss: 5.0043\n",
            "[Batch 8] Current Loss: 5.3894\n",
            "[Batch 9] Current Loss: 6.1352\n",
            "Ep 3 (Step 018780): Train loss 3.243, Val loss 5.656\n",
            "[Batch 0] Current Loss: 3.6402\n",
            "[Batch 1] Current Loss: 2.3938\n",
            "[Batch 2] Current Loss: 3.4880\n",
            "[Batch 3] Current Loss: 2.9941\n",
            "[Batch 4] Current Loss: 3.2631\n",
            "[Batch 5] Current Loss: 3.8253\n",
            "[Batch 6] Current Loss: 3.7910\n",
            "[Batch 7] Current Loss: 3.4176\n",
            "[Batch 8] Current Loss: 3.8581\n",
            "[Batch 9] Current Loss: 3.6033\n",
            "[Batch 0] Current Loss: 5.5958\n",
            "[Batch 1] Current Loss: 4.8799\n",
            "[Batch 2] Current Loss: 5.8755\n",
            "[Batch 3] Current Loss: 5.2355\n",
            "[Batch 4] Current Loss: 5.3443\n",
            "[Batch 5] Current Loss: 4.8545\n",
            "[Batch 6] Current Loss: 5.1826\n",
            "[Batch 7] Current Loss: 5.2074\n",
            "[Batch 8] Current Loss: 5.6530\n",
            "[Batch 9] Current Loss: 6.0056\n",
            "Ep 3 (Step 018800): Train loss 3.427, Val loss 5.383\n",
            "[Batch 0] Current Loss: 3.1770\n",
            "[Batch 1] Current Loss: 3.4996\n",
            "[Batch 2] Current Loss: 3.3715\n",
            "[Batch 3] Current Loss: 3.8628\n",
            "[Batch 4] Current Loss: 3.2045\n",
            "[Batch 5] Current Loss: 3.2830\n",
            "[Batch 6] Current Loss: 3.5476\n",
            "[Batch 7] Current Loss: 3.3245\n",
            "[Batch 8] Current Loss: 3.4260\n",
            "[Batch 9] Current Loss: 3.1599\n",
            "[Batch 0] Current Loss: 5.6642\n",
            "[Batch 1] Current Loss: 5.6326\n",
            "[Batch 2] Current Loss: 4.7895\n",
            "[Batch 3] Current Loss: 4.8798\n",
            "[Batch 4] Current Loss: 5.0562\n",
            "[Batch 5] Current Loss: 5.0074\n",
            "[Batch 6] Current Loss: 5.3828\n",
            "[Batch 7] Current Loss: 5.9318\n",
            "[Batch 8] Current Loss: 5.4269\n",
            "[Batch 9] Current Loss: 5.5132\n",
            "Ep 3 (Step 018820): Train loss 3.386, Val loss 5.328\n",
            "[Batch 0] Current Loss: 3.2227\n",
            "[Batch 1] Current Loss: 3.1140\n",
            "[Batch 2] Current Loss: 2.8279\n",
            "[Batch 3] Current Loss: 3.7960\n",
            "[Batch 4] Current Loss: 3.0405\n",
            "[Batch 5] Current Loss: 2.9502\n",
            "[Batch 6] Current Loss: 3.4118\n",
            "[Batch 7] Current Loss: 2.3508\n",
            "[Batch 8] Current Loss: 4.0416\n",
            "[Batch 9] Current Loss: 3.2664\n",
            "[Batch 0] Current Loss: 5.0626\n",
            "[Batch 1] Current Loss: 4.9797\n",
            "[Batch 2] Current Loss: 5.9915\n",
            "[Batch 3] Current Loss: 5.6550\n",
            "[Batch 4] Current Loss: 5.4433\n",
            "[Batch 5] Current Loss: 5.0740\n",
            "[Batch 6] Current Loss: 4.9751\n",
            "[Batch 7] Current Loss: 5.6944\n",
            "[Batch 8] Current Loss: 5.2494\n",
            "[Batch 9] Current Loss: 5.3345\n",
            "Ep 3 (Step 018840): Train loss 3.202, Val loss 5.346\n",
            "[Batch 0] Current Loss: 3.7115\n",
            "[Batch 1] Current Loss: 3.2790\n",
            "[Batch 2] Current Loss: 3.7959\n",
            "[Batch 3] Current Loss: 2.6360\n",
            "[Batch 4] Current Loss: 3.4450\n",
            "[Batch 5] Current Loss: 4.1464\n",
            "[Batch 6] Current Loss: 3.3991\n",
            "[Batch 7] Current Loss: 2.8314\n",
            "[Batch 8] Current Loss: 3.2113\n",
            "[Batch 9] Current Loss: 3.4727\n",
            "[Batch 0] Current Loss: 5.3638\n",
            "[Batch 1] Current Loss: 5.7057\n",
            "[Batch 2] Current Loss: 5.3784\n",
            "[Batch 3] Current Loss: 5.4052\n",
            "[Batch 4] Current Loss: 5.7139\n",
            "[Batch 5] Current Loss: 5.7518\n",
            "[Batch 6] Current Loss: 5.7261\n",
            "[Batch 7] Current Loss: 4.6201\n",
            "[Batch 8] Current Loss: 5.4492\n",
            "[Batch 9] Current Loss: 5.3523\n",
            "Ep 3 (Step 018860): Train loss 3.393, Val loss 5.447\n",
            "[Batch 0] Current Loss: 3.3961\n",
            "[Batch 1] Current Loss: 3.4312\n",
            "[Batch 2] Current Loss: 3.3068\n",
            "[Batch 3] Current Loss: 2.8491\n",
            "[Batch 4] Current Loss: 4.0898\n",
            "[Batch 5] Current Loss: 2.8776\n",
            "[Batch 6] Current Loss: 3.8750\n",
            "[Batch 7] Current Loss: 3.5915\n",
            "[Batch 8] Current Loss: 3.0777\n",
            "[Batch 9] Current Loss: 2.5318\n",
            "[Batch 0] Current Loss: 5.3432\n",
            "[Batch 1] Current Loss: 5.5701\n",
            "[Batch 2] Current Loss: 5.0415\n",
            "[Batch 3] Current Loss: 4.7350\n",
            "[Batch 4] Current Loss: 5.3640\n",
            "[Batch 5] Current Loss: 5.4997\n",
            "[Batch 6] Current Loss: 4.7957\n",
            "[Batch 7] Current Loss: 5.4083\n",
            "[Batch 8] Current Loss: 5.2841\n",
            "[Batch 9] Current Loss: 5.3070\n",
            "Ep 3 (Step 018880): Train loss 3.303, Val loss 5.235\n",
            "[Batch 0] Current Loss: 3.4508\n",
            "[Batch 1] Current Loss: 3.8961\n",
            "[Batch 2] Current Loss: 3.2452\n",
            "[Batch 3] Current Loss: 3.1346\n",
            "[Batch 4] Current Loss: 2.7746\n",
            "[Batch 5] Current Loss: 3.1716\n",
            "[Batch 6] Current Loss: 3.8407\n",
            "[Batch 7] Current Loss: 3.2895\n",
            "[Batch 8] Current Loss: 2.4553\n",
            "[Batch 9] Current Loss: 3.9763\n",
            "[Batch 0] Current Loss: 5.1528\n",
            "[Batch 1] Current Loss: 5.2798\n",
            "[Batch 2] Current Loss: 5.7636\n",
            "[Batch 3] Current Loss: 5.2174\n",
            "[Batch 4] Current Loss: 4.7288\n",
            "[Batch 5] Current Loss: 5.3188\n",
            "[Batch 6] Current Loss: 5.7596\n",
            "[Batch 7] Current Loss: 5.3534\n",
            "[Batch 8] Current Loss: 5.3842\n",
            "[Batch 9] Current Loss: 5.3019\n",
            "Ep 3 (Step 018900): Train loss 3.323, Val loss 5.326\n",
            "[Batch 0] Current Loss: 3.0343\n",
            "[Batch 1] Current Loss: 3.5919\n",
            "[Batch 2] Current Loss: 3.0506\n",
            "[Batch 3] Current Loss: 2.9729\n",
            "[Batch 4] Current Loss: 3.3591\n",
            "[Batch 5] Current Loss: 3.3940\n",
            "[Batch 6] Current Loss: 3.1875\n",
            "[Batch 7] Current Loss: 3.2874\n",
            "[Batch 8] Current Loss: 3.2147\n",
            "[Batch 9] Current Loss: 2.8699\n",
            "[Batch 0] Current Loss: 4.9442\n",
            "[Batch 1] Current Loss: 5.1376\n",
            "[Batch 2] Current Loss: 5.0995\n",
            "[Batch 3] Current Loss: 4.7805\n",
            "[Batch 4] Current Loss: 5.8695\n",
            "[Batch 5] Current Loss: 4.8011\n",
            "[Batch 6] Current Loss: 5.8435\n",
            "[Batch 7] Current Loss: 5.7961\n",
            "[Batch 8] Current Loss: 5.1938\n",
            "[Batch 9] Current Loss: 5.0832\n",
            "Ep 3 (Step 018920): Train loss 3.196, Val loss 5.255\n",
            "[Batch 0] Current Loss: 3.0617\n",
            "[Batch 1] Current Loss: 3.2290\n",
            "[Batch 2] Current Loss: 2.7792\n",
            "[Batch 3] Current Loss: 3.4473\n",
            "[Batch 4] Current Loss: 3.7942\n",
            "[Batch 5] Current Loss: 2.7491\n",
            "[Batch 6] Current Loss: 2.4682\n",
            "[Batch 7] Current Loss: 3.9560\n",
            "[Batch 8] Current Loss: 2.9208\n",
            "[Batch 9] Current Loss: 3.1396\n",
            "[Batch 0] Current Loss: 5.0620\n",
            "[Batch 1] Current Loss: 4.8947\n",
            "[Batch 2] Current Loss: 5.0953\n",
            "[Batch 3] Current Loss: 5.8232\n",
            "[Batch 4] Current Loss: 5.9288\n",
            "[Batch 5] Current Loss: 5.7727\n",
            "[Batch 6] Current Loss: 4.5728\n",
            "[Batch 7] Current Loss: 5.6042\n",
            "[Batch 8] Current Loss: 5.0332\n",
            "[Batch 9] Current Loss: 5.9924\n",
            "Ep 3 (Step 018940): Train loss 3.155, Val loss 5.378\n",
            "[Batch 0] Current Loss: 2.9059\n",
            "[Batch 1] Current Loss: 3.8509\n",
            "[Batch 2] Current Loss: 2.9300\n",
            "[Batch 3] Current Loss: 2.6785\n",
            "[Batch 4] Current Loss: 3.3431\n",
            "[Batch 5] Current Loss: 3.5362\n",
            "[Batch 6] Current Loss: 2.5873\n",
            "[Batch 7] Current Loss: 2.4298\n",
            "[Batch 8] Current Loss: 3.0004\n",
            "[Batch 9] Current Loss: 3.0430\n",
            "[Batch 0] Current Loss: 4.8279\n",
            "[Batch 1] Current Loss: 5.4891\n",
            "[Batch 2] Current Loss: 5.5634\n",
            "[Batch 3] Current Loss: 4.7247\n",
            "[Batch 4] Current Loss: 6.1283\n",
            "[Batch 5] Current Loss: 4.9887\n",
            "[Batch 6] Current Loss: 5.7224\n",
            "[Batch 7] Current Loss: 5.1929\n",
            "[Batch 8] Current Loss: 5.6560\n",
            "[Batch 9] Current Loss: 5.1692\n",
            "Ep 3 (Step 018960): Train loss 3.031, Val loss 5.346\n",
            "[Batch 0] Current Loss: 3.6075\n",
            "[Batch 1] Current Loss: 2.7720\n",
            "[Batch 2] Current Loss: 4.0479\n",
            "[Batch 3] Current Loss: 3.4819\n",
            "[Batch 4] Current Loss: 3.4457\n",
            "[Batch 5] Current Loss: 2.5619\n",
            "[Batch 6] Current Loss: 3.7571\n",
            "[Batch 7] Current Loss: 3.3328\n",
            "[Batch 8] Current Loss: 2.7817\n",
            "[Batch 9] Current Loss: 3.4479\n",
            "[Batch 0] Current Loss: 5.0346\n",
            "[Batch 1] Current Loss: 6.1280\n",
            "[Batch 2] Current Loss: 5.0011\n",
            "[Batch 3] Current Loss: 5.0819\n",
            "[Batch 4] Current Loss: 5.2695\n",
            "[Batch 5] Current Loss: 4.5450\n",
            "[Batch 6] Current Loss: 5.5082\n",
            "[Batch 7] Current Loss: 5.7739\n",
            "[Batch 8] Current Loss: 5.6745\n",
            "[Batch 9] Current Loss: 5.8941\n",
            "Ep 3 (Step 018980): Train loss 3.324, Val loss 5.391\n",
            "[Batch 0] Current Loss: 3.0135\n",
            "[Batch 1] Current Loss: 3.3700\n",
            "[Batch 2] Current Loss: 3.4388\n",
            "[Batch 3] Current Loss: 2.7939\n",
            "[Batch 4] Current Loss: 2.8952\n",
            "[Batch 5] Current Loss: 3.4760\n",
            "[Batch 6] Current Loss: 3.8282\n",
            "[Batch 7] Current Loss: 3.5887\n",
            "[Batch 8] Current Loss: 3.5168\n",
            "[Batch 9] Current Loss: 2.8085\n",
            "[Batch 0] Current Loss: 5.8736\n",
            "[Batch 1] Current Loss: 5.6869\n",
            "[Batch 2] Current Loss: 5.0757\n",
            "[Batch 3] Current Loss: 5.4863\n",
            "[Batch 4] Current Loss: 5.1837\n",
            "[Batch 5] Current Loss: 5.1371\n",
            "[Batch 6] Current Loss: 5.5886\n",
            "[Batch 7] Current Loss: 5.4105\n",
            "[Batch 8] Current Loss: 5.7466\n",
            "[Batch 9] Current Loss: 5.6346\n",
            "Ep 3 (Step 019000): Train loss 3.273, Val loss 5.482\n",
            "[Batch 0] Current Loss: 2.7066\n",
            "[Batch 1] Current Loss: 3.0771\n",
            "[Batch 2] Current Loss: 3.0790\n",
            "[Batch 3] Current Loss: 3.3659\n",
            "[Batch 4] Current Loss: 3.2980\n",
            "[Batch 5] Current Loss: 2.9184\n",
            "[Batch 6] Current Loss: 2.7587\n",
            "[Batch 7] Current Loss: 2.8732\n",
            "[Batch 8] Current Loss: 3.5146\n",
            "[Batch 9] Current Loss: 3.3723\n",
            "[Batch 0] Current Loss: 5.5421\n",
            "[Batch 1] Current Loss: 5.5748\n",
            "[Batch 2] Current Loss: 5.5873\n",
            "[Batch 3] Current Loss: 5.7158\n",
            "[Batch 4] Current Loss: 5.0587\n",
            "[Batch 5] Current Loss: 5.1212\n",
            "[Batch 6] Current Loss: 5.0923\n",
            "[Batch 7] Current Loss: 5.3330\n",
            "[Batch 8] Current Loss: 5.0152\n",
            "[Batch 9] Current Loss: 5.2859\n",
            "Ep 3 (Step 019020): Train loss 3.096, Val loss 5.333\n",
            "[Batch 0] Current Loss: 3.7351\n",
            "[Batch 1] Current Loss: 3.7603\n",
            "[Batch 2] Current Loss: 2.9487\n",
            "[Batch 3] Current Loss: 3.3767\n",
            "[Batch 4] Current Loss: 2.7401\n",
            "[Batch 5] Current Loss: 3.3890\n",
            "[Batch 6] Current Loss: 3.6824\n",
            "[Batch 7] Current Loss: 3.2320\n",
            "[Batch 8] Current Loss: 2.9768\n",
            "[Batch 9] Current Loss: 3.8166\n",
            "[Batch 0] Current Loss: 5.3845\n",
            "[Batch 1] Current Loss: 4.9729\n",
            "[Batch 2] Current Loss: 6.1184\n",
            "[Batch 3] Current Loss: 5.7299\n",
            "[Batch 4] Current Loss: 5.5612\n",
            "[Batch 5] Current Loss: 5.3348\n",
            "[Batch 6] Current Loss: 5.2683\n",
            "[Batch 7] Current Loss: 6.2639\n",
            "[Batch 8] Current Loss: 5.4398\n",
            "[Batch 9] Current Loss: 4.7236\n",
            "Ep 3 (Step 019040): Train loss 3.366, Val loss 5.480\n",
            "[Batch 0] Current Loss: 3.4664\n",
            "[Batch 1] Current Loss: 3.0439\n",
            "[Batch 2] Current Loss: 2.7374\n",
            "[Batch 3] Current Loss: 3.8513\n",
            "[Batch 4] Current Loss: 2.8345\n",
            "[Batch 5] Current Loss: 3.1929\n",
            "[Batch 6] Current Loss: 3.4467\n",
            "[Batch 7] Current Loss: 2.6810\n",
            "[Batch 8] Current Loss: 3.0925\n",
            "[Batch 9] Current Loss: 3.6466\n",
            "[Batch 0] Current Loss: 5.3054\n",
            "[Batch 1] Current Loss: 4.6995\n",
            "[Batch 2] Current Loss: 5.4324\n",
            "[Batch 3] Current Loss: 5.2961\n",
            "[Batch 4] Current Loss: 5.1534\n",
            "[Batch 5] Current Loss: 5.2224\n",
            "[Batch 6] Current Loss: 5.3201\n",
            "[Batch 7] Current Loss: 5.2386\n",
            "[Batch 8] Current Loss: 5.8795\n",
            "[Batch 9] Current Loss: 5.1659\n",
            "Ep 3 (Step 019060): Train loss 3.199, Val loss 5.271\n",
            "[Batch 0] Current Loss: 3.1765\n",
            "[Batch 1] Current Loss: 3.4197\n",
            "[Batch 2] Current Loss: 3.1630\n",
            "[Batch 3] Current Loss: 2.7309\n",
            "[Batch 4] Current Loss: 3.2946\n",
            "[Batch 5] Current Loss: 3.3735\n",
            "[Batch 6] Current Loss: 3.2528\n",
            "[Batch 7] Current Loss: 3.1533\n",
            "[Batch 8] Current Loss: 2.9443\n",
            "[Batch 9] Current Loss: 3.1542\n",
            "[Batch 0] Current Loss: 5.5468\n",
            "[Batch 1] Current Loss: 5.8634\n",
            "[Batch 2] Current Loss: 5.1638\n",
            "[Batch 3] Current Loss: 5.8217\n",
            "[Batch 4] Current Loss: 5.9311\n",
            "[Batch 5] Current Loss: 5.3209\n",
            "[Batch 6] Current Loss: 5.6945\n",
            "[Batch 7] Current Loss: 4.6549\n",
            "[Batch 8] Current Loss: 4.9683\n",
            "[Batch 9] Current Loss: 5.5511\n",
            "Ep 3 (Step 019080): Train loss 3.166, Val loss 5.452\n",
            "[Batch 0] Current Loss: 3.2061\n",
            "[Batch 1] Current Loss: 3.2697\n",
            "[Batch 2] Current Loss: 3.8192\n",
            "[Batch 3] Current Loss: 3.2952\n",
            "[Batch 4] Current Loss: 3.4606\n",
            "[Batch 5] Current Loss: 3.3241\n",
            "[Batch 6] Current Loss: 3.2978\n",
            "[Batch 7] Current Loss: 2.9860\n",
            "[Batch 8] Current Loss: 2.9985\n",
            "[Batch 9] Current Loss: 3.5990\n",
            "[Batch 0] Current Loss: 5.4472\n",
            "[Batch 1] Current Loss: 5.3155\n",
            "[Batch 2] Current Loss: 5.7141\n",
            "[Batch 3] Current Loss: 5.8804\n",
            "[Batch 4] Current Loss: 5.3344\n",
            "[Batch 5] Current Loss: 4.5015\n",
            "[Batch 6] Current Loss: 5.2180\n",
            "[Batch 7] Current Loss: 5.8028\n",
            "[Batch 8] Current Loss: 6.0993\n",
            "[Batch 9] Current Loss: 5.0095\n",
            "Ep 3 (Step 019100): Train loss 3.326, Val loss 5.432\n",
            "[Batch 0] Current Loss: 3.0192\n",
            "[Batch 1] Current Loss: 2.9954\n",
            "[Batch 2] Current Loss: 3.1887\n",
            "[Batch 3] Current Loss: 2.7814\n",
            "[Batch 4] Current Loss: 2.7768\n",
            "[Batch 5] Current Loss: 2.6394\n",
            "[Batch 6] Current Loss: 4.2663\n",
            "[Batch 7] Current Loss: 3.0779\n",
            "[Batch 8] Current Loss: 3.9964\n",
            "[Batch 9] Current Loss: 2.2763\n",
            "[Batch 0] Current Loss: 5.2921\n",
            "[Batch 1] Current Loss: 5.3325\n",
            "[Batch 2] Current Loss: 5.5782\n",
            "[Batch 3] Current Loss: 6.0351\n",
            "[Batch 4] Current Loss: 4.6974\n",
            "[Batch 5] Current Loss: 4.8979\n",
            "[Batch 6] Current Loss: 5.4246\n",
            "[Batch 7] Current Loss: 4.8193\n",
            "[Batch 8] Current Loss: 5.6713\n",
            "[Batch 9] Current Loss: 5.5098\n",
            "Ep 3 (Step 019120): Train loss 3.102, Val loss 5.326\n",
            "[Batch 0] Current Loss: 3.3564\n",
            "[Batch 1] Current Loss: 3.5341\n",
            "[Batch 2] Current Loss: 3.8550\n",
            "[Batch 3] Current Loss: 3.7016\n",
            "[Batch 4] Current Loss: 3.0637\n",
            "[Batch 5] Current Loss: 3.7931\n",
            "[Batch 6] Current Loss: 3.4583\n",
            "[Batch 7] Current Loss: 3.0657\n",
            "[Batch 8] Current Loss: 3.5767\n",
            "[Batch 9] Current Loss: 3.1954\n",
            "[Batch 0] Current Loss: 5.3011\n",
            "[Batch 1] Current Loss: 6.0251\n",
            "[Batch 2] Current Loss: 5.3044\n",
            "[Batch 3] Current Loss: 5.5321\n",
            "[Batch 4] Current Loss: 5.5247\n",
            "[Batch 5] Current Loss: 5.4342\n",
            "[Batch 6] Current Loss: 5.9224\n",
            "[Batch 7] Current Loss: 5.0078\n",
            "[Batch 8] Current Loss: 4.6836\n",
            "[Batch 9] Current Loss: 4.8746\n",
            "Ep 3 (Step 019140): Train loss 3.460, Val loss 5.361\n",
            "[Batch 0] Current Loss: 3.3592\n",
            "[Batch 1] Current Loss: 4.0886\n",
            "[Batch 2] Current Loss: 3.4936\n",
            "[Batch 3] Current Loss: 3.6623\n",
            "[Batch 4] Current Loss: 2.7413\n",
            "[Batch 5] Current Loss: 4.2954\n",
            "[Batch 6] Current Loss: 3.3534\n",
            "[Batch 7] Current Loss: 3.3134\n",
            "[Batch 8] Current Loss: 3.5814\n",
            "[Batch 9] Current Loss: 2.8298\n",
            "[Batch 0] Current Loss: 5.1866\n",
            "[Batch 1] Current Loss: 6.1009\n",
            "[Batch 2] Current Loss: 5.8987\n",
            "[Batch 3] Current Loss: 5.0740\n",
            "[Batch 4] Current Loss: 5.0976\n",
            "[Batch 5] Current Loss: 4.7130\n",
            "[Batch 6] Current Loss: 5.7060\n",
            "[Batch 7] Current Loss: 5.6144\n",
            "[Batch 8] Current Loss: 5.5716\n",
            "[Batch 9] Current Loss: 5.0368\n",
            "Ep 3 (Step 019160): Train loss 3.472, Val loss 5.400\n",
            "[Batch 0] Current Loss: 2.7711\n",
            "[Batch 1] Current Loss: 3.4560\n",
            "[Batch 2] Current Loss: 2.7759\n",
            "[Batch 3] Current Loss: 2.7573\n",
            "[Batch 4] Current Loss: 3.2384\n",
            "[Batch 5] Current Loss: 3.0533\n",
            "[Batch 6] Current Loss: 3.2547\n",
            "[Batch 7] Current Loss: 3.2767\n",
            "[Batch 8] Current Loss: 2.8297\n",
            "[Batch 9] Current Loss: 2.6839\n",
            "[Batch 0] Current Loss: 5.6769\n",
            "[Batch 1] Current Loss: 5.7460\n",
            "[Batch 2] Current Loss: 5.2258\n",
            "[Batch 3] Current Loss: 5.4611\n",
            "[Batch 4] Current Loss: 5.6650\n",
            "[Batch 5] Current Loss: 5.0782\n",
            "[Batch 6] Current Loss: 4.6535\n",
            "[Batch 7] Current Loss: 5.7214\n",
            "[Batch 8] Current Loss: 5.4703\n",
            "[Batch 9] Current Loss: 5.4061\n",
            "Ep 3 (Step 019180): Train loss 3.010, Val loss 5.410\n",
            "[Batch 0] Current Loss: 3.2133\n",
            "[Batch 1] Current Loss: 3.5907\n",
            "[Batch 2] Current Loss: 3.4334\n",
            "[Batch 3] Current Loss: 3.3169\n",
            "[Batch 4] Current Loss: 3.3442\n",
            "[Batch 5] Current Loss: 3.3551\n",
            "[Batch 6] Current Loss: 3.3762\n",
            "[Batch 7] Current Loss: 3.2626\n",
            "[Batch 8] Current Loss: 2.6221\n",
            "[Batch 9] Current Loss: 3.0792\n",
            "[Batch 0] Current Loss: 6.1777\n",
            "[Batch 1] Current Loss: 5.4937\n",
            "[Batch 2] Current Loss: 4.3967\n",
            "[Batch 3] Current Loss: 5.2114\n",
            "[Batch 4] Current Loss: 6.2042\n",
            "[Batch 5] Current Loss: 5.2471\n",
            "[Batch 6] Current Loss: 5.9434\n",
            "[Batch 7] Current Loss: 5.6489\n",
            "[Batch 8] Current Loss: 5.5227\n",
            "[Batch 9] Current Loss: 5.7850\n",
            "Ep 3 (Step 019200): Train loss 3.259, Val loss 5.563\n",
            "[Batch 0] Current Loss: 3.2335\n",
            "[Batch 1] Current Loss: 3.6675\n",
            "[Batch 2] Current Loss: 3.6716\n",
            "[Batch 3] Current Loss: 3.5767\n",
            "[Batch 4] Current Loss: 2.0441\n",
            "[Batch 5] Current Loss: 2.9380\n",
            "[Batch 6] Current Loss: 3.8925\n",
            "[Batch 7] Current Loss: 3.5393\n",
            "[Batch 8] Current Loss: 3.1672\n",
            "[Batch 9] Current Loss: 4.0378\n",
            "[Batch 0] Current Loss: 5.5314\n",
            "[Batch 1] Current Loss: 4.6554\n",
            "[Batch 2] Current Loss: 5.0566\n",
            "[Batch 3] Current Loss: 5.6988\n",
            "[Batch 4] Current Loss: 6.2642\n",
            "[Batch 5] Current Loss: 5.2470\n",
            "[Batch 6] Current Loss: 5.9863\n",
            "[Batch 7] Current Loss: 5.7659\n",
            "[Batch 8] Current Loss: 5.2394\n",
            "[Batch 9] Current Loss: 5.3107\n",
            "Ep 3 (Step 019220): Train loss 3.377, Val loss 5.476\n",
            "[Batch 0] Current Loss: 3.3652\n",
            "[Batch 1] Current Loss: 3.2805\n",
            "[Batch 2] Current Loss: 3.4552\n",
            "[Batch 3] Current Loss: 3.6658\n",
            "[Batch 4] Current Loss: 3.0977\n",
            "[Batch 5] Current Loss: 3.2458\n",
            "[Batch 6] Current Loss: 3.1751\n",
            "[Batch 7] Current Loss: 3.2147\n",
            "[Batch 8] Current Loss: 3.1253\n",
            "[Batch 9] Current Loss: 3.6405\n",
            "[Batch 0] Current Loss: 5.7504\n",
            "[Batch 1] Current Loss: 5.5504\n",
            "[Batch 2] Current Loss: 5.1387\n",
            "[Batch 3] Current Loss: 5.2627\n",
            "[Batch 4] Current Loss: 5.5472\n",
            "[Batch 5] Current Loss: 5.4627\n",
            "[Batch 6] Current Loss: 4.7915\n",
            "[Batch 7] Current Loss: 4.8901\n",
            "[Batch 8] Current Loss: 5.0595\n",
            "[Batch 9] Current Loss: 4.3640\n",
            "Ep 3 (Step 019240): Train loss 3.327, Val loss 5.182\n",
            "[Batch 0] Current Loss: 3.1906\n",
            "[Batch 1] Current Loss: 3.2444\n",
            "[Batch 2] Current Loss: 3.3204\n",
            "[Batch 3] Current Loss: 3.0518\n",
            "[Batch 4] Current Loss: 3.3329\n",
            "[Batch 5] Current Loss: 3.4598\n",
            "[Batch 6] Current Loss: 3.0176\n",
            "[Batch 7] Current Loss: 3.5512\n",
            "[Batch 8] Current Loss: 2.8182\n",
            "[Batch 9] Current Loss: 3.4711\n",
            "[Batch 0] Current Loss: 5.5603\n",
            "[Batch 1] Current Loss: 5.1123\n",
            "[Batch 2] Current Loss: 5.2634\n",
            "[Batch 3] Current Loss: 5.6525\n",
            "[Batch 4] Current Loss: 4.4457\n",
            "[Batch 5] Current Loss: 5.6524\n",
            "[Batch 6] Current Loss: 5.2076\n",
            "[Batch 7] Current Loss: 4.8708\n",
            "[Batch 8] Current Loss: 6.0088\n",
            "[Batch 9] Current Loss: 5.4283\n",
            "Ep 3 (Step 019260): Train loss 3.246, Val loss 5.320\n",
            "[Batch 0] Current Loss: 3.2240\n",
            "[Batch 1] Current Loss: 3.0993\n",
            "[Batch 2] Current Loss: 3.4198\n",
            "[Batch 3] Current Loss: 3.4518\n",
            "[Batch 4] Current Loss: 2.9742\n",
            "[Batch 5] Current Loss: 3.3626\n",
            "[Batch 6] Current Loss: 2.9273\n",
            "[Batch 7] Current Loss: 2.8291\n",
            "[Batch 8] Current Loss: 3.2201\n",
            "[Batch 9] Current Loss: 3.4199\n",
            "[Batch 0] Current Loss: 5.6694\n",
            "[Batch 1] Current Loss: 4.4656\n",
            "[Batch 2] Current Loss: 5.3361\n",
            "[Batch 3] Current Loss: 5.4692\n",
            "[Batch 4] Current Loss: 5.0088\n",
            "[Batch 5] Current Loss: 5.9737\n",
            "[Batch 6] Current Loss: 5.4098\n",
            "[Batch 7] Current Loss: 5.5547\n",
            "[Batch 8] Current Loss: 5.6166\n",
            "[Batch 9] Current Loss: 4.6098\n",
            "Ep 3 (Step 019280): Train loss 3.193, Val loss 5.311\n",
            "[Batch 0] Current Loss: 3.4235\n",
            "[Batch 1] Current Loss: 2.8106\n",
            "[Batch 2] Current Loss: 2.9591\n",
            "[Batch 3] Current Loss: 3.1993\n",
            "[Batch 4] Current Loss: 3.0345\n",
            "[Batch 5] Current Loss: 2.9901\n",
            "[Batch 6] Current Loss: 3.6825\n",
            "[Batch 7] Current Loss: 3.5984\n",
            "[Batch 8] Current Loss: 2.5918\n",
            "[Batch 9] Current Loss: 2.6682\n",
            "[Batch 0] Current Loss: 5.8381\n",
            "[Batch 1] Current Loss: 4.6057\n",
            "[Batch 2] Current Loss: 4.9640\n",
            "[Batch 3] Current Loss: 5.5883\n",
            "[Batch 4] Current Loss: 5.3307\n",
            "[Batch 5] Current Loss: 5.8524\n",
            "[Batch 6] Current Loss: 5.9609\n",
            "[Batch 7] Current Loss: 5.1307\n",
            "[Batch 8] Current Loss: 5.1213\n",
            "[Batch 9] Current Loss: 4.7004\n",
            "Ep 3 (Step 019300): Train loss 3.096, Val loss 5.309\n",
            "[Batch 0] Current Loss: 3.1705\n",
            "[Batch 1] Current Loss: 3.4603\n",
            "[Batch 2] Current Loss: 3.1112\n",
            "[Batch 3] Current Loss: 2.9585\n",
            "[Batch 4] Current Loss: 3.1959\n",
            "[Batch 5] Current Loss: 3.2340\n",
            "[Batch 6] Current Loss: 3.8051\n",
            "[Batch 7] Current Loss: 3.0621\n",
            "[Batch 8] Current Loss: 2.8028\n",
            "[Batch 9] Current Loss: 2.9740\n",
            "[Batch 0] Current Loss: 5.7278\n",
            "[Batch 1] Current Loss: 5.3319\n",
            "[Batch 2] Current Loss: 5.7113\n",
            "[Batch 3] Current Loss: 5.9308\n",
            "[Batch 4] Current Loss: 5.1809\n",
            "[Batch 5] Current Loss: 5.5214\n",
            "[Batch 6] Current Loss: 5.3267\n",
            "[Batch 7] Current Loss: 6.3338\n",
            "[Batch 8] Current Loss: 5.7364\n",
            "[Batch 9] Current Loss: 5.4345\n",
            "Ep 3 (Step 019320): Train loss 3.177, Val loss 5.624\n",
            "[Batch 0] Current Loss: 3.0967\n",
            "[Batch 1] Current Loss: 3.0436\n",
            "[Batch 2] Current Loss: 2.7980\n",
            "[Batch 3] Current Loss: 3.1066\n",
            "[Batch 4] Current Loss: 3.6343\n",
            "[Batch 5] Current Loss: 3.0796\n",
            "[Batch 6] Current Loss: 3.5021\n",
            "[Batch 7] Current Loss: 3.7077\n",
            "[Batch 8] Current Loss: 3.2514\n",
            "[Batch 9] Current Loss: 3.2209\n",
            "[Batch 0] Current Loss: 5.3535\n",
            "[Batch 1] Current Loss: 5.7961\n",
            "[Batch 2] Current Loss: 5.0009\n",
            "[Batch 3] Current Loss: 4.8746\n",
            "[Batch 4] Current Loss: 5.5050\n",
            "[Batch 5] Current Loss: 5.2874\n",
            "[Batch 6] Current Loss: 5.1302\n",
            "[Batch 7] Current Loss: 5.4572\n",
            "[Batch 8] Current Loss: 5.5172\n",
            "[Batch 9] Current Loss: 5.3794\n",
            "Ep 3 (Step 019340): Train loss 3.244, Val loss 5.330\n",
            "[Batch 0] Current Loss: 3.3606\n",
            "[Batch 1] Current Loss: 3.5254\n",
            "[Batch 2] Current Loss: 3.3887\n",
            "[Batch 3] Current Loss: 2.7544\n",
            "[Batch 4] Current Loss: 3.0582\n",
            "[Batch 5] Current Loss: 2.2940\n",
            "[Batch 6] Current Loss: 2.7145\n",
            "[Batch 7] Current Loss: 3.1377\n",
            "[Batch 8] Current Loss: 3.5498\n",
            "[Batch 9] Current Loss: 3.5007\n",
            "[Batch 0] Current Loss: 5.5986\n",
            "[Batch 1] Current Loss: 6.1227\n",
            "[Batch 2] Current Loss: 5.2893\n",
            "[Batch 3] Current Loss: 5.6304\n",
            "[Batch 4] Current Loss: 5.2640\n",
            "[Batch 5] Current Loss: 5.6108\n",
            "[Batch 6] Current Loss: 5.4566\n",
            "[Batch 7] Current Loss: 5.4309\n",
            "[Batch 8] Current Loss: 5.6306\n",
            "[Batch 9] Current Loss: 4.8829\n",
            "Ep 3 (Step 019360): Train loss 3.128, Val loss 5.492\n",
            "[Batch 0] Current Loss: 3.8330\n",
            "[Batch 1] Current Loss: 3.3384\n",
            "[Batch 2] Current Loss: 3.4064\n",
            "[Batch 3] Current Loss: 3.1868\n",
            "[Batch 4] Current Loss: 3.2732\n",
            "[Batch 5] Current Loss: 3.8964\n",
            "[Batch 6] Current Loss: 2.8996\n",
            "[Batch 7] Current Loss: 3.7868\n",
            "[Batch 8] Current Loss: 3.1418\n",
            "[Batch 9] Current Loss: 3.3646\n",
            "[Batch 0] Current Loss: 5.2964\n",
            "[Batch 1] Current Loss: 5.4975\n",
            "[Batch 2] Current Loss: 5.0030\n",
            "[Batch 3] Current Loss: 5.0843\n",
            "[Batch 4] Current Loss: 5.4536\n",
            "[Batch 5] Current Loss: 5.2347\n",
            "[Batch 6] Current Loss: 4.9788\n",
            "[Batch 7] Current Loss: 5.7610\n",
            "[Batch 8] Current Loss: 5.2884\n",
            "[Batch 9] Current Loss: 5.2858\n",
            "Ep 3 (Step 019380): Train loss 3.413, Val loss 5.288\n",
            "[Batch 0] Current Loss: 3.1755\n",
            "[Batch 1] Current Loss: 3.7498\n",
            "[Batch 2] Current Loss: 2.4848\n",
            "[Batch 3] Current Loss: 3.9339\n",
            "[Batch 4] Current Loss: 3.4120\n",
            "[Batch 5] Current Loss: 3.5907\n",
            "[Batch 6] Current Loss: 3.0454\n",
            "[Batch 7] Current Loss: 3.0475\n",
            "[Batch 8] Current Loss: 2.7745\n",
            "[Batch 9] Current Loss: 3.0508\n",
            "[Batch 0] Current Loss: 5.1571\n",
            "[Batch 1] Current Loss: 4.9150\n",
            "[Batch 2] Current Loss: 4.9090\n",
            "[Batch 3] Current Loss: 5.4416\n",
            "[Batch 4] Current Loss: 5.2063\n",
            "[Batch 5] Current Loss: 6.1796\n",
            "[Batch 6] Current Loss: 5.1605\n",
            "[Batch 7] Current Loss: 5.6546\n",
            "[Batch 8] Current Loss: 5.7011\n",
            "[Batch 9] Current Loss: 5.0794\n",
            "Ep 3 (Step 019400): Train loss 3.226, Val loss 5.340\n",
            "[Batch 0] Current Loss: 3.2528\n",
            "[Batch 1] Current Loss: 3.7211\n",
            "[Batch 2] Current Loss: 2.8407\n",
            "[Batch 3] Current Loss: 3.2902\n",
            "[Batch 4] Current Loss: 2.8214\n",
            "[Batch 5] Current Loss: 2.6881\n",
            "[Batch 6] Current Loss: 3.0479\n",
            "[Batch 7] Current Loss: 3.1382\n",
            "[Batch 8] Current Loss: 3.5223\n",
            "[Batch 9] Current Loss: 2.6064\n",
            "[Batch 0] Current Loss: 5.0986\n",
            "[Batch 1] Current Loss: 5.7518\n",
            "[Batch 2] Current Loss: 5.0884\n",
            "[Batch 3] Current Loss: 5.4293\n",
            "[Batch 4] Current Loss: 5.0242\n",
            "[Batch 5] Current Loss: 5.1520\n",
            "[Batch 6] Current Loss: 4.7104\n",
            "[Batch 7] Current Loss: 5.7683\n",
            "[Batch 8] Current Loss: 5.1796\n",
            "[Batch 9] Current Loss: 4.6638\n",
            "Ep 3 (Step 019420): Train loss 3.093, Val loss 5.187\n",
            "[Batch 0] Current Loss: 3.2602\n",
            "[Batch 1] Current Loss: 2.5888\n",
            "[Batch 2] Current Loss: 2.9330\n",
            "[Batch 3] Current Loss: 2.9611\n",
            "[Batch 4] Current Loss: 2.6273\n",
            "[Batch 5] Current Loss: 3.3168\n",
            "[Batch 6] Current Loss: 4.2795\n",
            "[Batch 7] Current Loss: 3.2086\n",
            "[Batch 8] Current Loss: 3.7499\n",
            "[Batch 9] Current Loss: 3.2617\n",
            "[Batch 0] Current Loss: 5.0312\n",
            "[Batch 1] Current Loss: 6.1371\n",
            "[Batch 2] Current Loss: 5.5342\n",
            "[Batch 3] Current Loss: 5.9358\n",
            "[Batch 4] Current Loss: 5.8739\n",
            "[Batch 5] Current Loss: 5.3738\n",
            "[Batch 6] Current Loss: 5.8031\n",
            "[Batch 7] Current Loss: 5.8976\n",
            "[Batch 8] Current Loss: 5.2004\n",
            "[Batch 9] Current Loss: 5.3286\n",
            "Ep 3 (Step 019440): Train loss 3.219, Val loss 5.612\n",
            "[Batch 0] Current Loss: 3.4716\n",
            "[Batch 1] Current Loss: 3.7995\n",
            "[Batch 2] Current Loss: 3.3515\n",
            "[Batch 3] Current Loss: 3.7088\n",
            "[Batch 4] Current Loss: 3.0826\n",
            "[Batch 5] Current Loss: 3.5167\n",
            "[Batch 6] Current Loss: 3.3225\n",
            "[Batch 7] Current Loss: 3.5199\n",
            "[Batch 8] Current Loss: 3.4447\n",
            "[Batch 9] Current Loss: 2.7955\n",
            "[Batch 0] Current Loss: 5.2004\n",
            "[Batch 1] Current Loss: 5.1054\n",
            "[Batch 2] Current Loss: 4.9708\n",
            "[Batch 3] Current Loss: 5.1443\n",
            "[Batch 4] Current Loss: 5.2214\n",
            "[Batch 5] Current Loss: 4.4658\n",
            "[Batch 6] Current Loss: 5.5792\n",
            "[Batch 7] Current Loss: 4.9396\n",
            "[Batch 8] Current Loss: 5.0055\n",
            "[Batch 9] Current Loss: 5.2473\n",
            "Ep 3 (Step 019460): Train loss 3.401, Val loss 5.088\n",
            "[Batch 0] Current Loss: 3.3032\n",
            "[Batch 1] Current Loss: 3.4461\n",
            "[Batch 2] Current Loss: 2.9944\n",
            "[Batch 3] Current Loss: 2.7095\n",
            "[Batch 4] Current Loss: 2.8455\n",
            "[Batch 5] Current Loss: 3.5807\n",
            "[Batch 6] Current Loss: 2.7091\n",
            "[Batch 7] Current Loss: 3.4692\n",
            "[Batch 8] Current Loss: 2.8980\n",
            "[Batch 9] Current Loss: 3.5068\n",
            "[Batch 0] Current Loss: 5.7309\n",
            "[Batch 1] Current Loss: 5.4516\n",
            "[Batch 2] Current Loss: 5.4393\n",
            "[Batch 3] Current Loss: 5.7662\n",
            "[Batch 4] Current Loss: 5.2968\n",
            "[Batch 5] Current Loss: 5.0059\n",
            "[Batch 6] Current Loss: 5.6558\n",
            "[Batch 7] Current Loss: 4.9752\n",
            "[Batch 8] Current Loss: 4.5924\n",
            "[Batch 9] Current Loss: 5.9627\n",
            "Ep 3 (Step 019480): Train loss 3.146, Val loss 5.388\n",
            "[Batch 0] Current Loss: 3.2017\n",
            "[Batch 1] Current Loss: 3.2055\n",
            "[Batch 2] Current Loss: 2.9418\n",
            "[Batch 3] Current Loss: 3.3604\n",
            "[Batch 4] Current Loss: 3.4235\n",
            "[Batch 5] Current Loss: 3.2840\n",
            "[Batch 6] Current Loss: 2.9708\n",
            "[Batch 7] Current Loss: 3.0936\n",
            "[Batch 8] Current Loss: 2.9612\n",
            "[Batch 9] Current Loss: 3.4334\n",
            "[Batch 0] Current Loss: 5.5385\n",
            "[Batch 1] Current Loss: 4.9520\n",
            "[Batch 2] Current Loss: 5.3794\n",
            "[Batch 3] Current Loss: 5.5030\n",
            "[Batch 4] Current Loss: 5.7918\n",
            "[Batch 5] Current Loss: 4.3198\n",
            "[Batch 6] Current Loss: 5.6373\n",
            "[Batch 7] Current Loss: 5.3122\n",
            "[Batch 8] Current Loss: 5.7276\n",
            "[Batch 9] Current Loss: 5.7209\n",
            "Ep 3 (Step 019500): Train loss 3.188, Val loss 5.388\n",
            "[Batch 0] Current Loss: 3.1087\n",
            "[Batch 1] Current Loss: 3.5925\n",
            "[Batch 2] Current Loss: 2.8681\n",
            "[Batch 3] Current Loss: 3.2600\n",
            "[Batch 4] Current Loss: 3.0165\n",
            "[Batch 5] Current Loss: 3.6184\n",
            "[Batch 6] Current Loss: 2.3959\n",
            "[Batch 7] Current Loss: 3.6460\n",
            "[Batch 8] Current Loss: 3.0565\n",
            "[Batch 9] Current Loss: 3.5278\n",
            "[Batch 0] Current Loss: 4.5782\n",
            "[Batch 1] Current Loss: 5.5454\n",
            "[Batch 2] Current Loss: 5.5354\n",
            "[Batch 3] Current Loss: 5.1661\n",
            "[Batch 4] Current Loss: 5.4230\n",
            "[Batch 5] Current Loss: 4.7643\n",
            "[Batch 6] Current Loss: 4.6842\n",
            "[Batch 7] Current Loss: 5.1343\n",
            "[Batch 8] Current Loss: 4.8144\n",
            "[Batch 9] Current Loss: 5.3642\n",
            "Ep 3 (Step 019520): Train loss 3.209, Val loss 5.101\n",
            "[Batch 0] Current Loss: 3.0090\n",
            "[Batch 1] Current Loss: 3.0532\n",
            "[Batch 2] Current Loss: 3.7117\n",
            "[Batch 3] Current Loss: 3.2345\n",
            "[Batch 4] Current Loss: 3.2469\n",
            "[Batch 5] Current Loss: 2.5741\n",
            "[Batch 6] Current Loss: 3.1532\n",
            "[Batch 7] Current Loss: 2.6008\n",
            "[Batch 8] Current Loss: 3.4354\n",
            "[Batch 9] Current Loss: 3.2625\n",
            "[Batch 0] Current Loss: 5.7344\n",
            "[Batch 1] Current Loss: 6.2001\n",
            "[Batch 2] Current Loss: 5.5366\n",
            "[Batch 3] Current Loss: 5.7347\n",
            "[Batch 4] Current Loss: 5.4671\n",
            "[Batch 5] Current Loss: 5.4663\n",
            "[Batch 6] Current Loss: 5.7243\n",
            "[Batch 7] Current Loss: 4.9794\n",
            "[Batch 8] Current Loss: 5.0742\n",
            "[Batch 9] Current Loss: 4.9319\n",
            "Ep 3 (Step 019540): Train loss 3.128, Val loss 5.485\n",
            "[Batch 0] Current Loss: 3.1026\n",
            "[Batch 1] Current Loss: 2.9845\n",
            "[Batch 2] Current Loss: 3.5468\n",
            "[Batch 3] Current Loss: 3.1681\n",
            "[Batch 4] Current Loss: 3.1624\n",
            "[Batch 5] Current Loss: 3.7475\n",
            "[Batch 6] Current Loss: 3.0925\n",
            "[Batch 7] Current Loss: 3.4224\n",
            "[Batch 8] Current Loss: 3.5819\n",
            "[Batch 9] Current Loss: 3.2825\n",
            "[Batch 0] Current Loss: 5.9401\n",
            "[Batch 1] Current Loss: 4.4251\n",
            "[Batch 2] Current Loss: 6.0642\n",
            "[Batch 3] Current Loss: 5.8122\n",
            "[Batch 4] Current Loss: 5.8462\n",
            "[Batch 5] Current Loss: 4.8623\n",
            "[Batch 6] Current Loss: 5.7422\n",
            "[Batch 7] Current Loss: 5.0306\n",
            "[Batch 8] Current Loss: 6.5053\n",
            "[Batch 9] Current Loss: 5.5468\n",
            "Ep 3 (Step 019560): Train loss 3.309, Val loss 5.577\n",
            "[Batch 0] Current Loss: 3.4839\n",
            "[Batch 1] Current Loss: 3.6385\n",
            "[Batch 2] Current Loss: 3.5771\n",
            "[Batch 3] Current Loss: 3.1760\n",
            "[Batch 4] Current Loss: 3.3242\n",
            "[Batch 5] Current Loss: 3.2225\n",
            "[Batch 6] Current Loss: 3.0281\n",
            "[Batch 7] Current Loss: 3.4784\n",
            "[Batch 8] Current Loss: 3.1795\n",
            "[Batch 9] Current Loss: 3.3567\n",
            "[Batch 0] Current Loss: 6.0687\n",
            "[Batch 1] Current Loss: 5.0110\n",
            "[Batch 2] Current Loss: 5.3777\n",
            "[Batch 3] Current Loss: 5.1075\n",
            "[Batch 4] Current Loss: 5.9030\n",
            "[Batch 5] Current Loss: 5.3979\n",
            "[Batch 6] Current Loss: 5.5678\n",
            "[Batch 7] Current Loss: 5.0646\n",
            "[Batch 8] Current Loss: 5.8476\n",
            "[Batch 9] Current Loss: 5.4360\n",
            "Ep 3 (Step 019580): Train loss 3.346, Val loss 5.478\n",
            "[Batch 0] Current Loss: 3.4273\n",
            "[Batch 1] Current Loss: 3.7739\n",
            "[Batch 2] Current Loss: 3.5256\n",
            "[Batch 3] Current Loss: 2.5976\n",
            "[Batch 4] Current Loss: 2.7701\n",
            "[Batch 5] Current Loss: 2.6296\n",
            "[Batch 6] Current Loss: 2.8829\n",
            "[Batch 7] Current Loss: 2.9405\n",
            "[Batch 8] Current Loss: 3.5465\n",
            "[Batch 9] Current Loss: 3.1539\n",
            "[Batch 0] Current Loss: 5.1711\n",
            "[Batch 1] Current Loss: 5.3258\n",
            "[Batch 2] Current Loss: 5.7629\n",
            "[Batch 3] Current Loss: 5.5050\n",
            "[Batch 4] Current Loss: 5.8162\n",
            "[Batch 5] Current Loss: 5.2937\n",
            "[Batch 6] Current Loss: 5.7463\n",
            "[Batch 7] Current Loss: 5.1678\n",
            "[Batch 8] Current Loss: 5.0752\n",
            "[Batch 9] Current Loss: 5.1060\n",
            "Ep 3 (Step 019600): Train loss 3.125, Val loss 5.397\n",
            "[Batch 0] Current Loss: 2.9283\n",
            "[Batch 1] Current Loss: 3.6416\n",
            "[Batch 2] Current Loss: 2.9357\n",
            "[Batch 3] Current Loss: 3.1626\n",
            "[Batch 4] Current Loss: 3.2899\n",
            "[Batch 5] Current Loss: 3.4917\n",
            "[Batch 6] Current Loss: 3.1640\n",
            "[Batch 7] Current Loss: 2.0746\n",
            "[Batch 8] Current Loss: 3.1325\n",
            "[Batch 9] Current Loss: 3.2238\n",
            "[Batch 0] Current Loss: 5.4464\n",
            "[Batch 1] Current Loss: 4.9653\n",
            "[Batch 2] Current Loss: 5.1295\n",
            "[Batch 3] Current Loss: 5.5095\n",
            "[Batch 4] Current Loss: 5.1847\n",
            "[Batch 5] Current Loss: 5.5192\n",
            "[Batch 6] Current Loss: 5.1246\n",
            "[Batch 7] Current Loss: 4.9657\n",
            "[Batch 8] Current Loss: 5.6221\n",
            "[Batch 9] Current Loss: 5.7037\n",
            "Ep 3 (Step 019620): Train loss 3.104, Val loss 5.317\n",
            "[Batch 0] Current Loss: 3.0239\n",
            "[Batch 1] Current Loss: 3.5630\n",
            "[Batch 2] Current Loss: 2.9982\n",
            "[Batch 3] Current Loss: 3.2430\n",
            "[Batch 4] Current Loss: 2.2412\n",
            "[Batch 5] Current Loss: 3.1298\n",
            "[Batch 6] Current Loss: 2.7865\n",
            "[Batch 7] Current Loss: 3.1918\n",
            "[Batch 8] Current Loss: 3.6664\n",
            "[Batch 9] Current Loss: 3.0877\n",
            "[Batch 0] Current Loss: 5.4353\n",
            "[Batch 1] Current Loss: 6.0238\n",
            "[Batch 2] Current Loss: 5.3438\n",
            "[Batch 3] Current Loss: 5.2004\n",
            "[Batch 4] Current Loss: 4.9760\n",
            "[Batch 5] Current Loss: 5.3463\n",
            "[Batch 6] Current Loss: 5.6467\n",
            "[Batch 7] Current Loss: 5.2716\n",
            "[Batch 8] Current Loss: 5.0605\n",
            "[Batch 9] Current Loss: 4.7351\n",
            "Ep 3 (Step 019640): Train loss 3.093, Val loss 5.304\n",
            "[Batch 0] Current Loss: 3.3638\n",
            "[Batch 1] Current Loss: 3.5700\n",
            "[Batch 2] Current Loss: 2.8553\n",
            "[Batch 3] Current Loss: 2.7451\n",
            "[Batch 4] Current Loss: 2.7027\n",
            "[Batch 5] Current Loss: 3.0223\n",
            "[Batch 6] Current Loss: 3.0635\n",
            "[Batch 7] Current Loss: 3.6658\n",
            "[Batch 8] Current Loss: 2.7802\n",
            "[Batch 9] Current Loss: 2.8494\n",
            "[Batch 0] Current Loss: 5.7161\n",
            "[Batch 1] Current Loss: 4.7988\n",
            "[Batch 2] Current Loss: 5.2970\n",
            "[Batch 3] Current Loss: 5.4329\n",
            "[Batch 4] Current Loss: 5.0144\n",
            "[Batch 5] Current Loss: 6.4590\n",
            "[Batch 6] Current Loss: 5.4438\n",
            "[Batch 7] Current Loss: 5.5330\n",
            "[Batch 8] Current Loss: 5.4919\n",
            "[Batch 9] Current Loss: 4.9554\n",
            "Ep 3 (Step 019660): Train loss 3.062, Val loss 5.414\n",
            "[Batch 0] Current Loss: 3.9888\n",
            "[Batch 1] Current Loss: 3.2607\n",
            "[Batch 2] Current Loss: 2.8479\n",
            "[Batch 3] Current Loss: 2.7311\n",
            "[Batch 4] Current Loss: 3.0372\n",
            "[Batch 5] Current Loss: 2.6629\n",
            "[Batch 6] Current Loss: 3.7859\n",
            "[Batch 7] Current Loss: 2.6993\n",
            "[Batch 8] Current Loss: 3.1526\n",
            "[Batch 9] Current Loss: 3.2696\n",
            "[Batch 0] Current Loss: 5.8671\n",
            "[Batch 1] Current Loss: 5.3302\n",
            "[Batch 2] Current Loss: 5.5115\n",
            "[Batch 3] Current Loss: 5.1453\n",
            "[Batch 4] Current Loss: 5.4769\n",
            "[Batch 5] Current Loss: 5.0481\n",
            "[Batch 6] Current Loss: 5.8820\n",
            "[Batch 7] Current Loss: 4.9358\n",
            "[Batch 8] Current Loss: 5.6209\n",
            "[Batch 9] Current Loss: 5.7852\n",
            "Ep 3 (Step 019680): Train loss 3.144, Val loss 5.460\n",
            "[Batch 0] Current Loss: 3.0157\n",
            "[Batch 1] Current Loss: 3.1948\n",
            "[Batch 2] Current Loss: 3.2530\n",
            "[Batch 3] Current Loss: 3.3088\n",
            "[Batch 4] Current Loss: 3.0213\n",
            "[Batch 5] Current Loss: 3.4788\n",
            "[Batch 6] Current Loss: 3.4749\n",
            "[Batch 7] Current Loss: 3.2291\n",
            "[Batch 8] Current Loss: 2.8285\n",
            "[Batch 9] Current Loss: 3.0003\n",
            "[Batch 0] Current Loss: 5.7840\n",
            "[Batch 1] Current Loss: 5.1708\n",
            "[Batch 2] Current Loss: 6.0115\n",
            "[Batch 3] Current Loss: 5.0096\n",
            "[Batch 4] Current Loss: 5.4665\n",
            "[Batch 5] Current Loss: 4.1803\n",
            "[Batch 6] Current Loss: 4.8190\n",
            "[Batch 7] Current Loss: 5.7219\n",
            "[Batch 8] Current Loss: 5.1653\n",
            "[Batch 9] Current Loss: 5.5928\n",
            "Ep 3 (Step 019700): Train loss 3.181, Val loss 5.292\n",
            "[Batch 0] Current Loss: 3.1106\n",
            "[Batch 1] Current Loss: 3.1250\n",
            "[Batch 2] Current Loss: 3.4975\n",
            "[Batch 3] Current Loss: 4.0800\n",
            "[Batch 4] Current Loss: 3.2382\n",
            "[Batch 5] Current Loss: 3.3187\n",
            "[Batch 6] Current Loss: 3.0857\n",
            "[Batch 7] Current Loss: 4.1091\n",
            "[Batch 8] Current Loss: 2.0889\n",
            "[Batch 9] Current Loss: 3.1953\n",
            "[Batch 0] Current Loss: 4.8582\n",
            "[Batch 1] Current Loss: 5.1995\n",
            "[Batch 2] Current Loss: 5.0972\n",
            "[Batch 3] Current Loss: 4.9338\n",
            "[Batch 4] Current Loss: 5.4194\n",
            "[Batch 5] Current Loss: 5.3943\n",
            "[Batch 6] Current Loss: 5.5930\n",
            "[Batch 7] Current Loss: 5.0528\n",
            "[Batch 8] Current Loss: 5.2541\n",
            "[Batch 9] Current Loss: 5.1785\n",
            "Ep 3 (Step 019720): Train loss 3.285, Val loss 5.198\n",
            "[Batch 0] Current Loss: 3.0045\n",
            "[Batch 1] Current Loss: 3.2328\n",
            "[Batch 2] Current Loss: 3.4226\n",
            "[Batch 3] Current Loss: 3.7069\n",
            "[Batch 4] Current Loss: 2.8757\n",
            "[Batch 5] Current Loss: 2.5848\n",
            "[Batch 6] Current Loss: 3.4760\n",
            "[Batch 7] Current Loss: 3.0988\n",
            "[Batch 8] Current Loss: 3.3144\n",
            "[Batch 9] Current Loss: 3.2591\n",
            "[Batch 0] Current Loss: 4.9629\n",
            "[Batch 1] Current Loss: 4.9913\n",
            "[Batch 2] Current Loss: 5.4788\n",
            "[Batch 3] Current Loss: 5.2558\n",
            "[Batch 4] Current Loss: 5.1903\n",
            "[Batch 5] Current Loss: 4.9290\n",
            "[Batch 6] Current Loss: 5.2899\n",
            "[Batch 7] Current Loss: 5.2440\n",
            "[Batch 8] Current Loss: 5.0592\n",
            "[Batch 9] Current Loss: 4.7824\n",
            "Ep 3 (Step 019740): Train loss 3.198, Val loss 5.118\n",
            "[Batch 0] Current Loss: 3.5696\n",
            "[Batch 1] Current Loss: 3.4407\n",
            "[Batch 2] Current Loss: 3.1342\n",
            "[Batch 3] Current Loss: 3.4856\n",
            "[Batch 4] Current Loss: 2.9511\n",
            "[Batch 5] Current Loss: 2.6361\n",
            "[Batch 6] Current Loss: 3.7210\n",
            "[Batch 7] Current Loss: 3.0960\n",
            "[Batch 8] Current Loss: 3.1587\n",
            "[Batch 9] Current Loss: 3.4335\n",
            "[Batch 0] Current Loss: 5.0883\n",
            "[Batch 1] Current Loss: 5.4292\n",
            "[Batch 2] Current Loss: 4.6702\n",
            "[Batch 3] Current Loss: 5.7635\n",
            "[Batch 4] Current Loss: 5.8268\n",
            "[Batch 5] Current Loss: 6.0529\n",
            "[Batch 6] Current Loss: 5.7827\n",
            "[Batch 7] Current Loss: 5.3125\n",
            "[Batch 8] Current Loss: 5.4701\n",
            "[Batch 9] Current Loss: 5.0099\n",
            "Ep 3 (Step 019760): Train loss 3.263, Val loss 5.441\n",
            "[Batch 0] Current Loss: 3.3532\n",
            "[Batch 1] Current Loss: 3.7297\n",
            "[Batch 2] Current Loss: 2.9690\n",
            "[Batch 3] Current Loss: 3.1666\n",
            "[Batch 4] Current Loss: 3.3798\n",
            "[Batch 5] Current Loss: 2.7030\n",
            "[Batch 6] Current Loss: 3.1084\n",
            "[Batch 7] Current Loss: 3.8232\n",
            "[Batch 8] Current Loss: 3.2410\n",
            "[Batch 9] Current Loss: 3.3973\n",
            "[Batch 0] Current Loss: 4.9943\n",
            "[Batch 1] Current Loss: 5.5297\n",
            "[Batch 2] Current Loss: 5.6988\n",
            "[Batch 3] Current Loss: 5.2022\n",
            "[Batch 4] Current Loss: 5.2308\n",
            "[Batch 5] Current Loss: 5.4094\n",
            "[Batch 6] Current Loss: 5.3585\n",
            "[Batch 7] Current Loss: 5.2681\n",
            "[Batch 8] Current Loss: 5.3690\n",
            "[Batch 9] Current Loss: 4.9147\n",
            "Ep 3 (Step 019780): Train loss 3.287, Val loss 5.298\n",
            "[Batch 0] Current Loss: 3.0243\n",
            "[Batch 1] Current Loss: 3.3292\n",
            "[Batch 2] Current Loss: 2.4185\n",
            "[Batch 3] Current Loss: 3.6957\n",
            "[Batch 4] Current Loss: 2.1653\n",
            "[Batch 5] Current Loss: 2.9290\n",
            "[Batch 6] Current Loss: 3.3285\n",
            "[Batch 7] Current Loss: 2.7253\n",
            "[Batch 8] Current Loss: 2.9207\n",
            "[Batch 9] Current Loss: 3.7925\n",
            "[Batch 0] Current Loss: 5.9435\n",
            "[Batch 1] Current Loss: 5.6119\n",
            "[Batch 2] Current Loss: 5.1962\n",
            "[Batch 3] Current Loss: 4.9600\n",
            "[Batch 4] Current Loss: 4.8169\n",
            "[Batch 5] Current Loss: 5.5746\n",
            "[Batch 6] Current Loss: 5.6183\n",
            "[Batch 7] Current Loss: 4.9688\n",
            "[Batch 8] Current Loss: 5.5829\n",
            "[Batch 9] Current Loss: 4.8256\n",
            "Ep 3 (Step 019800): Train loss 3.033, Val loss 5.310\n",
            "[Batch 0] Current Loss: 2.7765\n",
            "[Batch 1] Current Loss: 2.0158\n",
            "[Batch 2] Current Loss: 3.4462\n",
            "[Batch 3] Current Loss: 2.8834\n",
            "[Batch 4] Current Loss: 3.1395\n",
            "[Batch 5] Current Loss: 3.8140\n",
            "[Batch 6] Current Loss: 3.2467\n",
            "[Batch 7] Current Loss: 2.8045\n",
            "[Batch 8] Current Loss: 2.4267\n",
            "[Batch 9] Current Loss: 3.0594\n",
            "[Batch 0] Current Loss: 5.3820\n",
            "[Batch 1] Current Loss: 5.1560\n",
            "[Batch 2] Current Loss: 5.0596\n",
            "[Batch 3] Current Loss: 4.7397\n",
            "[Batch 4] Current Loss: 5.7248\n",
            "[Batch 5] Current Loss: 5.0468\n",
            "[Batch 6] Current Loss: 5.5283\n",
            "[Batch 7] Current Loss: 6.0639\n",
            "[Batch 8] Current Loss: 5.7634\n",
            "[Batch 9] Current Loss: 5.3498\n",
            "Ep 3 (Step 019820): Train loss 2.961, Val loss 5.381\n",
            "[Batch 0] Current Loss: 2.7247\n",
            "[Batch 1] Current Loss: 3.1627\n",
            "[Batch 2] Current Loss: 3.2017\n",
            "[Batch 3] Current Loss: 3.0650\n",
            "[Batch 4] Current Loss: 2.7094\n",
            "[Batch 5] Current Loss: 3.1000\n",
            "[Batch 6] Current Loss: 3.1047\n",
            "[Batch 7] Current Loss: 3.1933\n",
            "[Batch 8] Current Loss: 2.1718\n",
            "[Batch 9] Current Loss: 2.8414\n",
            "[Batch 0] Current Loss: 5.4542\n",
            "[Batch 1] Current Loss: 4.8028\n",
            "[Batch 2] Current Loss: 4.9512\n",
            "[Batch 3] Current Loss: 5.2418\n",
            "[Batch 4] Current Loss: 5.5344\n",
            "[Batch 5] Current Loss: 5.4599\n",
            "[Batch 6] Current Loss: 5.6062\n",
            "[Batch 7] Current Loss: 5.2556\n",
            "[Batch 8] Current Loss: 4.9521\n",
            "[Batch 9] Current Loss: 5.1046\n",
            "Ep 3 (Step 019840): Train loss 2.927, Val loss 5.236\n",
            "[Batch 0] Current Loss: 3.3547\n",
            "[Batch 1] Current Loss: 3.4862\n",
            "[Batch 2] Current Loss: 2.7824\n",
            "[Batch 3] Current Loss: 2.9268\n",
            "[Batch 4] Current Loss: 3.6163\n",
            "[Batch 5] Current Loss: 2.8733\n",
            "[Batch 6] Current Loss: 3.0423\n",
            "[Batch 7] Current Loss: 2.7133\n",
            "[Batch 8] Current Loss: 3.0245\n",
            "[Batch 9] Current Loss: 3.1130\n",
            "[Batch 0] Current Loss: 4.6537\n",
            "[Batch 1] Current Loss: 5.0809\n",
            "[Batch 2] Current Loss: 5.4710\n",
            "[Batch 3] Current Loss: 4.9874\n",
            "[Batch 4] Current Loss: 5.7019\n",
            "[Batch 5] Current Loss: 5.5611\n",
            "[Batch 6] Current Loss: 4.4435\n",
            "[Batch 7] Current Loss: 5.4318\n",
            "[Batch 8] Current Loss: 5.3383\n",
            "[Batch 9] Current Loss: 4.9239\n",
            "Ep 3 (Step 019860): Train loss 3.093, Val loss 5.159\n",
            "[Batch 0] Current Loss: 3.3195\n",
            "[Batch 1] Current Loss: 3.4126\n",
            "[Batch 2] Current Loss: 3.3818\n",
            "[Batch 3] Current Loss: 2.6154\n",
            "[Batch 4] Current Loss: 3.3798\n",
            "[Batch 5] Current Loss: 3.5753\n",
            "[Batch 6] Current Loss: 3.7384\n",
            "[Batch 7] Current Loss: 3.6263\n",
            "[Batch 8] Current Loss: 3.3289\n",
            "[Batch 9] Current Loss: 2.7867\n",
            "[Batch 0] Current Loss: 5.2456\n",
            "[Batch 1] Current Loss: 5.8387\n",
            "[Batch 2] Current Loss: 4.9259\n",
            "[Batch 3] Current Loss: 4.9977\n",
            "[Batch 4] Current Loss: 4.8196\n",
            "[Batch 5] Current Loss: 5.3978\n",
            "[Batch 6] Current Loss: 5.2625\n",
            "[Batch 7] Current Loss: 5.0070\n",
            "[Batch 8] Current Loss: 4.2612\n",
            "[Batch 9] Current Loss: 5.4706\n",
            "Ep 3 (Step 019880): Train loss 3.316, Val loss 5.123\n",
            "[Batch 0] Current Loss: 2.6975\n",
            "[Batch 1] Current Loss: 3.0256\n",
            "[Batch 2] Current Loss: 3.5440\n",
            "[Batch 3] Current Loss: 2.7919\n",
            "[Batch 4] Current Loss: 3.7422\n",
            "[Batch 5] Current Loss: 2.7251\n",
            "[Batch 6] Current Loss: 3.1072\n",
            "[Batch 7] Current Loss: 3.3121\n",
            "[Batch 8] Current Loss: 3.2989\n",
            "[Batch 9] Current Loss: 3.3724\n",
            "[Batch 0] Current Loss: 4.7540\n",
            "[Batch 1] Current Loss: 4.2607\n",
            "[Batch 2] Current Loss: 5.5215\n",
            "[Batch 3] Current Loss: 5.5898\n",
            "[Batch 4] Current Loss: 5.8153\n",
            "[Batch 5] Current Loss: 5.4277\n",
            "[Batch 6] Current Loss: 5.5604\n",
            "[Batch 7] Current Loss: 5.8529\n",
            "[Batch 8] Current Loss: 4.5571\n",
            "[Batch 9] Current Loss: 4.8190\n",
            "Ep 3 (Step 019900): Train loss 3.162, Val loss 5.216\n",
            "[Batch 0] Current Loss: 3.1670\n",
            "[Batch 1] Current Loss: 3.6313\n",
            "[Batch 2] Current Loss: 3.8782\n",
            "[Batch 3] Current Loss: 3.5430\n",
            "[Batch 4] Current Loss: 2.9343\n",
            "[Batch 5] Current Loss: 3.7304\n",
            "[Batch 6] Current Loss: 3.9938\n",
            "[Batch 7] Current Loss: 3.2400\n",
            "[Batch 8] Current Loss: 3.6371\n",
            "[Batch 9] Current Loss: 2.9194\n",
            "[Batch 0] Current Loss: 5.0678\n",
            "[Batch 1] Current Loss: 5.0650\n",
            "[Batch 2] Current Loss: 5.2132\n",
            "[Batch 3] Current Loss: 4.1963\n",
            "[Batch 4] Current Loss: 5.5043\n",
            "[Batch 5] Current Loss: 5.7118\n",
            "[Batch 6] Current Loss: 5.3120\n",
            "[Batch 7] Current Loss: 6.2238\n",
            "[Batch 8] Current Loss: 5.0862\n",
            "[Batch 9] Current Loss: 5.5518\n",
            "Ep 3 (Step 019920): Train loss 3.467, Val loss 5.293\n",
            "[Batch 0] Current Loss: 3.7950\n",
            "[Batch 1] Current Loss: 3.2936\n",
            "[Batch 2] Current Loss: 3.2173\n",
            "[Batch 3] Current Loss: 3.1954\n",
            "[Batch 4] Current Loss: 3.3460\n",
            "[Batch 5] Current Loss: 3.3248\n",
            "[Batch 6] Current Loss: 3.7168\n",
            "[Batch 7] Current Loss: 2.8833\n",
            "[Batch 8] Current Loss: 3.0824\n",
            "[Batch 9] Current Loss: 3.4423\n",
            "[Batch 0] Current Loss: 4.7263\n",
            "[Batch 1] Current Loss: 5.4445\n",
            "[Batch 2] Current Loss: 5.8982\n",
            "[Batch 3] Current Loss: 5.3503\n",
            "[Batch 4] Current Loss: 5.7351\n",
            "[Batch 5] Current Loss: 5.5904\n",
            "[Batch 6] Current Loss: 5.4150\n",
            "[Batch 7] Current Loss: 4.9590\n",
            "[Batch 8] Current Loss: 3.9664\n",
            "[Batch 9] Current Loss: 5.8939\n",
            "Ep 3 (Step 019940): Train loss 3.330, Val loss 5.298\n",
            "[Batch 0] Current Loss: 3.5503\n",
            "[Batch 1] Current Loss: 2.9114\n",
            "[Batch 2] Current Loss: 3.4299\n",
            "[Batch 3] Current Loss: 2.1104\n",
            "[Batch 4] Current Loss: 3.7606\n",
            "[Batch 5] Current Loss: 2.3054\n",
            "[Batch 6] Current Loss: 3.4677\n",
            "[Batch 7] Current Loss: 3.1481\n",
            "[Batch 8] Current Loss: 3.2286\n",
            "[Batch 9] Current Loss: 3.2292\n",
            "[Batch 0] Current Loss: 5.4770\n",
            "[Batch 1] Current Loss: 4.9446\n",
            "[Batch 2] Current Loss: 5.1431\n",
            "[Batch 3] Current Loss: 4.7900\n",
            "[Batch 4] Current Loss: 5.3723\n",
            "[Batch 5] Current Loss: 4.8521\n",
            "[Batch 6] Current Loss: 5.3366\n",
            "[Batch 7] Current Loss: 5.1899\n",
            "[Batch 8] Current Loss: 4.7125\n",
            "[Batch 9] Current Loss: 4.9898\n",
            "Ep 3 (Step 019960): Train loss 3.114, Val loss 5.081\n",
            "[Batch 0] Current Loss: 3.2793\n",
            "[Batch 1] Current Loss: 3.5159\n",
            "[Batch 2] Current Loss: 3.1129\n",
            "[Batch 3] Current Loss: 3.0145\n",
            "[Batch 4] Current Loss: 2.9107\n",
            "[Batch 5] Current Loss: 2.6078\n",
            "[Batch 6] Current Loss: 2.8143\n",
            "[Batch 7] Current Loss: 3.9045\n",
            "[Batch 8] Current Loss: 3.0514\n",
            "[Batch 9] Current Loss: 3.0890\n",
            "[Batch 0] Current Loss: 5.9605\n",
            "[Batch 1] Current Loss: 5.7307\n",
            "[Batch 2] Current Loss: 6.3055\n",
            "[Batch 3] Current Loss: 5.3040\n",
            "[Batch 4] Current Loss: 5.3428\n",
            "[Batch 5] Current Loss: 5.8440\n",
            "[Batch 6] Current Loss: 4.9509\n",
            "[Batch 7] Current Loss: 5.0703\n",
            "[Batch 8] Current Loss: 5.7172\n",
            "[Batch 9] Current Loss: 4.9167\n",
            "Ep 3 (Step 019980): Train loss 3.130, Val loss 5.514\n",
            "[Batch 0] Current Loss: 2.8441\n",
            "[Batch 1] Current Loss: 2.7390\n",
            "[Batch 2] Current Loss: 2.5894\n",
            "[Batch 3] Current Loss: 3.2833\n",
            "[Batch 4] Current Loss: 2.4921\n",
            "[Batch 5] Current Loss: 3.3954\n",
            "[Batch 6] Current Loss: 3.2849\n",
            "[Batch 7] Current Loss: 3.3307\n",
            "[Batch 8] Current Loss: 2.9831\n",
            "[Batch 9] Current Loss: 2.7232\n",
            "[Batch 0] Current Loss: 5.0712\n",
            "[Batch 1] Current Loss: 5.8515\n",
            "[Batch 2] Current Loss: 4.6538\n",
            "[Batch 3] Current Loss: 4.7072\n",
            "[Batch 4] Current Loss: 5.6877\n",
            "[Batch 5] Current Loss: 5.1042\n",
            "[Batch 6] Current Loss: 5.4029\n",
            "[Batch 7] Current Loss: 5.3326\n",
            "[Batch 8] Current Loss: 5.8384\n",
            "[Batch 9] Current Loss: 4.6054\n",
            "Ep 3 (Step 020000): Train loss 2.967, Val loss 5.225\n",
            "[Batch 0] Current Loss: 3.1493\n",
            "[Batch 1] Current Loss: 3.4466\n",
            "[Batch 2] Current Loss: 3.2495\n",
            "[Batch 3] Current Loss: 3.1447\n",
            "[Batch 4] Current Loss: 3.1362\n",
            "[Batch 5] Current Loss: 2.9251\n",
            "[Batch 6] Current Loss: 2.9838\n",
            "[Batch 7] Current Loss: 3.1375\n",
            "[Batch 8] Current Loss: 3.2203\n",
            "[Batch 9] Current Loss: 2.9729\n",
            "[Batch 0] Current Loss: 5.8659\n",
            "[Batch 1] Current Loss: 4.8012\n",
            "[Batch 2] Current Loss: 4.7713\n",
            "[Batch 3] Current Loss: 5.3764\n",
            "[Batch 4] Current Loss: 5.2444\n",
            "[Batch 5] Current Loss: 5.3753\n",
            "[Batch 6] Current Loss: 5.9945\n",
            "[Batch 7] Current Loss: 5.3591\n",
            "[Batch 8] Current Loss: 5.2979\n",
            "[Batch 9] Current Loss: 5.7616\n",
            "Ep 3 (Step 020020): Train loss 3.137, Val loss 5.385\n",
            "[Batch 0] Current Loss: 3.1681\n",
            "[Batch 1] Current Loss: 3.2579\n",
            "[Batch 2] Current Loss: 3.6873\n",
            "[Batch 3] Current Loss: 3.6946\n",
            "[Batch 4] Current Loss: 3.7759\n",
            "[Batch 5] Current Loss: 3.2671\n",
            "[Batch 6] Current Loss: 2.6640\n",
            "[Batch 7] Current Loss: 3.6021\n",
            "[Batch 8] Current Loss: 3.4694\n",
            "[Batch 9] Current Loss: 3.6225\n",
            "[Batch 0] Current Loss: 5.6452\n",
            "[Batch 1] Current Loss: 5.6251\n",
            "[Batch 2] Current Loss: 5.6552\n",
            "[Batch 3] Current Loss: 5.5441\n",
            "[Batch 4] Current Loss: 5.0000\n",
            "[Batch 5] Current Loss: 5.3659\n",
            "[Batch 6] Current Loss: 5.5893\n",
            "[Batch 7] Current Loss: 5.4790\n",
            "[Batch 8] Current Loss: 5.0147\n",
            "[Batch 9] Current Loss: 5.2985\n",
            "Ep 3 (Step 020040): Train loss 3.421, Val loss 5.422\n",
            "[Batch 0] Current Loss: 2.8641\n",
            "[Batch 1] Current Loss: 3.1813\n",
            "[Batch 2] Current Loss: 2.9317\n",
            "[Batch 3] Current Loss: 3.4483\n",
            "[Batch 4] Current Loss: 3.5080\n",
            "[Batch 5] Current Loss: 3.6211\n",
            "[Batch 6] Current Loss: 2.7216\n",
            "[Batch 7] Current Loss: 3.5809\n",
            "[Batch 8] Current Loss: 2.9701\n",
            "[Batch 9] Current Loss: 3.3601\n",
            "[Batch 0] Current Loss: 5.1977\n",
            "[Batch 1] Current Loss: 5.7372\n",
            "[Batch 2] Current Loss: 4.4832\n",
            "[Batch 3] Current Loss: 6.1672\n",
            "[Batch 4] Current Loss: 4.3157\n",
            "[Batch 5] Current Loss: 5.8904\n",
            "[Batch 6] Current Loss: 5.0219\n",
            "[Batch 7] Current Loss: 5.2245\n",
            "[Batch 8] Current Loss: 4.9217\n",
            "[Batch 9] Current Loss: 5.1617\n",
            "Ep 3 (Step 020060): Train loss 3.219, Val loss 5.212\n",
            "[Batch 0] Current Loss: 3.9457\n",
            "[Batch 1] Current Loss: 2.8157\n",
            "[Batch 2] Current Loss: 2.7615\n",
            "[Batch 3] Current Loss: 2.4664\n",
            "[Batch 4] Current Loss: 3.4200\n",
            "[Batch 5] Current Loss: 3.0648\n",
            "[Batch 6] Current Loss: 3.3361\n",
            "[Batch 7] Current Loss: 3.2920\n",
            "[Batch 8] Current Loss: 3.6083\n",
            "[Batch 9] Current Loss: 2.2482\n",
            "[Batch 0] Current Loss: 5.4748\n",
            "[Batch 1] Current Loss: 5.1903\n",
            "[Batch 2] Current Loss: 5.5040\n",
            "[Batch 3] Current Loss: 5.1828\n",
            "[Batch 4] Current Loss: 4.9919\n",
            "[Batch 5] Current Loss: 5.2609\n",
            "[Batch 6] Current Loss: 5.7455\n",
            "[Batch 7] Current Loss: 4.7266\n",
            "[Batch 8] Current Loss: 4.9444\n",
            "[Batch 9] Current Loss: 5.4202\n",
            "Ep 3 (Step 020080): Train loss 3.096, Val loss 5.244\n",
            "[Batch 0] Current Loss: 2.9539\n",
            "[Batch 1] Current Loss: 2.8946\n",
            "[Batch 2] Current Loss: 3.6484\n",
            "[Batch 3] Current Loss: 3.7262\n",
            "[Batch 4] Current Loss: 2.7582\n",
            "[Batch 5] Current Loss: 3.3732\n",
            "[Batch 6] Current Loss: 3.2687\n",
            "[Batch 7] Current Loss: 3.0187\n",
            "[Batch 8] Current Loss: 2.8454\n",
            "[Batch 9] Current Loss: 4.0310\n",
            "[Batch 0] Current Loss: 5.4139\n",
            "[Batch 1] Current Loss: 5.3505\n",
            "[Batch 2] Current Loss: 4.6049\n",
            "[Batch 3] Current Loss: 5.7668\n",
            "[Batch 4] Current Loss: 5.1781\n",
            "[Batch 5] Current Loss: 5.2748\n",
            "[Batch 6] Current Loss: 4.9166\n",
            "[Batch 7] Current Loss: 5.3517\n",
            "[Batch 8] Current Loss: 4.9808\n",
            "[Batch 9] Current Loss: 5.5539\n",
            "Ep 3 (Step 020100): Train loss 3.252, Val loss 5.239\n",
            "[Batch 0] Current Loss: 3.1674\n",
            "[Batch 1] Current Loss: 3.3456\n",
            "[Batch 2] Current Loss: 3.0116\n",
            "[Batch 3] Current Loss: 2.7989\n",
            "[Batch 4] Current Loss: 2.6110\n",
            "[Batch 5] Current Loss: 3.2857\n",
            "[Batch 6] Current Loss: 4.2636\n",
            "[Batch 7] Current Loss: 2.6545\n",
            "[Batch 8] Current Loss: 3.1535\n",
            "[Batch 9] Current Loss: 3.6220\n",
            "[Batch 0] Current Loss: 5.4914\n",
            "[Batch 1] Current Loss: 5.5354\n",
            "[Batch 2] Current Loss: 5.0389\n",
            "[Batch 3] Current Loss: 5.1646\n",
            "[Batch 4] Current Loss: 5.0904\n",
            "[Batch 5] Current Loss: 4.7205\n",
            "[Batch 6] Current Loss: 5.2382\n",
            "[Batch 7] Current Loss: 5.2558\n",
            "[Batch 8] Current Loss: 4.7333\n",
            "[Batch 9] Current Loss: 5.7820\n",
            "Ep 3 (Step 020120): Train loss 3.191, Val loss 5.205\n",
            "[Batch 0] Current Loss: 3.2262\n",
            "[Batch 1] Current Loss: 2.9578\n",
            "[Batch 2] Current Loss: 3.0608\n",
            "[Batch 3] Current Loss: 3.2027\n",
            "[Batch 4] Current Loss: 2.9714\n",
            "[Batch 5] Current Loss: 2.8444\n",
            "[Batch 6] Current Loss: 2.7018\n",
            "[Batch 7] Current Loss: 3.7178\n",
            "[Batch 8] Current Loss: 3.5732\n",
            "[Batch 9] Current Loss: 2.5754\n",
            "[Batch 0] Current Loss: 5.9409\n",
            "[Batch 1] Current Loss: 5.8663\n",
            "[Batch 2] Current Loss: 5.4031\n",
            "[Batch 3] Current Loss: 4.5478\n",
            "[Batch 4] Current Loss: 5.7844\n",
            "[Batch 5] Current Loss: 5.4257\n",
            "[Batch 6] Current Loss: 5.1681\n",
            "[Batch 7] Current Loss: 5.8301\n",
            "[Batch 8] Current Loss: 5.5980\n",
            "[Batch 9] Current Loss: 4.7242\n",
            "Ep 3 (Step 020140): Train loss 3.083, Val loss 5.429\n",
            "[Batch 0] Current Loss: 3.0210\n",
            "[Batch 1] Current Loss: 2.2879\n",
            "[Batch 2] Current Loss: 3.3681\n",
            "[Batch 3] Current Loss: 3.3557\n",
            "[Batch 4] Current Loss: 3.4812\n",
            "[Batch 5] Current Loss: 3.0896\n",
            "[Batch 6] Current Loss: 3.0079\n",
            "[Batch 7] Current Loss: 2.7297\n",
            "[Batch 8] Current Loss: 2.8720\n",
            "[Batch 9] Current Loss: 3.4126\n",
            "[Batch 0] Current Loss: 4.9835\n",
            "[Batch 1] Current Loss: 6.0555\n",
            "[Batch 2] Current Loss: 5.2861\n",
            "[Batch 3] Current Loss: 5.5466\n",
            "[Batch 4] Current Loss: 5.2030\n",
            "[Batch 5] Current Loss: 5.8971\n",
            "[Batch 6] Current Loss: 5.5497\n",
            "[Batch 7] Current Loss: 5.6756\n",
            "[Batch 8] Current Loss: 5.3246\n",
            "[Batch 9] Current Loss: 5.0624\n",
            "Ep 3 (Step 020160): Train loss 3.063, Val loss 5.458\n",
            "[Batch 0] Current Loss: 3.4637\n",
            "[Batch 1] Current Loss: 3.0528\n",
            "[Batch 2] Current Loss: 2.8566\n",
            "[Batch 3] Current Loss: 2.5265\n",
            "[Batch 4] Current Loss: 3.8721\n",
            "[Batch 5] Current Loss: 2.5511\n",
            "[Batch 6] Current Loss: 3.0715\n",
            "[Batch 7] Current Loss: 3.0653\n",
            "[Batch 8] Current Loss: 2.5300\n",
            "[Batch 9] Current Loss: 3.1064\n",
            "[Batch 0] Current Loss: 5.2477\n",
            "[Batch 1] Current Loss: 5.5632\n",
            "[Batch 2] Current Loss: 5.1544\n",
            "[Batch 3] Current Loss: 5.7135\n",
            "[Batch 4] Current Loss: 5.0851\n",
            "[Batch 5] Current Loss: 4.9761\n",
            "[Batch 6] Current Loss: 6.0290\n",
            "[Batch 7] Current Loss: 5.5795\n",
            "[Batch 8] Current Loss: 5.1474\n",
            "[Batch 9] Current Loss: 5.2374\n",
            "Ep 3 (Step 020180): Train loss 3.010, Val loss 5.373\n",
            "[Batch 0] Current Loss: 3.5757\n",
            "[Batch 1] Current Loss: 2.9496\n",
            "[Batch 2] Current Loss: 3.3353\n",
            "[Batch 3] Current Loss: 3.4644\n",
            "[Batch 4] Current Loss: 3.6746\n",
            "[Batch 5] Current Loss: 2.8718\n",
            "[Batch 6] Current Loss: 2.8632\n",
            "[Batch 7] Current Loss: 3.7944\n",
            "[Batch 8] Current Loss: 2.8026\n",
            "[Batch 9] Current Loss: 3.4383\n",
            "[Batch 0] Current Loss: 5.5272\n",
            "[Batch 1] Current Loss: 5.0707\n",
            "[Batch 2] Current Loss: 4.9780\n",
            "[Batch 3] Current Loss: 4.6027\n",
            "[Batch 4] Current Loss: 5.9318\n",
            "[Batch 5] Current Loss: 5.9417\n",
            "[Batch 6] Current Loss: 5.2760\n",
            "[Batch 7] Current Loss: 4.6781\n",
            "[Batch 8] Current Loss: 4.7769\n",
            "[Batch 9] Current Loss: 5.8850\n",
            "Ep 3 (Step 020200): Train loss 3.277, Val loss 5.267\n",
            "[Batch 0] Current Loss: 2.9483\n",
            "[Batch 1] Current Loss: 2.9970\n",
            "[Batch 2] Current Loss: 3.0167\n",
            "[Batch 3] Current Loss: 2.8070\n",
            "[Batch 4] Current Loss: 3.1409\n",
            "[Batch 5] Current Loss: 3.2582\n",
            "[Batch 6] Current Loss: 3.1257\n",
            "[Batch 7] Current Loss: 3.0173\n",
            "[Batch 8] Current Loss: 4.0203\n",
            "[Batch 9] Current Loss: 4.2761\n",
            "[Batch 0] Current Loss: 4.8545\n",
            "[Batch 1] Current Loss: 5.2276\n",
            "[Batch 2] Current Loss: 4.8269\n",
            "[Batch 3] Current Loss: 5.9117\n",
            "[Batch 4] Current Loss: 5.6506\n",
            "[Batch 5] Current Loss: 6.0424\n",
            "[Batch 6] Current Loss: 5.4550\n",
            "[Batch 7] Current Loss: 5.2595\n",
            "[Batch 8] Current Loss: 4.9060\n",
            "[Batch 9] Current Loss: 5.9000\n",
            "Ep 3 (Step 020220): Train loss 3.261, Val loss 5.403\n",
            "[Batch 0] Current Loss: 3.6193\n",
            "[Batch 1] Current Loss: 3.0473\n",
            "[Batch 2] Current Loss: 3.2051\n",
            "[Batch 3] Current Loss: 3.6591\n",
            "[Batch 4] Current Loss: 3.0280\n",
            "[Batch 5] Current Loss: 3.1216\n",
            "[Batch 6] Current Loss: 2.9743\n",
            "[Batch 7] Current Loss: 3.2005\n",
            "[Batch 8] Current Loss: 3.2809\n",
            "[Batch 9] Current Loss: 3.3502\n",
            "[Batch 0] Current Loss: 5.5691\n",
            "[Batch 1] Current Loss: 5.4784\n",
            "[Batch 2] Current Loss: 5.2895\n",
            "[Batch 3] Current Loss: 5.9346\n",
            "[Batch 4] Current Loss: 5.3651\n",
            "[Batch 5] Current Loss: 5.3302\n",
            "[Batch 6] Current Loss: 5.5995\n",
            "[Batch 7] Current Loss: 5.7549\n",
            "[Batch 8] Current Loss: 5.6770\n",
            "[Batch 9] Current Loss: 5.9955\n",
            "Ep 3 (Step 020240): Train loss 3.249, Val loss 5.599\n",
            "[Batch 0] Current Loss: 3.1618\n",
            "[Batch 1] Current Loss: 2.8390\n",
            "[Batch 2] Current Loss: 3.5775\n",
            "[Batch 3] Current Loss: 2.5712\n",
            "[Batch 4] Current Loss: 3.1136\n",
            "[Batch 5] Current Loss: 2.5430\n",
            "[Batch 6] Current Loss: 3.1940\n",
            "[Batch 7] Current Loss: 3.0036\n",
            "[Batch 8] Current Loss: 2.9531\n",
            "[Batch 9] Current Loss: 2.4630\n",
            "[Batch 0] Current Loss: 5.8553\n",
            "[Batch 1] Current Loss: 5.4580\n",
            "[Batch 2] Current Loss: 5.7530\n",
            "[Batch 3] Current Loss: 4.9025\n",
            "[Batch 4] Current Loss: 5.0410\n",
            "[Batch 5] Current Loss: 4.7932\n",
            "[Batch 6] Current Loss: 5.5190\n",
            "[Batch 7] Current Loss: 5.0157\n",
            "[Batch 8] Current Loss: 5.5291\n",
            "[Batch 9] Current Loss: 5.3262\n",
            "Ep 3 (Step 020260): Train loss 2.942, Val loss 5.319\n",
            "[Batch 0] Current Loss: 3.6020\n",
            "[Batch 1] Current Loss: 3.0471\n",
            "[Batch 2] Current Loss: 3.6630\n",
            "[Batch 3] Current Loss: 3.5864\n",
            "[Batch 4] Current Loss: 3.0090\n",
            "[Batch 5] Current Loss: 3.5770\n",
            "[Batch 6] Current Loss: 3.1839\n",
            "[Batch 7] Current Loss: 2.9123\n",
            "[Batch 8] Current Loss: 3.4113\n",
            "[Batch 9] Current Loss: 3.3343\n",
            "[Batch 0] Current Loss: 5.6424\n",
            "[Batch 1] Current Loss: 5.1378\n",
            "[Batch 2] Current Loss: 5.5594\n",
            "[Batch 3] Current Loss: 4.8205\n",
            "[Batch 4] Current Loss: 4.5846\n",
            "[Batch 5] Current Loss: 5.4085\n",
            "[Batch 6] Current Loss: 5.5583\n",
            "[Batch 7] Current Loss: 4.9311\n",
            "[Batch 8] Current Loss: 5.5013\n",
            "[Batch 9] Current Loss: 4.9677\n",
            "Ep 3 (Step 020280): Train loss 3.333, Val loss 5.211\n",
            "[Batch 0] Current Loss: 3.1280\n",
            "[Batch 1] Current Loss: 3.3698\n",
            "[Batch 2] Current Loss: 3.3587\n",
            "[Batch 3] Current Loss: 3.2155\n",
            "[Batch 4] Current Loss: 3.2030\n",
            "[Batch 5] Current Loss: 3.4360\n",
            "[Batch 6] Current Loss: 3.9223\n",
            "[Batch 7] Current Loss: 3.1270\n",
            "[Batch 8] Current Loss: 3.2334\n",
            "[Batch 9] Current Loss: 3.2465\n",
            "[Batch 0] Current Loss: 5.1033\n",
            "[Batch 1] Current Loss: 5.9145\n",
            "[Batch 2] Current Loss: 6.3914\n",
            "[Batch 3] Current Loss: 5.9754\n",
            "[Batch 4] Current Loss: 5.6206\n",
            "[Batch 5] Current Loss: 4.3735\n",
            "[Batch 6] Current Loss: 5.3759\n",
            "[Batch 7] Current Loss: 4.9585\n",
            "[Batch 8] Current Loss: 5.1571\n",
            "[Batch 9] Current Loss: 5.1808\n",
            "Ep 3 (Step 020300): Train loss 3.324, Val loss 5.405\n",
            "[Batch 0] Current Loss: 2.9955\n",
            "[Batch 1] Current Loss: 3.9842\n",
            "[Batch 2] Current Loss: 2.8946\n",
            "[Batch 3] Current Loss: 3.3407\n",
            "[Batch 4] Current Loss: 3.1508\n",
            "[Batch 5] Current Loss: 3.5571\n",
            "[Batch 6] Current Loss: 3.7091\n",
            "[Batch 7] Current Loss: 3.4956\n",
            "[Batch 8] Current Loss: 4.2367\n",
            "[Batch 9] Current Loss: 2.8126\n",
            "[Batch 0] Current Loss: 5.1463\n",
            "[Batch 1] Current Loss: 5.7688\n",
            "[Batch 2] Current Loss: 6.1806\n",
            "[Batch 3] Current Loss: 4.9779\n",
            "[Batch 4] Current Loss: 4.5994\n",
            "[Batch 5] Current Loss: 4.3579\n",
            "[Batch 6] Current Loss: 5.0665\n",
            "[Batch 7] Current Loss: 5.6290\n",
            "[Batch 8] Current Loss: 5.0124\n",
            "[Batch 9] Current Loss: 4.9512\n",
            "Ep 3 (Step 020320): Train loss 3.418, Val loss 5.169\n",
            "[Batch 0] Current Loss: 3.2782\n",
            "[Batch 1] Current Loss: 3.4127\n",
            "[Batch 2] Current Loss: 3.5388\n",
            "[Batch 3] Current Loss: 2.4390\n",
            "[Batch 4] Current Loss: 3.5438\n",
            "[Batch 5] Current Loss: 2.4271\n",
            "[Batch 6] Current Loss: 3.3680\n",
            "[Batch 7] Current Loss: 3.4095\n",
            "[Batch 8] Current Loss: 3.4530\n",
            "[Batch 9] Current Loss: 3.1459\n",
            "[Batch 0] Current Loss: 5.4242\n",
            "[Batch 1] Current Loss: 5.0880\n",
            "[Batch 2] Current Loss: 4.9920\n",
            "[Batch 3] Current Loss: 4.8251\n",
            "[Batch 4] Current Loss: 4.8611\n",
            "[Batch 5] Current Loss: 4.9618\n",
            "[Batch 6] Current Loss: 5.1795\n",
            "[Batch 7] Current Loss: 5.0765\n",
            "[Batch 8] Current Loss: 4.9694\n",
            "[Batch 9] Current Loss: 5.9151\n",
            "Ep 3 (Step 020340): Train loss 3.202, Val loss 5.129\n",
            "[Batch 0] Current Loss: 3.8314\n",
            "[Batch 1] Current Loss: 2.9471\n",
            "[Batch 2] Current Loss: 2.9764\n",
            "[Batch 3] Current Loss: 2.7090\n",
            "[Batch 4] Current Loss: 3.2147\n",
            "[Batch 5] Current Loss: 3.4775\n",
            "[Batch 6] Current Loss: 3.0240\n",
            "[Batch 7] Current Loss: 2.2020\n",
            "[Batch 8] Current Loss: 2.9200\n",
            "[Batch 9] Current Loss: 3.1836\n",
            "[Batch 0] Current Loss: 4.7084\n",
            "[Batch 1] Current Loss: 5.4327\n",
            "[Batch 2] Current Loss: 4.6775\n",
            "[Batch 3] Current Loss: 5.0070\n",
            "[Batch 4] Current Loss: 5.6130\n",
            "[Batch 5] Current Loss: 5.5575\n",
            "[Batch 6] Current Loss: 4.9488\n",
            "[Batch 7] Current Loss: 5.0075\n",
            "[Batch 8] Current Loss: 5.7961\n",
            "[Batch 9] Current Loss: 6.0446\n",
            "Ep 3 (Step 020360): Train loss 3.049, Val loss 5.279\n",
            "[Batch 0] Current Loss: 3.5621\n",
            "[Batch 1] Current Loss: 3.1668\n",
            "[Batch 2] Current Loss: 2.6807\n",
            "[Batch 3] Current Loss: 3.6772\n",
            "[Batch 4] Current Loss: 3.5263\n",
            "[Batch 5] Current Loss: 3.7025\n",
            "[Batch 6] Current Loss: 2.6002\n",
            "[Batch 7] Current Loss: 2.6765\n",
            "[Batch 8] Current Loss: 2.9768\n",
            "[Batch 9] Current Loss: 3.6223\n",
            "[Batch 0] Current Loss: 5.0156\n",
            "[Batch 1] Current Loss: 5.2641\n",
            "[Batch 2] Current Loss: 5.6623\n",
            "[Batch 3] Current Loss: 4.8163\n",
            "[Batch 4] Current Loss: 5.4757\n",
            "[Batch 5] Current Loss: 5.0561\n",
            "[Batch 6] Current Loss: 5.2365\n",
            "[Batch 7] Current Loss: 5.0505\n",
            "[Batch 8] Current Loss: 4.5294\n",
            "[Batch 9] Current Loss: 5.0634\n",
            "Ep 3 (Step 020380): Train loss 3.219, Val loss 5.117\n",
            "[Batch 0] Current Loss: 3.3495\n",
            "[Batch 1] Current Loss: 3.5453\n",
            "[Batch 2] Current Loss: 2.9398\n",
            "[Batch 3] Current Loss: 2.9166\n",
            "[Batch 4] Current Loss: 3.5940\n",
            "[Batch 5] Current Loss: 3.3315\n",
            "[Batch 6] Current Loss: 3.5507\n",
            "[Batch 7] Current Loss: 3.1290\n",
            "[Batch 8] Current Loss: 2.5338\n",
            "[Batch 9] Current Loss: 3.4181\n",
            "[Batch 0] Current Loss: 4.5245\n",
            "[Batch 1] Current Loss: 5.4583\n",
            "[Batch 2] Current Loss: 5.4324\n",
            "[Batch 3] Current Loss: 5.1105\n",
            "[Batch 4] Current Loss: 5.7203\n",
            "[Batch 5] Current Loss: 5.6690\n",
            "[Batch 6] Current Loss: 5.3463\n",
            "[Batch 7] Current Loss: 5.1074\n",
            "[Batch 8] Current Loss: 5.4719\n",
            "[Batch 9] Current Loss: 5.0461\n",
            "Ep 3 (Step 020400): Train loss 3.231, Val loss 5.289\n",
            "[Batch 0] Current Loss: 2.7745\n",
            "[Batch 1] Current Loss: 2.9711\n",
            "[Batch 2] Current Loss: 3.0747\n",
            "[Batch 3] Current Loss: 3.1445\n",
            "[Batch 4] Current Loss: 2.9994\n",
            "[Batch 5] Current Loss: 3.5340\n",
            "[Batch 6] Current Loss: 3.1644\n",
            "[Batch 7] Current Loss: 3.2093\n",
            "[Batch 8] Current Loss: 2.9660\n",
            "[Batch 9] Current Loss: 2.9654\n",
            "[Batch 0] Current Loss: 5.3811\n",
            "[Batch 1] Current Loss: 5.2965\n",
            "[Batch 2] Current Loss: 5.1333\n",
            "[Batch 3] Current Loss: 4.6087\n",
            "[Batch 4] Current Loss: 5.1686\n",
            "[Batch 5] Current Loss: 4.7990\n",
            "[Batch 6] Current Loss: 5.0742\n",
            "[Batch 7] Current Loss: 5.4475\n",
            "[Batch 8] Current Loss: 5.1077\n",
            "[Batch 9] Current Loss: 5.5675\n",
            "Ep 3 (Step 020420): Train loss 3.080, Val loss 5.158\n",
            "[Batch 0] Current Loss: 3.2567\n",
            "[Batch 1] Current Loss: 3.6662\n",
            "[Batch 2] Current Loss: 3.3477\n",
            "[Batch 3] Current Loss: 3.9461\n",
            "[Batch 4] Current Loss: 3.0299\n",
            "[Batch 5] Current Loss: 3.8887\n",
            "[Batch 6] Current Loss: 3.1058\n",
            "[Batch 7] Current Loss: 2.9674\n",
            "[Batch 8] Current Loss: 3.3988\n",
            "[Batch 9] Current Loss: 3.1450\n",
            "[Batch 0] Current Loss: 4.8954\n",
            "[Batch 1] Current Loss: 4.2464\n",
            "[Batch 2] Current Loss: 4.7857\n",
            "[Batch 3] Current Loss: 5.2050\n",
            "[Batch 4] Current Loss: 5.3906\n",
            "[Batch 5] Current Loss: 6.2142\n",
            "[Batch 6] Current Loss: 5.1488\n",
            "[Batch 7] Current Loss: 5.3456\n",
            "[Batch 8] Current Loss: 5.8307\n",
            "[Batch 9] Current Loss: 5.7047\n",
            "Ep 3 (Step 020440): Train loss 3.375, Val loss 5.277\n",
            "[Batch 0] Current Loss: 2.5926\n",
            "[Batch 1] Current Loss: 2.9260\n",
            "[Batch 2] Current Loss: 3.4773\n",
            "[Batch 3] Current Loss: 3.6073\n",
            "[Batch 4] Current Loss: 2.4131\n",
            "[Batch 5] Current Loss: 3.0760\n",
            "[Batch 6] Current Loss: 3.0486\n",
            "[Batch 7] Current Loss: 3.6064\n",
            "[Batch 8] Current Loss: 2.3823\n",
            "[Batch 9] Current Loss: 3.3341\n",
            "[Batch 0] Current Loss: 5.4897\n",
            "[Batch 1] Current Loss: 5.7017\n",
            "[Batch 2] Current Loss: 4.9178\n",
            "[Batch 3] Current Loss: 5.1863\n",
            "[Batch 4] Current Loss: 5.6591\n",
            "[Batch 5] Current Loss: 6.3617\n",
            "[Batch 6] Current Loss: 5.7664\n",
            "[Batch 7] Current Loss: 5.3849\n",
            "[Batch 8] Current Loss: 5.3397\n",
            "[Batch 9] Current Loss: 4.8943\n",
            "Ep 3 (Step 020460): Train loss 3.046, Val loss 5.470\n",
            "[Batch 0] Current Loss: 3.1037\n",
            "[Batch 1] Current Loss: 2.5460\n",
            "[Batch 2] Current Loss: 3.4999\n",
            "[Batch 3] Current Loss: 2.8263\n",
            "[Batch 4] Current Loss: 3.1256\n",
            "[Batch 5] Current Loss: 3.2199\n",
            "[Batch 6] Current Loss: 3.3922\n",
            "[Batch 7] Current Loss: 2.7289\n",
            "[Batch 8] Current Loss: 3.1604\n",
            "[Batch 9] Current Loss: 2.9966\n",
            "[Batch 0] Current Loss: 5.4956\n",
            "[Batch 1] Current Loss: 5.6069\n",
            "[Batch 2] Current Loss: 4.7236\n",
            "[Batch 3] Current Loss: 5.8214\n",
            "[Batch 4] Current Loss: 5.6234\n",
            "[Batch 5] Current Loss: 5.6237\n",
            "[Batch 6] Current Loss: 5.0434\n",
            "[Batch 7] Current Loss: 5.2920\n",
            "[Batch 8] Current Loss: 4.9005\n",
            "[Batch 9] Current Loss: 5.1406\n",
            "Ep 3 (Step 020480): Train loss 3.060, Val loss 5.327\n",
            "[Batch 0] Current Loss: 3.4530\n",
            "[Batch 1] Current Loss: 2.6894\n",
            "[Batch 2] Current Loss: 2.9300\n",
            "[Batch 3] Current Loss: 3.1269\n",
            "[Batch 4] Current Loss: 3.2480\n",
            "[Batch 5] Current Loss: 3.7684\n",
            "[Batch 6] Current Loss: 3.2913\n",
            "[Batch 7] Current Loss: 3.5483\n",
            "[Batch 8] Current Loss: 3.4326\n",
            "[Batch 9] Current Loss: 2.5740\n",
            "[Batch 0] Current Loss: 4.9354\n",
            "[Batch 1] Current Loss: 5.6041\n",
            "[Batch 2] Current Loss: 5.0828\n",
            "[Batch 3] Current Loss: 5.6330\n",
            "[Batch 4] Current Loss: 5.4234\n",
            "[Batch 5] Current Loss: 5.4378\n",
            "[Batch 6] Current Loss: 4.7790\n",
            "[Batch 7] Current Loss: 5.2691\n",
            "[Batch 8] Current Loss: 5.6606\n",
            "[Batch 9] Current Loss: 5.5274\n",
            "Ep 3 (Step 020500): Train loss 3.206, Val loss 5.335\n",
            "[Batch 0] Current Loss: 2.7167\n",
            "[Batch 1] Current Loss: 3.1724\n",
            "[Batch 2] Current Loss: 3.4072\n",
            "[Batch 3] Current Loss: 3.3342\n",
            "[Batch 4] Current Loss: 3.2566\n",
            "[Batch 5] Current Loss: 2.9591\n",
            "[Batch 6] Current Loss: 2.6082\n",
            "[Batch 7] Current Loss: 3.3863\n",
            "[Batch 8] Current Loss: 3.3214\n",
            "[Batch 9] Current Loss: 3.4647\n",
            "[Batch 0] Current Loss: 5.0117\n",
            "[Batch 1] Current Loss: 5.4389\n",
            "[Batch 2] Current Loss: 6.3862\n",
            "[Batch 3] Current Loss: 4.5476\n",
            "[Batch 4] Current Loss: 5.7096\n",
            "[Batch 5] Current Loss: 5.2553\n",
            "[Batch 6] Current Loss: 4.3383\n",
            "[Batch 7] Current Loss: 5.5119\n",
            "[Batch 8] Current Loss: 5.0715\n",
            "[Batch 9] Current Loss: 5.4864\n",
            "Ep 3 (Step 020520): Train loss 3.163, Val loss 5.276\n",
            "[Batch 0] Current Loss: 2.8112\n",
            "[Batch 1] Current Loss: 2.3519\n",
            "[Batch 2] Current Loss: 3.5384\n",
            "[Batch 3] Current Loss: 2.7385\n",
            "[Batch 4] Current Loss: 2.9555\n",
            "[Batch 5] Current Loss: 3.2089\n",
            "[Batch 6] Current Loss: 2.9077\n",
            "[Batch 7] Current Loss: 2.7679\n",
            "[Batch 8] Current Loss: 3.4215\n",
            "[Batch 9] Current Loss: 3.5236\n",
            "[Batch 0] Current Loss: 5.6517\n",
            "[Batch 1] Current Loss: 5.2021\n",
            "[Batch 2] Current Loss: 5.3394\n",
            "[Batch 3] Current Loss: 4.9291\n",
            "[Batch 4] Current Loss: 4.7253\n",
            "[Batch 5] Current Loss: 5.5295\n",
            "[Batch 6] Current Loss: 5.2864\n",
            "[Batch 7] Current Loss: 5.4492\n",
            "[Batch 8] Current Loss: 5.0316\n",
            "[Batch 9] Current Loss: 5.0899\n",
            "Ep 3 (Step 020540): Train loss 3.023, Val loss 5.223\n",
            "[Batch 0] Current Loss: 2.3030\n",
            "[Batch 1] Current Loss: 2.9636\n",
            "[Batch 2] Current Loss: 3.1776\n",
            "[Batch 3] Current Loss: 2.8596\n",
            "[Batch 4] Current Loss: 3.1600\n",
            "[Batch 5] Current Loss: 3.2953\n",
            "[Batch 6] Current Loss: 2.7390\n",
            "[Batch 7] Current Loss: 3.4604\n",
            "[Batch 8] Current Loss: 3.1804\n",
            "[Batch 9] Current Loss: 3.4097\n",
            "[Batch 0] Current Loss: 5.0402\n",
            "[Batch 1] Current Loss: 4.3659\n",
            "[Batch 2] Current Loss: 4.8700\n",
            "[Batch 3] Current Loss: 4.9730\n",
            "[Batch 4] Current Loss: 5.4091\n",
            "[Batch 5] Current Loss: 5.0956\n",
            "[Batch 6] Current Loss: 4.6071\n",
            "[Batch 7] Current Loss: 4.7076\n",
            "[Batch 8] Current Loss: 5.4585\n",
            "[Batch 9] Current Loss: 6.3640\n",
            "Ep 3 (Step 020560): Train loss 3.055, Val loss 5.089\n",
            "[Batch 0] Current Loss: 2.9402\n",
            "[Batch 1] Current Loss: 2.7097\n",
            "[Batch 2] Current Loss: 2.4920\n",
            "[Batch 3] Current Loss: 2.9155\n",
            "[Batch 4] Current Loss: 2.8946\n",
            "[Batch 5] Current Loss: 2.8675\n",
            "[Batch 6] Current Loss: 3.1353\n",
            "[Batch 7] Current Loss: 3.0638\n",
            "[Batch 8] Current Loss: 2.8493\n",
            "[Batch 9] Current Loss: 3.2161\n",
            "[Batch 0] Current Loss: 5.1500\n",
            "[Batch 1] Current Loss: 5.5729\n",
            "[Batch 2] Current Loss: 5.8740\n",
            "[Batch 3] Current Loss: 5.1742\n",
            "[Batch 4] Current Loss: 5.7321\n",
            "[Batch 5] Current Loss: 5.6058\n",
            "[Batch 6] Current Loss: 5.1899\n",
            "[Batch 7] Current Loss: 5.3752\n",
            "[Batch 8] Current Loss: 5.5330\n",
            "[Batch 9] Current Loss: 5.1419\n",
            "Ep 3 (Step 020580): Train loss 2.908, Val loss 5.435\n",
            "[Batch 0] Current Loss: 3.0996\n",
            "[Batch 1] Current Loss: 3.4860\n",
            "[Batch 2] Current Loss: 3.0122\n",
            "[Batch 3] Current Loss: 2.5632\n",
            "[Batch 4] Current Loss: 3.2577\n",
            "[Batch 5] Current Loss: 2.6132\n",
            "[Batch 6] Current Loss: 3.3303\n",
            "[Batch 7] Current Loss: 3.5232\n",
            "[Batch 8] Current Loss: 3.1059\n",
            "[Batch 9] Current Loss: 2.4638\n",
            "[Batch 0] Current Loss: 5.2039\n",
            "[Batch 1] Current Loss: 4.7723\n",
            "[Batch 2] Current Loss: 4.8382\n",
            "[Batch 3] Current Loss: 4.7583\n",
            "[Batch 4] Current Loss: 5.3511\n",
            "[Batch 5] Current Loss: 5.2170\n",
            "[Batch 6] Current Loss: 4.4281\n",
            "[Batch 7] Current Loss: 5.5374\n",
            "[Batch 8] Current Loss: 5.1274\n",
            "[Batch 9] Current Loss: 5.4494\n",
            "Ep 3 (Step 020600): Train loss 3.046, Val loss 5.068\n",
            "[Batch 0] Current Loss: 3.0771\n",
            "[Batch 1] Current Loss: 2.9764\n",
            "[Batch 2] Current Loss: 2.6655\n",
            "[Batch 3] Current Loss: 3.1888\n",
            "[Batch 4] Current Loss: 3.8345\n",
            "[Batch 5] Current Loss: 3.3597\n",
            "[Batch 6] Current Loss: 2.9792\n",
            "[Batch 7] Current Loss: 2.3144\n",
            "[Batch 8] Current Loss: 2.5556\n",
            "[Batch 9] Current Loss: 2.8889\n",
            "[Batch 0] Current Loss: 5.8463\n",
            "[Batch 1] Current Loss: 5.5968\n",
            "[Batch 2] Current Loss: 5.4638\n",
            "[Batch 3] Current Loss: 5.3704\n",
            "[Batch 4] Current Loss: 5.0751\n",
            "[Batch 5] Current Loss: 5.4307\n",
            "[Batch 6] Current Loss: 5.6527\n",
            "[Batch 7] Current Loss: 4.9648\n",
            "[Batch 8] Current Loss: 4.9140\n",
            "[Batch 9] Current Loss: 5.3394\n",
            "Ep 3 (Step 020620): Train loss 2.984, Val loss 5.365\n",
            "[Batch 0] Current Loss: 2.8519\n",
            "[Batch 1] Current Loss: 2.4781\n",
            "[Batch 2] Current Loss: 3.3156\n",
            "[Batch 3] Current Loss: 2.9278\n",
            "[Batch 4] Current Loss: 3.2480\n",
            "[Batch 5] Current Loss: 2.8795\n",
            "[Batch 6] Current Loss: 3.1395\n",
            "[Batch 7] Current Loss: 3.2665\n",
            "[Batch 8] Current Loss: 3.2946\n",
            "[Batch 9] Current Loss: 2.7690\n",
            "[Batch 0] Current Loss: 5.1597\n",
            "[Batch 1] Current Loss: 4.8066\n",
            "[Batch 2] Current Loss: 5.7175\n",
            "[Batch 3] Current Loss: 5.3955\n",
            "[Batch 4] Current Loss: 4.9710\n",
            "[Batch 5] Current Loss: 5.4852\n",
            "[Batch 6] Current Loss: 5.7055\n",
            "[Batch 7] Current Loss: 5.3415\n",
            "[Batch 8] Current Loss: 5.6149\n",
            "[Batch 9] Current Loss: 5.4545\n",
            "Ep 3 (Step 020640): Train loss 3.017, Val loss 5.365\n",
            "[Batch 0] Current Loss: 3.1954\n",
            "[Batch 1] Current Loss: 2.9587\n",
            "[Batch 2] Current Loss: 2.9810\n",
            "[Batch 3] Current Loss: 3.1805\n",
            "[Batch 4] Current Loss: 2.8724\n",
            "[Batch 5] Current Loss: 2.8985\n",
            "[Batch 6] Current Loss: 2.4939\n",
            "[Batch 7] Current Loss: 3.2727\n",
            "[Batch 8] Current Loss: 2.3985\n",
            "[Batch 9] Current Loss: 3.2177\n",
            "[Batch 0] Current Loss: 5.1801\n",
            "[Batch 1] Current Loss: 5.3699\n",
            "[Batch 2] Current Loss: 5.6684\n",
            "[Batch 3] Current Loss: 4.9827\n",
            "[Batch 4] Current Loss: 5.7407\n",
            "[Batch 5] Current Loss: 5.3293\n",
            "[Batch 6] Current Loss: 4.6907\n",
            "[Batch 7] Current Loss: 5.3444\n",
            "[Batch 8] Current Loss: 4.5394\n",
            "[Batch 9] Current Loss: 5.7901\n",
            "Ep 3 (Step 020660): Train loss 2.947, Val loss 5.264\n",
            "[Batch 0] Current Loss: 2.4629\n",
            "[Batch 1] Current Loss: 3.2331\n",
            "[Batch 2] Current Loss: 3.4927\n",
            "[Batch 3] Current Loss: 3.1903\n",
            "[Batch 4] Current Loss: 2.9909\n",
            "[Batch 5] Current Loss: 3.3608\n",
            "[Batch 6] Current Loss: 3.1193\n",
            "[Batch 7] Current Loss: 3.1155\n",
            "[Batch 8] Current Loss: 2.9217\n",
            "[Batch 9] Current Loss: 3.1958\n",
            "[Batch 0] Current Loss: 5.0415\n",
            "[Batch 1] Current Loss: 5.2050\n",
            "[Batch 2] Current Loss: 5.4206\n",
            "[Batch 3] Current Loss: 5.0938\n",
            "[Batch 4] Current Loss: 4.7562\n",
            "[Batch 5] Current Loss: 5.7704\n",
            "[Batch 6] Current Loss: 5.1961\n",
            "[Batch 7] Current Loss: 5.4409\n",
            "[Batch 8] Current Loss: 5.3353\n",
            "[Batch 9] Current Loss: 4.6477\n",
            "Ep 3 (Step 020680): Train loss 3.108, Val loss 5.191\n",
            "[Batch 0] Current Loss: 2.8932\n",
            "[Batch 1] Current Loss: 3.8929\n",
            "[Batch 2] Current Loss: 3.6230\n",
            "[Batch 3] Current Loss: 3.7768\n",
            "[Batch 4] Current Loss: 2.9517\n",
            "[Batch 5] Current Loss: 2.7719\n",
            "[Batch 6] Current Loss: 3.6367\n",
            "[Batch 7] Current Loss: 3.0092\n",
            "[Batch 8] Current Loss: 3.1783\n",
            "[Batch 9] Current Loss: 2.9053\n",
            "[Batch 0] Current Loss: 5.8023\n",
            "[Batch 1] Current Loss: 5.5485\n",
            "[Batch 2] Current Loss: 6.1061\n",
            "[Batch 3] Current Loss: 5.2614\n",
            "[Batch 4] Current Loss: 4.9934\n",
            "[Batch 5] Current Loss: 4.6711\n",
            "[Batch 6] Current Loss: 5.3657\n",
            "[Batch 7] Current Loss: 5.1207\n",
            "[Batch 8] Current Loss: 4.8256\n",
            "[Batch 9] Current Loss: 5.9505\n",
            "Ep 3 (Step 020700): Train loss 3.264, Val loss 5.365\n",
            "[Batch 0] Current Loss: 3.1077\n",
            "[Batch 1] Current Loss: 2.2736\n",
            "[Batch 2] Current Loss: 3.2428\n",
            "[Batch 3] Current Loss: 2.8087\n",
            "[Batch 4] Current Loss: 4.0818\n",
            "[Batch 5] Current Loss: 2.7425\n",
            "[Batch 6] Current Loss: 3.5073\n",
            "[Batch 7] Current Loss: 2.5838\n",
            "[Batch 8] Current Loss: 3.2433\n",
            "[Batch 9] Current Loss: 2.6931\n",
            "[Batch 0] Current Loss: 4.8217\n",
            "[Batch 1] Current Loss: 5.1544\n",
            "[Batch 2] Current Loss: 6.2834\n",
            "[Batch 3] Current Loss: 4.9511\n",
            "[Batch 4] Current Loss: 4.6515\n",
            "[Batch 5] Current Loss: 5.7530\n",
            "[Batch 6] Current Loss: 6.1028\n",
            "[Batch 7] Current Loss: 5.3236\n",
            "[Batch 8] Current Loss: 5.3659\n",
            "[Batch 9] Current Loss: 5.6290\n",
            "Ep 3 (Step 020720): Train loss 3.028, Val loss 5.404\n",
            "[Batch 0] Current Loss: 3.6664\n",
            "[Batch 1] Current Loss: 2.9499\n",
            "[Batch 2] Current Loss: 3.9006\n",
            "[Batch 3] Current Loss: 3.6057\n",
            "[Batch 4] Current Loss: 2.7399\n",
            "[Batch 5] Current Loss: 2.9773\n",
            "[Batch 6] Current Loss: 3.3497\n",
            "[Batch 7] Current Loss: 2.8805\n",
            "[Batch 8] Current Loss: 3.1025\n",
            "[Batch 9] Current Loss: 2.8764\n",
            "[Batch 0] Current Loss: 5.2798\n",
            "[Batch 1] Current Loss: 4.7463\n",
            "[Batch 2] Current Loss: 4.8870\n",
            "[Batch 3] Current Loss: 5.7454\n",
            "[Batch 4] Current Loss: 4.3905\n",
            "[Batch 5] Current Loss: 4.9339\n",
            "[Batch 6] Current Loss: 5.3907\n",
            "[Batch 7] Current Loss: 5.2829\n",
            "[Batch 8] Current Loss: 5.2602\n",
            "[Batch 9] Current Loss: 6.0598\n",
            "Ep 3 (Step 020740): Train loss 3.205, Val loss 5.198\n",
            "[Batch 0] Current Loss: 3.4573\n",
            "[Batch 1] Current Loss: 3.6563\n",
            "[Batch 2] Current Loss: 3.1041\n",
            "[Batch 3] Current Loss: 2.5605\n",
            "[Batch 4] Current Loss: 2.6704\n",
            "[Batch 5] Current Loss: 3.5244\n",
            "[Batch 6] Current Loss: 3.2748\n",
            "[Batch 7] Current Loss: 3.3264\n",
            "[Batch 8] Current Loss: 2.9382\n",
            "[Batch 9] Current Loss: 3.2658\n",
            "[Batch 0] Current Loss: 5.1760\n",
            "[Batch 1] Current Loss: 5.1759\n",
            "[Batch 2] Current Loss: 5.4041\n",
            "[Batch 3] Current Loss: 5.5818\n",
            "[Batch 4] Current Loss: 4.5005\n",
            "[Batch 5] Current Loss: 4.4877\n",
            "[Batch 6] Current Loss: 5.3932\n",
            "[Batch 7] Current Loss: 5.4842\n",
            "[Batch 8] Current Loss: 5.4959\n",
            "[Batch 9] Current Loss: 5.6865\n",
            "Ep 3 (Step 020760): Train loss 3.178, Val loss 5.239\n",
            "[Batch 0] Current Loss: 3.3610\n",
            "[Batch 1] Current Loss: 3.1634\n",
            "[Batch 2] Current Loss: 2.8258\n",
            "[Batch 3] Current Loss: 3.2397\n",
            "[Batch 4] Current Loss: 3.2929\n",
            "[Batch 5] Current Loss: 2.9440\n",
            "[Batch 6] Current Loss: 2.8033\n",
            "[Batch 7] Current Loss: 2.7789\n",
            "[Batch 8] Current Loss: 3.5999\n",
            "[Batch 9] Current Loss: 3.5562\n",
            "[Batch 0] Current Loss: 5.6518\n",
            "[Batch 1] Current Loss: 4.9956\n",
            "[Batch 2] Current Loss: 5.2054\n",
            "[Batch 3] Current Loss: 4.7125\n",
            "[Batch 4] Current Loss: 4.8319\n",
            "[Batch 5] Current Loss: 4.6323\n",
            "[Batch 6] Current Loss: 4.9161\n",
            "[Batch 7] Current Loss: 5.3952\n",
            "[Batch 8] Current Loss: 5.6006\n",
            "[Batch 9] Current Loss: 4.8249\n",
            "Ep 3 (Step 020780): Train loss 3.157, Val loss 5.077\n",
            "[Batch 0] Current Loss: 3.4526\n",
            "[Batch 1] Current Loss: 3.8398\n",
            "[Batch 2] Current Loss: 3.9978\n",
            "[Batch 3] Current Loss: 2.3193\n",
            "[Batch 4] Current Loss: 2.8777\n",
            "[Batch 5] Current Loss: 2.4734\n",
            "[Batch 6] Current Loss: 3.5963\n",
            "[Batch 7] Current Loss: 3.2976\n",
            "[Batch 8] Current Loss: 2.0471\n",
            "[Batch 9] Current Loss: 3.0455\n",
            "[Batch 0] Current Loss: 5.4049\n",
            "[Batch 1] Current Loss: 5.3028\n",
            "[Batch 2] Current Loss: 5.3907\n",
            "[Batch 3] Current Loss: 5.2574\n",
            "[Batch 4] Current Loss: 4.9515\n",
            "[Batch 5] Current Loss: 4.8109\n",
            "[Batch 6] Current Loss: 5.4745\n",
            "[Batch 7] Current Loss: 5.3793\n",
            "[Batch 8] Current Loss: 5.0118\n",
            "[Batch 9] Current Loss: 4.6112\n",
            "Ep 3 (Step 020800): Train loss 3.095, Val loss 5.159\n",
            "[Batch 0] Current Loss: 2.6704\n",
            "[Batch 1] Current Loss: 2.8779\n",
            "[Batch 2] Current Loss: 2.9993\n",
            "[Batch 3] Current Loss: 3.2836\n",
            "[Batch 4] Current Loss: 3.6012\n",
            "[Batch 5] Current Loss: 3.0053\n",
            "[Batch 6] Current Loss: 3.5277\n",
            "[Batch 7] Current Loss: 4.2473\n",
            "[Batch 8] Current Loss: 2.7527\n",
            "[Batch 9] Current Loss: 3.1425\n",
            "[Batch 0] Current Loss: 5.5917\n",
            "[Batch 1] Current Loss: 5.4965\n",
            "[Batch 2] Current Loss: 5.1065\n",
            "[Batch 3] Current Loss: 4.1326\n",
            "[Batch 4] Current Loss: 5.4264\n",
            "[Batch 5] Current Loss: 4.9063\n",
            "[Batch 6] Current Loss: 5.2042\n",
            "[Batch 7] Current Loss: 5.3951\n",
            "[Batch 8] Current Loss: 4.7529\n",
            "[Batch 9] Current Loss: 5.1998\n",
            "Ep 3 (Step 020820): Train loss 3.211, Val loss 5.121\n",
            "[Batch 0] Current Loss: 2.5255\n",
            "[Batch 1] Current Loss: 2.5702\n",
            "[Batch 2] Current Loss: 3.2263\n",
            "[Batch 3] Current Loss: 3.3334\n",
            "[Batch 4] Current Loss: 3.0936\n",
            "[Batch 5] Current Loss: 3.5027\n",
            "[Batch 6] Current Loss: 3.0241\n",
            "[Batch 7] Current Loss: 3.1294\n",
            "[Batch 8] Current Loss: 3.2403\n",
            "[Batch 9] Current Loss: 3.0393\n",
            "[Batch 0] Current Loss: 5.1783\n",
            "[Batch 1] Current Loss: 4.6583\n",
            "[Batch 2] Current Loss: 5.7701\n",
            "[Batch 3] Current Loss: 4.7192\n",
            "[Batch 4] Current Loss: 5.4251\n",
            "[Batch 5] Current Loss: 6.0157\n",
            "[Batch 6] Current Loss: 5.3095\n",
            "[Batch 7] Current Loss: 6.1648\n",
            "[Batch 8] Current Loss: 5.5492\n",
            "[Batch 9] Current Loss: 6.1064\n",
            "Ep 3 (Step 020840): Train loss 3.068, Val loss 5.490\n",
            "[Batch 0] Current Loss: 2.5811\n",
            "[Batch 1] Current Loss: 3.1612\n",
            "[Batch 2] Current Loss: 3.2924\n",
            "[Batch 3] Current Loss: 3.1424\n",
            "[Batch 4] Current Loss: 3.0535\n",
            "[Batch 5] Current Loss: 3.4694\n",
            "[Batch 6] Current Loss: 2.6183\n",
            "[Batch 7] Current Loss: 3.5023\n",
            "[Batch 8] Current Loss: 3.3427\n",
            "[Batch 9] Current Loss: 2.9525\n",
            "[Batch 0] Current Loss: 4.9671\n",
            "[Batch 1] Current Loss: 5.6788\n",
            "[Batch 2] Current Loss: 6.1464\n",
            "[Batch 3] Current Loss: 4.7299\n",
            "[Batch 4] Current Loss: 4.9332\n",
            "[Batch 5] Current Loss: 5.6361\n",
            "[Batch 6] Current Loss: 4.6267\n",
            "[Batch 7] Current Loss: 5.8186\n",
            "[Batch 8] Current Loss: 5.6579\n",
            "[Batch 9] Current Loss: 5.9235\n",
            "Ep 3 (Step 020860): Train loss 3.112, Val loss 5.412\n",
            "[Batch 0] Current Loss: 2.9512\n",
            "[Batch 1] Current Loss: 3.3512\n",
            "[Batch 2] Current Loss: 2.8882\n",
            "[Batch 3] Current Loss: 2.6618\n",
            "[Batch 4] Current Loss: 3.1228\n",
            "[Batch 5] Current Loss: 3.0858\n",
            "[Batch 6] Current Loss: 2.6900\n",
            "[Batch 7] Current Loss: 3.0947\n",
            "[Batch 8] Current Loss: 2.9573\n",
            "[Batch 9] Current Loss: 3.2580\n",
            "[Batch 0] Current Loss: 6.2534\n",
            "[Batch 1] Current Loss: 5.2494\n",
            "[Batch 2] Current Loss: 5.4154\n",
            "[Batch 3] Current Loss: 5.1982\n",
            "[Batch 4] Current Loss: 5.7001\n",
            "[Batch 5] Current Loss: 5.5592\n",
            "[Batch 6] Current Loss: 5.2334\n",
            "[Batch 7] Current Loss: 5.8207\n",
            "[Batch 8] Current Loss: 5.8315\n",
            "[Batch 9] Current Loss: 5.8873\n",
            "Ep 3 (Step 020880): Train loss 3.006, Val loss 5.615\n",
            "[Batch 0] Current Loss: 2.9591\n",
            "[Batch 1] Current Loss: 2.2693\n",
            "[Batch 2] Current Loss: 3.1929\n",
            "[Batch 3] Current Loss: 2.4687\n",
            "[Batch 4] Current Loss: 2.8468\n",
            "[Batch 5] Current Loss: 2.9440\n",
            "[Batch 6] Current Loss: 2.5068\n",
            "[Batch 7] Current Loss: 3.7030\n",
            "[Batch 8] Current Loss: 2.3908\n",
            "[Batch 9] Current Loss: 3.6950\n",
            "[Batch 0] Current Loss: 6.1882\n",
            "[Batch 1] Current Loss: 5.4422\n",
            "[Batch 2] Current Loss: 4.6516\n",
            "[Batch 3] Current Loss: 5.2862\n",
            "[Batch 4] Current Loss: 5.0143\n",
            "[Batch 5] Current Loss: 5.3890\n",
            "[Batch 6] Current Loss: 4.9838\n",
            "[Batch 7] Current Loss: 5.6478\n",
            "[Batch 8] Current Loss: 5.0216\n",
            "[Batch 9] Current Loss: 5.0858\n",
            "Ep 3 (Step 020900): Train loss 2.898, Val loss 5.271\n",
            "[Batch 0] Current Loss: 3.4864\n",
            "[Batch 1] Current Loss: 2.7519\n",
            "[Batch 2] Current Loss: 3.3207\n",
            "[Batch 3] Current Loss: 3.0561\n",
            "[Batch 4] Current Loss: 3.2601\n",
            "[Batch 5] Current Loss: 3.0183\n",
            "[Batch 6] Current Loss: 2.6876\n",
            "[Batch 7] Current Loss: 2.9139\n",
            "[Batch 8] Current Loss: 2.8853\n",
            "[Batch 9] Current Loss: 2.8947\n",
            "[Batch 0] Current Loss: 5.9850\n",
            "[Batch 1] Current Loss: 6.0299\n",
            "[Batch 2] Current Loss: 5.7305\n",
            "[Batch 3] Current Loss: 5.2545\n",
            "[Batch 4] Current Loss: 5.1368\n",
            "[Batch 5] Current Loss: 5.3791\n",
            "[Batch 6] Current Loss: 5.6852\n",
            "[Batch 7] Current Loss: 5.8663\n",
            "[Batch 8] Current Loss: 5.5416\n",
            "[Batch 9] Current Loss: 5.5786\n",
            "Ep 3 (Step 020920): Train loss 3.028, Val loss 5.619\n",
            "[Batch 0] Current Loss: 3.5537\n",
            "[Batch 1] Current Loss: 3.3721\n",
            "[Batch 2] Current Loss: 2.0740\n",
            "[Batch 3] Current Loss: 3.1183\n",
            "[Batch 4] Current Loss: 2.8478\n",
            "[Batch 5] Current Loss: 3.0025\n",
            "[Batch 6] Current Loss: 3.3017\n",
            "[Batch 7] Current Loss: 2.8841\n",
            "[Batch 8] Current Loss: 2.6691\n",
            "[Batch 9] Current Loss: 3.7418\n",
            "[Batch 0] Current Loss: 5.5681\n",
            "[Batch 1] Current Loss: 5.9302\n",
            "[Batch 2] Current Loss: 5.4967\n",
            "[Batch 3] Current Loss: 5.4746\n",
            "[Batch 4] Current Loss: 5.4177\n",
            "[Batch 5] Current Loss: 5.4522\n",
            "[Batch 6] Current Loss: 5.8033\n",
            "[Batch 7] Current Loss: 5.5771\n",
            "[Batch 8] Current Loss: 5.0122\n",
            "[Batch 9] Current Loss: 4.7943\n",
            "Ep 3 (Step 020940): Train loss 3.057, Val loss 5.453\n",
            "[Batch 0] Current Loss: 2.8078\n",
            "[Batch 1] Current Loss: 3.9603\n",
            "[Batch 2] Current Loss: 2.7620\n",
            "[Batch 3] Current Loss: 2.8850\n",
            "[Batch 4] Current Loss: 2.3804\n",
            "[Batch 5] Current Loss: 3.4342\n",
            "[Batch 6] Current Loss: 2.9290\n",
            "[Batch 7] Current Loss: 2.8612\n",
            "[Batch 8] Current Loss: 3.0340\n",
            "[Batch 9] Current Loss: 3.6277\n",
            "[Batch 0] Current Loss: 5.3442\n",
            "[Batch 1] Current Loss: 5.4235\n",
            "[Batch 2] Current Loss: 5.3985\n",
            "[Batch 3] Current Loss: 5.1227\n",
            "[Batch 4] Current Loss: 5.4921\n",
            "[Batch 5] Current Loss: 4.9853\n",
            "[Batch 6] Current Loss: 4.1812\n",
            "[Batch 7] Current Loss: 4.9925\n",
            "[Batch 8] Current Loss: 5.1299\n",
            "[Batch 9] Current Loss: 5.3318\n",
            "Ep 3 (Step 020960): Train loss 3.068, Val loss 5.140\n",
            "[Batch 0] Current Loss: 3.5752\n",
            "[Batch 1] Current Loss: 2.8874\n",
            "[Batch 2] Current Loss: 3.5354\n",
            "[Batch 3] Current Loss: 2.9420\n",
            "[Batch 4] Current Loss: 3.0829\n",
            "[Batch 5] Current Loss: 2.7063\n",
            "[Batch 6] Current Loss: 3.2354\n",
            "[Batch 7] Current Loss: 3.2197\n",
            "[Batch 8] Current Loss: 2.8401\n",
            "[Batch 9] Current Loss: 3.3881\n",
            "[Batch 0] Current Loss: 4.5612\n",
            "[Batch 1] Current Loss: 5.1567\n",
            "[Batch 2] Current Loss: 5.4137\n",
            "[Batch 3] Current Loss: 5.3163\n",
            "[Batch 4] Current Loss: 5.6270\n",
            "[Batch 5] Current Loss: 4.9535\n",
            "[Batch 6] Current Loss: 5.3787\n",
            "[Batch 7] Current Loss: 5.6798\n",
            "[Batch 8] Current Loss: 4.7888\n",
            "[Batch 9] Current Loss: 6.5227\n",
            "Ep 3 (Step 020980): Train loss 3.141, Val loss 5.340\n",
            "[Batch 0] Current Loss: 3.4285\n",
            "[Batch 1] Current Loss: 3.2131\n",
            "[Batch 2] Current Loss: 3.4704\n",
            "[Batch 3] Current Loss: 3.2515\n",
            "[Batch 4] Current Loss: 3.3402\n",
            "[Batch 5] Current Loss: 3.5476\n",
            "[Batch 6] Current Loss: 2.7600\n",
            "[Batch 7] Current Loss: 3.0335\n",
            "[Batch 8] Current Loss: 2.7643\n",
            "[Batch 9] Current Loss: 3.0281\n",
            "[Batch 0] Current Loss: 6.3072\n",
            "[Batch 1] Current Loss: 5.5395\n",
            "[Batch 2] Current Loss: 4.7800\n",
            "[Batch 3] Current Loss: 5.8838\n",
            "[Batch 4] Current Loss: 5.1227\n",
            "[Batch 5] Current Loss: 5.2511\n",
            "[Batch 6] Current Loss: 5.7717\n",
            "[Batch 7] Current Loss: 5.5783\n",
            "[Batch 8] Current Loss: 5.3525\n",
            "[Batch 9] Current Loss: 5.3130\n",
            "Ep 3 (Step 021000): Train loss 3.184, Val loss 5.490\n",
            "[Batch 0] Current Loss: 3.1381\n",
            "[Batch 1] Current Loss: 2.6633\n",
            "[Batch 2] Current Loss: 2.2484\n",
            "[Batch 3] Current Loss: 2.8652\n",
            "[Batch 4] Current Loss: 2.8636\n",
            "[Batch 5] Current Loss: 3.4670\n",
            "[Batch 6] Current Loss: 3.7384\n",
            "[Batch 7] Current Loss: 3.2710\n",
            "[Batch 8] Current Loss: 3.5871\n",
            "[Batch 9] Current Loss: 3.1625\n",
            "[Batch 0] Current Loss: 5.4229\n",
            "[Batch 1] Current Loss: 5.3137\n",
            "[Batch 2] Current Loss: 5.8112\n",
            "[Batch 3] Current Loss: 5.6726\n",
            "[Batch 4] Current Loss: 5.6993\n",
            "[Batch 5] Current Loss: 5.9651\n",
            "[Batch 6] Current Loss: 5.1430\n",
            "[Batch 7] Current Loss: 5.2962\n",
            "[Batch 8] Current Loss: 5.2389\n",
            "[Batch 9] Current Loss: 5.5018\n",
            "Ep 3 (Step 021020): Train loss 3.100, Val loss 5.506\n",
            "[Batch 0] Current Loss: 2.8373\n",
            "[Batch 1] Current Loss: 2.8804\n",
            "[Batch 2] Current Loss: 2.8721\n",
            "[Batch 3] Current Loss: 3.6145\n",
            "[Batch 4] Current Loss: 2.4731\n",
            "[Batch 5] Current Loss: 2.8246\n",
            "[Batch 6] Current Loss: 3.2258\n",
            "[Batch 7] Current Loss: 3.4852\n",
            "[Batch 8] Current Loss: 3.4430\n",
            "[Batch 9] Current Loss: 3.0066\n",
            "[Batch 0] Current Loss: 5.0592\n",
            "[Batch 1] Current Loss: 5.2677\n",
            "[Batch 2] Current Loss: 4.7746\n",
            "[Batch 3] Current Loss: 5.8114\n",
            "[Batch 4] Current Loss: 5.1762\n",
            "[Batch 5] Current Loss: 5.1221\n",
            "[Batch 6] Current Loss: 5.7698\n",
            "[Batch 7] Current Loss: 5.4563\n",
            "[Batch 8] Current Loss: 5.4667\n",
            "[Batch 9] Current Loss: 4.9716\n",
            "Ep 3 (Step 021040): Train loss 3.066, Val loss 5.288\n",
            "[Batch 0] Current Loss: 2.9536\n",
            "[Batch 1] Current Loss: 2.8341\n",
            "[Batch 2] Current Loss: 2.6090\n",
            "[Batch 3] Current Loss: 3.7439\n",
            "[Batch 4] Current Loss: 2.4719\n",
            "[Batch 5] Current Loss: 3.1821\n",
            "[Batch 6] Current Loss: 3.2462\n",
            "[Batch 7] Current Loss: 3.5890\n",
            "[Batch 8] Current Loss: 2.7557\n",
            "[Batch 9] Current Loss: 2.8167\n",
            "[Batch 0] Current Loss: 4.9094\n",
            "[Batch 1] Current Loss: 5.3749\n",
            "[Batch 2] Current Loss: 5.4705\n",
            "[Batch 3] Current Loss: 5.3488\n",
            "[Batch 4] Current Loss: 5.3006\n",
            "[Batch 5] Current Loss: 4.9591\n",
            "[Batch 6] Current Loss: 5.8228\n",
            "[Batch 7] Current Loss: 5.0924\n",
            "[Batch 8] Current Loss: 6.0230\n",
            "[Batch 9] Current Loss: 5.1214\n",
            "Ep 3 (Step 021060): Train loss 3.020, Val loss 5.342\n",
            "[Batch 0] Current Loss: 2.8894\n",
            "[Batch 1] Current Loss: 3.7095\n",
            "[Batch 2] Current Loss: 3.4022\n",
            "[Batch 3] Current Loss: 3.4121\n",
            "[Batch 4] Current Loss: 3.4409\n",
            "[Batch 5] Current Loss: 2.7155\n",
            "[Batch 6] Current Loss: 2.4853\n",
            "[Batch 7] Current Loss: 3.0070\n",
            "[Batch 8] Current Loss: 3.1636\n",
            "[Batch 9] Current Loss: 3.6768\n",
            "[Batch 0] Current Loss: 5.7354\n",
            "[Batch 1] Current Loss: 5.6914\n",
            "[Batch 2] Current Loss: 5.3438\n",
            "[Batch 3] Current Loss: 5.4887\n",
            "[Batch 4] Current Loss: 5.8371\n",
            "[Batch 5] Current Loss: 5.8451\n",
            "[Batch 6] Current Loss: 4.8508\n",
            "[Batch 7] Current Loss: 5.6315\n",
            "[Batch 8] Current Loss: 4.9241\n",
            "[Batch 9] Current Loss: 4.5213\n",
            "Ep 3 (Step 021080): Train loss 3.190, Val loss 5.387\n",
            "[Batch 0] Current Loss: 3.4481\n",
            "[Batch 1] Current Loss: 3.2190\n",
            "[Batch 2] Current Loss: 3.7253\n",
            "[Batch 3] Current Loss: 2.8599\n",
            "[Batch 4] Current Loss: 3.3040\n",
            "[Batch 5] Current Loss: 3.1300\n",
            "[Batch 6] Current Loss: 3.2795\n",
            "[Batch 7] Current Loss: 3.4870\n",
            "[Batch 8] Current Loss: 3.7016\n",
            "[Batch 9] Current Loss: 3.0670\n",
            "[Batch 0] Current Loss: 5.3155\n",
            "[Batch 1] Current Loss: 6.0265\n",
            "[Batch 2] Current Loss: 5.1461\n",
            "[Batch 3] Current Loss: 5.1891\n",
            "[Batch 4] Current Loss: 4.9073\n",
            "[Batch 5] Current Loss: 5.8610\n",
            "[Batch 6] Current Loss: 5.5105\n",
            "[Batch 7] Current Loss: 4.6729\n",
            "[Batch 8] Current Loss: 5.5851\n",
            "[Batch 9] Current Loss: 5.7599\n",
            "Ep 3 (Step 021100): Train loss 3.322, Val loss 5.397\n",
            "[Batch 0] Current Loss: 3.6580\n",
            "[Batch 1] Current Loss: 2.6024\n",
            "[Batch 2] Current Loss: 2.7589\n",
            "[Batch 3] Current Loss: 2.6095\n",
            "[Batch 4] Current Loss: 2.9610\n",
            "[Batch 5] Current Loss: 3.2215\n",
            "[Batch 6] Current Loss: 3.2210\n",
            "[Batch 7] Current Loss: 3.1387\n",
            "[Batch 8] Current Loss: 3.5338\n",
            "[Batch 9] Current Loss: 2.6413\n",
            "[Batch 0] Current Loss: 5.4777\n",
            "[Batch 1] Current Loss: 6.0385\n",
            "[Batch 2] Current Loss: 6.0304\n",
            "[Batch 3] Current Loss: 5.4612\n",
            "[Batch 4] Current Loss: 5.6240\n",
            "[Batch 5] Current Loss: 5.5217\n",
            "[Batch 6] Current Loss: 5.5239\n",
            "[Batch 7] Current Loss: 5.8601\n",
            "[Batch 8] Current Loss: 5.9290\n",
            "[Batch 9] Current Loss: 4.6483\n",
            "Ep 3 (Step 021120): Train loss 3.035, Val loss 5.611\n",
            "[Batch 0] Current Loss: 2.9451\n",
            "[Batch 1] Current Loss: 3.1395\n",
            "[Batch 2] Current Loss: 3.9840\n",
            "[Batch 3] Current Loss: 3.0274\n",
            "[Batch 4] Current Loss: 2.9816\n",
            "[Batch 5] Current Loss: 3.2781\n",
            "[Batch 6] Current Loss: 2.6291\n",
            "[Batch 7] Current Loss: 3.2108\n",
            "[Batch 8] Current Loss: 3.6171\n",
            "[Batch 9] Current Loss: 3.1878\n",
            "[Batch 0] Current Loss: 5.3712\n",
            "[Batch 1] Current Loss: 4.7598\n",
            "[Batch 2] Current Loss: 5.5524\n",
            "[Batch 3] Current Loss: 5.4962\n",
            "[Batch 4] Current Loss: 5.2853\n",
            "[Batch 5] Current Loss: 4.8860\n",
            "[Batch 6] Current Loss: 5.1738\n",
            "[Batch 7] Current Loss: 5.0210\n",
            "[Batch 8] Current Loss: 5.4273\n",
            "[Batch 9] Current Loss: 5.0637\n",
            "Ep 3 (Step 021140): Train loss 3.200, Val loss 5.204\n",
            "[Batch 0] Current Loss: 3.0741\n",
            "[Batch 1] Current Loss: 3.5249\n",
            "[Batch 2] Current Loss: 2.5731\n",
            "[Batch 3] Current Loss: 2.8393\n",
            "[Batch 4] Current Loss: 3.0781\n",
            "[Batch 5] Current Loss: 2.5150\n",
            "[Batch 6] Current Loss: 2.9784\n",
            "[Batch 7] Current Loss: 3.8176\n",
            "[Batch 8] Current Loss: 3.4257\n",
            "[Batch 9] Current Loss: 2.4606\n",
            "[Batch 0] Current Loss: 5.3235\n",
            "[Batch 1] Current Loss: 5.5258\n",
            "[Batch 2] Current Loss: 5.0244\n",
            "[Batch 3] Current Loss: 4.4513\n",
            "[Batch 4] Current Loss: 5.9219\n",
            "[Batch 5] Current Loss: 5.4040\n",
            "[Batch 6] Current Loss: 5.3494\n",
            "[Batch 7] Current Loss: 5.3175\n",
            "[Batch 8] Current Loss: 5.1341\n",
            "[Batch 9] Current Loss: 5.3479\n",
            "Ep 3 (Step 021160): Train loss 3.029, Val loss 5.280\n",
            "[Batch 0] Current Loss: 3.2504\n",
            "[Batch 1] Current Loss: 3.5845\n",
            "[Batch 2] Current Loss: 3.2520\n",
            "[Batch 3] Current Loss: 3.1316\n",
            "[Batch 4] Current Loss: 2.9290\n",
            "[Batch 5] Current Loss: 3.1364\n",
            "[Batch 6] Current Loss: 3.4510\n",
            "[Batch 7] Current Loss: 3.3123\n",
            "[Batch 8] Current Loss: 3.3156\n",
            "[Batch 9] Current Loss: 3.2362\n",
            "[Batch 0] Current Loss: 4.6444\n",
            "[Batch 1] Current Loss: 4.8049\n",
            "[Batch 2] Current Loss: 5.5839\n",
            "[Batch 3] Current Loss: 5.0417\n",
            "[Batch 4] Current Loss: 5.0863\n",
            "[Batch 5] Current Loss: 5.4357\n",
            "[Batch 6] Current Loss: 5.2599\n",
            "[Batch 7] Current Loss: 5.6087\n",
            "[Batch 8] Current Loss: 5.5382\n",
            "[Batch 9] Current Loss: 4.8036\n",
            "Ep 3 (Step 021180): Train loss 3.260, Val loss 5.181\n",
            "[Batch 0] Current Loss: 3.1975\n",
            "[Batch 1] Current Loss: 2.6319\n",
            "[Batch 2] Current Loss: 3.1100\n",
            "[Batch 3] Current Loss: 2.6387\n",
            "[Batch 4] Current Loss: 3.0548\n",
            "[Batch 5] Current Loss: 3.0825\n",
            "[Batch 6] Current Loss: 2.3512\n",
            "[Batch 7] Current Loss: 3.0950\n",
            "[Batch 8] Current Loss: 3.6574\n",
            "[Batch 9] Current Loss: 3.3968\n",
            "[Batch 0] Current Loss: 5.2139\n",
            "[Batch 1] Current Loss: 5.3166\n",
            "[Batch 2] Current Loss: 5.5472\n",
            "[Batch 3] Current Loss: 5.0110\n",
            "[Batch 4] Current Loss: 5.4473\n",
            "[Batch 5] Current Loss: 4.6957\n",
            "[Batch 6] Current Loss: 5.5084\n",
            "[Batch 7] Current Loss: 5.5644\n",
            "[Batch 8] Current Loss: 5.0936\n",
            "[Batch 9] Current Loss: 4.7872\n",
            "Ep 3 (Step 021200): Train loss 3.022, Val loss 5.219\n",
            "[Batch 0] Current Loss: 3.2283\n",
            "[Batch 1] Current Loss: 2.7417\n",
            "[Batch 2] Current Loss: 3.5546\n",
            "[Batch 3] Current Loss: 2.8296\n",
            "[Batch 4] Current Loss: 2.7011\n",
            "[Batch 5] Current Loss: 3.2275\n",
            "[Batch 6] Current Loss: 2.7182\n",
            "[Batch 7] Current Loss: 3.5223\n",
            "[Batch 8] Current Loss: 3.3731\n",
            "[Batch 9] Current Loss: 2.8324\n",
            "[Batch 0] Current Loss: 5.8127\n",
            "[Batch 1] Current Loss: 5.4729\n",
            "[Batch 2] Current Loss: 5.1886\n",
            "[Batch 3] Current Loss: 5.0955\n",
            "[Batch 4] Current Loss: 5.2573\n",
            "[Batch 5] Current Loss: 5.4731\n",
            "[Batch 6] Current Loss: 5.4853\n",
            "[Batch 7] Current Loss: 5.4871\n",
            "[Batch 8] Current Loss: 5.6757\n",
            "[Batch 9] Current Loss: 5.2868\n",
            "Ep 3 (Step 021220): Train loss 3.073, Val loss 5.424\n",
            "[Batch 0] Current Loss: 3.4819\n",
            "[Batch 1] Current Loss: 3.4613\n",
            "[Batch 2] Current Loss: 3.0279\n",
            "[Batch 3] Current Loss: 3.3659\n",
            "[Batch 4] Current Loss: 2.4430\n",
            "[Batch 5] Current Loss: 2.8754\n",
            "[Batch 6] Current Loss: 3.2718\n",
            "[Batch 7] Current Loss: 3.7386\n",
            "[Batch 8] Current Loss: 3.5334\n",
            "[Batch 9] Current Loss: 3.2817\n",
            "[Batch 0] Current Loss: 5.3730\n",
            "[Batch 1] Current Loss: 5.0994\n",
            "[Batch 2] Current Loss: 5.4806\n",
            "[Batch 3] Current Loss: 5.5744\n",
            "[Batch 4] Current Loss: 5.7245\n",
            "[Batch 5] Current Loss: 5.8638\n",
            "[Batch 6] Current Loss: 5.6935\n",
            "[Batch 7] Current Loss: 4.6582\n",
            "[Batch 8] Current Loss: 5.2357\n",
            "[Batch 9] Current Loss: 5.3675\n",
            "Ep 3 (Step 021240): Train loss 3.248, Val loss 5.407\n",
            "[Batch 0] Current Loss: 2.9595\n",
            "[Batch 1] Current Loss: 3.7315\n",
            "[Batch 2] Current Loss: 3.3806\n",
            "[Batch 3] Current Loss: 3.1185\n",
            "[Batch 4] Current Loss: 2.4097\n",
            "[Batch 5] Current Loss: 2.9080\n",
            "[Batch 6] Current Loss: 2.6940\n",
            "[Batch 7] Current Loss: 3.0634\n",
            "[Batch 8] Current Loss: 3.4101\n",
            "[Batch 9] Current Loss: 3.5923\n",
            "[Batch 0] Current Loss: 5.1300\n",
            "[Batch 1] Current Loss: 5.4539\n",
            "[Batch 2] Current Loss: 5.8400\n",
            "[Batch 3] Current Loss: 5.1945\n",
            "[Batch 4] Current Loss: 6.1537\n",
            "[Batch 5] Current Loss: 5.2816\n",
            "[Batch 6] Current Loss: 4.8553\n",
            "[Batch 7] Current Loss: 5.1705\n",
            "[Batch 8] Current Loss: 4.4866\n",
            "[Batch 9] Current Loss: 5.1985\n",
            "Ep 3 (Step 021260): Train loss 3.127, Val loss 5.276\n",
            "[Batch 0] Current Loss: 2.7062\n",
            "[Batch 1] Current Loss: 3.3582\n",
            "[Batch 2] Current Loss: 3.7045\n",
            "[Batch 3] Current Loss: 2.8825\n",
            "[Batch 4] Current Loss: 2.5388\n",
            "[Batch 5] Current Loss: 2.9586\n",
            "[Batch 6] Current Loss: 2.9186\n",
            "[Batch 7] Current Loss: 2.2756\n",
            "[Batch 8] Current Loss: 3.2797\n",
            "[Batch 9] Current Loss: 3.2554\n",
            "[Batch 0] Current Loss: 5.2553\n",
            "[Batch 1] Current Loss: 4.6239\n",
            "[Batch 2] Current Loss: 5.4940\n",
            "[Batch 3] Current Loss: 5.3561\n",
            "[Batch 4] Current Loss: 4.9539\n",
            "[Batch 5] Current Loss: 5.3846\n",
            "[Batch 6] Current Loss: 5.5291\n",
            "[Batch 7] Current Loss: 5.3224\n",
            "[Batch 8] Current Loss: 5.7313\n",
            "[Batch 9] Current Loss: 4.7103\n",
            "Ep 3 (Step 021280): Train loss 2.988, Val loss 5.236\n",
            "[Batch 0] Current Loss: 2.8069\n",
            "[Batch 1] Current Loss: 2.8896\n",
            "[Batch 2] Current Loss: 3.0871\n",
            "[Batch 3] Current Loss: 2.7152\n",
            "[Batch 4] Current Loss: 3.3145\n",
            "[Batch 5] Current Loss: 2.9683\n",
            "[Batch 6] Current Loss: 3.0077\n",
            "[Batch 7] Current Loss: 2.9583\n",
            "[Batch 8] Current Loss: 2.4662\n",
            "[Batch 9] Current Loss: 3.1678\n",
            "[Batch 0] Current Loss: 5.9317\n",
            "[Batch 1] Current Loss: 5.3880\n",
            "[Batch 2] Current Loss: 5.3851\n",
            "[Batch 3] Current Loss: 5.2212\n",
            "[Batch 4] Current Loss: 5.1936\n",
            "[Batch 5] Current Loss: 5.2931\n",
            "[Batch 6] Current Loss: 5.1641\n",
            "[Batch 7] Current Loss: 5.5069\n",
            "[Batch 8] Current Loss: 5.2306\n",
            "[Batch 9] Current Loss: 4.7710\n",
            "Ep 3 (Step 021300): Train loss 2.938, Val loss 5.309\n",
            "[Batch 0] Current Loss: 2.8709\n",
            "[Batch 1] Current Loss: 3.3565\n",
            "[Batch 2] Current Loss: 2.7452\n",
            "[Batch 3] Current Loss: 2.6909\n",
            "[Batch 4] Current Loss: 2.5547\n",
            "[Batch 5] Current Loss: 3.9252\n",
            "[Batch 6] Current Loss: 3.2282\n",
            "[Batch 7] Current Loss: 2.6612\n",
            "[Batch 8] Current Loss: 2.9843\n",
            "[Batch 9] Current Loss: 3.5763\n",
            "[Batch 0] Current Loss: 4.6914\n",
            "[Batch 1] Current Loss: 5.3327\n",
            "[Batch 2] Current Loss: 5.5019\n",
            "[Batch 3] Current Loss: 4.7801\n",
            "[Batch 4] Current Loss: 5.3544\n",
            "[Batch 5] Current Loss: 5.1689\n",
            "[Batch 6] Current Loss: 5.0768\n",
            "[Batch 7] Current Loss: 5.0694\n",
            "[Batch 8] Current Loss: 4.5927\n",
            "[Batch 9] Current Loss: 5.9844\n",
            "Ep 3 (Step 021320): Train loss 3.059, Val loss 5.155\n",
            "[Batch 0] Current Loss: 3.0556\n",
            "[Batch 1] Current Loss: 3.5412\n",
            "[Batch 2] Current Loss: 3.7906\n",
            "[Batch 3] Current Loss: 2.4796\n",
            "[Batch 4] Current Loss: 3.1701\n",
            "[Batch 5] Current Loss: 3.3907\n",
            "[Batch 6] Current Loss: 2.6669\n",
            "[Batch 7] Current Loss: 2.2700\n",
            "[Batch 8] Current Loss: 3.4793\n",
            "[Batch 9] Current Loss: 3.0214\n",
            "[Batch 0] Current Loss: 4.8398\n",
            "[Batch 1] Current Loss: 5.1606\n",
            "[Batch 2] Current Loss: 4.7721\n",
            "[Batch 3] Current Loss: 4.7460\n",
            "[Batch 4] Current Loss: 5.4247\n",
            "[Batch 5] Current Loss: 4.7283\n",
            "[Batch 6] Current Loss: 4.9782\n",
            "[Batch 7] Current Loss: 5.8094\n",
            "[Batch 8] Current Loss: 5.7954\n",
            "[Batch 9] Current Loss: 5.8288\n",
            "Ep 3 (Step 021340): Train loss 3.087, Val loss 5.208\n",
            "[Batch 0] Current Loss: 2.5597\n",
            "[Batch 1] Current Loss: 2.7060\n",
            "[Batch 2] Current Loss: 2.9489\n",
            "[Batch 3] Current Loss: 2.4632\n",
            "[Batch 4] Current Loss: 2.3229\n",
            "[Batch 5] Current Loss: 2.9285\n",
            "[Batch 6] Current Loss: 3.5242\n",
            "[Batch 7] Current Loss: 2.6077\n",
            "[Batch 8] Current Loss: 2.8173\n",
            "[Batch 9] Current Loss: 3.2926\n",
            "[Batch 0] Current Loss: 5.6430\n",
            "[Batch 1] Current Loss: 5.4956\n",
            "[Batch 2] Current Loss: 5.1419\n",
            "[Batch 3] Current Loss: 5.3039\n",
            "[Batch 4] Current Loss: 5.5338\n",
            "[Batch 5] Current Loss: 5.5804\n",
            "[Batch 6] Current Loss: 5.0476\n",
            "[Batch 7] Current Loss: 5.1364\n",
            "[Batch 8] Current Loss: 5.4262\n",
            "[Batch 9] Current Loss: 5.1276\n",
            "Ep 3 (Step 021360): Train loss 2.817, Val loss 5.344\n",
            "[Batch 0] Current Loss: 2.7039\n",
            "[Batch 1] Current Loss: 2.4789\n",
            "[Batch 2] Current Loss: 3.1935\n",
            "[Batch 3] Current Loss: 3.2309\n",
            "[Batch 4] Current Loss: 2.9893\n",
            "[Batch 5] Current Loss: 3.1986\n",
            "[Batch 6] Current Loss: 3.0251\n",
            "[Batch 7] Current Loss: 2.4067\n",
            "[Batch 8] Current Loss: 3.1687\n",
            "[Batch 9] Current Loss: 3.1801\n",
            "[Batch 0] Current Loss: 5.7431\n",
            "[Batch 1] Current Loss: 4.8242\n",
            "[Batch 2] Current Loss: 5.6219\n",
            "[Batch 3] Current Loss: 5.1232\n",
            "[Batch 4] Current Loss: 5.7740\n",
            "[Batch 5] Current Loss: 5.8562\n",
            "[Batch 6] Current Loss: 5.6064\n",
            "[Batch 7] Current Loss: 4.5164\n",
            "[Batch 8] Current Loss: 5.3449\n",
            "[Batch 9] Current Loss: 4.6577\n",
            "Ep 3 (Step 021380): Train loss 2.958, Val loss 5.307\n",
            "[Batch 0] Current Loss: 3.1556\n",
            "[Batch 1] Current Loss: 2.9992\n",
            "[Batch 2] Current Loss: 2.9359\n",
            "[Batch 3] Current Loss: 2.7748\n",
            "[Batch 4] Current Loss: 3.4092\n",
            "[Batch 5] Current Loss: 2.5804\n",
            "[Batch 6] Current Loss: 3.4193\n",
            "[Batch 7] Current Loss: 2.2247\n",
            "[Batch 8] Current Loss: 3.0993\n",
            "[Batch 9] Current Loss: 2.9734\n",
            "[Batch 0] Current Loss: 5.4912\n",
            "[Batch 1] Current Loss: 6.1186\n",
            "[Batch 2] Current Loss: 4.8634\n",
            "[Batch 3] Current Loss: 4.9886\n",
            "[Batch 4] Current Loss: 5.6521\n",
            "[Batch 5] Current Loss: 5.2335\n",
            "[Batch 6] Current Loss: 5.1246\n",
            "[Batch 7] Current Loss: 5.6405\n",
            "[Batch 8] Current Loss: 5.6196\n",
            "[Batch 9] Current Loss: 5.6408\n",
            "Ep 3 (Step 021400): Train loss 2.957, Val loss 5.437\n",
            "[Batch 0] Current Loss: 2.6730\n",
            "[Batch 1] Current Loss: 2.4472\n",
            "[Batch 2] Current Loss: 3.1122\n",
            "[Batch 3] Current Loss: 3.4567\n",
            "[Batch 4] Current Loss: 2.7114\n",
            "[Batch 5] Current Loss: 3.0139\n",
            "[Batch 6] Current Loss: 3.6865\n",
            "[Batch 7] Current Loss: 3.0592\n",
            "[Batch 8] Current Loss: 3.3101\n",
            "[Batch 9] Current Loss: 2.8224\n",
            "[Batch 0] Current Loss: 5.2211\n",
            "[Batch 1] Current Loss: 5.4906\n",
            "[Batch 2] Current Loss: 4.7821\n",
            "[Batch 3] Current Loss: 5.7999\n",
            "[Batch 4] Current Loss: 5.4097\n",
            "[Batch 5] Current Loss: 5.6916\n",
            "[Batch 6] Current Loss: 5.8002\n",
            "[Batch 7] Current Loss: 5.0961\n",
            "[Batch 8] Current Loss: 4.9030\n",
            "[Batch 9] Current Loss: 5.8216\n",
            "Ep 3 (Step 021420): Train loss 3.029, Val loss 5.402\n",
            "[Batch 0] Current Loss: 3.3639\n",
            "[Batch 1] Current Loss: 3.0892\n",
            "[Batch 2] Current Loss: 3.2505\n",
            "[Batch 3] Current Loss: 2.3352\n",
            "[Batch 4] Current Loss: 3.7985\n",
            "[Batch 5] Current Loss: 3.1858\n",
            "[Batch 6] Current Loss: 3.8073\n",
            "[Batch 7] Current Loss: 2.5958\n",
            "[Batch 8] Current Loss: 2.6895\n",
            "[Batch 9] Current Loss: 2.8651\n",
            "[Batch 0] Current Loss: 5.9568\n",
            "[Batch 1] Current Loss: 4.6297\n",
            "[Batch 2] Current Loss: 5.5084\n",
            "[Batch 3] Current Loss: 5.0242\n",
            "[Batch 4] Current Loss: 4.6978\n",
            "[Batch 5] Current Loss: 5.7662\n",
            "[Batch 6] Current Loss: 4.9484\n",
            "[Batch 7] Current Loss: 5.1852\n",
            "[Batch 8] Current Loss: 5.3546\n",
            "[Batch 9] Current Loss: 5.3576\n",
            "Ep 3 (Step 021440): Train loss 3.098, Val loss 5.243\n",
            "[Batch 0] Current Loss: 3.0518\n",
            "[Batch 1] Current Loss: 3.1028\n",
            "[Batch 2] Current Loss: 2.9305\n",
            "[Batch 3] Current Loss: 2.7298\n",
            "[Batch 4] Current Loss: 2.6284\n",
            "[Batch 5] Current Loss: 2.7188\n",
            "[Batch 6] Current Loss: 2.9095\n",
            "[Batch 7] Current Loss: 2.1965\n",
            "[Batch 8] Current Loss: 3.1906\n",
            "[Batch 9] Current Loss: 2.8829\n",
            "[Batch 0] Current Loss: 5.3365\n",
            "[Batch 1] Current Loss: 5.6147\n",
            "[Batch 2] Current Loss: 5.3496\n",
            "[Batch 3] Current Loss: 5.4029\n",
            "[Batch 4] Current Loss: 5.3139\n",
            "[Batch 5] Current Loss: 5.1809\n",
            "[Batch 6] Current Loss: 5.1144\n",
            "[Batch 7] Current Loss: 5.3998\n",
            "[Batch 8] Current Loss: 4.9652\n",
            "[Batch 9] Current Loss: 5.7563\n",
            "Ep 3 (Step 021460): Train loss 2.834, Val loss 5.343\n",
            "[Batch 0] Current Loss: 3.0693\n",
            "[Batch 1] Current Loss: 3.2833\n",
            "[Batch 2] Current Loss: 3.1137\n",
            "[Batch 3] Current Loss: 3.2622\n",
            "[Batch 4] Current Loss: 3.0764\n",
            "[Batch 5] Current Loss: 3.1147\n",
            "[Batch 6] Current Loss: 3.2525\n",
            "[Batch 7] Current Loss: 2.5653\n",
            "[Batch 8] Current Loss: 2.7228\n",
            "[Batch 9] Current Loss: 3.1194\n",
            "[Batch 0] Current Loss: 5.4118\n",
            "[Batch 1] Current Loss: 4.8719\n",
            "[Batch 2] Current Loss: 4.5265\n",
            "[Batch 3] Current Loss: 5.0792\n",
            "[Batch 4] Current Loss: 4.9160\n",
            "[Batch 5] Current Loss: 5.3887\n",
            "[Batch 6] Current Loss: 5.9599\n",
            "[Batch 7] Current Loss: 5.5949\n",
            "[Batch 8] Current Loss: 4.8140\n",
            "[Batch 9] Current Loss: 5.2756\n",
            "Ep 3 (Step 021480): Train loss 3.058, Val loss 5.184\n",
            "[Batch 0] Current Loss: 3.2761\n",
            "[Batch 1] Current Loss: 3.3086\n",
            "[Batch 2] Current Loss: 2.7247\n",
            "[Batch 3] Current Loss: 3.2120\n",
            "[Batch 4] Current Loss: 2.8240\n",
            "[Batch 5] Current Loss: 3.5221\n",
            "[Batch 6] Current Loss: 3.2757\n",
            "[Batch 7] Current Loss: 2.7083\n",
            "[Batch 8] Current Loss: 3.4991\n",
            "[Batch 9] Current Loss: 3.8401\n",
            "[Batch 0] Current Loss: 6.0138\n",
            "[Batch 1] Current Loss: 5.6507\n",
            "[Batch 2] Current Loss: 5.3554\n",
            "[Batch 3] Current Loss: 6.0894\n",
            "[Batch 4] Current Loss: 5.7893\n",
            "[Batch 5] Current Loss: 5.3249\n",
            "[Batch 6] Current Loss: 5.3419\n",
            "[Batch 7] Current Loss: 4.6556\n",
            "[Batch 8] Current Loss: 4.8854\n",
            "[Batch 9] Current Loss: 4.8440\n",
            "Ep 3 (Step 021500): Train loss 3.219, Val loss 5.395\n",
            "[Batch 0] Current Loss: 3.0840\n",
            "[Batch 1] Current Loss: 3.2159\n",
            "[Batch 2] Current Loss: 3.0638\n",
            "[Batch 3] Current Loss: 2.3693\n",
            "[Batch 4] Current Loss: 2.9786\n",
            "[Batch 5] Current Loss: 2.9155\n",
            "[Batch 6] Current Loss: 3.2339\n",
            "[Batch 7] Current Loss: 2.9264\n",
            "[Batch 8] Current Loss: 3.7381\n",
            "[Batch 9] Current Loss: 3.0790\n",
            "[Batch 0] Current Loss: 5.5181\n",
            "[Batch 1] Current Loss: 5.2936\n",
            "[Batch 2] Current Loss: 5.4411\n",
            "[Batch 3] Current Loss: 6.4943\n",
            "[Batch 4] Current Loss: 5.6030\n",
            "[Batch 5] Current Loss: 4.8481\n",
            "[Batch 6] Current Loss: 5.6406\n",
            "[Batch 7] Current Loss: 5.7768\n",
            "[Batch 8] Current Loss: 4.2389\n",
            "[Batch 9] Current Loss: 5.4933\n",
            "Ep 3 (Step 021520): Train loss 3.060, Val loss 5.435\n",
            "[Batch 0] Current Loss: 2.8606\n",
            "[Batch 1] Current Loss: 2.6936\n",
            "[Batch 2] Current Loss: 3.2953\n",
            "[Batch 3] Current Loss: 3.2893\n",
            "[Batch 4] Current Loss: 2.8730\n",
            "[Batch 5] Current Loss: 3.1109\n",
            "[Batch 6] Current Loss: 3.3837\n",
            "[Batch 7] Current Loss: 3.4062\n",
            "[Batch 8] Current Loss: 3.4849\n",
            "[Batch 9] Current Loss: 2.5317\n",
            "[Batch 0] Current Loss: 5.4228\n",
            "[Batch 1] Current Loss: 4.4721\n",
            "[Batch 2] Current Loss: 5.6197\n",
            "[Batch 3] Current Loss: 4.9610\n",
            "[Batch 4] Current Loss: 5.3623\n",
            "[Batch 5] Current Loss: 4.8474\n",
            "[Batch 6] Current Loss: 5.3722\n",
            "[Batch 7] Current Loss: 5.1404\n",
            "[Batch 8] Current Loss: 5.1952\n",
            "[Batch 9] Current Loss: 5.5259\n",
            "Ep 3 (Step 021540): Train loss 3.093, Val loss 5.192\n",
            "[Batch 0] Current Loss: 3.9957\n",
            "[Batch 1] Current Loss: 3.5229\n",
            "[Batch 2] Current Loss: 2.4481\n",
            "[Batch 3] Current Loss: 2.5693\n",
            "[Batch 4] Current Loss: 2.4510\n",
            "[Batch 5] Current Loss: 3.0785\n",
            "[Batch 6] Current Loss: 3.0988\n",
            "[Batch 7] Current Loss: 2.9390\n",
            "[Batch 8] Current Loss: 2.9700\n",
            "[Batch 9] Current Loss: 2.9166\n",
            "[Batch 0] Current Loss: 5.5372\n",
            "[Batch 1] Current Loss: 5.4712\n",
            "[Batch 2] Current Loss: 5.8204\n",
            "[Batch 3] Current Loss: 5.5899\n",
            "[Batch 4] Current Loss: 4.9447\n",
            "[Batch 5] Current Loss: 5.7661\n",
            "[Batch 6] Current Loss: 5.2934\n",
            "[Batch 7] Current Loss: 5.2071\n",
            "[Batch 8] Current Loss: 5.4504\n",
            "[Batch 9] Current Loss: 4.9470\n",
            "Ep 3 (Step 021560): Train loss 2.999, Val loss 5.403\n",
            "[Batch 0] Current Loss: 2.7344\n",
            "[Batch 1] Current Loss: 3.2712\n",
            "[Batch 2] Current Loss: 3.3371\n",
            "[Batch 3] Current Loss: 3.2835\n",
            "[Batch 4] Current Loss: 3.2642\n",
            "[Batch 5] Current Loss: 2.4249\n",
            "[Batch 6] Current Loss: 3.1318\n",
            "[Batch 7] Current Loss: 3.1970\n",
            "[Batch 8] Current Loss: 2.8992\n",
            "[Batch 9] Current Loss: 2.9432\n",
            "[Batch 0] Current Loss: 5.3329\n",
            "[Batch 1] Current Loss: 5.8380\n",
            "[Batch 2] Current Loss: 5.4053\n",
            "[Batch 3] Current Loss: 5.5185\n",
            "[Batch 4] Current Loss: 5.3614\n",
            "[Batch 5] Current Loss: 5.4011\n",
            "[Batch 6] Current Loss: 5.3524\n",
            "[Batch 7] Current Loss: 5.2162\n",
            "[Batch 8] Current Loss: 5.3804\n",
            "[Batch 9] Current Loss: 5.7921\n",
            "Ep 3 (Step 021580): Train loss 3.049, Val loss 5.460\n",
            "[Batch 0] Current Loss: 2.1227\n",
            "[Batch 1] Current Loss: 3.4124\n",
            "[Batch 2] Current Loss: 2.9731\n",
            "[Batch 3] Current Loss: 2.8988\n",
            "[Batch 4] Current Loss: 3.1838\n",
            "[Batch 5] Current Loss: 2.7135\n",
            "[Batch 6] Current Loss: 2.9860\n",
            "[Batch 7] Current Loss: 2.8009\n",
            "[Batch 8] Current Loss: 2.9153\n",
            "[Batch 9] Current Loss: 2.9924\n",
            "[Batch 0] Current Loss: 5.6675\n",
            "[Batch 1] Current Loss: 5.8450\n",
            "[Batch 2] Current Loss: 5.5119\n",
            "[Batch 3] Current Loss: 5.0006\n",
            "[Batch 4] Current Loss: 5.4686\n",
            "[Batch 5] Current Loss: 4.4673\n",
            "[Batch 6] Current Loss: 5.6953\n",
            "[Batch 7] Current Loss: 5.3120\n",
            "[Batch 8] Current Loss: 4.9423\n",
            "[Batch 9] Current Loss: 4.9531\n",
            "Ep 3 (Step 021600): Train loss 2.900, Val loss 5.286\n",
            "[Batch 0] Current Loss: 3.1110\n",
            "[Batch 1] Current Loss: 3.3265\n",
            "[Batch 2] Current Loss: 3.2255\n",
            "[Batch 3] Current Loss: 3.4187\n",
            "[Batch 4] Current Loss: 3.1860\n",
            "[Batch 5] Current Loss: 3.5690\n",
            "[Batch 6] Current Loss: 2.8808\n",
            "[Batch 7] Current Loss: 3.5107\n",
            "[Batch 8] Current Loss: 2.8191\n",
            "[Batch 9] Current Loss: 2.7971\n",
            "[Batch 0] Current Loss: 5.8841\n",
            "[Batch 1] Current Loss: 5.6964\n",
            "[Batch 2] Current Loss: 5.5263\n",
            "[Batch 3] Current Loss: 5.9291\n",
            "[Batch 4] Current Loss: 4.9786\n",
            "[Batch 5] Current Loss: 5.1609\n",
            "[Batch 6] Current Loss: 5.5980\n",
            "[Batch 7] Current Loss: 5.6952\n",
            "[Batch 8] Current Loss: 5.3082\n",
            "[Batch 9] Current Loss: 5.2764\n",
            "Ep 3 (Step 021620): Train loss 3.184, Val loss 5.505\n",
            "[Batch 0] Current Loss: 4.2650\n",
            "[Batch 1] Current Loss: 3.5690\n",
            "[Batch 2] Current Loss: 3.3143\n",
            "[Batch 3] Current Loss: 3.1565\n",
            "[Batch 4] Current Loss: 3.2259\n",
            "[Batch 5] Current Loss: 2.7387\n",
            "[Batch 6] Current Loss: 3.2301\n",
            "[Batch 7] Current Loss: 4.0114\n",
            "[Batch 8] Current Loss: 2.6959\n",
            "[Batch 9] Current Loss: 3.0535\n",
            "[Batch 0] Current Loss: 6.1258\n",
            "[Batch 1] Current Loss: 4.9495\n",
            "[Batch 2] Current Loss: 5.1291\n",
            "[Batch 3] Current Loss: 5.0504\n",
            "[Batch 4] Current Loss: 5.0483\n",
            "[Batch 5] Current Loss: 4.8037\n",
            "[Batch 6] Current Loss: 5.4018\n",
            "[Batch 7] Current Loss: 5.6380\n",
            "[Batch 8] Current Loss: 5.3896\n",
            "[Batch 9] Current Loss: 5.1698\n",
            "Ep 3 (Step 021640): Train loss 3.326, Val loss 5.271\n",
            "[Batch 0] Current Loss: 2.6330\n",
            "[Batch 1] Current Loss: 3.1257\n",
            "[Batch 2] Current Loss: 2.9363\n",
            "[Batch 3] Current Loss: 3.5704\n",
            "[Batch 4] Current Loss: 3.0903\n",
            "[Batch 5] Current Loss: 3.4655\n",
            "[Batch 6] Current Loss: 3.1655\n",
            "[Batch 7] Current Loss: 3.2433\n",
            "[Batch 8] Current Loss: 3.2834\n",
            "[Batch 9] Current Loss: 3.0018\n",
            "[Batch 0] Current Loss: 5.1404\n",
            "[Batch 1] Current Loss: 5.0981\n",
            "[Batch 2] Current Loss: 5.4550\n",
            "[Batch 3] Current Loss: 5.3531\n",
            "[Batch 4] Current Loss: 5.1588\n",
            "[Batch 5] Current Loss: 5.6008\n",
            "[Batch 6] Current Loss: 6.1722\n",
            "[Batch 7] Current Loss: 5.3127\n",
            "[Batch 8] Current Loss: 5.3636\n",
            "[Batch 9] Current Loss: 6.0401\n",
            "Ep 3 (Step 021660): Train loss 3.152, Val loss 5.469\n",
            "[Batch 0] Current Loss: 2.5991\n",
            "[Batch 1] Current Loss: 3.3474\n",
            "[Batch 2] Current Loss: 2.9667\n",
            "[Batch 3] Current Loss: 3.6291\n",
            "[Batch 4] Current Loss: 2.7625\n",
            "[Batch 5] Current Loss: 3.1317\n",
            "[Batch 6] Current Loss: 3.0541\n",
            "[Batch 7] Current Loss: 3.2940\n",
            "[Batch 8] Current Loss: 2.7512\n",
            "[Batch 9] Current Loss: 3.0700\n",
            "[Batch 0] Current Loss: 5.9684\n",
            "[Batch 1] Current Loss: 5.2944\n",
            "[Batch 2] Current Loss: 5.1453\n",
            "[Batch 3] Current Loss: 5.3748\n",
            "[Batch 4] Current Loss: 5.0085\n",
            "[Batch 5] Current Loss: 4.6177\n",
            "[Batch 6] Current Loss: 5.8759\n",
            "[Batch 7] Current Loss: 5.4132\n",
            "[Batch 8] Current Loss: 5.5060\n",
            "[Batch 9] Current Loss: 5.3764\n",
            "Ep 3 (Step 021680): Train loss 3.061, Val loss 5.358\n",
            "[Batch 0] Current Loss: 3.2870\n",
            "[Batch 1] Current Loss: 3.0837\n",
            "[Batch 2] Current Loss: 3.0671\n",
            "[Batch 3] Current Loss: 3.0551\n",
            "[Batch 4] Current Loss: 2.8428\n",
            "[Batch 5] Current Loss: 3.1898\n",
            "[Batch 6] Current Loss: 2.7931\n",
            "[Batch 7] Current Loss: 3.7941\n",
            "[Batch 8] Current Loss: 2.8530\n",
            "[Batch 9] Current Loss: 4.0654\n",
            "[Batch 0] Current Loss: 5.3690\n",
            "[Batch 1] Current Loss: 4.8652\n",
            "[Batch 2] Current Loss: 5.2715\n",
            "[Batch 3] Current Loss: 4.9707\n",
            "[Batch 4] Current Loss: 5.6110\n",
            "[Batch 5] Current Loss: 5.4171\n",
            "[Batch 6] Current Loss: 4.7392\n",
            "[Batch 7] Current Loss: 5.2679\n",
            "[Batch 8] Current Loss: 5.6085\n",
            "[Batch 9] Current Loss: 4.8487\n",
            "Ep 3 (Step 021700): Train loss 3.203, Val loss 5.197\n",
            "[Batch 0] Current Loss: 3.0369\n",
            "[Batch 1] Current Loss: 3.1034\n",
            "[Batch 2] Current Loss: 3.5135\n",
            "[Batch 3] Current Loss: 2.8486\n",
            "[Batch 4] Current Loss: 3.1115\n",
            "[Batch 5] Current Loss: 3.2431\n",
            "[Batch 6] Current Loss: 3.3013\n",
            "[Batch 7] Current Loss: 3.3496\n",
            "[Batch 8] Current Loss: 3.6516\n",
            "[Batch 9] Current Loss: 2.5924\n",
            "[Batch 0] Current Loss: 5.3838\n",
            "[Batch 1] Current Loss: 5.0749\n",
            "[Batch 2] Current Loss: 5.9349\n",
            "[Batch 3] Current Loss: 6.0001\n",
            "[Batch 4] Current Loss: 5.5729\n",
            "[Batch 5] Current Loss: 5.2354\n",
            "[Batch 6] Current Loss: 5.2319\n",
            "[Batch 7] Current Loss: 5.2496\n",
            "[Batch 8] Current Loss: 5.2670\n",
            "[Batch 9] Current Loss: 4.6870\n",
            "Ep 3 (Step 021720): Train loss 3.175, Val loss 5.364\n",
            "[Batch 0] Current Loss: 3.3227\n",
            "[Batch 1] Current Loss: 3.0060\n",
            "[Batch 2] Current Loss: 2.7673\n",
            "[Batch 3] Current Loss: 3.4674\n",
            "[Batch 4] Current Loss: 3.1743\n",
            "[Batch 5] Current Loss: 3.4691\n",
            "[Batch 6] Current Loss: 2.6701\n",
            "[Batch 7] Current Loss: 3.2705\n",
            "[Batch 8] Current Loss: 2.3210\n",
            "[Batch 9] Current Loss: 3.1988\n",
            "[Batch 0] Current Loss: 5.7349\n",
            "[Batch 1] Current Loss: 5.2641\n",
            "[Batch 2] Current Loss: 5.1125\n",
            "[Batch 3] Current Loss: 5.6778\n",
            "[Batch 4] Current Loss: 4.7963\n",
            "[Batch 5] Current Loss: 5.2286\n",
            "[Batch 6] Current Loss: 5.1211\n",
            "[Batch 7] Current Loss: 5.2616\n",
            "[Batch 8] Current Loss: 5.2216\n",
            "[Batch 9] Current Loss: 5.6106\n",
            "Ep 3 (Step 021740): Train loss 3.067, Val loss 5.303\n",
            "[Batch 0] Current Loss: 2.9926\n",
            "[Batch 1] Current Loss: 2.8623\n",
            "[Batch 2] Current Loss: 2.9951\n",
            "[Batch 3] Current Loss: 2.8889\n",
            "[Batch 4] Current Loss: 2.8100\n",
            "[Batch 5] Current Loss: 2.5658\n",
            "[Batch 6] Current Loss: 2.6104\n",
            "[Batch 7] Current Loss: 3.3425\n",
            "[Batch 8] Current Loss: 3.0527\n",
            "[Batch 9] Current Loss: 2.8267\n",
            "[Batch 0] Current Loss: 5.8454\n",
            "[Batch 1] Current Loss: 4.9394\n",
            "[Batch 2] Current Loss: 4.9385\n",
            "[Batch 3] Current Loss: 5.7146\n",
            "[Batch 4] Current Loss: 5.9454\n",
            "[Batch 5] Current Loss: 5.5593\n",
            "[Batch 6] Current Loss: 5.5823\n",
            "[Batch 7] Current Loss: 4.6792\n",
            "[Batch 8] Current Loss: 5.3330\n",
            "[Batch 9] Current Loss: 5.3580\n",
            "Ep 3 (Step 021760): Train loss 2.895, Val loss 5.390\n",
            "[Batch 0] Current Loss: 3.6784\n",
            "[Batch 1] Current Loss: 2.4435\n",
            "[Batch 2] Current Loss: 2.8832\n",
            "[Batch 3] Current Loss: 3.6184\n",
            "[Batch 4] Current Loss: 2.9629\n",
            "[Batch 5] Current Loss: 2.9369\n",
            "[Batch 6] Current Loss: 3.2294\n",
            "[Batch 7] Current Loss: 2.6012\n",
            "[Batch 8] Current Loss: 3.6464\n",
            "[Batch 9] Current Loss: 3.3077\n",
            "[Batch 0] Current Loss: 5.1604\n",
            "[Batch 1] Current Loss: 5.4012\n",
            "[Batch 2] Current Loss: 4.9249\n",
            "[Batch 3] Current Loss: 5.2883\n",
            "[Batch 4] Current Loss: 5.3909\n",
            "[Batch 5] Current Loss: 4.6710\n",
            "[Batch 6] Current Loss: 5.0200\n",
            "[Batch 7] Current Loss: 4.3600\n",
            "[Batch 8] Current Loss: 5.5043\n",
            "[Batch 9] Current Loss: 4.1804\n",
            "Ep 3 (Step 021780): Train loss 3.131, Val loss 4.990\n",
            "[Batch 0] Current Loss: 3.0075\n",
            "[Batch 1] Current Loss: 3.1960\n",
            "[Batch 2] Current Loss: 3.2150\n",
            "[Batch 3] Current Loss: 3.3645\n",
            "[Batch 4] Current Loss: 2.6596\n",
            "[Batch 5] Current Loss: 3.1571\n",
            "[Batch 6] Current Loss: 3.4619\n",
            "[Batch 7] Current Loss: 3.4006\n",
            "[Batch 8] Current Loss: 2.9156\n",
            "[Batch 9] Current Loss: 3.7687\n",
            "[Batch 0] Current Loss: 4.9546\n",
            "[Batch 1] Current Loss: 5.4816\n",
            "[Batch 2] Current Loss: 4.3473\n",
            "[Batch 3] Current Loss: 4.7866\n",
            "[Batch 4] Current Loss: 5.3212\n",
            "[Batch 5] Current Loss: 5.4013\n",
            "[Batch 6] Current Loss: 5.9457\n",
            "[Batch 7] Current Loss: 5.2837\n",
            "[Batch 8] Current Loss: 5.0693\n",
            "[Batch 9] Current Loss: 4.9749\n",
            "Ep 3 (Step 021800): Train loss 3.215, Val loss 5.157\n",
            "[Batch 0] Current Loss: 2.7714\n",
            "[Batch 1] Current Loss: 2.7786\n",
            "[Batch 2] Current Loss: 3.3361\n",
            "[Batch 3] Current Loss: 2.7733\n",
            "[Batch 4] Current Loss: 2.9021\n",
            "[Batch 5] Current Loss: 2.9013\n",
            "[Batch 6] Current Loss: 2.6114\n",
            "[Batch 7] Current Loss: 3.7700\n",
            "[Batch 8] Current Loss: 3.0357\n",
            "[Batch 9] Current Loss: 3.4522\n",
            "[Batch 0] Current Loss: 5.0598\n",
            "[Batch 1] Current Loss: 5.4930\n",
            "[Batch 2] Current Loss: 5.0437\n",
            "[Batch 3] Current Loss: 5.3805\n",
            "[Batch 4] Current Loss: 5.3379\n",
            "[Batch 5] Current Loss: 5.1051\n",
            "[Batch 6] Current Loss: 5.0691\n",
            "[Batch 7] Current Loss: 5.8413\n",
            "[Batch 8] Current Loss: 5.1889\n",
            "[Batch 9] Current Loss: 5.3661\n",
            "Ep 3 (Step 021820): Train loss 3.033, Val loss 5.289\n",
            "[Batch 0] Current Loss: 2.7102\n",
            "[Batch 1] Current Loss: 2.8479\n",
            "[Batch 2] Current Loss: 3.8683\n",
            "[Batch 3] Current Loss: 3.3054\n",
            "[Batch 4] Current Loss: 3.6039\n",
            "[Batch 5] Current Loss: 3.2133\n",
            "[Batch 6] Current Loss: 3.0685\n",
            "[Batch 7] Current Loss: 3.1007\n",
            "[Batch 8] Current Loss: 4.1337\n",
            "[Batch 9] Current Loss: 2.4899\n",
            "[Batch 0] Current Loss: 4.7839\n",
            "[Batch 1] Current Loss: 4.9161\n",
            "[Batch 2] Current Loss: 5.0084\n",
            "[Batch 3] Current Loss: 5.6173\n",
            "[Batch 4] Current Loss: 5.5344\n",
            "[Batch 5] Current Loss: 5.5270\n",
            "[Batch 6] Current Loss: 5.1814\n",
            "[Batch 7] Current Loss: 5.1284\n",
            "[Batch 8] Current Loss: 4.5473\n",
            "[Batch 9] Current Loss: 5.2435\n",
            "Ep 3 (Step 021840): Train loss 3.234, Val loss 5.149\n",
            "[Batch 0] Current Loss: 3.3441\n",
            "[Batch 1] Current Loss: 2.9496\n",
            "[Batch 2] Current Loss: 2.9528\n",
            "[Batch 3] Current Loss: 2.9818\n",
            "[Batch 4] Current Loss: 2.9700\n",
            "[Batch 5] Current Loss: 3.3102\n",
            "[Batch 6] Current Loss: 2.5887\n",
            "[Batch 7] Current Loss: 3.5671\n",
            "[Batch 8] Current Loss: 3.0044\n",
            "[Batch 9] Current Loss: 3.1284\n",
            "[Batch 0] Current Loss: 5.2199\n",
            "[Batch 1] Current Loss: 5.9204\n",
            "[Batch 2] Current Loss: 4.9083\n",
            "[Batch 3] Current Loss: 4.9663\n",
            "[Batch 4] Current Loss: 5.6626\n",
            "[Batch 5] Current Loss: 5.1745\n",
            "[Batch 6] Current Loss: 5.5338\n",
            "[Batch 7] Current Loss: 5.7153\n",
            "[Batch 8] Current Loss: 6.0803\n",
            "[Batch 9] Current Loss: 5.3324\n",
            "Ep 3 (Step 021860): Train loss 3.080, Val loss 5.451\n",
            "[Batch 0] Current Loss: 3.1458\n",
            "[Batch 1] Current Loss: 3.0364\n",
            "[Batch 2] Current Loss: 2.4047\n",
            "[Batch 3] Current Loss: 3.0437\n",
            "[Batch 4] Current Loss: 2.8995\n",
            "[Batch 5] Current Loss: 3.2059\n",
            "[Batch 6] Current Loss: 3.4899\n",
            "[Batch 7] Current Loss: 2.8091\n",
            "[Batch 8] Current Loss: 3.0112\n",
            "[Batch 9] Current Loss: 3.0307\n",
            "[Batch 0] Current Loss: 5.6145\n",
            "[Batch 1] Current Loss: 5.0201\n",
            "[Batch 2] Current Loss: 6.0617\n",
            "[Batch 3] Current Loss: 5.2435\n",
            "[Batch 4] Current Loss: 5.6606\n",
            "[Batch 5] Current Loss: 5.3197\n",
            "[Batch 6] Current Loss: 5.8557\n",
            "[Batch 7] Current Loss: 5.0753\n",
            "[Batch 8] Current Loss: 5.6435\n",
            "[Batch 9] Current Loss: 4.7287\n",
            "Ep 3 (Step 021880): Train loss 3.008, Val loss 5.422\n",
            "[Batch 0] Current Loss: 3.5535\n",
            "[Batch 1] Current Loss: 3.6281\n",
            "[Batch 2] Current Loss: 3.3663\n",
            "[Batch 3] Current Loss: 2.7710\n",
            "[Batch 4] Current Loss: 3.0381\n",
            "[Batch 5] Current Loss: 3.3048\n",
            "[Batch 6] Current Loss: 3.4226\n",
            "[Batch 7] Current Loss: 3.0391\n",
            "[Batch 8] Current Loss: 2.7588\n",
            "[Batch 9] Current Loss: 2.9021\n",
            "[Batch 0] Current Loss: 5.0699\n",
            "[Batch 1] Current Loss: 5.5912\n",
            "[Batch 2] Current Loss: 4.9870\n",
            "[Batch 3] Current Loss: 4.8368\n",
            "[Batch 4] Current Loss: 5.1366\n",
            "[Batch 5] Current Loss: 4.8701\n",
            "[Batch 6] Current Loss: 5.0818\n",
            "[Batch 7] Current Loss: 5.5240\n",
            "[Batch 8] Current Loss: 4.9710\n",
            "[Batch 9] Current Loss: 4.5447\n",
            "Ep 3 (Step 021900): Train loss 3.178, Val loss 5.061\n",
            "[Batch 0] Current Loss: 3.4292\n",
            "[Batch 1] Current Loss: 3.0533\n",
            "[Batch 2] Current Loss: 3.7391\n",
            "[Batch 3] Current Loss: 3.0301\n",
            "[Batch 4] Current Loss: 2.9297\n",
            "[Batch 5] Current Loss: 2.5810\n",
            "[Batch 6] Current Loss: 2.7002\n",
            "[Batch 7] Current Loss: 3.3134\n",
            "[Batch 8] Current Loss: 3.2042\n",
            "[Batch 9] Current Loss: 3.0647\n",
            "[Batch 0] Current Loss: 4.7375\n",
            "[Batch 1] Current Loss: 5.6998\n",
            "[Batch 2] Current Loss: 5.1065\n",
            "[Batch 3] Current Loss: 4.9461\n",
            "[Batch 4] Current Loss: 4.7712\n",
            "[Batch 5] Current Loss: 5.5188\n",
            "[Batch 6] Current Loss: 5.3458\n",
            "[Batch 7] Current Loss: 5.0311\n",
            "[Batch 8] Current Loss: 5.3156\n",
            "[Batch 9] Current Loss: 5.7855\n",
            "Ep 3 (Step 021920): Train loss 3.105, Val loss 5.226\n",
            "[Batch 0] Current Loss: 2.9720\n",
            "[Batch 1] Current Loss: 3.3144\n",
            "[Batch 2] Current Loss: 3.2940\n",
            "[Batch 3] Current Loss: 3.0944\n",
            "[Batch 4] Current Loss: 3.2416\n",
            "[Batch 5] Current Loss: 2.4733\n",
            "[Batch 6] Current Loss: 3.6126\n",
            "[Batch 7] Current Loss: 3.3721\n",
            "[Batch 8] Current Loss: 3.4632\n",
            "[Batch 9] Current Loss: 2.7063\n",
            "[Batch 0] Current Loss: 5.7477\n",
            "[Batch 1] Current Loss: 4.7179\n",
            "[Batch 2] Current Loss: 4.8831\n",
            "[Batch 3] Current Loss: 5.9942\n",
            "[Batch 4] Current Loss: 5.5608\n",
            "[Batch 5] Current Loss: 5.0688\n",
            "[Batch 6] Current Loss: 5.2925\n",
            "[Batch 7] Current Loss: 4.9585\n",
            "[Batch 8] Current Loss: 5.9137\n",
            "[Batch 9] Current Loss: 5.5702\n",
            "Ep 3 (Step 021940): Train loss 3.154, Val loss 5.371\n",
            "[Batch 0] Current Loss: 2.7355\n",
            "[Batch 1] Current Loss: 3.0087\n",
            "[Batch 2] Current Loss: 2.8468\n",
            "[Batch 3] Current Loss: 3.0608\n",
            "[Batch 4] Current Loss: 2.7598\n",
            "[Batch 5] Current Loss: 3.0135\n",
            "[Batch 6] Current Loss: 3.3699\n",
            "[Batch 7] Current Loss: 3.1836\n",
            "[Batch 8] Current Loss: 3.1079\n",
            "[Batch 9] Current Loss: 2.6206\n",
            "[Batch 0] Current Loss: 5.0511\n",
            "[Batch 1] Current Loss: 4.2710\n",
            "[Batch 2] Current Loss: 5.5394\n",
            "[Batch 3] Current Loss: 6.2023\n",
            "[Batch 4] Current Loss: 5.8706\n",
            "[Batch 5] Current Loss: 5.6217\n",
            "[Batch 6] Current Loss: 4.6338\n",
            "[Batch 7] Current Loss: 4.9858\n",
            "[Batch 8] Current Loss: 5.8673\n",
            "[Batch 9] Current Loss: 5.0758\n",
            "Ep 3 (Step 021960): Train loss 2.971, Val loss 5.312\n",
            "[Batch 0] Current Loss: 2.4045\n",
            "[Batch 1] Current Loss: 3.1418\n",
            "[Batch 2] Current Loss: 3.2173\n",
            "[Batch 3] Current Loss: 2.8934\n",
            "[Batch 4] Current Loss: 3.1524\n",
            "[Batch 5] Current Loss: 3.3848\n",
            "[Batch 6] Current Loss: 3.4479\n",
            "[Batch 7] Current Loss: 2.0738\n",
            "[Batch 8] Current Loss: 2.7474\n",
            "[Batch 9] Current Loss: 2.2673\n",
            "[Batch 0] Current Loss: 5.2442\n",
            "[Batch 1] Current Loss: 5.7568\n",
            "[Batch 2] Current Loss: 5.1755\n",
            "[Batch 3] Current Loss: 4.9702\n",
            "[Batch 4] Current Loss: 5.3646\n",
            "[Batch 5] Current Loss: 5.1047\n",
            "[Batch 6] Current Loss: 5.5069\n",
            "[Batch 7] Current Loss: 5.0942\n",
            "[Batch 8] Current Loss: 5.8488\n",
            "[Batch 9] Current Loss: 5.1563\n",
            "Ep 3 (Step 021980): Train loss 2.873, Val loss 5.322\n",
            "[Batch 0] Current Loss: 3.0866\n",
            "[Batch 1] Current Loss: 3.0116\n",
            "[Batch 2] Current Loss: 2.4302\n",
            "[Batch 3] Current Loss: 2.8772\n",
            "[Batch 4] Current Loss: 3.3904\n",
            "[Batch 5] Current Loss: 3.3019\n",
            "[Batch 6] Current Loss: 3.1860\n",
            "[Batch 7] Current Loss: 2.9946\n",
            "[Batch 8] Current Loss: 3.1627\n",
            "[Batch 9] Current Loss: 3.1686\n",
            "[Batch 0] Current Loss: 5.0453\n",
            "[Batch 1] Current Loss: 6.0702\n",
            "[Batch 2] Current Loss: 5.3903\n",
            "[Batch 3] Current Loss: 5.8896\n",
            "[Batch 4] Current Loss: 5.5714\n",
            "[Batch 5] Current Loss: 6.0259\n",
            "[Batch 6] Current Loss: 4.9542\n",
            "[Batch 7] Current Loss: 5.1857\n",
            "[Batch 8] Current Loss: 5.7628\n",
            "[Batch 9] Current Loss: 4.9636\n",
            "Ep 3 (Step 022000): Train loss 3.061, Val loss 5.486\n",
            "[Batch 0] Current Loss: 2.2678\n",
            "[Batch 1] Current Loss: 3.2193\n",
            "[Batch 2] Current Loss: 2.9414\n",
            "[Batch 3] Current Loss: 2.5592\n",
            "[Batch 4] Current Loss: 3.6906\n",
            "[Batch 5] Current Loss: 3.1563\n",
            "[Batch 6] Current Loss: 2.4637\n",
            "[Batch 7] Current Loss: 2.6721\n",
            "[Batch 8] Current Loss: 2.3230\n",
            "[Batch 9] Current Loss: 3.1469\n",
            "[Batch 0] Current Loss: 5.7801\n",
            "[Batch 1] Current Loss: 4.8876\n",
            "[Batch 2] Current Loss: 5.3526\n",
            "[Batch 3] Current Loss: 5.3822\n",
            "[Batch 4] Current Loss: 5.4748\n",
            "[Batch 5] Current Loss: 4.7064\n",
            "[Batch 6] Current Loss: 5.0665\n",
            "[Batch 7] Current Loss: 5.7618\n",
            "[Batch 8] Current Loss: 5.2738\n",
            "[Batch 9] Current Loss: 4.2442\n",
            "Ep 3 (Step 022020): Train loss 2.844, Val loss 5.193\n",
            "[Batch 0] Current Loss: 3.0270\n",
            "[Batch 1] Current Loss: 3.0490\n",
            "[Batch 2] Current Loss: 3.3910\n",
            "[Batch 3] Current Loss: 3.1558\n",
            "[Batch 4] Current Loss: 2.8184\n",
            "[Batch 5] Current Loss: 2.3064\n",
            "[Batch 6] Current Loss: 2.6578\n",
            "[Batch 7] Current Loss: 2.6527\n",
            "[Batch 8] Current Loss: 3.1680\n",
            "[Batch 9] Current Loss: 3.3611\n",
            "[Batch 0] Current Loss: 4.9779\n",
            "[Batch 1] Current Loss: 5.4959\n",
            "[Batch 2] Current Loss: 5.0084\n",
            "[Batch 3] Current Loss: 4.7305\n",
            "[Batch 4] Current Loss: 5.6394\n",
            "[Batch 5] Current Loss: 5.8661\n",
            "[Batch 6] Current Loss: 5.3446\n",
            "[Batch 7] Current Loss: 5.6113\n",
            "[Batch 8] Current Loss: 5.5839\n",
            "[Batch 9] Current Loss: 6.0508\n",
            "Ep 3 (Step 022040): Train loss 2.959, Val loss 5.431\n",
            "[Batch 0] Current Loss: 2.6547\n",
            "[Batch 1] Current Loss: 2.7068\n",
            "[Batch 2] Current Loss: 2.5615\n",
            "[Batch 3] Current Loss: 3.6336\n",
            "[Batch 4] Current Loss: 3.1710\n",
            "[Batch 5] Current Loss: 2.8984\n",
            "[Batch 6] Current Loss: 2.2975\n",
            "[Batch 7] Current Loss: 3.4497\n",
            "[Batch 8] Current Loss: 2.9553\n",
            "[Batch 9] Current Loss: 3.2766\n",
            "[Batch 0] Current Loss: 5.6386\n",
            "[Batch 1] Current Loss: 4.9122\n",
            "[Batch 2] Current Loss: 5.7283\n",
            "[Batch 3] Current Loss: 5.6402\n",
            "[Batch 4] Current Loss: 5.0937\n",
            "[Batch 5] Current Loss: 5.5983\n",
            "[Batch 6] Current Loss: 5.4912\n",
            "[Batch 7] Current Loss: 5.0660\n",
            "[Batch 8] Current Loss: 5.0535\n",
            "[Batch 9] Current Loss: 4.9720\n",
            "Ep 3 (Step 022060): Train loss 2.961, Val loss 5.319\n",
            "[Batch 0] Current Loss: 3.2189\n",
            "[Batch 1] Current Loss: 3.0841\n",
            "[Batch 2] Current Loss: 2.9268\n",
            "[Batch 3] Current Loss: 2.9292\n",
            "[Batch 4] Current Loss: 3.4468\n",
            "[Batch 5] Current Loss: 3.1976\n",
            "[Batch 6] Current Loss: 3.4145\n",
            "[Batch 7] Current Loss: 2.9992\n",
            "[Batch 8] Current Loss: 3.1357\n",
            "[Batch 9] Current Loss: 3.5470\n",
            "[Batch 0] Current Loss: 5.4828\n",
            "[Batch 1] Current Loss: 4.8044\n",
            "[Batch 2] Current Loss: 4.8165\n",
            "[Batch 3] Current Loss: 4.6895\n",
            "[Batch 4] Current Loss: 4.7021\n",
            "[Batch 5] Current Loss: 4.9958\n",
            "[Batch 6] Current Loss: 5.5488\n",
            "[Batch 7] Current Loss: 4.7564\n",
            "[Batch 8] Current Loss: 6.0558\n",
            "[Batch 9] Current Loss: 5.6292\n",
            "Ep 3 (Step 022080): Train loss 3.190, Val loss 5.148\n",
            "[Batch 0] Current Loss: 3.0566\n",
            "[Batch 1] Current Loss: 3.3627\n",
            "[Batch 2] Current Loss: 3.8648\n",
            "[Batch 3] Current Loss: 3.0694\n",
            "[Batch 4] Current Loss: 2.3753\n",
            "[Batch 5] Current Loss: 2.7738\n",
            "[Batch 6] Current Loss: 3.2248\n",
            "[Batch 7] Current Loss: 3.5612\n",
            "[Batch 8] Current Loss: 2.8250\n",
            "[Batch 9] Current Loss: 2.8944\n",
            "[Batch 0] Current Loss: 4.9912\n",
            "[Batch 1] Current Loss: 5.7315\n",
            "[Batch 2] Current Loss: 5.1870\n",
            "[Batch 3] Current Loss: 5.1217\n",
            "[Batch 4] Current Loss: 5.1571\n",
            "[Batch 5] Current Loss: 5.3462\n",
            "[Batch 6] Current Loss: 5.4582\n",
            "[Batch 7] Current Loss: 5.5952\n",
            "[Batch 8] Current Loss: 4.9374\n",
            "[Batch 9] Current Loss: 6.3236\n",
            "Ep 3 (Step 022100): Train loss 3.101, Val loss 5.385\n",
            "[Batch 0] Current Loss: 3.7577\n",
            "[Batch 1] Current Loss: 3.5259\n",
            "[Batch 2] Current Loss: 2.6980\n",
            "[Batch 3] Current Loss: 3.5487\n",
            "[Batch 4] Current Loss: 2.6893\n",
            "[Batch 5] Current Loss: 2.4495\n",
            "[Batch 6] Current Loss: 3.6032\n",
            "[Batch 7] Current Loss: 3.2130\n",
            "[Batch 8] Current Loss: 2.8203\n",
            "[Batch 9] Current Loss: 3.0503\n",
            "[Batch 0] Current Loss: 5.6156\n",
            "[Batch 1] Current Loss: 4.6195\n",
            "[Batch 2] Current Loss: 6.0060\n",
            "[Batch 3] Current Loss: 5.2267\n",
            "[Batch 4] Current Loss: 5.5034\n",
            "[Batch 5] Current Loss: 4.7127\n",
            "[Batch 6] Current Loss: 4.7927\n",
            "[Batch 7] Current Loss: 4.9606\n",
            "[Batch 8] Current Loss: 6.0387\n",
            "[Batch 9] Current Loss: 5.8383\n",
            "Ep 3 (Step 022120): Train loss 3.136, Val loss 5.331\n",
            "[Batch 0] Current Loss: 3.6381\n",
            "[Batch 1] Current Loss: 3.0760\n",
            "[Batch 2] Current Loss: 3.0021\n",
            "[Batch 3] Current Loss: 2.9649\n",
            "[Batch 4] Current Loss: 3.8195\n",
            "[Batch 5] Current Loss: 3.5109\n",
            "[Batch 6] Current Loss: 3.2781\n",
            "[Batch 7] Current Loss: 3.2992\n",
            "[Batch 8] Current Loss: 3.2713\n",
            "[Batch 9] Current Loss: 2.1937\n",
            "[Batch 0] Current Loss: 4.4697\n",
            "[Batch 1] Current Loss: 5.1730\n",
            "[Batch 2] Current Loss: 4.5086\n",
            "[Batch 3] Current Loss: 5.4736\n",
            "[Batch 4] Current Loss: 4.6731\n",
            "[Batch 5] Current Loss: 5.4356\n",
            "[Batch 6] Current Loss: 4.5909\n",
            "[Batch 7] Current Loss: 5.4198\n",
            "[Batch 8] Current Loss: 5.1347\n",
            "[Batch 9] Current Loss: 5.4262\n",
            "Ep 3 (Step 022140): Train loss 3.205, Val loss 5.031\n",
            "[Batch 0] Current Loss: 3.1129\n",
            "[Batch 1] Current Loss: 2.9924\n",
            "[Batch 2] Current Loss: 3.5454\n",
            "[Batch 3] Current Loss: 3.1004\n",
            "[Batch 4] Current Loss: 2.8187\n",
            "[Batch 5] Current Loss: 3.6958\n",
            "[Batch 6] Current Loss: 3.2543\n",
            "[Batch 7] Current Loss: 3.3145\n",
            "[Batch 8] Current Loss: 3.3386\n",
            "[Batch 9] Current Loss: 2.5044\n",
            "[Batch 0] Current Loss: 5.6479\n",
            "[Batch 1] Current Loss: 5.4348\n",
            "[Batch 2] Current Loss: 5.3785\n",
            "[Batch 3] Current Loss: 5.3003\n",
            "[Batch 4] Current Loss: 5.4232\n",
            "[Batch 5] Current Loss: 5.1218\n",
            "[Batch 6] Current Loss: 4.8940\n",
            "[Batch 7] Current Loss: 4.9841\n",
            "[Batch 8] Current Loss: 5.6701\n",
            "[Batch 9] Current Loss: 5.2419\n",
            "Ep 3 (Step 022160): Train loss 3.168, Val loss 5.310\n",
            "[Batch 0] Current Loss: 2.8596\n",
            "[Batch 1] Current Loss: 3.1175\n",
            "[Batch 2] Current Loss: 3.3721\n",
            "[Batch 3] Current Loss: 3.4033\n",
            "[Batch 4] Current Loss: 3.0691\n",
            "[Batch 5] Current Loss: 2.5017\n",
            "[Batch 6] Current Loss: 2.5525\n",
            "[Batch 7] Current Loss: 2.9785\n",
            "[Batch 8] Current Loss: 2.8478\n",
            "[Batch 9] Current Loss: 3.3878\n",
            "[Batch 0] Current Loss: 4.8081\n",
            "[Batch 1] Current Loss: 6.1663\n",
            "[Batch 2] Current Loss: 4.8307\n",
            "[Batch 3] Current Loss: 5.5168\n",
            "[Batch 4] Current Loss: 4.9382\n",
            "[Batch 5] Current Loss: 5.7304\n",
            "[Batch 6] Current Loss: 5.5722\n",
            "[Batch 7] Current Loss: 4.7381\n",
            "[Batch 8] Current Loss: 5.3341\n",
            "[Batch 9] Current Loss: 5.3420\n",
            "Ep 3 (Step 022180): Train loss 3.009, Val loss 5.298\n",
            "[Batch 0] Current Loss: 3.3273\n",
            "[Batch 1] Current Loss: 2.8808\n",
            "[Batch 2] Current Loss: 2.9415\n",
            "[Batch 3] Current Loss: 3.1514\n",
            "[Batch 4] Current Loss: 2.8849\n",
            "[Batch 5] Current Loss: 3.4256\n",
            "[Batch 6] Current Loss: 2.9507\n",
            "[Batch 7] Current Loss: 2.9324\n",
            "[Batch 8] Current Loss: 2.2964\n",
            "[Batch 9] Current Loss: 3.0712\n",
            "[Batch 0] Current Loss: 4.7325\n",
            "[Batch 1] Current Loss: 5.2714\n",
            "[Batch 2] Current Loss: 5.7104\n",
            "[Batch 3] Current Loss: 6.0587\n",
            "[Batch 4] Current Loss: 5.3152\n",
            "[Batch 5] Current Loss: 4.7206\n",
            "[Batch 6] Current Loss: 4.9415\n",
            "[Batch 7] Current Loss: 4.9468\n",
            "[Batch 8] Current Loss: 5.1008\n",
            "[Batch 9] Current Loss: 5.7279\n",
            "Ep 3 (Step 022200): Train loss 2.986, Val loss 5.253\n",
            "[Batch 0] Current Loss: 2.4640\n",
            "[Batch 1] Current Loss: 2.8398\n",
            "[Batch 2] Current Loss: 3.7804\n",
            "[Batch 3] Current Loss: 3.0640\n",
            "[Batch 4] Current Loss: 3.3493\n",
            "[Batch 5] Current Loss: 2.6623\n",
            "[Batch 6] Current Loss: 2.8504\n",
            "[Batch 7] Current Loss: 2.9199\n",
            "[Batch 8] Current Loss: 3.6087\n",
            "[Batch 9] Current Loss: 2.6722\n",
            "[Batch 0] Current Loss: 5.5844\n",
            "[Batch 1] Current Loss: 5.4887\n",
            "[Batch 2] Current Loss: 5.3487\n",
            "[Batch 3] Current Loss: 5.8991\n",
            "[Batch 4] Current Loss: 5.2296\n",
            "[Batch 5] Current Loss: 5.0331\n",
            "[Batch 6] Current Loss: 5.1496\n",
            "[Batch 7] Current Loss: 5.2065\n",
            "[Batch 8] Current Loss: 5.1851\n",
            "[Batch 9] Current Loss: 4.9748\n",
            "Ep 3 (Step 022220): Train loss 3.021, Val loss 5.310\n",
            "[Batch 0] Current Loss: 2.8792\n",
            "[Batch 1] Current Loss: 2.9547\n",
            "[Batch 2] Current Loss: 3.5903\n",
            "[Batch 3] Current Loss: 2.8491\n",
            "[Batch 4] Current Loss: 2.6156\n",
            "[Batch 5] Current Loss: 2.7981\n",
            "[Batch 6] Current Loss: 3.6778\n",
            "[Batch 7] Current Loss: 3.3816\n",
            "[Batch 8] Current Loss: 2.7310\n",
            "[Batch 9] Current Loss: 3.1423\n",
            "[Batch 0] Current Loss: 5.5299\n",
            "[Batch 1] Current Loss: 4.8080\n",
            "[Batch 2] Current Loss: 5.4776\n",
            "[Batch 3] Current Loss: 5.8329\n",
            "[Batch 4] Current Loss: 5.5805\n",
            "[Batch 5] Current Loss: 5.0069\n",
            "[Batch 6] Current Loss: 6.3061\n",
            "[Batch 7] Current Loss: 5.0529\n",
            "[Batch 8] Current Loss: 5.1551\n",
            "[Batch 9] Current Loss: 5.4008\n",
            "Ep 3 (Step 022240): Train loss 3.062, Val loss 5.415\n",
            "[Batch 0] Current Loss: 3.2989\n",
            "[Batch 1] Current Loss: 3.4740\n",
            "[Batch 2] Current Loss: 3.0598\n",
            "[Batch 3] Current Loss: 3.5069\n",
            "[Batch 4] Current Loss: 2.2872\n",
            "[Batch 5] Current Loss: 2.4629\n",
            "[Batch 6] Current Loss: 3.1651\n",
            "[Batch 7] Current Loss: 2.6308\n",
            "[Batch 8] Current Loss: 3.1752\n",
            "[Batch 9] Current Loss: 2.7794\n",
            "[Batch 0] Current Loss: 4.4297\n",
            "[Batch 1] Current Loss: 5.4860\n",
            "[Batch 2] Current Loss: 4.8476\n",
            "[Batch 3] Current Loss: 4.9496\n",
            "[Batch 4] Current Loss: 5.3170\n",
            "[Batch 5] Current Loss: 5.6730\n",
            "[Batch 6] Current Loss: 5.0798\n",
            "[Batch 7] Current Loss: 4.4085\n",
            "[Batch 8] Current Loss: 5.4902\n",
            "[Batch 9] Current Loss: 5.1698\n",
            "Ep 3 (Step 022260): Train loss 2.984, Val loss 5.085\n",
            "[Batch 0] Current Loss: 3.2805\n",
            "[Batch 1] Current Loss: 2.7244\n",
            "[Batch 2] Current Loss: 2.7570\n",
            "[Batch 3] Current Loss: 2.8501\n",
            "[Batch 4] Current Loss: 2.8580\n",
            "[Batch 5] Current Loss: 3.2015\n",
            "[Batch 6] Current Loss: 2.6347\n",
            "[Batch 7] Current Loss: 2.1246\n",
            "[Batch 8] Current Loss: 3.7488\n",
            "[Batch 9] Current Loss: 2.9003\n",
            "[Batch 0] Current Loss: 4.7513\n",
            "[Batch 1] Current Loss: 5.6950\n",
            "[Batch 2] Current Loss: 5.7130\n",
            "[Batch 3] Current Loss: 4.8079\n",
            "[Batch 4] Current Loss: 4.8966\n",
            "[Batch 5] Current Loss: 5.0157\n",
            "[Batch 6] Current Loss: 5.3427\n",
            "[Batch 7] Current Loss: 5.3834\n",
            "[Batch 8] Current Loss: 5.3407\n",
            "[Batch 9] Current Loss: 5.4329\n",
            "Ep 3 (Step 022280): Train loss 2.908, Val loss 5.238\n",
            "[Batch 0] Current Loss: 3.1197\n",
            "[Batch 1] Current Loss: 3.4134\n",
            "[Batch 2] Current Loss: 3.4877\n",
            "[Batch 3] Current Loss: 3.0043\n",
            "[Batch 4] Current Loss: 3.0075\n",
            "[Batch 5] Current Loss: 3.3696\n",
            "[Batch 6] Current Loss: 3.1668\n",
            "[Batch 7] Current Loss: 3.4882\n",
            "[Batch 8] Current Loss: 2.9722\n",
            "[Batch 9] Current Loss: 2.2807\n",
            "[Batch 0] Current Loss: 4.5348\n",
            "[Batch 1] Current Loss: 5.1444\n",
            "[Batch 2] Current Loss: 5.0387\n",
            "[Batch 3] Current Loss: 5.3555\n",
            "[Batch 4] Current Loss: 5.1191\n",
            "[Batch 5] Current Loss: 5.2972\n",
            "[Batch 6] Current Loss: 5.5803\n",
            "[Batch 7] Current Loss: 5.4444\n",
            "[Batch 8] Current Loss: 4.3978\n",
            "[Batch 9] Current Loss: 4.9835\n",
            "Ep 3 (Step 022300): Train loss 3.131, Val loss 5.090\n",
            "[Batch 0] Current Loss: 3.4015\n",
            "[Batch 1] Current Loss: 2.2056\n",
            "[Batch 2] Current Loss: 2.8100\n",
            "[Batch 3] Current Loss: 2.8641\n",
            "[Batch 4] Current Loss: 2.8451\n",
            "[Batch 5] Current Loss: 3.7047\n",
            "[Batch 6] Current Loss: 2.6745\n",
            "[Batch 7] Current Loss: 2.6623\n",
            "[Batch 8] Current Loss: 2.5979\n",
            "[Batch 9] Current Loss: 2.8753\n",
            "[Batch 0] Current Loss: 4.6933\n",
            "[Batch 1] Current Loss: 5.5358\n",
            "[Batch 2] Current Loss: 5.5094\n",
            "[Batch 3] Current Loss: 5.8182\n",
            "[Batch 4] Current Loss: 5.5302\n",
            "[Batch 5] Current Loss: 5.5996\n",
            "[Batch 6] Current Loss: 5.5677\n",
            "[Batch 7] Current Loss: 5.5937\n",
            "[Batch 8] Current Loss: 5.1853\n",
            "[Batch 9] Current Loss: 5.4833\n",
            "Ep 3 (Step 022320): Train loss 2.864, Val loss 5.452\n",
            "[Batch 0] Current Loss: 2.8330\n",
            "[Batch 1] Current Loss: 3.6029\n",
            "[Batch 2] Current Loss: 2.7062\n",
            "[Batch 3] Current Loss: 2.8544\n",
            "[Batch 4] Current Loss: 3.0198\n",
            "[Batch 5] Current Loss: 2.7674\n",
            "[Batch 6] Current Loss: 2.9355\n",
            "[Batch 7] Current Loss: 2.6225\n",
            "[Batch 8] Current Loss: 2.4367\n",
            "[Batch 9] Current Loss: 2.6118\n",
            "[Batch 0] Current Loss: 5.4024\n",
            "[Batch 1] Current Loss: 5.6262\n",
            "[Batch 2] Current Loss: 5.1077\n",
            "[Batch 3] Current Loss: 6.0439\n",
            "[Batch 4] Current Loss: 5.4439\n",
            "[Batch 5] Current Loss: 5.8619\n",
            "[Batch 6] Current Loss: 5.6291\n",
            "[Batch 7] Current Loss: 5.5158\n",
            "[Batch 8] Current Loss: 5.2402\n",
            "[Batch 9] Current Loss: 5.3111\n",
            "Ep 3 (Step 022340): Train loss 2.839, Val loss 5.518\n",
            "[Batch 0] Current Loss: 3.0734\n",
            "[Batch 1] Current Loss: 2.6207\n",
            "[Batch 2] Current Loss: 3.0804\n",
            "[Batch 3] Current Loss: 3.1125\n",
            "[Batch 4] Current Loss: 3.2747\n",
            "[Batch 5] Current Loss: 3.2015\n",
            "[Batch 6] Current Loss: 3.6977\n",
            "[Batch 7] Current Loss: 3.0041\n",
            "[Batch 8] Current Loss: 2.7467\n",
            "[Batch 9] Current Loss: 2.9615\n",
            "[Batch 0] Current Loss: 5.2276\n",
            "[Batch 1] Current Loss: 5.0550\n",
            "[Batch 2] Current Loss: 5.3696\n",
            "[Batch 3] Current Loss: 4.9216\n",
            "[Batch 4] Current Loss: 4.8668\n",
            "[Batch 5] Current Loss: 5.5130\n",
            "[Batch 6] Current Loss: 5.6255\n",
            "[Batch 7] Current Loss: 4.8806\n",
            "[Batch 8] Current Loss: 5.9605\n",
            "[Batch 9] Current Loss: 5.2738\n",
            "Ep 3 (Step 022360): Train loss 3.077, Val loss 5.269\n",
            "[Batch 0] Current Loss: 3.4351\n",
            "[Batch 1] Current Loss: 2.9475\n",
            "[Batch 2] Current Loss: 3.4905\n",
            "[Batch 3] Current Loss: 2.4854\n",
            "[Batch 4] Current Loss: 3.0556\n",
            "[Batch 5] Current Loss: 2.9572\n",
            "[Batch 6] Current Loss: 3.0236\n",
            "[Batch 7] Current Loss: 2.4983\n",
            "[Batch 8] Current Loss: 3.2712\n",
            "[Batch 9] Current Loss: 2.0306\n",
            "[Batch 0] Current Loss: 5.3519\n",
            "[Batch 1] Current Loss: 5.4159\n",
            "[Batch 2] Current Loss: 5.5668\n",
            "[Batch 3] Current Loss: 5.0984\n",
            "[Batch 4] Current Loss: 4.8563\n",
            "[Batch 5] Current Loss: 5.5094\n",
            "[Batch 6] Current Loss: 5.9111\n",
            "[Batch 7] Current Loss: 5.2994\n",
            "[Batch 8] Current Loss: 5.3720\n",
            "[Batch 9] Current Loss: 5.7244\n",
            "Ep 3 (Step 022380): Train loss 2.920, Val loss 5.411\n",
            "[Batch 0] Current Loss: 2.4580\n",
            "[Batch 1] Current Loss: 2.8493\n",
            "[Batch 2] Current Loss: 2.8578\n",
            "[Batch 3] Current Loss: 3.3122\n",
            "[Batch 4] Current Loss: 3.3527\n",
            "[Batch 5] Current Loss: 2.4406\n",
            "[Batch 6] Current Loss: 2.7249\n",
            "[Batch 7] Current Loss: 2.9767\n",
            "[Batch 8] Current Loss: 3.0501\n",
            "[Batch 9] Current Loss: 2.4584\n",
            "[Batch 0] Current Loss: 4.8236\n",
            "[Batch 1] Current Loss: 5.5962\n",
            "[Batch 2] Current Loss: 5.5491\n",
            "[Batch 3] Current Loss: 5.2725\n",
            "[Batch 4] Current Loss: 5.4778\n",
            "[Batch 5] Current Loss: 6.0536\n",
            "[Batch 6] Current Loss: 5.3909\n",
            "[Batch 7] Current Loss: 5.3191\n",
            "[Batch 8] Current Loss: 5.2566\n",
            "[Batch 9] Current Loss: 5.7589\n",
            "Ep 3 (Step 022400): Train loss 2.848, Val loss 5.450\n",
            "[Batch 0] Current Loss: 3.2657\n",
            "[Batch 1] Current Loss: 3.2795\n",
            "[Batch 2] Current Loss: 3.1602\n",
            "[Batch 3] Current Loss: 2.8735\n",
            "[Batch 4] Current Loss: 2.5922\n",
            "[Batch 5] Current Loss: 3.1330\n",
            "[Batch 6] Current Loss: 3.1100\n",
            "[Batch 7] Current Loss: 2.1489\n",
            "[Batch 8] Current Loss: 3.0931\n",
            "[Batch 9] Current Loss: 2.7680\n",
            "[Batch 0] Current Loss: 5.3182\n",
            "[Batch 1] Current Loss: 5.8874\n",
            "[Batch 2] Current Loss: 5.5074\n",
            "[Batch 3] Current Loss: 5.6484\n",
            "[Batch 4] Current Loss: 6.2517\n",
            "[Batch 5] Current Loss: 5.4103\n",
            "[Batch 6] Current Loss: 4.7353\n",
            "[Batch 7] Current Loss: 5.5180\n",
            "[Batch 8] Current Loss: 5.0505\n",
            "[Batch 9] Current Loss: 4.9410\n",
            "Ep 3 (Step 022420): Train loss 2.942, Val loss 5.427\n",
            "[Batch 0] Current Loss: 2.7149\n",
            "[Batch 1] Current Loss: 2.8089\n",
            "[Batch 2] Current Loss: 3.0160\n",
            "[Batch 3] Current Loss: 3.7900\n",
            "[Batch 4] Current Loss: 3.4410\n",
            "[Batch 5] Current Loss: 2.8493\n",
            "[Batch 6] Current Loss: 2.3657\n",
            "[Batch 7] Current Loss: 3.4996\n",
            "[Batch 8] Current Loss: 2.8407\n",
            "[Batch 9] Current Loss: 3.7408\n",
            "[Batch 0] Current Loss: 4.9786\n",
            "[Batch 1] Current Loss: 4.6622\n",
            "[Batch 2] Current Loss: 5.2804\n",
            "[Batch 3] Current Loss: 5.2617\n",
            "[Batch 4] Current Loss: 5.3116\n",
            "[Batch 5] Current Loss: 5.2795\n",
            "[Batch 6] Current Loss: 4.8350\n",
            "[Batch 7] Current Loss: 4.9505\n",
            "[Batch 8] Current Loss: 5.6209\n",
            "[Batch 9] Current Loss: 5.4581\n",
            "Ep 3 (Step 022440): Train loss 3.107, Val loss 5.164\n",
            "[Batch 0] Current Loss: 2.6797\n",
            "[Batch 1] Current Loss: 2.7491\n",
            "[Batch 2] Current Loss: 3.0265\n",
            "[Batch 3] Current Loss: 2.9419\n",
            "[Batch 4] Current Loss: 2.9798\n",
            "[Batch 5] Current Loss: 3.1997\n",
            "[Batch 6] Current Loss: 3.1903\n",
            "[Batch 7] Current Loss: 2.6530\n",
            "[Batch 8] Current Loss: 2.7439\n",
            "[Batch 9] Current Loss: 2.5843\n",
            "[Batch 0] Current Loss: 5.5002\n",
            "[Batch 1] Current Loss: 5.5938\n",
            "[Batch 2] Current Loss: 4.9732\n",
            "[Batch 3] Current Loss: 5.5642\n",
            "[Batch 4] Current Loss: 5.2609\n",
            "[Batch 5] Current Loss: 5.4729\n",
            "[Batch 6] Current Loss: 5.4877\n",
            "[Batch 7] Current Loss: 4.7586\n",
            "[Batch 8] Current Loss: 5.0226\n",
            "[Batch 9] Current Loss: 5.4788\n",
            "Ep 3 (Step 022460): Train loss 2.875, Val loss 5.311\n",
            "[Batch 0] Current Loss: 2.7441\n",
            "[Batch 1] Current Loss: 3.7286\n",
            "[Batch 2] Current Loss: 2.4943\n",
            "[Batch 3] Current Loss: 3.0557\n",
            "[Batch 4] Current Loss: 3.0598\n",
            "[Batch 5] Current Loss: 3.3722\n",
            "[Batch 6] Current Loss: 2.5468\n",
            "[Batch 7] Current Loss: 2.6792\n",
            "[Batch 8] Current Loss: 2.7233\n",
            "[Batch 9] Current Loss: 2.9674\n",
            "[Batch 0] Current Loss: 5.7916\n",
            "[Batch 1] Current Loss: 5.3302\n",
            "[Batch 2] Current Loss: 4.9884\n",
            "[Batch 3] Current Loss: 5.5717\n",
            "[Batch 4] Current Loss: 4.7149\n",
            "[Batch 5] Current Loss: 5.3984\n",
            "[Batch 6] Current Loss: 5.8408\n",
            "[Batch 7] Current Loss: 5.2048\n",
            "[Batch 8] Current Loss: 5.2411\n",
            "[Batch 9] Current Loss: 5.3253\n",
            "Ep 3 (Step 022480): Train loss 2.937, Val loss 5.341\n",
            "[Batch 0] Current Loss: 3.3683\n",
            "[Batch 1] Current Loss: 3.1569\n",
            "[Batch 2] Current Loss: 2.5253\n",
            "[Batch 3] Current Loss: 2.7545\n",
            "[Batch 4] Current Loss: 2.7691\n",
            "[Batch 5] Current Loss: 3.4582\n",
            "[Batch 6] Current Loss: 3.1556\n",
            "[Batch 7] Current Loss: 2.8874\n",
            "[Batch 8] Current Loss: 3.4355\n",
            "[Batch 9] Current Loss: 2.7610\n",
            "[Batch 0] Current Loss: 5.3866\n",
            "[Batch 1] Current Loss: 4.9965\n",
            "[Batch 2] Current Loss: 5.6089\n",
            "[Batch 3] Current Loss: 5.7666\n",
            "[Batch 4] Current Loss: 4.4314\n",
            "[Batch 5] Current Loss: 5.2403\n",
            "[Batch 6] Current Loss: 5.1134\n",
            "[Batch 7] Current Loss: 5.7436\n",
            "[Batch 8] Current Loss: 5.5568\n",
            "[Batch 9] Current Loss: 5.4626\n",
            "Ep 3 (Step 022500): Train loss 3.027, Val loss 5.331\n",
            "[Batch 0] Current Loss: 2.8398\n",
            "[Batch 1] Current Loss: 2.7316\n",
            "[Batch 2] Current Loss: 3.2487\n",
            "[Batch 3] Current Loss: 2.7442\n",
            "[Batch 4] Current Loss: 3.1508\n",
            "[Batch 5] Current Loss: 3.6362\n",
            "[Batch 6] Current Loss: 3.0469\n",
            "[Batch 7] Current Loss: 2.9620\n",
            "[Batch 8] Current Loss: 2.9350\n",
            "[Batch 9] Current Loss: 3.2817\n",
            "[Batch 0] Current Loss: 5.0930\n",
            "[Batch 1] Current Loss: 6.0842\n",
            "[Batch 2] Current Loss: 4.9142\n",
            "[Batch 3] Current Loss: 4.5616\n",
            "[Batch 4] Current Loss: 5.6328\n",
            "[Batch 5] Current Loss: 5.6682\n",
            "[Batch 6] Current Loss: 4.7366\n",
            "[Batch 7] Current Loss: 5.6802\n",
            "[Batch 8] Current Loss: 5.8886\n",
            "[Batch 9] Current Loss: 5.1779\n",
            "Ep 3 (Step 022520): Train loss 3.058, Val loss 5.344\n",
            "[Batch 0] Current Loss: 3.1556\n",
            "[Batch 1] Current Loss: 2.6663\n",
            "[Batch 2] Current Loss: 2.8440\n",
            "[Batch 3] Current Loss: 2.5247\n",
            "[Batch 4] Current Loss: 3.0391\n",
            "[Batch 5] Current Loss: 3.5244\n",
            "[Batch 6] Current Loss: 2.7538\n",
            "[Batch 7] Current Loss: 3.2918\n",
            "[Batch 8] Current Loss: 3.0513\n",
            "[Batch 9] Current Loss: 2.0559\n",
            "[Batch 0] Current Loss: 4.6650\n",
            "[Batch 1] Current Loss: 5.6330\n",
            "[Batch 2] Current Loss: 5.5300\n",
            "[Batch 3] Current Loss: 5.3466\n",
            "[Batch 4] Current Loss: 5.3404\n",
            "[Batch 5] Current Loss: 6.1441\n",
            "[Batch 6] Current Loss: 5.2162\n",
            "[Batch 7] Current Loss: 5.8693\n",
            "[Batch 8] Current Loss: 5.1355\n",
            "[Batch 9] Current Loss: 5.2425\n",
            "Ep 3 (Step 022540): Train loss 2.891, Val loss 5.412\n",
            "[Batch 0] Current Loss: 2.6814\n",
            "[Batch 1] Current Loss: 2.6631\n",
            "[Batch 2] Current Loss: 3.2279\n",
            "[Batch 3] Current Loss: 2.2706\n",
            "[Batch 4] Current Loss: 2.6026\n",
            "[Batch 5] Current Loss: 2.7143\n",
            "[Batch 6] Current Loss: 3.5558\n",
            "[Batch 7] Current Loss: 3.0992\n",
            "[Batch 8] Current Loss: 3.2817\n",
            "[Batch 9] Current Loss: 3.5184\n",
            "[Batch 0] Current Loss: 5.6095\n",
            "[Batch 1] Current Loss: 5.1576\n",
            "[Batch 2] Current Loss: 4.9235\n",
            "[Batch 3] Current Loss: 5.7694\n",
            "[Batch 4] Current Loss: 4.9151\n",
            "[Batch 5] Current Loss: 5.5849\n",
            "[Batch 6] Current Loss: 5.3237\n",
            "[Batch 7] Current Loss: 5.5077\n",
            "[Batch 8] Current Loss: 4.8660\n",
            "[Batch 9] Current Loss: 5.7810\n",
            "Ep 3 (Step 022560): Train loss 2.961, Val loss 5.344\n",
            "[Batch 0] Current Loss: 2.8600\n",
            "[Batch 1] Current Loss: 3.3129\n",
            "[Batch 2] Current Loss: 3.0688\n",
            "[Batch 3] Current Loss: 2.6577\n",
            "[Batch 4] Current Loss: 3.5909\n",
            "[Batch 5] Current Loss: 3.2778\n",
            "[Batch 6] Current Loss: 3.2323\n",
            "[Batch 7] Current Loss: 2.7253\n",
            "[Batch 8] Current Loss: 2.9212\n",
            "[Batch 9] Current Loss: 2.5059\n",
            "[Batch 0] Current Loss: 5.3199\n",
            "[Batch 1] Current Loss: 5.0525\n",
            "[Batch 2] Current Loss: 5.1274\n",
            "[Batch 3] Current Loss: 5.4698\n",
            "[Batch 4] Current Loss: 4.6987\n",
            "[Batch 5] Current Loss: 6.1282\n",
            "[Batch 6] Current Loss: 4.9424\n",
            "[Batch 7] Current Loss: 5.4796\n",
            "[Batch 8] Current Loss: 5.0105\n",
            "[Batch 9] Current Loss: 5.2953\n",
            "Ep 3 (Step 022580): Train loss 3.015, Val loss 5.252\n",
            "[Batch 0] Current Loss: 3.1111\n",
            "[Batch 1] Current Loss: 2.9398\n",
            "[Batch 2] Current Loss: 2.8312\n",
            "[Batch 3] Current Loss: 3.2498\n",
            "[Batch 4] Current Loss: 3.1930\n",
            "[Batch 5] Current Loss: 3.0842\n",
            "[Batch 6] Current Loss: 3.0175\n",
            "[Batch 7] Current Loss: 2.5032\n",
            "[Batch 8] Current Loss: 3.4794\n",
            "[Batch 9] Current Loss: 3.3798\n",
            "[Batch 0] Current Loss: 5.5724\n",
            "[Batch 1] Current Loss: 5.2235\n",
            "[Batch 2] Current Loss: 6.2085\n",
            "[Batch 3] Current Loss: 4.8464\n",
            "[Batch 4] Current Loss: 5.1881\n",
            "[Batch 5] Current Loss: 5.9762\n",
            "[Batch 6] Current Loss: 5.3884\n",
            "[Batch 7] Current Loss: 5.9496\n",
            "[Batch 8] Current Loss: 5.2295\n",
            "[Batch 9] Current Loss: 4.6350\n",
            "Ep 3 (Step 022600): Train loss 3.079, Val loss 5.422\n",
            "[Batch 0] Current Loss: 3.0875\n",
            "[Batch 1] Current Loss: 3.2298\n",
            "[Batch 2] Current Loss: 3.4774\n",
            "[Batch 3] Current Loss: 3.1714\n",
            "[Batch 4] Current Loss: 2.5473\n",
            "[Batch 5] Current Loss: 2.9352\n",
            "[Batch 6] Current Loss: 3.0994\n",
            "[Batch 7] Current Loss: 3.1484\n",
            "[Batch 8] Current Loss: 2.2974\n",
            "[Batch 9] Current Loss: 2.5000\n",
            "[Batch 0] Current Loss: 4.8721\n",
            "[Batch 1] Current Loss: 5.8038\n",
            "[Batch 2] Current Loss: 4.9731\n",
            "[Batch 3] Current Loss: 5.1850\n",
            "[Batch 4] Current Loss: 4.4745\n",
            "[Batch 5] Current Loss: 5.6251\n",
            "[Batch 6] Current Loss: 4.7371\n",
            "[Batch 7] Current Loss: 5.3174\n",
            "[Batch 8] Current Loss: 5.0632\n",
            "[Batch 9] Current Loss: 4.8129\n",
            "Ep 3 (Step 022620): Train loss 2.949, Val loss 5.086\n",
            "[Batch 0] Current Loss: 3.5774\n",
            "[Batch 1] Current Loss: 3.3696\n",
            "[Batch 2] Current Loss: 2.5982\n",
            "[Batch 3] Current Loss: 2.7900\n",
            "[Batch 4] Current Loss: 2.6639\n",
            "[Batch 5] Current Loss: 2.2253\n",
            "[Batch 6] Current Loss: 2.7704\n",
            "[Batch 7] Current Loss: 3.0085\n",
            "[Batch 8] Current Loss: 2.6039\n",
            "[Batch 9] Current Loss: 3.7668\n",
            "[Batch 0] Current Loss: 5.0292\n",
            "[Batch 1] Current Loss: 4.5341\n",
            "[Batch 2] Current Loss: 5.2868\n",
            "[Batch 3] Current Loss: 5.5562\n",
            "[Batch 4] Current Loss: 5.8497\n",
            "[Batch 5] Current Loss: 5.3826\n",
            "[Batch 6] Current Loss: 6.1455\n",
            "[Batch 7] Current Loss: 5.2539\n",
            "[Batch 8] Current Loss: 5.2219\n",
            "[Batch 9] Current Loss: 5.6183\n",
            "Ep 3 (Step 022640): Train loss 2.937, Val loss 5.388\n",
            "[Batch 0] Current Loss: 2.8722\n",
            "[Batch 1] Current Loss: 3.0485\n",
            "[Batch 2] Current Loss: 3.3220\n",
            "[Batch 3] Current Loss: 2.4506\n",
            "[Batch 4] Current Loss: 3.2494\n",
            "[Batch 5] Current Loss: 3.0084\n",
            "[Batch 6] Current Loss: 2.9762\n",
            "[Batch 7] Current Loss: 3.0088\n",
            "[Batch 8] Current Loss: 2.9803\n",
            "[Batch 9] Current Loss: 3.5692\n",
            "[Batch 0] Current Loss: 5.5352\n",
            "[Batch 1] Current Loss: 5.3298\n",
            "[Batch 2] Current Loss: 5.5355\n",
            "[Batch 3] Current Loss: 5.3376\n",
            "[Batch 4] Current Loss: 5.6841\n",
            "[Batch 5] Current Loss: 5.5335\n",
            "[Batch 6] Current Loss: 4.9984\n",
            "[Batch 7] Current Loss: 5.5377\n",
            "[Batch 8] Current Loss: 5.4812\n",
            "[Batch 9] Current Loss: 5.8624\n",
            "Ep 3 (Step 022660): Train loss 3.049, Val loss 5.484\n",
            "[Batch 0] Current Loss: 2.4518\n",
            "[Batch 1] Current Loss: 3.0394\n",
            "[Batch 2] Current Loss: 3.0576\n",
            "[Batch 3] Current Loss: 2.9748\n",
            "[Batch 4] Current Loss: 2.8848\n",
            "[Batch 5] Current Loss: 2.4577\n",
            "[Batch 6] Current Loss: 3.4474\n",
            "[Batch 7] Current Loss: 2.7078\n",
            "[Batch 8] Current Loss: 3.0115\n",
            "[Batch 9] Current Loss: 2.5272\n",
            "[Batch 0] Current Loss: 5.5257\n",
            "[Batch 1] Current Loss: 4.7286\n",
            "[Batch 2] Current Loss: 4.3875\n",
            "[Batch 3] Current Loss: 5.3455\n",
            "[Batch 4] Current Loss: 5.6719\n",
            "[Batch 5] Current Loss: 5.2997\n",
            "[Batch 6] Current Loss: 5.3567\n",
            "[Batch 7] Current Loss: 5.4271\n",
            "[Batch 8] Current Loss: 5.0598\n",
            "[Batch 9] Current Loss: 5.6889\n",
            "Ep 3 (Step 022680): Train loss 2.856, Val loss 5.249\n",
            "[Batch 0] Current Loss: 3.2597\n",
            "[Batch 1] Current Loss: 2.7907\n",
            "[Batch 2] Current Loss: 2.2751\n",
            "[Batch 3] Current Loss: 3.4589\n",
            "[Batch 4] Current Loss: 3.1399\n",
            "[Batch 5] Current Loss: 2.8915\n",
            "[Batch 6] Current Loss: 2.8681\n",
            "[Batch 7] Current Loss: 3.0757\n",
            "[Batch 8] Current Loss: 1.9362\n",
            "[Batch 9] Current Loss: 2.3655\n",
            "[Batch 0] Current Loss: 5.2103\n",
            "[Batch 1] Current Loss: 5.8358\n",
            "[Batch 2] Current Loss: 6.2397\n",
            "[Batch 3] Current Loss: 4.8184\n",
            "[Batch 4] Current Loss: 5.1676\n",
            "[Batch 5] Current Loss: 5.5418\n",
            "[Batch 6] Current Loss: 5.4119\n",
            "[Batch 7] Current Loss: 5.7348\n",
            "[Batch 8] Current Loss: 5.4375\n",
            "[Batch 9] Current Loss: 5.2607\n",
            "Ep 3 (Step 022700): Train loss 2.806, Val loss 5.466\n",
            "[Batch 0] Current Loss: 3.5606\n",
            "[Batch 1] Current Loss: 2.6050\n",
            "[Batch 2] Current Loss: 2.6551\n",
            "[Batch 3] Current Loss: 2.9585\n",
            "[Batch 4] Current Loss: 2.8542\n",
            "[Batch 5] Current Loss: 3.1607\n",
            "[Batch 6] Current Loss: 3.4192\n",
            "[Batch 7] Current Loss: 3.0342\n",
            "[Batch 8] Current Loss: 2.9279\n",
            "[Batch 9] Current Loss: 3.4251\n",
            "[Batch 0] Current Loss: 6.3434\n",
            "[Batch 1] Current Loss: 4.7117\n",
            "[Batch 2] Current Loss: 5.3521\n",
            "[Batch 3] Current Loss: 5.0740\n",
            "[Batch 4] Current Loss: 5.0074\n",
            "[Batch 5] Current Loss: 5.6622\n",
            "[Batch 6] Current Loss: 5.6234\n",
            "[Batch 7] Current Loss: 5.0720\n",
            "[Batch 8] Current Loss: 5.1062\n",
            "[Batch 9] Current Loss: 5.3930\n",
            "Ep 3 (Step 022720): Train loss 3.060, Val loss 5.335\n",
            "[Batch 0] Current Loss: 2.9233\n",
            "[Batch 1] Current Loss: 3.8270\n",
            "[Batch 2] Current Loss: 2.3382\n",
            "[Batch 3] Current Loss: 3.3745\n",
            "[Batch 4] Current Loss: 2.1536\n",
            "[Batch 5] Current Loss: 2.3536\n",
            "[Batch 6] Current Loss: 3.7867\n",
            "[Batch 7] Current Loss: 3.5416\n",
            "[Batch 8] Current Loss: 3.5704\n",
            "[Batch 9] Current Loss: 2.5006\n",
            "[Batch 0] Current Loss: 4.5490\n",
            "[Batch 1] Current Loss: 4.8008\n",
            "[Batch 2] Current Loss: 4.7783\n",
            "[Batch 3] Current Loss: 5.6985\n",
            "[Batch 4] Current Loss: 4.7419\n",
            "[Batch 5] Current Loss: 5.0550\n",
            "[Batch 6] Current Loss: 6.1146\n",
            "[Batch 7] Current Loss: 5.3616\n",
            "[Batch 8] Current Loss: 5.5144\n",
            "[Batch 9] Current Loss: 5.2228\n",
            "Ep 3 (Step 022740): Train loss 3.037, Val loss 5.184\n",
            "[Batch 0] Current Loss: 2.9301\n",
            "[Batch 1] Current Loss: 2.8741\n",
            "[Batch 2] Current Loss: 3.2598\n",
            "[Batch 3] Current Loss: 3.3252\n",
            "[Batch 4] Current Loss: 2.6407\n",
            "[Batch 5] Current Loss: 2.6990\n",
            "[Batch 6] Current Loss: 2.7865\n",
            "[Batch 7] Current Loss: 3.0732\n",
            "[Batch 8] Current Loss: 2.3962\n",
            "[Batch 9] Current Loss: 2.9730\n",
            "[Batch 0] Current Loss: 5.1414\n",
            "[Batch 1] Current Loss: 5.7011\n",
            "[Batch 2] Current Loss: 5.1784\n",
            "[Batch 3] Current Loss: 5.3901\n",
            "[Batch 4] Current Loss: 5.0357\n",
            "[Batch 5] Current Loss: 5.4909\n",
            "[Batch 6] Current Loss: 4.9705\n",
            "[Batch 7] Current Loss: 5.7599\n",
            "[Batch 8] Current Loss: 5.4184\n",
            "[Batch 9] Current Loss: 6.0763\n",
            "Ep 3 (Step 022760): Train loss 2.896, Val loss 5.416\n",
            "[Batch 0] Current Loss: 3.2570\n",
            "[Batch 1] Current Loss: 2.6727\n",
            "[Batch 2] Current Loss: 2.7595\n",
            "[Batch 3] Current Loss: 3.4556\n",
            "[Batch 4] Current Loss: 3.5634\n",
            "[Batch 5] Current Loss: 2.6300\n",
            "[Batch 6] Current Loss: 3.1245\n",
            "[Batch 7] Current Loss: 3.1220\n",
            "[Batch 8] Current Loss: 2.7881\n",
            "[Batch 9] Current Loss: 2.7886\n",
            "[Batch 0] Current Loss: 5.7155\n",
            "[Batch 1] Current Loss: 5.4116\n",
            "[Batch 2] Current Loss: 5.4803\n",
            "[Batch 3] Current Loss: 6.3943\n",
            "[Batch 4] Current Loss: 5.1781\n",
            "[Batch 5] Current Loss: 4.8915\n",
            "[Batch 6] Current Loss: 5.8088\n",
            "[Batch 7] Current Loss: 5.8253\n",
            "[Batch 8] Current Loss: 4.6179\n",
            "[Batch 9] Current Loss: 5.6713\n",
            "Ep 3 (Step 022780): Train loss 3.016, Val loss 5.499\n",
            "[Batch 0] Current Loss: 2.9455\n",
            "[Batch 1] Current Loss: 2.8831\n",
            "[Batch 2] Current Loss: 3.1430\n",
            "[Batch 3] Current Loss: 3.3191\n",
            "[Batch 4] Current Loss: 2.8144\n",
            "[Batch 5] Current Loss: 3.2251\n",
            "[Batch 6] Current Loss: 3.1124\n",
            "[Batch 7] Current Loss: 2.4764\n",
            "[Batch 8] Current Loss: 3.8755\n",
            "[Batch 9] Current Loss: 2.7952\n",
            "[Batch 0] Current Loss: 5.6109\n",
            "[Batch 1] Current Loss: 5.4319\n",
            "[Batch 2] Current Loss: 5.1350\n",
            "[Batch 3] Current Loss: 5.6754\n",
            "[Batch 4] Current Loss: 4.8270\n",
            "[Batch 5] Current Loss: 5.1202\n",
            "[Batch 6] Current Loss: 5.6542\n",
            "[Batch 7] Current Loss: 5.2225\n",
            "[Batch 8] Current Loss: 5.1437\n",
            "[Batch 9] Current Loss: 5.4131\n",
            "Ep 3 (Step 022800): Train loss 3.059, Val loss 5.323\n",
            "[Batch 0] Current Loss: 3.0926\n",
            "[Batch 1] Current Loss: 3.0193\n",
            "[Batch 2] Current Loss: 2.5542\n",
            "[Batch 3] Current Loss: 3.2598\n",
            "[Batch 4] Current Loss: 2.9851\n",
            "[Batch 5] Current Loss: 3.5207\n",
            "[Batch 6] Current Loss: 3.1002\n",
            "[Batch 7] Current Loss: 3.3449\n",
            "[Batch 8] Current Loss: 2.5770\n",
            "[Batch 9] Current Loss: 3.5906\n",
            "[Batch 0] Current Loss: 5.5323\n",
            "[Batch 1] Current Loss: 4.7633\n",
            "[Batch 2] Current Loss: 4.9843\n",
            "[Batch 3] Current Loss: 5.1047\n",
            "[Batch 4] Current Loss: 5.6407\n",
            "[Batch 5] Current Loss: 5.7908\n",
            "[Batch 6] Current Loss: 6.1629\n",
            "[Batch 7] Current Loss: 5.5920\n",
            "[Batch 8] Current Loss: 5.0205\n",
            "[Batch 9] Current Loss: 4.9778\n",
            "Ep 3 (Step 022820): Train loss 3.104, Val loss 5.357\n",
            "[Batch 0] Current Loss: 3.0984\n",
            "[Batch 1] Current Loss: 3.5922\n",
            "[Batch 2] Current Loss: 3.2650\n",
            "[Batch 3] Current Loss: 3.4418\n",
            "[Batch 4] Current Loss: 2.7369\n",
            "[Batch 5] Current Loss: 3.2632\n",
            "[Batch 6] Current Loss: 3.1806\n",
            "[Batch 7] Current Loss: 2.8926\n",
            "[Batch 8] Current Loss: 3.0615\n",
            "[Batch 9] Current Loss: 2.7063\n",
            "[Batch 0] Current Loss: 5.2531\n",
            "[Batch 1] Current Loss: 5.6013\n",
            "[Batch 2] Current Loss: 5.3187\n",
            "[Batch 3] Current Loss: 5.8466\n",
            "[Batch 4] Current Loss: 5.3872\n",
            "[Batch 5] Current Loss: 6.0960\n",
            "[Batch 6] Current Loss: 5.0658\n",
            "[Batch 7] Current Loss: 4.5443\n",
            "[Batch 8] Current Loss: 4.0113\n",
            "[Batch 9] Current Loss: 5.6702\n",
            "Ep 3 (Step 022840): Train loss 3.124, Val loss 5.279\n",
            "[Batch 0] Current Loss: 2.7781\n",
            "[Batch 1] Current Loss: 3.2978\n",
            "[Batch 2] Current Loss: 2.7056\n",
            "[Batch 3] Current Loss: 3.2268\n",
            "[Batch 4] Current Loss: 3.4159\n",
            "[Batch 5] Current Loss: 3.1208\n",
            "[Batch 6] Current Loss: 3.1800\n",
            "[Batch 7] Current Loss: 3.1751\n",
            "[Batch 8] Current Loss: 2.5741\n",
            "[Batch 9] Current Loss: 2.6383\n",
            "[Batch 0] Current Loss: 4.8230\n",
            "[Batch 1] Current Loss: 5.6535\n",
            "[Batch 2] Current Loss: 5.0828\n",
            "[Batch 3] Current Loss: 5.7172\n",
            "[Batch 4] Current Loss: 5.4929\n",
            "[Batch 5] Current Loss: 4.7662\n",
            "[Batch 6] Current Loss: 5.8209\n",
            "[Batch 7] Current Loss: 6.0254\n",
            "[Batch 8] Current Loss: 5.0006\n",
            "[Batch 9] Current Loss: 5.1829\n",
            "Ep 3 (Step 022860): Train loss 3.011, Val loss 5.357\n",
            "[Batch 0] Current Loss: 2.6409\n",
            "[Batch 1] Current Loss: 3.5885\n",
            "[Batch 2] Current Loss: 3.6083\n",
            "[Batch 3] Current Loss: 3.5195\n",
            "[Batch 4] Current Loss: 3.1871\n",
            "[Batch 5] Current Loss: 3.4085\n",
            "[Batch 6] Current Loss: 3.1782\n",
            "[Batch 7] Current Loss: 1.9773\n",
            "[Batch 8] Current Loss: 2.5611\n",
            "[Batch 9] Current Loss: 3.1960\n",
            "[Batch 0] Current Loss: 4.4385\n",
            "[Batch 1] Current Loss: 5.4105\n",
            "[Batch 2] Current Loss: 4.3999\n",
            "[Batch 3] Current Loss: 5.2560\n",
            "[Batch 4] Current Loss: 5.0279\n",
            "[Batch 5] Current Loss: 5.2215\n",
            "[Batch 6] Current Loss: 4.6871\n",
            "[Batch 7] Current Loss: 5.3849\n",
            "[Batch 8] Current Loss: 5.9290\n",
            "[Batch 9] Current Loss: 5.6588\n",
            "Ep 3 (Step 022880): Train loss 3.087, Val loss 5.141\n",
            "[Batch 0] Current Loss: 2.7382\n",
            "[Batch 1] Current Loss: 2.9695\n",
            "[Batch 2] Current Loss: 2.9698\n",
            "[Batch 3] Current Loss: 3.4878\n",
            "[Batch 4] Current Loss: 3.1652\n",
            "[Batch 5] Current Loss: 2.6135\n",
            "[Batch 6] Current Loss: 2.6970\n",
            "[Batch 7] Current Loss: 3.1510\n",
            "[Batch 8] Current Loss: 2.8367\n",
            "[Batch 9] Current Loss: 2.4714\n",
            "[Batch 0] Current Loss: 4.8013\n",
            "[Batch 1] Current Loss: 5.2707\n",
            "[Batch 2] Current Loss: 5.4977\n",
            "[Batch 3] Current Loss: 5.9671\n",
            "[Batch 4] Current Loss: 5.7462\n",
            "[Batch 5] Current Loss: 5.7622\n",
            "[Batch 6] Current Loss: 5.0018\n",
            "[Batch 7] Current Loss: 4.5264\n",
            "[Batch 8] Current Loss: 4.6584\n",
            "[Batch 9] Current Loss: 4.7528\n",
            "Ep 3 (Step 022900): Train loss 2.910, Val loss 5.198\n",
            "[Batch 0] Current Loss: 3.1313\n",
            "[Batch 1] Current Loss: 3.4688\n",
            "[Batch 2] Current Loss: 2.8320\n",
            "[Batch 3] Current Loss: 3.0005\n",
            "[Batch 4] Current Loss: 2.6696\n",
            "[Batch 5] Current Loss: 3.0427\n",
            "[Batch 6] Current Loss: 3.1386\n",
            "[Batch 7] Current Loss: 2.6124\n",
            "[Batch 8] Current Loss: 2.8539\n",
            "[Batch 9] Current Loss: 2.6625\n",
            "[Batch 0] Current Loss: 4.7317\n",
            "[Batch 1] Current Loss: 5.3204\n",
            "[Batch 2] Current Loss: 5.9465\n",
            "[Batch 3] Current Loss: 4.8785\n",
            "[Batch 4] Current Loss: 5.1267\n",
            "[Batch 5] Current Loss: 5.8385\n",
            "[Batch 6] Current Loss: 5.6087\n",
            "[Batch 7] Current Loss: 4.7674\n",
            "[Batch 8] Current Loss: 5.2237\n",
            "[Batch 9] Current Loss: 5.2352\n",
            "Ep 3 (Step 022920): Train loss 2.941, Val loss 5.268\n",
            "[Batch 0] Current Loss: 3.2122\n",
            "[Batch 1] Current Loss: 3.3644\n",
            "[Batch 2] Current Loss: 2.9307\n",
            "[Batch 3] Current Loss: 3.0689\n",
            "[Batch 4] Current Loss: 3.0253\n",
            "[Batch 5] Current Loss: 3.3288\n",
            "[Batch 6] Current Loss: 2.8518\n",
            "[Batch 7] Current Loss: 2.1918\n",
            "[Batch 8] Current Loss: 2.6875\n",
            "[Batch 9] Current Loss: 2.7983\n",
            "[Batch 0] Current Loss: 5.4070\n",
            "[Batch 1] Current Loss: 4.9229\n",
            "[Batch 2] Current Loss: 5.0817\n",
            "[Batch 3] Current Loss: 5.7930\n",
            "[Batch 4] Current Loss: 5.1167\n",
            "[Batch 5] Current Loss: 5.8302\n",
            "[Batch 6] Current Loss: 5.5675\n",
            "[Batch 7] Current Loss: 5.6093\n",
            "[Batch 8] Current Loss: 5.3892\n",
            "[Batch 9] Current Loss: 4.8543\n",
            "Ep 3 (Step 022940): Train loss 2.946, Val loss 5.357\n",
            "[Batch 0] Current Loss: 3.2462\n",
            "[Batch 1] Current Loss: 2.9695\n",
            "[Batch 2] Current Loss: 2.3175\n",
            "[Batch 3] Current Loss: 2.8887\n",
            "[Batch 4] Current Loss: 3.0080\n",
            "[Batch 5] Current Loss: 2.9370\n",
            "[Batch 6] Current Loss: 2.8365\n",
            "[Batch 7] Current Loss: 3.2266\n",
            "[Batch 8] Current Loss: 3.2390\n",
            "[Batch 9] Current Loss: 3.1120\n",
            "[Batch 0] Current Loss: 5.0839\n",
            "[Batch 1] Current Loss: 5.1664\n",
            "[Batch 2] Current Loss: 4.7693\n",
            "[Batch 3] Current Loss: 5.2049\n",
            "[Batch 4] Current Loss: 4.6191\n",
            "[Batch 5] Current Loss: 4.7412\n",
            "[Batch 6] Current Loss: 5.5064\n",
            "[Batch 7] Current Loss: 5.0840\n",
            "[Batch 8] Current Loss: 5.5207\n",
            "[Batch 9] Current Loss: 4.9800\n",
            "Ep 3 (Step 022960): Train loss 2.978, Val loss 5.068\n",
            "[Batch 0] Current Loss: 3.2706\n",
            "[Batch 1] Current Loss: 2.8038\n",
            "[Batch 2] Current Loss: 2.9342\n",
            "[Batch 3] Current Loss: 3.8451\n",
            "[Batch 4] Current Loss: 2.8441\n",
            "[Batch 5] Current Loss: 3.2373\n",
            "[Batch 6] Current Loss: 3.6574\n",
            "[Batch 7] Current Loss: 2.3194\n",
            "[Batch 8] Current Loss: 2.7717\n",
            "[Batch 9] Current Loss: 2.7839\n",
            "[Batch 0] Current Loss: 5.1285\n",
            "[Batch 1] Current Loss: 6.1387\n",
            "[Batch 2] Current Loss: 4.9932\n",
            "[Batch 3] Current Loss: 5.2608\n",
            "[Batch 4] Current Loss: 5.3160\n",
            "[Batch 5] Current Loss: 5.5903\n",
            "[Batch 6] Current Loss: 5.4659\n",
            "[Batch 7] Current Loss: 5.2499\n",
            "[Batch 8] Current Loss: 5.2202\n",
            "[Batch 9] Current Loss: 5.2300\n",
            "Ep 3 (Step 022980): Train loss 3.047, Val loss 5.359\n",
            "[Batch 0] Current Loss: 3.0111\n",
            "[Batch 1] Current Loss: 2.9480\n",
            "[Batch 2] Current Loss: 3.2032\n",
            "[Batch 3] Current Loss: 2.2531\n",
            "[Batch 4] Current Loss: 2.7194\n",
            "[Batch 5] Current Loss: 3.5257\n",
            "[Batch 6] Current Loss: 2.5929\n",
            "[Batch 7] Current Loss: 2.6598\n",
            "[Batch 8] Current Loss: 2.5610\n",
            "[Batch 9] Current Loss: 2.9072\n",
            "[Batch 0] Current Loss: 5.1569\n",
            "[Batch 1] Current Loss: 4.6189\n",
            "[Batch 2] Current Loss: 4.6085\n",
            "[Batch 3] Current Loss: 5.4741\n",
            "[Batch 4] Current Loss: 4.9646\n",
            "[Batch 5] Current Loss: 5.9429\n",
            "[Batch 6] Current Loss: 4.5969\n",
            "[Batch 7] Current Loss: 5.0995\n",
            "[Batch 8] Current Loss: 5.1312\n",
            "[Batch 9] Current Loss: 5.3180\n",
            "Ep 3 (Step 023000): Train loss 2.838, Val loss 5.091\n",
            "[Batch 0] Current Loss: 2.9952\n",
            "[Batch 1] Current Loss: 2.5493\n",
            "[Batch 2] Current Loss: 3.0081\n",
            "[Batch 3] Current Loss: 3.4340\n",
            "[Batch 4] Current Loss: 2.7117\n",
            "[Batch 5] Current Loss: 2.8607\n",
            "[Batch 6] Current Loss: 3.0934\n",
            "[Batch 7] Current Loss: 3.1715\n",
            "[Batch 8] Current Loss: 3.3284\n",
            "[Batch 9] Current Loss: 2.7380\n",
            "[Batch 0] Current Loss: 5.2117\n",
            "[Batch 1] Current Loss: 5.2552\n",
            "[Batch 2] Current Loss: 5.9130\n",
            "[Batch 3] Current Loss: 4.9790\n",
            "[Batch 4] Current Loss: 5.4072\n",
            "[Batch 5] Current Loss: 5.1375\n",
            "[Batch 6] Current Loss: 4.8636\n",
            "[Batch 7] Current Loss: 5.5731\n",
            "[Batch 8] Current Loss: 5.0315\n",
            "[Batch 9] Current Loss: 4.4968\n",
            "Ep 3 (Step 023020): Train loss 2.989, Val loss 5.187\n",
            "[Batch 0] Current Loss: 3.2924\n",
            "[Batch 1] Current Loss: 3.4117\n",
            "[Batch 2] Current Loss: 2.8094\n",
            "[Batch 3] Current Loss: 3.0539\n",
            "[Batch 4] Current Loss: 3.0390\n",
            "[Batch 5] Current Loss: 3.1885\n",
            "[Batch 6] Current Loss: 2.6865\n",
            "[Batch 7] Current Loss: 2.8066\n",
            "[Batch 8] Current Loss: 3.1918\n",
            "[Batch 9] Current Loss: 2.9363\n",
            "[Batch 0] Current Loss: 4.4612\n",
            "[Batch 1] Current Loss: 5.7006\n",
            "[Batch 2] Current Loss: 4.3280\n",
            "[Batch 3] Current Loss: 4.8672\n",
            "[Batch 4] Current Loss: 4.8128\n",
            "[Batch 5] Current Loss: 5.6365\n",
            "[Batch 6] Current Loss: 5.3274\n",
            "[Batch 7] Current Loss: 5.8544\n",
            "[Batch 8] Current Loss: 5.1979\n",
            "[Batch 9] Current Loss: 5.5223\n",
            "Ep 3 (Step 023040): Train loss 3.042, Val loss 5.171\n",
            "[Batch 0] Current Loss: 2.7065\n",
            "[Batch 1] Current Loss: 2.2819\n",
            "[Batch 2] Current Loss: 2.6777\n",
            "[Batch 3] Current Loss: 3.0738\n",
            "[Batch 4] Current Loss: 2.3422\n",
            "[Batch 5] Current Loss: 3.5644\n",
            "[Batch 6] Current Loss: 2.8139\n",
            "[Batch 7] Current Loss: 2.8832\n",
            "[Batch 8] Current Loss: 2.4960\n",
            "[Batch 9] Current Loss: 2.7913\n",
            "[Batch 0] Current Loss: 5.1282\n",
            "[Batch 1] Current Loss: 5.2132\n",
            "[Batch 2] Current Loss: 4.7969\n",
            "[Batch 3] Current Loss: 5.3833\n",
            "[Batch 4] Current Loss: 5.9147\n",
            "[Batch 5] Current Loss: 5.1607\n",
            "[Batch 6] Current Loss: 4.9827\n",
            "[Batch 7] Current Loss: 5.5615\n",
            "[Batch 8] Current Loss: 5.6432\n",
            "[Batch 9] Current Loss: 4.8037\n",
            "Ep 3 (Step 023060): Train loss 2.763, Val loss 5.259\n",
            "[Batch 0] Current Loss: 2.9923\n",
            "[Batch 1] Current Loss: 2.3671\n",
            "[Batch 2] Current Loss: 3.1438\n",
            "[Batch 3] Current Loss: 2.9961\n",
            "[Batch 4] Current Loss: 3.4958\n",
            "[Batch 5] Current Loss: 2.9259\n",
            "[Batch 6] Current Loss: 2.6004\n",
            "[Batch 7] Current Loss: 2.9685\n",
            "[Batch 8] Current Loss: 2.6175\n",
            "[Batch 9] Current Loss: 2.7601\n",
            "[Batch 0] Current Loss: 4.8054\n",
            "[Batch 1] Current Loss: 5.2888\n",
            "[Batch 2] Current Loss: 4.9301\n",
            "[Batch 3] Current Loss: 5.0682\n",
            "[Batch 4] Current Loss: 5.6158\n",
            "[Batch 5] Current Loss: 5.7882\n",
            "[Batch 6] Current Loss: 5.9703\n",
            "[Batch 7] Current Loss: 5.0391\n",
            "[Batch 8] Current Loss: 5.0626\n",
            "[Batch 9] Current Loss: 5.1844\n",
            "Ep 3 (Step 023080): Train loss 2.887, Val loss 5.275\n",
            "[Batch 0] Current Loss: 2.6127\n",
            "[Batch 1] Current Loss: 3.2423\n",
            "[Batch 2] Current Loss: 2.6463\n",
            "[Batch 3] Current Loss: 2.8251\n",
            "[Batch 4] Current Loss: 3.0295\n",
            "[Batch 5] Current Loss: 2.5677\n",
            "[Batch 6] Current Loss: 2.9254\n",
            "[Batch 7] Current Loss: 2.9129\n",
            "[Batch 8] Current Loss: 2.9916\n",
            "[Batch 9] Current Loss: 3.2226\n",
            "[Batch 0] Current Loss: 5.3871\n",
            "[Batch 1] Current Loss: 5.3933\n",
            "[Batch 2] Current Loss: 5.5739\n",
            "[Batch 3] Current Loss: 5.3724\n",
            "[Batch 4] Current Loss: 4.9365\n",
            "[Batch 5] Current Loss: 5.3477\n",
            "[Batch 6] Current Loss: 5.1763\n",
            "[Batch 7] Current Loss: 4.8777\n",
            "[Batch 8] Current Loss: 5.2006\n",
            "[Batch 9] Current Loss: 5.0884\n",
            "Ep 3 (Step 023100): Train loss 2.898, Val loss 5.235\n",
            "[Batch 0] Current Loss: 2.4986\n",
            "[Batch 1] Current Loss: 3.1726\n",
            "[Batch 2] Current Loss: 3.1665\n",
            "[Batch 3] Current Loss: 2.3359\n",
            "[Batch 4] Current Loss: 3.1501\n",
            "[Batch 5] Current Loss: 3.3467\n",
            "[Batch 6] Current Loss: 3.2253\n",
            "[Batch 7] Current Loss: 2.9506\n",
            "[Batch 8] Current Loss: 3.0373\n",
            "[Batch 9] Current Loss: 2.8180\n",
            "[Batch 0] Current Loss: 4.6309\n",
            "[Batch 1] Current Loss: 5.8500\n",
            "[Batch 2] Current Loss: 5.4281\n",
            "[Batch 3] Current Loss: 4.9118\n",
            "[Batch 4] Current Loss: 5.8495\n",
            "[Batch 5] Current Loss: 5.3604\n",
            "[Batch 6] Current Loss: 5.2227\n",
            "[Batch 7] Current Loss: 5.0990\n",
            "[Batch 8] Current Loss: 5.3852\n",
            "[Batch 9] Current Loss: 5.1855\n",
            "Ep 3 (Step 023120): Train loss 2.970, Val loss 5.292\n",
            "[Batch 0] Current Loss: 2.9066\n",
            "[Batch 1] Current Loss: 3.0049\n",
            "[Batch 2] Current Loss: 3.2099\n",
            "[Batch 3] Current Loss: 3.0370\n",
            "[Batch 4] Current Loss: 2.9398\n",
            "[Batch 5] Current Loss: 2.9232\n",
            "[Batch 6] Current Loss: 3.0857\n",
            "[Batch 7] Current Loss: 2.6249\n",
            "[Batch 8] Current Loss: 2.5777\n",
            "[Batch 9] Current Loss: 2.6480\n",
            "[Batch 0] Current Loss: 4.4823\n",
            "[Batch 1] Current Loss: 5.4053\n",
            "[Batch 2] Current Loss: 5.6535\n",
            "[Batch 3] Current Loss: 6.2825\n",
            "[Batch 4] Current Loss: 6.0963\n",
            "[Batch 5] Current Loss: 5.0301\n",
            "[Batch 6] Current Loss: 5.1136\n",
            "[Batch 7] Current Loss: 5.2658\n",
            "[Batch 8] Current Loss: 5.1040\n",
            "[Batch 9] Current Loss: 4.8431\n",
            "Ep 3 (Step 023140): Train loss 2.896, Val loss 5.328\n",
            "[Batch 0] Current Loss: 3.3145\n",
            "[Batch 1] Current Loss: 2.7163\n",
            "[Batch 2] Current Loss: 2.4220\n",
            "[Batch 3] Current Loss: 3.4524\n",
            "[Batch 4] Current Loss: 3.4370\n",
            "[Batch 5] Current Loss: 2.9489\n",
            "[Batch 6] Current Loss: 2.9436\n",
            "[Batch 7] Current Loss: 2.6817\n",
            "[Batch 8] Current Loss: 3.0092\n",
            "[Batch 9] Current Loss: 3.1866\n",
            "[Batch 0] Current Loss: 5.9436\n",
            "[Batch 1] Current Loss: 5.4977\n",
            "[Batch 2] Current Loss: 4.7297\n",
            "[Batch 3] Current Loss: 4.8830\n",
            "[Batch 4] Current Loss: 5.7465\n",
            "[Batch 5] Current Loss: 5.6924\n",
            "[Batch 6] Current Loss: 5.1468\n",
            "[Batch 7] Current Loss: 5.6108\n",
            "[Batch 8] Current Loss: 5.2515\n",
            "[Batch 9] Current Loss: 5.7409\n",
            "Ep 3 (Step 023160): Train loss 3.011, Val loss 5.424\n",
            "[Batch 0] Current Loss: 2.6179\n",
            "[Batch 1] Current Loss: 3.2517\n",
            "[Batch 2] Current Loss: 3.0240\n",
            "[Batch 3] Current Loss: 2.4500\n",
            "[Batch 4] Current Loss: 2.9749\n",
            "[Batch 5] Current Loss: 2.1615\n",
            "[Batch 6] Current Loss: 2.4741\n",
            "[Batch 7] Current Loss: 2.8876\n",
            "[Batch 8] Current Loss: 2.8210\n",
            "[Batch 9] Current Loss: 3.5299\n",
            "[Batch 0] Current Loss: 5.3848\n",
            "[Batch 1] Current Loss: 4.5838\n",
            "[Batch 2] Current Loss: 5.2322\n",
            "[Batch 3] Current Loss: 4.7876\n",
            "[Batch 4] Current Loss: 5.5939\n",
            "[Batch 5] Current Loss: 5.1670\n",
            "[Batch 6] Current Loss: 5.7663\n",
            "[Batch 7] Current Loss: 6.3110\n",
            "[Batch 8] Current Loss: 5.6746\n",
            "[Batch 9] Current Loss: 5.2998\n",
            "Ep 3 (Step 023180): Train loss 2.819, Val loss 5.380\n",
            "[Batch 0] Current Loss: 2.9992\n",
            "[Batch 1] Current Loss: 2.8658\n",
            "[Batch 2] Current Loss: 2.6302\n",
            "[Batch 3] Current Loss: 2.7727\n",
            "[Batch 4] Current Loss: 2.7955\n",
            "[Batch 5] Current Loss: 2.8614\n",
            "[Batch 6] Current Loss: 3.1821\n",
            "[Batch 7] Current Loss: 3.1688\n",
            "[Batch 8] Current Loss: 3.4182\n",
            "[Batch 9] Current Loss: 3.2550\n",
            "[Batch 0] Current Loss: 5.7050\n",
            "[Batch 1] Current Loss: 5.5576\n",
            "[Batch 2] Current Loss: 4.5432\n",
            "[Batch 3] Current Loss: 5.4154\n",
            "[Batch 4] Current Loss: 4.9440\n",
            "[Batch 5] Current Loss: 5.8592\n",
            "[Batch 6] Current Loss: 4.8180\n",
            "[Batch 7] Current Loss: 4.7883\n",
            "[Batch 8] Current Loss: 5.5861\n",
            "[Batch 9] Current Loss: 4.8925\n",
            "Ep 3 (Step 023200): Train loss 2.995, Val loss 5.211\n",
            "[Batch 0] Current Loss: 3.1086\n",
            "[Batch 1] Current Loss: 3.0337\n",
            "[Batch 2] Current Loss: 2.5917\n",
            "[Batch 3] Current Loss: 2.4919\n",
            "[Batch 4] Current Loss: 2.8407\n",
            "[Batch 5] Current Loss: 2.9842\n",
            "[Batch 6] Current Loss: 3.1216\n",
            "[Batch 7] Current Loss: 3.2235\n",
            "[Batch 8] Current Loss: 2.7456\n",
            "[Batch 9] Current Loss: 2.9544\n",
            "[Batch 0] Current Loss: 4.9537\n",
            "[Batch 1] Current Loss: 5.4918\n",
            "[Batch 2] Current Loss: 5.5140\n",
            "[Batch 3] Current Loss: 6.3412\n",
            "[Batch 4] Current Loss: 4.4602\n",
            "[Batch 5] Current Loss: 5.6154\n",
            "[Batch 6] Current Loss: 5.0982\n",
            "[Batch 7] Current Loss: 5.1386\n",
            "[Batch 8] Current Loss: 5.3874\n",
            "[Batch 9] Current Loss: 4.5687\n",
            "Ep 3 (Step 023220): Train loss 2.910, Val loss 5.257\n",
            "[Batch 0] Current Loss: 2.6629\n",
            "[Batch 1] Current Loss: 2.8320\n",
            "[Batch 2] Current Loss: 2.9085\n",
            "[Batch 3] Current Loss: 2.3310\n",
            "[Batch 4] Current Loss: 2.6466\n",
            "[Batch 5] Current Loss: 2.7157\n",
            "[Batch 6] Current Loss: 2.4538\n",
            "[Batch 7] Current Loss: 2.1534\n",
            "[Batch 8] Current Loss: 3.0248\n",
            "[Batch 9] Current Loss: 2.8627\n",
            "[Batch 0] Current Loss: 5.3850\n",
            "[Batch 1] Current Loss: 5.3434\n",
            "[Batch 2] Current Loss: 4.8298\n",
            "[Batch 3] Current Loss: 5.3657\n",
            "[Batch 4] Current Loss: 4.5530\n",
            "[Batch 5] Current Loss: 5.4140\n",
            "[Batch 6] Current Loss: 5.4332\n",
            "[Batch 7] Current Loss: 4.5614\n",
            "[Batch 8] Current Loss: 4.9411\n",
            "[Batch 9] Current Loss: 5.1538\n",
            "Ep 3 (Step 023240): Train loss 2.659, Val loss 5.098\n",
            "[Batch 0] Current Loss: 2.5346\n",
            "[Batch 1] Current Loss: 3.0119\n",
            "[Batch 2] Current Loss: 2.8633\n",
            "[Batch 3] Current Loss: 3.1129\n",
            "[Batch 4] Current Loss: 3.1854\n",
            "[Batch 5] Current Loss: 2.8630\n",
            "[Batch 6] Current Loss: 2.7656\n",
            "[Batch 7] Current Loss: 2.8535\n",
            "[Batch 8] Current Loss: 3.1627\n",
            "[Batch 9] Current Loss: 2.8450\n",
            "[Batch 0] Current Loss: 6.0677\n",
            "[Batch 1] Current Loss: 5.2132\n",
            "[Batch 2] Current Loss: 5.2804\n",
            "[Batch 3] Current Loss: 5.7747\n",
            "[Batch 4] Current Loss: 5.6476\n",
            "[Batch 5] Current Loss: 5.4029\n",
            "[Batch 6] Current Loss: 5.7140\n",
            "[Batch 7] Current Loss: 5.0300\n",
            "[Batch 8] Current Loss: 5.0532\n",
            "[Batch 9] Current Loss: 5.1203\n",
            "Ep 3 (Step 023260): Train loss 2.920, Val loss 5.430\n",
            "[Batch 0] Current Loss: 2.8150\n",
            "[Batch 1] Current Loss: 3.4115\n",
            "[Batch 2] Current Loss: 2.6860\n",
            "[Batch 3] Current Loss: 3.2877\n",
            "[Batch 4] Current Loss: 3.1333\n",
            "[Batch 5] Current Loss: 3.1370\n",
            "[Batch 6] Current Loss: 3.0225\n",
            "[Batch 7] Current Loss: 2.2028\n",
            "[Batch 8] Current Loss: 2.7254\n",
            "[Batch 9] Current Loss: 3.3480\n",
            "[Batch 0] Current Loss: 5.1558\n",
            "[Batch 1] Current Loss: 4.9616\n",
            "[Batch 2] Current Loss: 5.6117\n",
            "[Batch 3] Current Loss: 5.2574\n",
            "[Batch 4] Current Loss: 5.5008\n",
            "[Batch 5] Current Loss: 5.7922\n",
            "[Batch 6] Current Loss: 4.7314\n",
            "[Batch 7] Current Loss: 5.4217\n",
            "[Batch 8] Current Loss: 5.5832\n",
            "[Batch 9] Current Loss: 4.8752\n",
            "Ep 3 (Step 023280): Train loss 2.977, Val loss 5.289\n",
            "[Batch 0] Current Loss: 3.5185\n",
            "[Batch 1] Current Loss: 3.1371\n",
            "[Batch 2] Current Loss: 3.1670\n",
            "[Batch 3] Current Loss: 3.4578\n",
            "[Batch 4] Current Loss: 2.8851\n",
            "[Batch 5] Current Loss: 3.2570\n",
            "[Batch 6] Current Loss: 2.8422\n",
            "[Batch 7] Current Loss: 3.5670\n",
            "[Batch 8] Current Loss: 3.0316\n",
            "[Batch 9] Current Loss: 2.6344\n",
            "[Batch 0] Current Loss: 4.6157\n",
            "[Batch 1] Current Loss: 4.9881\n",
            "[Batch 2] Current Loss: 5.2814\n",
            "[Batch 3] Current Loss: 5.3383\n",
            "[Batch 4] Current Loss: 5.3153\n",
            "[Batch 5] Current Loss: 5.2118\n",
            "[Batch 6] Current Loss: 4.6286\n",
            "[Batch 7] Current Loss: 5.4313\n",
            "[Batch 8] Current Loss: 5.5626\n",
            "[Batch 9] Current Loss: 4.8026\n",
            "Ep 3 (Step 023300): Train loss 3.150, Val loss 5.118\n",
            "[Batch 0] Current Loss: 2.9873\n",
            "[Batch 1] Current Loss: 3.1774\n",
            "[Batch 2] Current Loss: 2.7408\n",
            "[Batch 3] Current Loss: 2.8856\n",
            "[Batch 4] Current Loss: 3.5936\n",
            "[Batch 5] Current Loss: 3.4365\n",
            "[Batch 6] Current Loss: 3.0267\n",
            "[Batch 7] Current Loss: 3.5231\n",
            "[Batch 8] Current Loss: 3.1695\n",
            "[Batch 9] Current Loss: 3.0169\n",
            "[Batch 0] Current Loss: 6.0033\n",
            "[Batch 1] Current Loss: 5.6475\n",
            "[Batch 2] Current Loss: 5.0500\n",
            "[Batch 3] Current Loss: 5.2914\n",
            "[Batch 4] Current Loss: 5.5220\n",
            "[Batch 5] Current Loss: 6.0652\n",
            "[Batch 6] Current Loss: 4.7851\n",
            "[Batch 7] Current Loss: 5.3276\n",
            "[Batch 8] Current Loss: 5.0765\n",
            "[Batch 9] Current Loss: 4.9536\n",
            "Ep 3 (Step 023320): Train loss 3.156, Val loss 5.372\n",
            "[Batch 0] Current Loss: 3.0430\n",
            "[Batch 1] Current Loss: 2.6352\n",
            "[Batch 2] Current Loss: 2.7302\n",
            "[Batch 3] Current Loss: 2.7883\n",
            "[Batch 4] Current Loss: 2.6371\n",
            "[Batch 5] Current Loss: 2.8530\n",
            "[Batch 6] Current Loss: 2.3693\n",
            "[Batch 7] Current Loss: 3.0555\n",
            "[Batch 8] Current Loss: 2.8286\n",
            "[Batch 9] Current Loss: 2.8855\n",
            "[Batch 0] Current Loss: 5.1911\n",
            "[Batch 1] Current Loss: 5.0023\n",
            "[Batch 2] Current Loss: 5.0412\n",
            "[Batch 3] Current Loss: 5.4128\n",
            "[Batch 4] Current Loss: 5.4374\n",
            "[Batch 5] Current Loss: 5.0311\n",
            "[Batch 6] Current Loss: 5.2653\n",
            "[Batch 7] Current Loss: 4.6213\n",
            "[Batch 8] Current Loss: 5.3992\n",
            "[Batch 9] Current Loss: 5.3656\n",
            "Ep 3 (Step 023340): Train loss 2.783, Val loss 5.177\n",
            "[Batch 0] Current Loss: 3.1333\n",
            "[Batch 1] Current Loss: 2.8002\n",
            "[Batch 2] Current Loss: 3.1464\n",
            "[Batch 3] Current Loss: 2.5250\n",
            "[Batch 4] Current Loss: 2.7039\n",
            "[Batch 5] Current Loss: 3.1318\n",
            "[Batch 6] Current Loss: 2.9898\n",
            "[Batch 7] Current Loss: 3.2176\n",
            "[Batch 8] Current Loss: 3.3245\n",
            "[Batch 9] Current Loss: 3.7285\n",
            "[Batch 0] Current Loss: 5.5416\n",
            "[Batch 1] Current Loss: 4.9986\n",
            "[Batch 2] Current Loss: 4.9335\n",
            "[Batch 3] Current Loss: 5.4976\n",
            "[Batch 4] Current Loss: 5.4539\n",
            "[Batch 5] Current Loss: 5.1313\n",
            "[Batch 6] Current Loss: 5.7220\n",
            "[Batch 7] Current Loss: 5.3699\n",
            "[Batch 8] Current Loss: 5.5186\n",
            "[Batch 9] Current Loss: 6.0784\n",
            "Ep 3 (Step 023360): Train loss 3.070, Val loss 5.425\n",
            "[Batch 0] Current Loss: 2.9371\n",
            "[Batch 1] Current Loss: 3.6657\n",
            "[Batch 2] Current Loss: 2.8068\n",
            "[Batch 3] Current Loss: 3.7329\n",
            "[Batch 4] Current Loss: 3.4157\n",
            "[Batch 5] Current Loss: 3.2560\n",
            "[Batch 6] Current Loss: 3.2586\n",
            "[Batch 7] Current Loss: 2.8659\n",
            "[Batch 8] Current Loss: 2.8871\n",
            "[Batch 9] Current Loss: 2.5908\n",
            "[Batch 0] Current Loss: 5.1157\n",
            "[Batch 1] Current Loss: 5.1845\n",
            "[Batch 2] Current Loss: 5.0015\n",
            "[Batch 3] Current Loss: 5.5128\n",
            "[Batch 4] Current Loss: 5.9427\n",
            "[Batch 5] Current Loss: 5.2114\n",
            "[Batch 6] Current Loss: 6.1777\n",
            "[Batch 7] Current Loss: 5.1288\n",
            "[Batch 8] Current Loss: 4.8135\n",
            "[Batch 9] Current Loss: 4.8084\n",
            "Ep 3 (Step 023380): Train loss 3.142, Val loss 5.290\n",
            "[Batch 0] Current Loss: 3.1671\n",
            "[Batch 1] Current Loss: 2.8609\n",
            "[Batch 2] Current Loss: 2.7616\n",
            "[Batch 3] Current Loss: 2.3779\n",
            "[Batch 4] Current Loss: 3.1018\n",
            "[Batch 5] Current Loss: 2.7419\n",
            "[Batch 6] Current Loss: 2.3777\n",
            "[Batch 7] Current Loss: 3.5379\n",
            "[Batch 8] Current Loss: 1.9739\n",
            "[Batch 9] Current Loss: 2.6007\n",
            "[Batch 0] Current Loss: 5.0042\n",
            "[Batch 1] Current Loss: 5.5011\n",
            "[Batch 2] Current Loss: 5.2873\n",
            "[Batch 3] Current Loss: 5.4534\n",
            "[Batch 4] Current Loss: 5.2627\n",
            "[Batch 5] Current Loss: 4.7852\n",
            "[Batch 6] Current Loss: 5.0768\n",
            "[Batch 7] Current Loss: 5.3162\n",
            "[Batch 8] Current Loss: 4.7604\n",
            "[Batch 9] Current Loss: 5.7726\n",
            "Ep 3 (Step 023400): Train loss 2.750, Val loss 5.222\n",
            "[Batch 0] Current Loss: 3.2791\n",
            "[Batch 1] Current Loss: 2.9585\n",
            "[Batch 2] Current Loss: 2.3884\n",
            "[Batch 3] Current Loss: 2.9238\n",
            "[Batch 4] Current Loss: 2.8444\n",
            "[Batch 5] Current Loss: 2.8109\n",
            "[Batch 6] Current Loss: 2.9757\n",
            "[Batch 7] Current Loss: 2.9957\n",
            "[Batch 8] Current Loss: 2.2641\n",
            "[Batch 9] Current Loss: 2.8991\n",
            "[Batch 0] Current Loss: 4.8953\n",
            "[Batch 1] Current Loss: 5.0373\n",
            "[Batch 2] Current Loss: 4.9367\n",
            "[Batch 3] Current Loss: 5.6359\n",
            "[Batch 4] Current Loss: 6.0057\n",
            "[Batch 5] Current Loss: 5.7008\n",
            "[Batch 6] Current Loss: 5.0635\n",
            "[Batch 7] Current Loss: 5.1512\n",
            "[Batch 8] Current Loss: 4.9879\n",
            "[Batch 9] Current Loss: 6.1977\n",
            "Ep 3 (Step 023420): Train loss 2.834, Val loss 5.361\n",
            "[Batch 0] Current Loss: 3.1297\n",
            "[Batch 1] Current Loss: 2.8790\n",
            "[Batch 2] Current Loss: 3.0101\n",
            "[Batch 3] Current Loss: 2.7403\n",
            "[Batch 4] Current Loss: 2.0718\n",
            "[Batch 5] Current Loss: 3.1675\n",
            "[Batch 6] Current Loss: 3.3311\n",
            "[Batch 7] Current Loss: 2.7482\n",
            "[Batch 8] Current Loss: 2.6326\n",
            "[Batch 9] Current Loss: 2.4911\n",
            "[Batch 0] Current Loss: 5.3345\n",
            "[Batch 1] Current Loss: 5.9449\n",
            "[Batch 2] Current Loss: 5.8420\n",
            "[Batch 3] Current Loss: 5.4284\n",
            "[Batch 4] Current Loss: 5.2520\n",
            "[Batch 5] Current Loss: 5.3715\n",
            "[Batch 6] Current Loss: 5.3749\n",
            "[Batch 7] Current Loss: 5.7575\n",
            "[Batch 8] Current Loss: 5.6609\n",
            "[Batch 9] Current Loss: 5.7085\n",
            "Ep 3 (Step 023440): Train loss 2.820, Val loss 5.568\n",
            "[Batch 0] Current Loss: 3.5518\n",
            "[Batch 1] Current Loss: 2.9793\n",
            "[Batch 2] Current Loss: 3.0542\n",
            "[Batch 3] Current Loss: 2.6521\n",
            "[Batch 4] Current Loss: 3.2442\n",
            "[Batch 5] Current Loss: 3.0366\n",
            "[Batch 6] Current Loss: 3.0215\n",
            "[Batch 7] Current Loss: 2.3700\n",
            "[Batch 8] Current Loss: 2.7395\n",
            "[Batch 9] Current Loss: 3.5754\n",
            "[Batch 0] Current Loss: 6.2252\n",
            "[Batch 1] Current Loss: 5.2246\n",
            "[Batch 2] Current Loss: 5.3318\n",
            "[Batch 3] Current Loss: 5.4890\n",
            "[Batch 4] Current Loss: 5.5594\n",
            "[Batch 5] Current Loss: 5.3532\n",
            "[Batch 6] Current Loss: 5.3089\n",
            "[Batch 7] Current Loss: 5.6811\n",
            "[Batch 8] Current Loss: 6.0068\n",
            "[Batch 9] Current Loss: 5.1039\n",
            "Ep 3 (Step 023460): Train loss 3.022, Val loss 5.528\n",
            "[Batch 0] Current Loss: 3.0735\n",
            "[Batch 1] Current Loss: 2.9243\n",
            "[Batch 2] Current Loss: 2.2566\n",
            "[Batch 3] Current Loss: 2.7681\n",
            "[Batch 4] Current Loss: 2.7531\n",
            "[Batch 5] Current Loss: 2.8315\n",
            "[Batch 6] Current Loss: 2.6893\n",
            "[Batch 7] Current Loss: 2.9720\n",
            "[Batch 8] Current Loss: 3.7724\n",
            "[Batch 9] Current Loss: 3.1985\n",
            "[Batch 0] Current Loss: 5.9355\n",
            "[Batch 1] Current Loss: 4.7603\n",
            "[Batch 2] Current Loss: 5.3662\n",
            "[Batch 3] Current Loss: 4.9579\n",
            "[Batch 4] Current Loss: 4.9573\n",
            "[Batch 5] Current Loss: 5.2138\n",
            "[Batch 6] Current Loss: 5.7386\n",
            "[Batch 7] Current Loss: 4.3137\n",
            "[Batch 8] Current Loss: 5.4644\n",
            "[Batch 9] Current Loss: 5.0343\n",
            "Ep 3 (Step 023480): Train loss 2.924, Val loss 5.174\n",
            "[Batch 0] Current Loss: 2.8044\n",
            "[Batch 1] Current Loss: 2.3520\n",
            "[Batch 2] Current Loss: 2.9830\n",
            "[Batch 3] Current Loss: 2.6986\n",
            "[Batch 4] Current Loss: 3.0742\n",
            "[Batch 5] Current Loss: 3.4083\n",
            "[Batch 6] Current Loss: 3.1649\n",
            "[Batch 7] Current Loss: 3.2518\n",
            "[Batch 8] Current Loss: 3.2979\n",
            "[Batch 9] Current Loss: 3.1577\n",
            "[Batch 0] Current Loss: 5.4820\n",
            "[Batch 1] Current Loss: 4.2265\n",
            "[Batch 2] Current Loss: 5.4049\n",
            "[Batch 3] Current Loss: 5.1922\n",
            "[Batch 4] Current Loss: 5.4369\n",
            "[Batch 5] Current Loss: 5.4316\n",
            "[Batch 6] Current Loss: 5.1894\n",
            "[Batch 7] Current Loss: 4.7784\n",
            "[Batch 8] Current Loss: 4.9398\n",
            "[Batch 9] Current Loss: 5.5488\n",
            "Ep 3 (Step 023500): Train loss 3.019, Val loss 5.163\n",
            "[Batch 0] Current Loss: 3.0999\n",
            "[Batch 1] Current Loss: 2.7927\n",
            "[Batch 2] Current Loss: 2.7428\n",
            "[Batch 3] Current Loss: 2.6756\n",
            "[Batch 4] Current Loss: 3.0772\n",
            "[Batch 5] Current Loss: 3.2864\n",
            "[Batch 6] Current Loss: 2.7933\n",
            "[Batch 7] Current Loss: 3.4699\n",
            "[Batch 8] Current Loss: 2.2528\n",
            "[Batch 9] Current Loss: 2.9289\n",
            "[Batch 0] Current Loss: 5.2658\n",
            "[Batch 1] Current Loss: 4.4580\n",
            "[Batch 2] Current Loss: 4.8554\n",
            "[Batch 3] Current Loss: 4.8267\n",
            "[Batch 4] Current Loss: 5.1235\n",
            "[Batch 5] Current Loss: 5.3211\n",
            "[Batch 6] Current Loss: 4.7809\n",
            "[Batch 7] Current Loss: 5.3330\n",
            "[Batch 8] Current Loss: 4.7368\n",
            "[Batch 9] Current Loss: 4.5038\n",
            "Ep 3 (Step 023520): Train loss 2.912, Val loss 4.920\n",
            "[Batch 0] Current Loss: 2.5429\n",
            "[Batch 1] Current Loss: 2.7896\n",
            "[Batch 2] Current Loss: 3.1388\n",
            "[Batch 3] Current Loss: 3.0316\n",
            "[Batch 4] Current Loss: 2.9517\n",
            "[Batch 5] Current Loss: 2.1921\n",
            "[Batch 6] Current Loss: 2.7128\n",
            "[Batch 7] Current Loss: 2.7262\n",
            "[Batch 8] Current Loss: 3.0989\n",
            "[Batch 9] Current Loss: 2.7077\n",
            "[Batch 0] Current Loss: 5.8176\n",
            "[Batch 1] Current Loss: 4.4906\n",
            "[Batch 2] Current Loss: 5.2453\n",
            "[Batch 3] Current Loss: 4.1595\n",
            "[Batch 4] Current Loss: 4.9484\n",
            "[Batch 5] Current Loss: 5.2340\n",
            "[Batch 6] Current Loss: 5.2149\n",
            "[Batch 7] Current Loss: 5.1806\n",
            "[Batch 8] Current Loss: 5.4553\n",
            "[Batch 9] Current Loss: 6.0643\n",
            "Ep 3 (Step 023540): Train loss 2.789, Val loss 5.181\n",
            "[Batch 0] Current Loss: 2.7119\n",
            "[Batch 1] Current Loss: 2.3372\n",
            "[Batch 2] Current Loss: 2.7708\n",
            "[Batch 3] Current Loss: 3.2217\n",
            "[Batch 4] Current Loss: 2.9188\n",
            "[Batch 5] Current Loss: 3.0712\n",
            "[Batch 6] Current Loss: 3.0625\n",
            "[Batch 7] Current Loss: 3.4456\n",
            "[Batch 8] Current Loss: 3.3837\n",
            "[Batch 9] Current Loss: 2.6903\n",
            "[Batch 0] Current Loss: 5.4600\n",
            "[Batch 1] Current Loss: 4.9055\n",
            "[Batch 2] Current Loss: 5.6612\n",
            "[Batch 3] Current Loss: 5.7059\n",
            "[Batch 4] Current Loss: 5.1167\n",
            "[Batch 5] Current Loss: 5.6005\n",
            "[Batch 6] Current Loss: 5.1176\n",
            "[Batch 7] Current Loss: 4.8015\n",
            "[Batch 8] Current Loss: 5.5449\n",
            "[Batch 9] Current Loss: 4.8287\n",
            "Ep 3 (Step 023560): Train loss 2.961, Val loss 5.274\n",
            "[Batch 0] Current Loss: 2.5470\n",
            "[Batch 1] Current Loss: 2.7740\n",
            "[Batch 2] Current Loss: 2.5849\n",
            "[Batch 3] Current Loss: 3.2674\n",
            "[Batch 4] Current Loss: 2.8753\n",
            "[Batch 5] Current Loss: 2.9163\n",
            "[Batch 6] Current Loss: 3.1333\n",
            "[Batch 7] Current Loss: 2.4596\n",
            "[Batch 8] Current Loss: 2.4903\n",
            "[Batch 9] Current Loss: 2.6522\n",
            "[Batch 0] Current Loss: 5.2346\n",
            "[Batch 1] Current Loss: 5.2892\n",
            "[Batch 2] Current Loss: 5.2990\n",
            "[Batch 3] Current Loss: 4.9666\n",
            "[Batch 4] Current Loss: 5.3317\n",
            "[Batch 5] Current Loss: 5.0308\n",
            "[Batch 6] Current Loss: 5.4309\n",
            "[Batch 7] Current Loss: 5.1228\n",
            "[Batch 8] Current Loss: 5.3032\n",
            "[Batch 9] Current Loss: 4.9567\n",
            "Ep 3 (Step 023580): Train loss 2.770, Val loss 5.197\n",
            "[Batch 0] Current Loss: 3.1476\n",
            "[Batch 1] Current Loss: 2.9353\n",
            "[Batch 2] Current Loss: 2.5936\n",
            "[Batch 3] Current Loss: 2.6141\n",
            "[Batch 4] Current Loss: 2.2196\n",
            "[Batch 5] Current Loss: 2.6577\n",
            "[Batch 6] Current Loss: 3.0201\n",
            "[Batch 7] Current Loss: 2.8412\n",
            "[Batch 8] Current Loss: 3.2800\n",
            "[Batch 9] Current Loss: 2.2919\n",
            "[Batch 0] Current Loss: 5.0177\n",
            "[Batch 1] Current Loss: 5.1622\n",
            "[Batch 2] Current Loss: 5.6413\n",
            "[Batch 3] Current Loss: 5.6124\n",
            "[Batch 4] Current Loss: 5.3967\n",
            "[Batch 5] Current Loss: 5.8947\n",
            "[Batch 6] Current Loss: 4.1757\n",
            "[Batch 7] Current Loss: 5.3198\n",
            "[Batch 8] Current Loss: 5.7156\n",
            "[Batch 9] Current Loss: 4.7017\n",
            "Ep 3 (Step 023600): Train loss 2.760, Val loss 5.264\n",
            "[Batch 0] Current Loss: 3.0273\n",
            "[Batch 1] Current Loss: 2.9432\n",
            "[Batch 2] Current Loss: 2.2573\n",
            "[Batch 3] Current Loss: 2.7914\n",
            "[Batch 4] Current Loss: 3.1728\n",
            "[Batch 5] Current Loss: 2.6502\n",
            "[Batch 6] Current Loss: 2.9750\n",
            "[Batch 7] Current Loss: 2.6339\n",
            "[Batch 8] Current Loss: 2.5483\n",
            "[Batch 9] Current Loss: 2.2386\n",
            "[Batch 0] Current Loss: 4.5611\n",
            "[Batch 1] Current Loss: 5.9668\n",
            "[Batch 2] Current Loss: 4.5417\n",
            "[Batch 3] Current Loss: 5.5919\n",
            "[Batch 4] Current Loss: 5.1882\n",
            "[Batch 5] Current Loss: 5.6307\n",
            "[Batch 6] Current Loss: 5.3877\n",
            "[Batch 7] Current Loss: 5.3884\n",
            "[Batch 8] Current Loss: 4.8940\n",
            "[Batch 9] Current Loss: 5.5769\n",
            "Ep 3 (Step 023620): Train loss 2.724, Val loss 5.273\n",
            "[Batch 0] Current Loss: 2.8181\n",
            "[Batch 1] Current Loss: 2.7380\n",
            "[Batch 2] Current Loss: 2.9573\n",
            "[Batch 3] Current Loss: 2.9907\n",
            "[Batch 4] Current Loss: 2.9724\n",
            "[Batch 5] Current Loss: 2.6697\n",
            "[Batch 6] Current Loss: 2.7662\n",
            "[Batch 7] Current Loss: 2.4859\n",
            "[Batch 8] Current Loss: 3.2687\n",
            "[Batch 9] Current Loss: 3.1761\n",
            "[Batch 0] Current Loss: 5.6739\n",
            "[Batch 1] Current Loss: 5.7337\n",
            "[Batch 2] Current Loss: 4.4691\n",
            "[Batch 3] Current Loss: 5.0953\n",
            "[Batch 4] Current Loss: 5.8985\n",
            "[Batch 5] Current Loss: 4.8138\n",
            "[Batch 6] Current Loss: 5.0041\n",
            "[Batch 7] Current Loss: 5.5461\n",
            "[Batch 8] Current Loss: 4.9557\n",
            "[Batch 9] Current Loss: 5.4839\n",
            "Ep 3 (Step 023640): Train loss 2.884, Val loss 5.267\n",
            "[Batch 0] Current Loss: 2.9825\n",
            "[Batch 1] Current Loss: 3.0642\n",
            "[Batch 2] Current Loss: 2.6898\n",
            "[Batch 3] Current Loss: 2.8010\n",
            "[Batch 4] Current Loss: 2.9073\n",
            "[Batch 5] Current Loss: 3.2056\n",
            "[Batch 6] Current Loss: 2.6297\n",
            "[Batch 7] Current Loss: 3.1986\n",
            "[Batch 8] Current Loss: 2.7973\n",
            "[Batch 9] Current Loss: 3.4409\n",
            "[Batch 0] Current Loss: 5.3435\n",
            "[Batch 1] Current Loss: 5.4874\n",
            "[Batch 2] Current Loss: 5.1625\n",
            "[Batch 3] Current Loss: 5.2756\n",
            "[Batch 4] Current Loss: 5.3385\n",
            "[Batch 5] Current Loss: 5.7857\n",
            "[Batch 6] Current Loss: 5.4446\n",
            "[Batch 7] Current Loss: 5.0155\n",
            "[Batch 8] Current Loss: 5.1758\n",
            "[Batch 9] Current Loss: 5.6496\n",
            "Ep 3 (Step 023660): Train loss 2.972, Val loss 5.368\n",
            "[Batch 0] Current Loss: 2.8499\n",
            "[Batch 1] Current Loss: 2.3915\n",
            "[Batch 2] Current Loss: 2.9935\n",
            "[Batch 3] Current Loss: 2.5296\n",
            "[Batch 4] Current Loss: 3.1586\n",
            "[Batch 5] Current Loss: 2.3565\n",
            "[Batch 6] Current Loss: 3.5482\n",
            "[Batch 7] Current Loss: 2.5510\n",
            "[Batch 8] Current Loss: 2.8746\n",
            "[Batch 9] Current Loss: 2.6340\n",
            "[Batch 0] Current Loss: 5.3977\n",
            "[Batch 1] Current Loss: 5.0867\n",
            "[Batch 2] Current Loss: 5.4944\n",
            "[Batch 3] Current Loss: 5.0828\n",
            "[Batch 4] Current Loss: 5.6846\n",
            "[Batch 5] Current Loss: 4.7924\n",
            "[Batch 6] Current Loss: 5.4546\n",
            "[Batch 7] Current Loss: 5.2043\n",
            "[Batch 8] Current Loss: 5.4346\n",
            "[Batch 9] Current Loss: 5.2251\n",
            "Ep 3 (Step 023680): Train loss 2.789, Val loss 5.286\n",
            "[Batch 0] Current Loss: 3.1450\n",
            "[Batch 1] Current Loss: 2.6819\n",
            "[Batch 2] Current Loss: 2.5997\n",
            "[Batch 3] Current Loss: 2.4672\n",
            "[Batch 4] Current Loss: 3.4049\n",
            "[Batch 5] Current Loss: 2.8744\n",
            "[Batch 6] Current Loss: 2.3950\n",
            "[Batch 7] Current Loss: 2.9454\n",
            "[Batch 8] Current Loss: 3.1142\n",
            "[Batch 9] Current Loss: 3.3036\n",
            "[Batch 0] Current Loss: 5.7287\n",
            "[Batch 1] Current Loss: 5.0678\n",
            "[Batch 2] Current Loss: 5.2514\n",
            "[Batch 3] Current Loss: 4.7728\n",
            "[Batch 4] Current Loss: 5.5867\n",
            "[Batch 5] Current Loss: 4.7623\n",
            "[Batch 6] Current Loss: 5.0404\n",
            "[Batch 7] Current Loss: 5.4066\n",
            "[Batch 8] Current Loss: 5.6153\n",
            "[Batch 9] Current Loss: 4.8943\n",
            "Ep 3 (Step 023700): Train loss 2.893, Val loss 5.213\n",
            "[Batch 0] Current Loss: 2.8009\n",
            "[Batch 1] Current Loss: 2.9969\n",
            "[Batch 2] Current Loss: 3.0503\n",
            "[Batch 3] Current Loss: 3.0624\n",
            "[Batch 4] Current Loss: 2.8931\n",
            "[Batch 5] Current Loss: 2.7157\n",
            "[Batch 6] Current Loss: 3.2565\n",
            "[Batch 7] Current Loss: 2.8581\n",
            "[Batch 8] Current Loss: 2.9143\n",
            "[Batch 9] Current Loss: 2.9906\n",
            "[Batch 0] Current Loss: 5.6028\n",
            "[Batch 1] Current Loss: 5.8087\n",
            "[Batch 2] Current Loss: 4.9952\n",
            "[Batch 3] Current Loss: 5.2188\n",
            "[Batch 4] Current Loss: 4.1028\n",
            "[Batch 5] Current Loss: 5.7610\n",
            "[Batch 6] Current Loss: 5.8107\n",
            "[Batch 7] Current Loss: 6.0311\n",
            "[Batch 8] Current Loss: 5.6416\n",
            "[Batch 9] Current Loss: 5.5515\n",
            "Ep 3 (Step 023720): Train loss 2.954, Val loss 5.452\n",
            "[Batch 0] Current Loss: 3.1978\n",
            "[Batch 1] Current Loss: 2.7920\n",
            "[Batch 2] Current Loss: 3.5477\n",
            "[Batch 3] Current Loss: 2.7692\n",
            "[Batch 4] Current Loss: 2.8105\n",
            "[Batch 5] Current Loss: 2.4292\n",
            "[Batch 6] Current Loss: 3.3493\n",
            "[Batch 7] Current Loss: 3.1646\n",
            "[Batch 8] Current Loss: 3.1342\n",
            "[Batch 9] Current Loss: 2.6470\n",
            "[Batch 0] Current Loss: 4.9835\n",
            "[Batch 1] Current Loss: 5.2114\n",
            "[Batch 2] Current Loss: 5.6530\n",
            "[Batch 3] Current Loss: 4.6003\n",
            "[Batch 4] Current Loss: 5.4201\n",
            "[Batch 5] Current Loss: 5.0518\n",
            "[Batch 6] Current Loss: 5.8739\n",
            "[Batch 7] Current Loss: 5.6017\n",
            "[Batch 8] Current Loss: 5.3242\n",
            "[Batch 9] Current Loss: 5.7808\n",
            "Ep 3 (Step 023740): Train loss 2.984, Val loss 5.350\n",
            "[Batch 0] Current Loss: 2.7435\n",
            "[Batch 1] Current Loss: 2.7991\n",
            "[Batch 2] Current Loss: 2.7186\n",
            "[Batch 3] Current Loss: 2.7800\n",
            "[Batch 4] Current Loss: 2.7332\n",
            "[Batch 5] Current Loss: 2.3687\n",
            "[Batch 6] Current Loss: 3.1179\n",
            "[Batch 7] Current Loss: 3.3682\n",
            "[Batch 8] Current Loss: 2.8246\n",
            "[Batch 9] Current Loss: 2.9220\n",
            "[Batch 0] Current Loss: 5.9257\n",
            "[Batch 1] Current Loss: 5.2494\n",
            "[Batch 2] Current Loss: 5.3633\n",
            "[Batch 3] Current Loss: 4.9950\n",
            "[Batch 4] Current Loss: 5.5072\n",
            "[Batch 5] Current Loss: 5.3891\n",
            "[Batch 6] Current Loss: 5.6573\n",
            "[Batch 7] Current Loss: 4.5940\n",
            "[Batch 8] Current Loss: 4.7342\n",
            "[Batch 9] Current Loss: 4.5458\n",
            "Ep 3 (Step 023760): Train loss 2.838, Val loss 5.196\n",
            "[Batch 0] Current Loss: 2.9439\n",
            "[Batch 1] Current Loss: 3.0736\n",
            "[Batch 2] Current Loss: 2.2197\n",
            "[Batch 3] Current Loss: 2.5362\n",
            "[Batch 4] Current Loss: 3.0252\n",
            "[Batch 5] Current Loss: 3.0576\n",
            "[Batch 6] Current Loss: 3.2818\n",
            "[Batch 7] Current Loss: 2.3010\n",
            "[Batch 8] Current Loss: 3.2351\n",
            "[Batch 9] Current Loss: 2.6101\n",
            "[Batch 0] Current Loss: 4.7166\n",
            "[Batch 1] Current Loss: 5.7315\n",
            "[Batch 2] Current Loss: 5.9288\n",
            "[Batch 3] Current Loss: 4.5964\n",
            "[Batch 4] Current Loss: 5.6817\n",
            "[Batch 5] Current Loss: 5.6593\n",
            "[Batch 6] Current Loss: 4.6730\n",
            "[Batch 7] Current Loss: 5.8233\n",
            "[Batch 8] Current Loss: 4.4875\n",
            "[Batch 9] Current Loss: 5.8894\n",
            "Ep 3 (Step 023780): Train loss 2.828, Val loss 5.319\n",
            "[Batch 0] Current Loss: 3.0851\n",
            "[Batch 1] Current Loss: 3.0714\n",
            "[Batch 2] Current Loss: 2.9835\n",
            "[Batch 3] Current Loss: 3.2177\n",
            "[Batch 4] Current Loss: 3.1411\n",
            "[Batch 5] Current Loss: 3.1216\n",
            "[Batch 6] Current Loss: 2.7346\n",
            "[Batch 7] Current Loss: 3.0940\n",
            "[Batch 8] Current Loss: 3.4095\n",
            "[Batch 9] Current Loss: 2.7692\n",
            "[Batch 0] Current Loss: 5.3953\n",
            "[Batch 1] Current Loss: 5.4849\n",
            "[Batch 2] Current Loss: 5.1144\n",
            "[Batch 3] Current Loss: 5.1682\n",
            "[Batch 4] Current Loss: 5.0752\n",
            "[Batch 5] Current Loss: 4.8724\n",
            "[Batch 6] Current Loss: 4.7440\n",
            "[Batch 7] Current Loss: 5.0166\n",
            "[Batch 8] Current Loss: 4.7650\n",
            "[Batch 9] Current Loss: 5.8687\n",
            "Ep 3 (Step 023800): Train loss 3.063, Val loss 5.150\n",
            "[Batch 0] Current Loss: 2.8431\n",
            "[Batch 1] Current Loss: 3.2024\n",
            "[Batch 2] Current Loss: 2.3084\n",
            "[Batch 3] Current Loss: 2.9131\n",
            "[Batch 4] Current Loss: 2.3649\n",
            "[Batch 5] Current Loss: 2.7566\n",
            "[Batch 6] Current Loss: 3.2554\n",
            "[Batch 7] Current Loss: 2.7047\n",
            "[Batch 8] Current Loss: 2.9274\n",
            "[Batch 9] Current Loss: 2.8534\n",
            "[Batch 0] Current Loss: 5.1740\n",
            "[Batch 1] Current Loss: 6.4244\n",
            "[Batch 2] Current Loss: 5.0427\n",
            "[Batch 3] Current Loss: 5.5378\n",
            "[Batch 4] Current Loss: 5.8185\n",
            "[Batch 5] Current Loss: 6.3911\n",
            "[Batch 6] Current Loss: 5.5566\n",
            "[Batch 7] Current Loss: 4.1702\n",
            "[Batch 8] Current Loss: 5.3621\n",
            "[Batch 9] Current Loss: 4.8973\n",
            "Ep 3 (Step 023820): Train loss 2.813, Val loss 5.437\n",
            "[Batch 0] Current Loss: 2.8150\n",
            "[Batch 1] Current Loss: 3.0977\n",
            "[Batch 2] Current Loss: 3.3532\n",
            "[Batch 3] Current Loss: 2.7309\n",
            "[Batch 4] Current Loss: 2.7967\n",
            "[Batch 5] Current Loss: 2.7177\n",
            "[Batch 6] Current Loss: 2.4925\n",
            "[Batch 7] Current Loss: 2.4388\n",
            "[Batch 8] Current Loss: 3.1725\n",
            "[Batch 9] Current Loss: 2.7436\n",
            "[Batch 0] Current Loss: 5.9430\n",
            "[Batch 1] Current Loss: 5.2548\n",
            "[Batch 2] Current Loss: 6.5369\n",
            "[Batch 3] Current Loss: 4.8222\n",
            "[Batch 4] Current Loss: 4.7319\n",
            "[Batch 5] Current Loss: 5.5211\n",
            "[Batch 6] Current Loss: 5.1238\n",
            "[Batch 7] Current Loss: 5.5799\n",
            "[Batch 8] Current Loss: 5.5475\n",
            "[Batch 9] Current Loss: 5.3285\n",
            "Ep 3 (Step 023840): Train loss 2.836, Val loss 5.439\n",
            "[Batch 0] Current Loss: 2.7517\n",
            "[Batch 1] Current Loss: 2.9008\n",
            "[Batch 2] Current Loss: 2.5437\n",
            "[Batch 3] Current Loss: 2.5691\n",
            "[Batch 4] Current Loss: 3.2444\n",
            "[Batch 5] Current Loss: 2.8670\n",
            "[Batch 6] Current Loss: 2.5421\n",
            "[Batch 7] Current Loss: 2.4842\n",
            "[Batch 8] Current Loss: 3.0589\n",
            "[Batch 9] Current Loss: 3.4449\n",
            "[Batch 0] Current Loss: 5.0551\n",
            "[Batch 1] Current Loss: 4.9674\n",
            "[Batch 2] Current Loss: 4.3754\n",
            "[Batch 3] Current Loss: 5.1329\n",
            "[Batch 4] Current Loss: 5.0162\n",
            "[Batch 5] Current Loss: 5.2946\n",
            "[Batch 6] Current Loss: 5.0846\n",
            "[Batch 7] Current Loss: 4.8317\n",
            "[Batch 8] Current Loss: 6.3733\n",
            "[Batch 9] Current Loss: 4.6812\n",
            "Ep 3 (Step 023860): Train loss 2.841, Val loss 5.081\n",
            "[Batch 0] Current Loss: 3.2657\n",
            "[Batch 1] Current Loss: 2.6560\n",
            "[Batch 2] Current Loss: 2.3379\n",
            "[Batch 3] Current Loss: 2.6447\n",
            "[Batch 4] Current Loss: 2.7442\n",
            "[Batch 5] Current Loss: 2.3756\n",
            "[Batch 6] Current Loss: 2.9904\n",
            "[Batch 7] Current Loss: 2.4654\n",
            "[Batch 8] Current Loss: 2.4468\n",
            "[Batch 9] Current Loss: 2.9004\n",
            "[Batch 0] Current Loss: 5.4482\n",
            "[Batch 1] Current Loss: 5.0010\n",
            "[Batch 2] Current Loss: 5.2076\n",
            "[Batch 3] Current Loss: 5.4719\n",
            "[Batch 4] Current Loss: 5.9184\n",
            "[Batch 5] Current Loss: 5.8414\n",
            "[Batch 6] Current Loss: 5.4567\n",
            "[Batch 7] Current Loss: 5.0148\n",
            "[Batch 8] Current Loss: 5.6970\n",
            "[Batch 9] Current Loss: 5.3237\n",
            "Ep 3 (Step 023880): Train loss 2.683, Val loss 5.438\n",
            "[Batch 0] Current Loss: 3.2830\n",
            "[Batch 1] Current Loss: 2.6194\n",
            "[Batch 2] Current Loss: 2.6960\n",
            "[Batch 3] Current Loss: 3.2994\n",
            "[Batch 4] Current Loss: 2.9620\n",
            "[Batch 5] Current Loss: 2.7603\n",
            "[Batch 6] Current Loss: 3.1531\n",
            "[Batch 7] Current Loss: 2.7922\n",
            "[Batch 8] Current Loss: 3.3041\n",
            "[Batch 9] Current Loss: 2.3905\n",
            "[Batch 0] Current Loss: 5.6553\n",
            "[Batch 1] Current Loss: 5.4137\n",
            "[Batch 2] Current Loss: 4.5809\n",
            "[Batch 3] Current Loss: 6.0686\n",
            "[Batch 4] Current Loss: 5.7567\n",
            "[Batch 5] Current Loss: 5.7921\n",
            "[Batch 6] Current Loss: 5.3208\n",
            "[Batch 7] Current Loss: 5.2784\n",
            "[Batch 8] Current Loss: 5.6073\n",
            "[Batch 9] Current Loss: 5.5485\n",
            "Ep 3 (Step 023900): Train loss 2.926, Val loss 5.502\n",
            "[Batch 0] Current Loss: 2.3087\n",
            "[Batch 1] Current Loss: 2.7486\n",
            "[Batch 2] Current Loss: 3.4511\n",
            "[Batch 3] Current Loss: 2.6593\n",
            "[Batch 4] Current Loss: 2.3905\n",
            "[Batch 5] Current Loss: 2.8276\n",
            "[Batch 6] Current Loss: 3.3195\n",
            "[Batch 7] Current Loss: 2.6029\n",
            "[Batch 8] Current Loss: 2.6804\n",
            "[Batch 9] Current Loss: 3.1192\n",
            "[Batch 0] Current Loss: 5.3847\n",
            "[Batch 1] Current Loss: 5.5252\n",
            "[Batch 2] Current Loss: 6.3753\n",
            "[Batch 3] Current Loss: 5.5945\n",
            "[Batch 4] Current Loss: 5.5473\n",
            "[Batch 5] Current Loss: 5.0711\n",
            "[Batch 6] Current Loss: 5.5137\n",
            "[Batch 7] Current Loss: 4.6840\n",
            "[Batch 8] Current Loss: 6.0302\n",
            "[Batch 9] Current Loss: 5.3489\n",
            "Ep 3 (Step 023920): Train loss 2.811, Val loss 5.507\n",
            "[Batch 0] Current Loss: 2.3138\n",
            "[Batch 1] Current Loss: 3.5047\n",
            "[Batch 2] Current Loss: 3.6106\n",
            "[Batch 3] Current Loss: 2.3691\n",
            "[Batch 4] Current Loss: 2.9905\n",
            "[Batch 5] Current Loss: 2.4100\n",
            "[Batch 6] Current Loss: 3.0754\n",
            "[Batch 7] Current Loss: 2.7550\n",
            "[Batch 8] Current Loss: 2.7315\n",
            "[Batch 9] Current Loss: 3.4146\n",
            "[Batch 0] Current Loss: 5.7544\n",
            "[Batch 1] Current Loss: 5.3104\n",
            "[Batch 2] Current Loss: 5.4255\n",
            "[Batch 3] Current Loss: 4.7230\n",
            "[Batch 4] Current Loss: 5.4520\n",
            "[Batch 5] Current Loss: 4.8782\n",
            "[Batch 6] Current Loss: 6.0710\n",
            "[Batch 7] Current Loss: 5.6770\n",
            "[Batch 8] Current Loss: 5.6449\n",
            "[Batch 9] Current Loss: 5.1884\n",
            "Ep 3 (Step 023940): Train loss 2.918, Val loss 5.412\n",
            "[Batch 0] Current Loss: 3.5879\n",
            "[Batch 1] Current Loss: 2.9994\n",
            "[Batch 2] Current Loss: 2.7716\n",
            "[Batch 3] Current Loss: 2.8547\n",
            "[Batch 4] Current Loss: 2.7741\n",
            "[Batch 5] Current Loss: 2.8768\n",
            "[Batch 6] Current Loss: 2.9803\n",
            "[Batch 7] Current Loss: 3.1546\n",
            "[Batch 8] Current Loss: 2.5476\n",
            "[Batch 9] Current Loss: 3.4716\n",
            "[Batch 0] Current Loss: 5.8892\n",
            "[Batch 1] Current Loss: 5.3239\n",
            "[Batch 2] Current Loss: 5.3751\n",
            "[Batch 3] Current Loss: 5.6664\n",
            "[Batch 4] Current Loss: 5.6243\n",
            "[Batch 5] Current Loss: 5.2398\n",
            "[Batch 6] Current Loss: 5.7293\n",
            "[Batch 7] Current Loss: 5.5216\n",
            "[Batch 8] Current Loss: 6.1456\n",
            "[Batch 9] Current Loss: 5.5076\n",
            "Ep 3 (Step 023960): Train loss 3.002, Val loss 5.602\n",
            "[Batch 0] Current Loss: 2.9406\n",
            "[Batch 1] Current Loss: 3.6883\n",
            "[Batch 2] Current Loss: 2.7738\n",
            "[Batch 3] Current Loss: 2.7204\n",
            "[Batch 4] Current Loss: 2.3387\n",
            "[Batch 5] Current Loss: 3.0296\n",
            "[Batch 6] Current Loss: 2.4638\n",
            "[Batch 7] Current Loss: 3.5286\n",
            "[Batch 8] Current Loss: 3.4293\n",
            "[Batch 9] Current Loss: 2.3692\n",
            "[Batch 0] Current Loss: 5.2805\n",
            "[Batch 1] Current Loss: 5.7077\n",
            "[Batch 2] Current Loss: 5.3236\n",
            "[Batch 3] Current Loss: 5.0399\n",
            "[Batch 4] Current Loss: 5.4630\n",
            "[Batch 5] Current Loss: 4.4518\n",
            "[Batch 6] Current Loss: 5.4135\n",
            "[Batch 7] Current Loss: 5.4853\n",
            "[Batch 8] Current Loss: 4.8008\n",
            "[Batch 9] Current Loss: 5.5651\n",
            "Ep 3 (Step 023980): Train loss 2.928, Val loss 5.253\n",
            "[Batch 0] Current Loss: 2.5601\n",
            "[Batch 1] Current Loss: 3.1879\n",
            "[Batch 2] Current Loss: 2.9177\n",
            "[Batch 3] Current Loss: 2.7113\n",
            "[Batch 4] Current Loss: 2.7899\n",
            "[Batch 5] Current Loss: 2.9844\n",
            "[Batch 6] Current Loss: 2.4747\n",
            "[Batch 7] Current Loss: 3.0939\n",
            "[Batch 8] Current Loss: 2.2670\n",
            "[Batch 9] Current Loss: 3.1831\n",
            "[Batch 0] Current Loss: 5.2991\n",
            "[Batch 1] Current Loss: 5.8268\n",
            "[Batch 2] Current Loss: 5.3071\n",
            "[Batch 3] Current Loss: 5.4353\n",
            "[Batch 4] Current Loss: 6.1349\n",
            "[Batch 5] Current Loss: 5.6330\n",
            "[Batch 6] Current Loss: 5.3089\n",
            "[Batch 7] Current Loss: 5.3536\n",
            "[Batch 8] Current Loss: 5.7608\n",
            "[Batch 9] Current Loss: 5.5160\n",
            "Ep 3 (Step 024000): Train loss 2.817, Val loss 5.558\n",
            "[Batch 0] Current Loss: 2.5948\n",
            "[Batch 1] Current Loss: 2.9524\n",
            "[Batch 2] Current Loss: 2.8713\n",
            "[Batch 3] Current Loss: 3.0620\n",
            "[Batch 4] Current Loss: 2.7486\n",
            "[Batch 5] Current Loss: 2.6663\n",
            "[Batch 6] Current Loss: 3.4901\n",
            "[Batch 7] Current Loss: 2.3804\n",
            "[Batch 8] Current Loss: 3.2262\n",
            "[Batch 9] Current Loss: 2.6827\n",
            "[Batch 0] Current Loss: 4.8892\n",
            "[Batch 1] Current Loss: 5.3424\n",
            "[Batch 2] Current Loss: 5.6972\n",
            "[Batch 3] Current Loss: 4.5580\n",
            "[Batch 4] Current Loss: 4.9838\n",
            "[Batch 5] Current Loss: 5.6677\n",
            "[Batch 6] Current Loss: 5.7014\n",
            "[Batch 7] Current Loss: 5.9056\n",
            "[Batch 8] Current Loss: 5.0702\n",
            "[Batch 9] Current Loss: 5.6747\n",
            "Ep 3 (Step 024020): Train loss 2.867, Val loss 5.349\n",
            "[Batch 0] Current Loss: 3.1293\n",
            "[Batch 1] Current Loss: 2.6272\n",
            "[Batch 2] Current Loss: 2.8636\n",
            "[Batch 3] Current Loss: 3.0810\n",
            "[Batch 4] Current Loss: 3.4264\n",
            "[Batch 5] Current Loss: 2.7039\n",
            "[Batch 6] Current Loss: 3.2085\n",
            "[Batch 7] Current Loss: 2.7304\n",
            "[Batch 8] Current Loss: 3.2150\n",
            "[Batch 9] Current Loss: 3.1898\n",
            "[Batch 0] Current Loss: 5.8033\n",
            "[Batch 1] Current Loss: 5.3103\n",
            "[Batch 2] Current Loss: 5.0076\n",
            "[Batch 3] Current Loss: 5.1787\n",
            "[Batch 4] Current Loss: 6.0895\n",
            "[Batch 5] Current Loss: 5.0257\n",
            "[Batch 6] Current Loss: 5.0616\n",
            "[Batch 7] Current Loss: 5.0588\n",
            "[Batch 8] Current Loss: 5.6488\n",
            "[Batch 9] Current Loss: 4.8503\n",
            "Ep 3 (Step 024040): Train loss 3.018, Val loss 5.303\n",
            "[Batch 0] Current Loss: 2.8481\n",
            "[Batch 1] Current Loss: 2.2583\n",
            "[Batch 2] Current Loss: 2.8717\n",
            "[Batch 3] Current Loss: 2.4504\n",
            "[Batch 4] Current Loss: 2.8020\n",
            "[Batch 5] Current Loss: 2.5009\n",
            "[Batch 6] Current Loss: 2.8262\n",
            "[Batch 7] Current Loss: 3.4184\n",
            "[Batch 8] Current Loss: 2.9219\n",
            "[Batch 9] Current Loss: 2.5725\n",
            "[Batch 0] Current Loss: 5.2532\n",
            "[Batch 1] Current Loss: 5.3450\n",
            "[Batch 2] Current Loss: 5.6120\n",
            "[Batch 3] Current Loss: 6.1872\n",
            "[Batch 4] Current Loss: 5.3905\n",
            "[Batch 5] Current Loss: 5.0376\n",
            "[Batch 6] Current Loss: 4.9211\n",
            "[Batch 7] Current Loss: 5.0151\n",
            "[Batch 8] Current Loss: 5.6301\n",
            "[Batch 9] Current Loss: 5.2526\n",
            "Ep 3 (Step 024060): Train loss 2.747, Val loss 5.364\n",
            "[Batch 0] Current Loss: 3.7524\n",
            "[Batch 1] Current Loss: 3.1451\n",
            "[Batch 2] Current Loss: 2.4991\n",
            "[Batch 3] Current Loss: 2.6366\n",
            "[Batch 4] Current Loss: 3.0610\n",
            "[Batch 5] Current Loss: 2.5917\n",
            "[Batch 6] Current Loss: 2.7270\n",
            "[Batch 7] Current Loss: 3.3788\n",
            "[Batch 8] Current Loss: 3.2250\n",
            "[Batch 9] Current Loss: 2.5308\n",
            "[Batch 0] Current Loss: 5.1117\n",
            "[Batch 1] Current Loss: 5.5637\n",
            "[Batch 2] Current Loss: 4.9903\n",
            "[Batch 3] Current Loss: 5.4384\n",
            "[Batch 4] Current Loss: 5.1896\n",
            "[Batch 5] Current Loss: 5.5535\n",
            "[Batch 6] Current Loss: 5.1506\n",
            "[Batch 7] Current Loss: 5.7012\n",
            "[Batch 8] Current Loss: 5.6602\n",
            "[Batch 9] Current Loss: 4.7218\n",
            "Ep 3 (Step 024080): Train loss 2.955, Val loss 5.308\n",
            "[Batch 0] Current Loss: 2.7290\n",
            "[Batch 1] Current Loss: 3.0745\n",
            "[Batch 2] Current Loss: 2.9642\n",
            "[Batch 3] Current Loss: 3.0253\n",
            "[Batch 4] Current Loss: 2.9748\n",
            "[Batch 5] Current Loss: 2.9185\n",
            "[Batch 6] Current Loss: 2.8610\n",
            "[Batch 7] Current Loss: 2.6228\n",
            "[Batch 8] Current Loss: 3.0804\n",
            "[Batch 9] Current Loss: 2.6977\n",
            "[Batch 0] Current Loss: 5.1319\n",
            "[Batch 1] Current Loss: 5.5947\n",
            "[Batch 2] Current Loss: 5.6279\n",
            "[Batch 3] Current Loss: 4.5720\n",
            "[Batch 4] Current Loss: 5.3826\n",
            "[Batch 5] Current Loss: 4.7270\n",
            "[Batch 6] Current Loss: 4.6526\n",
            "[Batch 7] Current Loss: 6.2058\n",
            "[Batch 8] Current Loss: 5.1433\n",
            "[Batch 9] Current Loss: 4.7414\n",
            "Ep 3 (Step 024100): Train loss 2.895, Val loss 5.178\n",
            "[Batch 0] Current Loss: 2.6953\n",
            "[Batch 1] Current Loss: 3.1492\n",
            "[Batch 2] Current Loss: 2.6560\n",
            "[Batch 3] Current Loss: 3.3513\n",
            "[Batch 4] Current Loss: 3.1477\n",
            "[Batch 5] Current Loss: 3.1434\n",
            "[Batch 6] Current Loss: 2.0044\n",
            "[Batch 7] Current Loss: 2.7973\n",
            "[Batch 8] Current Loss: 2.9887\n",
            "[Batch 9] Current Loss: 2.7750\n",
            "[Batch 0] Current Loss: 5.6852\n",
            "[Batch 1] Current Loss: 5.3633\n",
            "[Batch 2] Current Loss: 4.8579\n",
            "[Batch 3] Current Loss: 5.1885\n",
            "[Batch 4] Current Loss: 5.5608\n",
            "[Batch 5] Current Loss: 5.7349\n",
            "[Batch 6] Current Loss: 5.2823\n",
            "[Batch 7] Current Loss: 4.9697\n",
            "[Batch 8] Current Loss: 5.1860\n",
            "[Batch 9] Current Loss: 5.4040\n",
            "Ep 3 (Step 024120): Train loss 2.871, Val loss 5.323\n",
            "[Batch 0] Current Loss: 3.2176\n",
            "[Batch 1] Current Loss: 3.2104\n",
            "[Batch 2] Current Loss: 2.8683\n",
            "[Batch 3] Current Loss: 2.9549\n",
            "[Batch 4] Current Loss: 2.3139\n",
            "[Batch 5] Current Loss: 3.0923\n",
            "[Batch 6] Current Loss: 2.9713\n",
            "[Batch 7] Current Loss: 3.1863\n",
            "[Batch 8] Current Loss: 3.1714\n",
            "[Batch 9] Current Loss: 3.1132\n",
            "[Batch 0] Current Loss: 4.7481\n",
            "[Batch 1] Current Loss: 5.8119\n",
            "[Batch 2] Current Loss: 4.8811\n",
            "[Batch 3] Current Loss: 4.6599\n",
            "[Batch 4] Current Loss: 5.2201\n",
            "[Batch 5] Current Loss: 5.8918\n",
            "[Batch 6] Current Loss: 4.8953\n",
            "[Batch 7] Current Loss: 5.5084\n",
            "[Batch 8] Current Loss: 4.4121\n",
            "[Batch 9] Current Loss: 5.5941\n",
            "Ep 3 (Step 024140): Train loss 3.010, Val loss 5.162\n",
            "[Batch 0] Current Loss: 2.8604\n",
            "[Batch 1] Current Loss: 2.5746\n",
            "[Batch 2] Current Loss: 2.8428\n",
            "[Batch 3] Current Loss: 2.6385\n",
            "[Batch 4] Current Loss: 2.5808\n",
            "[Batch 5] Current Loss: 3.2785\n",
            "[Batch 6] Current Loss: 3.0856\n",
            "[Batch 7] Current Loss: 2.9130\n",
            "[Batch 8] Current Loss: 3.4980\n",
            "[Batch 9] Current Loss: 2.8195\n",
            "[Batch 0] Current Loss: 4.0566\n",
            "[Batch 1] Current Loss: 5.5482\n",
            "[Batch 2] Current Loss: 5.1390\n",
            "[Batch 3] Current Loss: 4.5016\n",
            "[Batch 4] Current Loss: 5.6104\n",
            "[Batch 5] Current Loss: 5.7229\n",
            "[Batch 6] Current Loss: 5.5550\n",
            "[Batch 7] Current Loss: 5.2001\n",
            "[Batch 8] Current Loss: 5.1707\n",
            "[Batch 9] Current Loss: 4.8870\n",
            "Ep 3 (Step 024160): Train loss 2.909, Val loss 5.139\n",
            "[Batch 0] Current Loss: 2.8080\n",
            "[Batch 1] Current Loss: 2.5166\n",
            "[Batch 2] Current Loss: 2.6202\n",
            "[Batch 3] Current Loss: 2.6557\n",
            "[Batch 4] Current Loss: 2.9853\n",
            "[Batch 5] Current Loss: 3.1158\n",
            "[Batch 6] Current Loss: 3.0628\n",
            "[Batch 7] Current Loss: 2.9464\n",
            "[Batch 8] Current Loss: 2.5536\n",
            "[Batch 9] Current Loss: 2.0059\n",
            "[Batch 0] Current Loss: 5.2378\n",
            "[Batch 1] Current Loss: 6.3846\n",
            "[Batch 2] Current Loss: 5.8546\n",
            "[Batch 3] Current Loss: 5.7395\n",
            "[Batch 4] Current Loss: 5.1573\n",
            "[Batch 5] Current Loss: 4.8402\n",
            "[Batch 6] Current Loss: 5.2042\n",
            "[Batch 7] Current Loss: 5.0690\n",
            "[Batch 8] Current Loss: 5.0459\n",
            "[Batch 9] Current Loss: 5.2849\n",
            "Ep 3 (Step 024180): Train loss 2.727, Val loss 5.382\n",
            "[Batch 0] Current Loss: 2.9211\n",
            "[Batch 1] Current Loss: 2.6972\n",
            "[Batch 2] Current Loss: 3.0701\n",
            "[Batch 3] Current Loss: 2.8243\n",
            "[Batch 4] Current Loss: 3.2244\n",
            "[Batch 5] Current Loss: 3.2278\n",
            "[Batch 6] Current Loss: 3.2631\n",
            "[Batch 7] Current Loss: 3.2637\n",
            "[Batch 8] Current Loss: 3.2070\n",
            "[Batch 9] Current Loss: 2.8867\n",
            "[Batch 0] Current Loss: 5.3439\n",
            "[Batch 1] Current Loss: 5.0153\n",
            "[Batch 2] Current Loss: 5.2833\n",
            "[Batch 3] Current Loss: 5.1028\n",
            "[Batch 4] Current Loss: 5.1963\n",
            "[Batch 5] Current Loss: 5.4794\n",
            "[Batch 6] Current Loss: 5.2622\n",
            "[Batch 7] Current Loss: 5.0999\n",
            "[Batch 8] Current Loss: 4.3816\n",
            "[Batch 9] Current Loss: 5.5118\n",
            "Ep 3 (Step 024200): Train loss 3.059, Val loss 5.168\n",
            "[Batch 0] Current Loss: 2.3630\n",
            "[Batch 1] Current Loss: 2.4473\n",
            "[Batch 2] Current Loss: 3.3229\n",
            "[Batch 3] Current Loss: 3.0419\n",
            "[Batch 4] Current Loss: 2.4001\n",
            "[Batch 5] Current Loss: 2.9915\n",
            "[Batch 6] Current Loss: 2.8757\n",
            "[Batch 7] Current Loss: 2.6304\n",
            "[Batch 8] Current Loss: 2.8750\n",
            "[Batch 9] Current Loss: 2.9900\n",
            "[Batch 0] Current Loss: 5.8239\n",
            "[Batch 1] Current Loss: 5.1758\n",
            "[Batch 2] Current Loss: 4.9658\n",
            "[Batch 3] Current Loss: 5.3255\n",
            "[Batch 4] Current Loss: 4.7131\n",
            "[Batch 5] Current Loss: 4.4313\n",
            "[Batch 6] Current Loss: 5.5618\n",
            "[Batch 7] Current Loss: 5.4817\n",
            "[Batch 8] Current Loss: 6.0122\n",
            "[Batch 9] Current Loss: 4.6750\n",
            "Ep 3 (Step 024220): Train loss 2.794, Val loss 5.217\n",
            "[Batch 0] Current Loss: 2.8335\n",
            "[Batch 1] Current Loss: 3.2182\n",
            "[Batch 2] Current Loss: 3.0188\n",
            "[Batch 3] Current Loss: 2.9802\n",
            "[Batch 4] Current Loss: 3.2472\n",
            "[Batch 5] Current Loss: 2.8612\n",
            "[Batch 6] Current Loss: 2.9047\n",
            "[Batch 7] Current Loss: 2.9379\n",
            "[Batch 8] Current Loss: 2.5059\n",
            "[Batch 9] Current Loss: 2.2591\n",
            "[Batch 0] Current Loss: 5.1202\n",
            "[Batch 1] Current Loss: 5.8460\n",
            "[Batch 2] Current Loss: 5.2740\n",
            "[Batch 3] Current Loss: 4.7778\n",
            "[Batch 4] Current Loss: 4.8861\n",
            "[Batch 5] Current Loss: 5.6588\n",
            "[Batch 6] Current Loss: 6.1909\n",
            "[Batch 7] Current Loss: 5.7552\n",
            "[Batch 8] Current Loss: 5.1835\n",
            "[Batch 9] Current Loss: 4.7388\n",
            "Ep 3 (Step 024240): Train loss 2.877, Val loss 5.343\n",
            "[Batch 0] Current Loss: 2.7537\n",
            "[Batch 1] Current Loss: 3.0962\n",
            "[Batch 2] Current Loss: 3.4554\n",
            "[Batch 3] Current Loss: 2.8642\n",
            "[Batch 4] Current Loss: 3.0079\n",
            "[Batch 5] Current Loss: 2.4798\n",
            "[Batch 6] Current Loss: 3.6278\n",
            "[Batch 7] Current Loss: 2.7606\n",
            "[Batch 8] Current Loss: 2.6775\n",
            "[Batch 9] Current Loss: 3.0365\n",
            "[Batch 0] Current Loss: 4.5467\n",
            "[Batch 1] Current Loss: 5.2121\n",
            "[Batch 2] Current Loss: 5.7212\n",
            "[Batch 3] Current Loss: 4.6732\n",
            "[Batch 4] Current Loss: 5.2265\n",
            "[Batch 5] Current Loss: 5.1788\n",
            "[Batch 6] Current Loss: 5.9754\n",
            "[Batch 7] Current Loss: 4.7384\n",
            "[Batch 8] Current Loss: 5.3117\n",
            "[Batch 9] Current Loss: 4.6046\n",
            "Ep 3 (Step 024260): Train loss 2.976, Val loss 5.119\n",
            "[Batch 0] Current Loss: 3.0305\n",
            "[Batch 1] Current Loss: 2.0434\n",
            "[Batch 2] Current Loss: 2.4633\n",
            "[Batch 3] Current Loss: 2.9644\n",
            "[Batch 4] Current Loss: 3.1208\n",
            "[Batch 5] Current Loss: 2.7771\n",
            "[Batch 6] Current Loss: 2.6979\n",
            "[Batch 7] Current Loss: 2.9864\n",
            "[Batch 8] Current Loss: 2.9214\n",
            "[Batch 9] Current Loss: 2.5186\n",
            "[Batch 0] Current Loss: 5.2853\n",
            "[Batch 1] Current Loss: 5.2207\n",
            "[Batch 2] Current Loss: 5.5089\n",
            "[Batch 3] Current Loss: 5.0421\n",
            "[Batch 4] Current Loss: 5.4164\n",
            "[Batch 5] Current Loss: 5.1072\n",
            "[Batch 6] Current Loss: 5.0373\n",
            "[Batch 7] Current Loss: 5.4964\n",
            "[Batch 8] Current Loss: 5.7935\n",
            "[Batch 9] Current Loss: 5.0513\n",
            "Ep 3 (Step 024280): Train loss 2.752, Val loss 5.296\n",
            "[Batch 0] Current Loss: 2.9628\n",
            "[Batch 1] Current Loss: 3.1917\n",
            "[Batch 2] Current Loss: 2.6694\n",
            "[Batch 3] Current Loss: 2.6633\n",
            "[Batch 4] Current Loss: 2.9625\n",
            "[Batch 5] Current Loss: 2.2657\n",
            "[Batch 6] Current Loss: 2.7142\n",
            "[Batch 7] Current Loss: 3.0073\n",
            "[Batch 8] Current Loss: 2.7255\n",
            "[Batch 9] Current Loss: 3.1224\n",
            "[Batch 0] Current Loss: 5.6798\n",
            "[Batch 1] Current Loss: 5.5594\n",
            "[Batch 2] Current Loss: 5.6910\n",
            "[Batch 3] Current Loss: 5.1381\n",
            "[Batch 4] Current Loss: 4.5662\n",
            "[Batch 5] Current Loss: 5.2428\n",
            "[Batch 6] Current Loss: 5.0711\n",
            "[Batch 7] Current Loss: 4.9424\n",
            "[Batch 8] Current Loss: 5.2706\n",
            "[Batch 9] Current Loss: 5.8026\n",
            "Ep 3 (Step 024300): Train loss 2.828, Val loss 5.296\n",
            "[Batch 0] Current Loss: 2.8347\n",
            "[Batch 1] Current Loss: 2.3661\n",
            "[Batch 2] Current Loss: 3.3432\n",
            "[Batch 3] Current Loss: 3.2726\n",
            "[Batch 4] Current Loss: 2.9125\n",
            "[Batch 5] Current Loss: 3.4151\n",
            "[Batch 6] Current Loss: 3.2861\n",
            "[Batch 7] Current Loss: 2.6946\n",
            "[Batch 8] Current Loss: 2.7027\n",
            "[Batch 9] Current Loss: 2.3352\n",
            "[Batch 0] Current Loss: 5.3122\n",
            "[Batch 1] Current Loss: 5.3048\n",
            "[Batch 2] Current Loss: 5.8080\n",
            "[Batch 3] Current Loss: 4.8112\n",
            "[Batch 4] Current Loss: 4.8572\n",
            "[Batch 5] Current Loss: 4.5604\n",
            "[Batch 6] Current Loss: 5.2388\n",
            "[Batch 7] Current Loss: 5.7542\n",
            "[Batch 8] Current Loss: 6.3036\n",
            "[Batch 9] Current Loss: 5.7768\n",
            "Ep 3 (Step 024320): Train loss 2.916, Val loss 5.373\n",
            "[Batch 0] Current Loss: 2.7833\n",
            "[Batch 1] Current Loss: 3.0653\n",
            "[Batch 2] Current Loss: 2.5368\n",
            "[Batch 3] Current Loss: 3.1997\n",
            "[Batch 4] Current Loss: 3.0964\n",
            "[Batch 5] Current Loss: 2.8581\n",
            "[Batch 6] Current Loss: 2.1398\n",
            "[Batch 7] Current Loss: 3.2915\n",
            "[Batch 8] Current Loss: 2.6075\n",
            "[Batch 9] Current Loss: 2.4180\n",
            "[Batch 0] Current Loss: 5.8931\n",
            "[Batch 1] Current Loss: 5.2514\n",
            "[Batch 2] Current Loss: 4.4218\n",
            "[Batch 3] Current Loss: 5.5598\n",
            "[Batch 4] Current Loss: 4.9247\n",
            "[Batch 5] Current Loss: 5.3213\n",
            "[Batch 6] Current Loss: 4.7146\n",
            "[Batch 7] Current Loss: 4.4281\n",
            "[Batch 8] Current Loss: 5.0926\n",
            "[Batch 9] Current Loss: 5.7950\n",
            "Ep 3 (Step 024340): Train loss 2.800, Val loss 5.140\n",
            "[Batch 0] Current Loss: 2.8963\n",
            "[Batch 1] Current Loss: 3.3022\n",
            "[Batch 2] Current Loss: 2.5402\n",
            "[Batch 3] Current Loss: 3.1740\n",
            "[Batch 4] Current Loss: 2.8491\n",
            "[Batch 5] Current Loss: 2.5234\n",
            "[Batch 6] Current Loss: 2.1648\n",
            "[Batch 7] Current Loss: 3.0293\n",
            "[Batch 8] Current Loss: 3.0369\n",
            "[Batch 9] Current Loss: 2.7043\n",
            "[Batch 0] Current Loss: 5.5117\n",
            "[Batch 1] Current Loss: 4.8009\n",
            "[Batch 2] Current Loss: 5.5254\n",
            "[Batch 3] Current Loss: 5.4869\n",
            "[Batch 4] Current Loss: 5.1077\n",
            "[Batch 5] Current Loss: 5.5292\n",
            "[Batch 6] Current Loss: 4.8720\n",
            "[Batch 7] Current Loss: 5.3856\n",
            "[Batch 8] Current Loss: 4.9188\n",
            "[Batch 9] Current Loss: 5.1329\n",
            "Ep 3 (Step 024360): Train loss 2.822, Val loss 5.227\n",
            "[Batch 0] Current Loss: 2.8081\n",
            "[Batch 1] Current Loss: 3.7976\n",
            "[Batch 2] Current Loss: 2.7106\n",
            "[Batch 3] Current Loss: 2.8036\n",
            "[Batch 4] Current Loss: 2.0195\n",
            "[Batch 5] Current Loss: 2.9765\n",
            "[Batch 6] Current Loss: 3.2904\n",
            "[Batch 7] Current Loss: 2.8699\n",
            "[Batch 8] Current Loss: 2.2624\n",
            "[Batch 9] Current Loss: 2.8248\n",
            "[Batch 0] Current Loss: 4.7796\n",
            "[Batch 1] Current Loss: 5.4191\n",
            "[Batch 2] Current Loss: 4.9871\n",
            "[Batch 3] Current Loss: 5.2223\n",
            "[Batch 4] Current Loss: 5.2006\n",
            "[Batch 5] Current Loss: 5.3838\n",
            "[Batch 6] Current Loss: 5.3275\n",
            "[Batch 7] Current Loss: 4.5919\n",
            "[Batch 8] Current Loss: 5.3310\n",
            "[Batch 9] Current Loss: 5.1453\n",
            "Ep 3 (Step 024380): Train loss 2.836, Val loss 5.139\n",
            "[Batch 0] Current Loss: 2.4541\n",
            "[Batch 1] Current Loss: 2.9500\n",
            "[Batch 2] Current Loss: 2.7646\n",
            "[Batch 3] Current Loss: 2.8810\n",
            "[Batch 4] Current Loss: 3.3511\n",
            "[Batch 5] Current Loss: 2.5449\n",
            "[Batch 6] Current Loss: 2.5058\n",
            "[Batch 7] Current Loss: 2.6605\n",
            "[Batch 8] Current Loss: 3.5254\n",
            "[Batch 9] Current Loss: 2.9470\n",
            "[Batch 0] Current Loss: 5.1283\n",
            "[Batch 1] Current Loss: 5.3286\n",
            "[Batch 2] Current Loss: 4.9777\n",
            "[Batch 3] Current Loss: 5.6989\n",
            "[Batch 4] Current Loss: 5.1806\n",
            "[Batch 5] Current Loss: 5.6828\n",
            "[Batch 6] Current Loss: 5.7002\n",
            "[Batch 7] Current Loss: 4.6100\n",
            "[Batch 8] Current Loss: 5.2326\n",
            "[Batch 9] Current Loss: 5.3130\n",
            "Ep 3 (Step 024400): Train loss 2.858, Val loss 5.285\n",
            "[Batch 0] Current Loss: 3.0456\n",
            "[Batch 1] Current Loss: 2.6897\n",
            "[Batch 2] Current Loss: 2.9894\n",
            "[Batch 3] Current Loss: 2.6976\n",
            "[Batch 4] Current Loss: 2.9619\n",
            "[Batch 5] Current Loss: 2.4234\n",
            "[Batch 6] Current Loss: 3.0122\n",
            "[Batch 7] Current Loss: 2.7748\n",
            "[Batch 8] Current Loss: 2.9097\n",
            "[Batch 9] Current Loss: 2.8291\n",
            "[Batch 0] Current Loss: 5.3913\n",
            "[Batch 1] Current Loss: 5.2941\n",
            "[Batch 2] Current Loss: 5.0495\n",
            "[Batch 3] Current Loss: 4.9977\n",
            "[Batch 4] Current Loss: 5.6104\n",
            "[Batch 5] Current Loss: 4.8395\n",
            "[Batch 6] Current Loss: 5.2506\n",
            "[Batch 7] Current Loss: 5.6511\n",
            "[Batch 8] Current Loss: 5.6243\n",
            "[Batch 9] Current Loss: 5.4812\n",
            "Ep 3 (Step 024420): Train loss 2.833, Val loss 5.319\n",
            "[Batch 0] Current Loss: 2.9862\n",
            "[Batch 1] Current Loss: 2.7120\n",
            "[Batch 2] Current Loss: 3.3015\n",
            "[Batch 3] Current Loss: 2.2498\n",
            "[Batch 4] Current Loss: 2.6302\n",
            "[Batch 5] Current Loss: 3.4142\n",
            "[Batch 6] Current Loss: 2.8759\n",
            "[Batch 7] Current Loss: 2.6259\n",
            "[Batch 8] Current Loss: 2.7618\n",
            "[Batch 9] Current Loss: 3.1291\n",
            "[Batch 0] Current Loss: 5.0771\n",
            "[Batch 1] Current Loss: 5.4819\n",
            "[Batch 2] Current Loss: 5.1888\n",
            "[Batch 3] Current Loss: 5.1355\n",
            "[Batch 4] Current Loss: 5.5256\n",
            "[Batch 5] Current Loss: 5.9920\n",
            "[Batch 6] Current Loss: 5.5845\n",
            "[Batch 7] Current Loss: 5.5692\n",
            "[Batch 8] Current Loss: 5.7218\n",
            "[Batch 9] Current Loss: 5.5424\n",
            "Ep 3 (Step 024440): Train loss 2.869, Val loss 5.482\n",
            "[Batch 0] Current Loss: 2.8848\n",
            "[Batch 1] Current Loss: 2.1472\n",
            "[Batch 2] Current Loss: 2.3535\n",
            "[Batch 3] Current Loss: 3.2946\n",
            "[Batch 4] Current Loss: 3.3517\n",
            "[Batch 5] Current Loss: 2.5579\n",
            "[Batch 6] Current Loss: 3.1625\n",
            "[Batch 7] Current Loss: 2.3442\n",
            "[Batch 8] Current Loss: 2.9031\n",
            "[Batch 9] Current Loss: 2.6399\n",
            "[Batch 0] Current Loss: 5.9015\n",
            "[Batch 1] Current Loss: 5.2390\n",
            "[Batch 2] Current Loss: 5.4288\n",
            "[Batch 3] Current Loss: 4.6910\n",
            "[Batch 4] Current Loss: 5.1416\n",
            "[Batch 5] Current Loss: 5.4684\n",
            "[Batch 6] Current Loss: 5.2213\n",
            "[Batch 7] Current Loss: 5.2618\n",
            "[Batch 8] Current Loss: 5.3023\n",
            "[Batch 9] Current Loss: 5.4115\n",
            "Ep 3 (Step 024460): Train loss 2.764, Val loss 5.307\n",
            "[Batch 0] Current Loss: 3.0218\n",
            "[Batch 1] Current Loss: 2.9760\n",
            "[Batch 2] Current Loss: 2.9409\n",
            "[Batch 3] Current Loss: 2.3071\n",
            "[Batch 4] Current Loss: 3.0312\n",
            "[Batch 5] Current Loss: 2.4622\n",
            "[Batch 6] Current Loss: 2.9834\n",
            "[Batch 7] Current Loss: 2.3815\n",
            "[Batch 8] Current Loss: 2.8373\n",
            "[Batch 9] Current Loss: 2.1816\n",
            "[Batch 0] Current Loss: 5.1621\n",
            "[Batch 1] Current Loss: 5.3613\n",
            "[Batch 2] Current Loss: 5.2663\n",
            "[Batch 3] Current Loss: 5.1219\n",
            "[Batch 4] Current Loss: 5.9262\n",
            "[Batch 5] Current Loss: 4.7856\n",
            "[Batch 6] Current Loss: 5.4340\n",
            "[Batch 7] Current Loss: 5.8907\n",
            "[Batch 8] Current Loss: 5.2972\n",
            "[Batch 9] Current Loss: 5.4423\n",
            "Ep 3 (Step 024480): Train loss 2.712, Val loss 5.369\n",
            "[Batch 0] Current Loss: 2.7828\n",
            "[Batch 1] Current Loss: 2.8601\n",
            "[Batch 2] Current Loss: 2.9396\n",
            "[Batch 3] Current Loss: 3.4424\n",
            "[Batch 4] Current Loss: 3.3589\n",
            "[Batch 5] Current Loss: 3.3908\n",
            "[Batch 6] Current Loss: 2.7395\n",
            "[Batch 7] Current Loss: 2.8275\n",
            "[Batch 8] Current Loss: 2.7970\n",
            "[Batch 9] Current Loss: 2.6416\n",
            "[Batch 0] Current Loss: 5.6094\n",
            "[Batch 1] Current Loss: 4.5790\n",
            "[Batch 2] Current Loss: 5.1939\n",
            "[Batch 3] Current Loss: 5.3624\n",
            "[Batch 4] Current Loss: 5.2579\n",
            "[Batch 5] Current Loss: 5.4408\n",
            "[Batch 6] Current Loss: 5.7099\n",
            "[Batch 7] Current Loss: 5.2692\n",
            "[Batch 8] Current Loss: 5.3038\n",
            "[Batch 9] Current Loss: 5.3442\n",
            "Ep 3 (Step 024500): Train loss 2.978, Val loss 5.307\n",
            "[Batch 0] Current Loss: 2.8975\n",
            "[Batch 1] Current Loss: 2.8469\n",
            "[Batch 2] Current Loss: 2.6973\n",
            "[Batch 3] Current Loss: 2.8658\n",
            "[Batch 4] Current Loss: 2.6013\n",
            "[Batch 5] Current Loss: 2.3700\n",
            "[Batch 6] Current Loss: 2.8555\n",
            "[Batch 7] Current Loss: 2.8955\n",
            "[Batch 8] Current Loss: 2.5859\n",
            "[Batch 9] Current Loss: 3.1479\n",
            "[Batch 0] Current Loss: 5.8405\n",
            "[Batch 1] Current Loss: 6.0942\n",
            "[Batch 2] Current Loss: 4.7103\n",
            "[Batch 3] Current Loss: 5.5773\n",
            "[Batch 4] Current Loss: 5.1563\n",
            "[Batch 5] Current Loss: 4.5634\n",
            "[Batch 6] Current Loss: 5.9227\n",
            "[Batch 7] Current Loss: 5.5457\n",
            "[Batch 8] Current Loss: 5.1572\n",
            "[Batch 9] Current Loss: 5.5700\n",
            "Ep 3 (Step 024520): Train loss 2.776, Val loss 5.414\n",
            "[Batch 0] Current Loss: 3.1376\n",
            "[Batch 1] Current Loss: 2.5698\n",
            "[Batch 2] Current Loss: 2.7346\n",
            "[Batch 3] Current Loss: 2.6621\n",
            "[Batch 4] Current Loss: 2.6519\n",
            "[Batch 5] Current Loss: 2.6324\n",
            "[Batch 6] Current Loss: 2.6839\n",
            "[Batch 7] Current Loss: 2.3254\n",
            "[Batch 8] Current Loss: 2.9917\n",
            "[Batch 9] Current Loss: 2.8940\n",
            "[Batch 0] Current Loss: 5.9500\n",
            "[Batch 1] Current Loss: 4.9734\n",
            "[Batch 2] Current Loss: 5.4828\n",
            "[Batch 3] Current Loss: 5.1990\n",
            "[Batch 4] Current Loss: 5.3554\n",
            "[Batch 5] Current Loss: 5.7680\n",
            "[Batch 6] Current Loss: 4.6103\n",
            "[Batch 7] Current Loss: 5.3817\n",
            "[Batch 8] Current Loss: 5.2446\n",
            "[Batch 9] Current Loss: 4.5595\n",
            "Ep 3 (Step 024540): Train loss 2.728, Val loss 5.252\n",
            "[Batch 0] Current Loss: 2.7745\n",
            "[Batch 1] Current Loss: 2.0019\n",
            "[Batch 2] Current Loss: 2.5959\n",
            "[Batch 3] Current Loss: 3.1292\n",
            "[Batch 4] Current Loss: 2.4687\n",
            "[Batch 5] Current Loss: 2.7219\n",
            "[Batch 6] Current Loss: 2.9633\n",
            "[Batch 7] Current Loss: 2.8867\n",
            "[Batch 8] Current Loss: 3.1651\n",
            "[Batch 9] Current Loss: 2.5984\n",
            "[Batch 0] Current Loss: 5.3379\n",
            "[Batch 1] Current Loss: 5.3170\n",
            "[Batch 2] Current Loss: 5.1981\n",
            "[Batch 3] Current Loss: 5.7166\n",
            "[Batch 4] Current Loss: 5.6246\n",
            "[Batch 5] Current Loss: 5.2769\n",
            "[Batch 6] Current Loss: 3.9700\n",
            "[Batch 7] Current Loss: 6.0815\n",
            "[Batch 8] Current Loss: 5.8470\n",
            "[Batch 9] Current Loss: 5.0191\n",
            "Ep 3 (Step 024560): Train loss 2.731, Val loss 5.339\n",
            "[Batch 0] Current Loss: 2.8596\n",
            "[Batch 1] Current Loss: 2.2136\n",
            "[Batch 2] Current Loss: 2.0021\n",
            "[Batch 3] Current Loss: 3.0862\n",
            "[Batch 4] Current Loss: 3.2167\n",
            "[Batch 5] Current Loss: 3.1234\n",
            "[Batch 6] Current Loss: 2.7164\n",
            "[Batch 7] Current Loss: 3.2446\n",
            "[Batch 8] Current Loss: 2.9388\n",
            "[Batch 9] Current Loss: 2.6175\n",
            "[Batch 0] Current Loss: 4.4893\n",
            "[Batch 1] Current Loss: 5.7979\n",
            "[Batch 2] Current Loss: 5.1656\n",
            "[Batch 3] Current Loss: 5.1974\n",
            "[Batch 4] Current Loss: 5.2092\n",
            "[Batch 5] Current Loss: 4.9628\n",
            "[Batch 6] Current Loss: 5.7317\n",
            "[Batch 7] Current Loss: 5.7878\n",
            "[Batch 8] Current Loss: 5.1915\n",
            "[Batch 9] Current Loss: 5.8618\n",
            "Ep 3 (Step 024580): Train loss 2.802, Val loss 5.339\n",
            "[Batch 0] Current Loss: 2.4830\n",
            "[Batch 1] Current Loss: 2.7882\n",
            "[Batch 2] Current Loss: 2.7349\n",
            "[Batch 3] Current Loss: 3.0042\n",
            "[Batch 4] Current Loss: 2.6575\n",
            "[Batch 5] Current Loss: 2.8880\n",
            "[Batch 6] Current Loss: 3.0368\n",
            "[Batch 7] Current Loss: 3.3835\n",
            "[Batch 8] Current Loss: 3.5692\n",
            "[Batch 9] Current Loss: 2.6376\n",
            "[Batch 0] Current Loss: 5.1139\n",
            "[Batch 1] Current Loss: 4.8344\n",
            "[Batch 2] Current Loss: 5.1006\n",
            "[Batch 3] Current Loss: 5.0040\n",
            "[Batch 4] Current Loss: 4.4804\n",
            "[Batch 5] Current Loss: 5.2809\n",
            "[Batch 6] Current Loss: 4.9168\n",
            "[Batch 7] Current Loss: 5.7188\n",
            "[Batch 8] Current Loss: 5.3980\n",
            "[Batch 9] Current Loss: 5.0076\n",
            "Ep 3 (Step 024600): Train loss 2.918, Val loss 5.086\n",
            "[Batch 0] Current Loss: 2.3658\n",
            "[Batch 1] Current Loss: 3.0398\n",
            "[Batch 2] Current Loss: 2.6885\n",
            "[Batch 3] Current Loss: 2.3024\n",
            "[Batch 4] Current Loss: 2.6120\n",
            "[Batch 5] Current Loss: 2.8286\n",
            "[Batch 6] Current Loss: 3.0066\n",
            "[Batch 7] Current Loss: 2.9078\n",
            "[Batch 8] Current Loss: 2.6527\n",
            "[Batch 9] Current Loss: 2.9966\n",
            "[Batch 0] Current Loss: 4.7008\n",
            "[Batch 1] Current Loss: 4.9367\n",
            "[Batch 2] Current Loss: 5.5992\n",
            "[Batch 3] Current Loss: 5.5212\n",
            "[Batch 4] Current Loss: 5.2910\n",
            "[Batch 5] Current Loss: 5.3946\n",
            "[Batch 6] Current Loss: 5.4410\n",
            "[Batch 7] Current Loss: 5.0686\n",
            "[Batch 8] Current Loss: 5.1851\n",
            "[Batch 9] Current Loss: 4.3617\n",
            "Ep 3 (Step 024620): Train loss 2.740, Val loss 5.150\n",
            "[Batch 0] Current Loss: 2.2735\n",
            "[Batch 1] Current Loss: 3.3389\n",
            "[Batch 2] Current Loss: 3.0111\n",
            "[Batch 3] Current Loss: 2.8058\n",
            "[Batch 4] Current Loss: 3.1025\n",
            "[Batch 5] Current Loss: 2.7986\n",
            "[Batch 6] Current Loss: 3.2195\n",
            "[Batch 7] Current Loss: 2.2594\n",
            "[Batch 8] Current Loss: 2.7818\n",
            "[Batch 9] Current Loss: 2.9301\n",
            "[Batch 0] Current Loss: 5.3600\n",
            "[Batch 1] Current Loss: 5.5657\n",
            "[Batch 2] Current Loss: 4.8980\n",
            "[Batch 3] Current Loss: 4.6199\n",
            "[Batch 4] Current Loss: 5.2985\n",
            "[Batch 5] Current Loss: 5.3420\n",
            "[Batch 6] Current Loss: 5.5875\n",
            "[Batch 7] Current Loss: 6.2698\n",
            "[Batch 8] Current Loss: 5.4176\n",
            "[Batch 9] Current Loss: 5.8457\n",
            "Ep 3 (Step 024640): Train loss 2.852, Val loss 5.420\n",
            "[Batch 0] Current Loss: 3.1968\n",
            "[Batch 1] Current Loss: 2.7443\n",
            "[Batch 2] Current Loss: 2.5768\n",
            "[Batch 3] Current Loss: 2.6994\n",
            "[Batch 4] Current Loss: 2.8530\n",
            "[Batch 5] Current Loss: 2.1086\n",
            "[Batch 6] Current Loss: 2.7633\n",
            "[Batch 7] Current Loss: 2.9337\n",
            "[Batch 8] Current Loss: 2.2454\n",
            "[Batch 9] Current Loss: 2.4768\n",
            "[Batch 0] Current Loss: 4.9696\n",
            "[Batch 1] Current Loss: 4.8767\n",
            "[Batch 2] Current Loss: 4.9613\n",
            "[Batch 3] Current Loss: 5.4823\n",
            "[Batch 4] Current Loss: 5.3374\n",
            "[Batch 5] Current Loss: 5.6622\n",
            "[Batch 6] Current Loss: 5.7346\n",
            "[Batch 7] Current Loss: 5.1358\n",
            "[Batch 8] Current Loss: 4.9268\n",
            "[Batch 9] Current Loss: 5.7865\n",
            "Ep 3 (Step 024660): Train loss 2.660, Val loss 5.287\n",
            "[Batch 0] Current Loss: 3.2636\n",
            "[Batch 1] Current Loss: 2.7745\n",
            "[Batch 2] Current Loss: 2.9947\n",
            "[Batch 3] Current Loss: 2.8267\n",
            "[Batch 4] Current Loss: 3.0497\n",
            "[Batch 5] Current Loss: 2.8052\n",
            "[Batch 6] Current Loss: 2.6287\n",
            "[Batch 7] Current Loss: 3.1611\n",
            "[Batch 8] Current Loss: 3.1761\n",
            "[Batch 9] Current Loss: 2.5919\n",
            "[Batch 0] Current Loss: 6.1382\n",
            "[Batch 1] Current Loss: 4.8212\n",
            "[Batch 2] Current Loss: 5.5748\n",
            "[Batch 3] Current Loss: 5.0197\n",
            "[Batch 4] Current Loss: 6.2888\n",
            "[Batch 5] Current Loss: 5.4063\n",
            "[Batch 6] Current Loss: 5.2424\n",
            "[Batch 7] Current Loss: 5.7922\n",
            "[Batch 8] Current Loss: 5.4708\n",
            "[Batch 9] Current Loss: 5.7707\n",
            "Ep 3 (Step 024680): Train loss 2.927, Val loss 5.553\n",
            "[Batch 0] Current Loss: 3.3537\n",
            "[Batch 1] Current Loss: 3.3786\n",
            "[Batch 2] Current Loss: 2.9632\n",
            "[Batch 3] Current Loss: 2.9522\n",
            "[Batch 4] Current Loss: 2.6029\n",
            "[Batch 5] Current Loss: 2.7102\n",
            "[Batch 6] Current Loss: 2.5609\n",
            "[Batch 7] Current Loss: 2.9523\n",
            "[Batch 8] Current Loss: 2.7286\n",
            "[Batch 9] Current Loss: 2.8255\n",
            "[Batch 0] Current Loss: 5.0880\n",
            "[Batch 1] Current Loss: 5.0613\n",
            "[Batch 2] Current Loss: 4.4741\n",
            "[Batch 3] Current Loss: 5.3131\n",
            "[Batch 4] Current Loss: 5.5618\n",
            "[Batch 5] Current Loss: 5.1114\n",
            "[Batch 6] Current Loss: 5.2991\n",
            "[Batch 7] Current Loss: 5.4414\n",
            "[Batch 8] Current Loss: 5.0744\n",
            "[Batch 9] Current Loss: 5.8116\n",
            "Ep 3 (Step 024700): Train loss 2.903, Val loss 5.224\n",
            "[Batch 0] Current Loss: 2.8206\n",
            "[Batch 1] Current Loss: 2.5417\n",
            "[Batch 2] Current Loss: 2.8869\n",
            "[Batch 3] Current Loss: 3.1737\n",
            "[Batch 4] Current Loss: 2.6826\n",
            "[Batch 5] Current Loss: 2.6818\n",
            "[Batch 6] Current Loss: 3.1474\n",
            "[Batch 7] Current Loss: 2.9221\n",
            "[Batch 8] Current Loss: 2.2926\n",
            "[Batch 9] Current Loss: 3.2817\n",
            "[Batch 0] Current Loss: 5.1587\n",
            "[Batch 1] Current Loss: 5.6691\n",
            "[Batch 2] Current Loss: 5.0663\n",
            "[Batch 3] Current Loss: 5.6031\n",
            "[Batch 4] Current Loss: 5.5391\n",
            "[Batch 5] Current Loss: 5.3324\n",
            "[Batch 6] Current Loss: 4.9355\n",
            "[Batch 7] Current Loss: 5.6987\n",
            "[Batch 8] Current Loss: 5.8230\n",
            "[Batch 9] Current Loss: 5.6087\n",
            "Ep 3 (Step 024720): Train loss 2.843, Val loss 5.443\n",
            "[Batch 0] Current Loss: 2.9270\n",
            "[Batch 1] Current Loss: 2.6148\n",
            "[Batch 2] Current Loss: 2.7946\n",
            "[Batch 3] Current Loss: 2.8117\n",
            "[Batch 4] Current Loss: 3.3272\n",
            "[Batch 5] Current Loss: 2.4455\n",
            "[Batch 6] Current Loss: 3.1888\n",
            "[Batch 7] Current Loss: 2.9231\n",
            "[Batch 8] Current Loss: 2.7938\n",
            "[Batch 9] Current Loss: 3.1395\n",
            "[Batch 0] Current Loss: 5.0074\n",
            "[Batch 1] Current Loss: 5.6449\n",
            "[Batch 2] Current Loss: 5.2964\n",
            "[Batch 3] Current Loss: 5.9661\n",
            "[Batch 4] Current Loss: 4.3262\n",
            "[Batch 5] Current Loss: 5.2419\n",
            "[Batch 6] Current Loss: 4.8977\n",
            "[Batch 7] Current Loss: 6.0745\n",
            "[Batch 8] Current Loss: 5.7373\n",
            "[Batch 9] Current Loss: 5.4875\n",
            "Ep 3 (Step 024740): Train loss 2.897, Val loss 5.368\n",
            "[Batch 0] Current Loss: 2.9374\n",
            "[Batch 1] Current Loss: 3.3385\n",
            "[Batch 2] Current Loss: 2.7963\n",
            "[Batch 3] Current Loss: 3.1551\n",
            "[Batch 4] Current Loss: 2.7858\n",
            "[Batch 5] Current Loss: 3.2678\n",
            "[Batch 6] Current Loss: 3.0330\n",
            "[Batch 7] Current Loss: 3.2648\n",
            "[Batch 8] Current Loss: 3.0635\n",
            "[Batch 9] Current Loss: 2.5028\n",
            "[Batch 0] Current Loss: 5.2958\n",
            "[Batch 1] Current Loss: 5.1271\n",
            "[Batch 2] Current Loss: 5.0546\n",
            "[Batch 3] Current Loss: 5.1492\n",
            "[Batch 4] Current Loss: 4.8859\n",
            "[Batch 5] Current Loss: 5.4078\n",
            "[Batch 6] Current Loss: 5.8087\n",
            "[Batch 7] Current Loss: 5.0662\n",
            "[Batch 8] Current Loss: 5.3776\n",
            "[Batch 9] Current Loss: 5.2134\n",
            "Ep 3 (Step 024760): Train loss 3.015, Val loss 5.239\n",
            "[Batch 0] Current Loss: 2.6733\n",
            "[Batch 1] Current Loss: 2.5522\n",
            "[Batch 2] Current Loss: 2.5849\n",
            "[Batch 3] Current Loss: 2.3603\n",
            "[Batch 4] Current Loss: 2.4485\n",
            "[Batch 5] Current Loss: 2.8481\n",
            "[Batch 6] Current Loss: 2.6293\n",
            "[Batch 7] Current Loss: 3.0591\n",
            "[Batch 8] Current Loss: 3.4579\n",
            "[Batch 9] Current Loss: 3.0209\n",
            "[Batch 0] Current Loss: 5.4883\n",
            "[Batch 1] Current Loss: 5.3629\n",
            "[Batch 2] Current Loss: 4.6914\n",
            "[Batch 3] Current Loss: 5.2641\n",
            "[Batch 4] Current Loss: 5.2400\n",
            "[Batch 5] Current Loss: 5.7311\n",
            "[Batch 6] Current Loss: 5.9429\n",
            "[Batch 7] Current Loss: 6.1954\n",
            "[Batch 8] Current Loss: 4.7478\n",
            "[Batch 9] Current Loss: 5.3469\n",
            "Ep 3 (Step 024780): Train loss 2.763, Val loss 5.401\n",
            "[Batch 0] Current Loss: 2.8693\n",
            "[Batch 1] Current Loss: 2.8286\n",
            "[Batch 2] Current Loss: 2.7241\n",
            "[Batch 3] Current Loss: 3.0184\n",
            "[Batch 4] Current Loss: 3.5491\n",
            "[Batch 5] Current Loss: 2.8289\n",
            "[Batch 6] Current Loss: 2.8344\n",
            "[Batch 7] Current Loss: 2.2828\n",
            "[Batch 8] Current Loss: 2.7396\n",
            "[Batch 9] Current Loss: 3.5203\n",
            "[Batch 0] Current Loss: 5.0583\n",
            "[Batch 1] Current Loss: 5.9863\n",
            "[Batch 2] Current Loss: 4.9987\n",
            "[Batch 3] Current Loss: 5.3685\n",
            "[Batch 4] Current Loss: 5.3881\n",
            "[Batch 5] Current Loss: 5.0086\n",
            "[Batch 6] Current Loss: 5.0344\n",
            "[Batch 7] Current Loss: 5.3546\n",
            "[Batch 8] Current Loss: 4.4879\n",
            "[Batch 9] Current Loss: 4.6000\n",
            "Ep 3 (Step 024800): Train loss 2.920, Val loss 5.129\n",
            "[Batch 0] Current Loss: 2.8134\n",
            "[Batch 1] Current Loss: 3.0258\n",
            "[Batch 2] Current Loss: 2.8198\n",
            "[Batch 3] Current Loss: 2.1255\n",
            "[Batch 4] Current Loss: 3.0435\n",
            "[Batch 5] Current Loss: 2.1092\n",
            "[Batch 6] Current Loss: 3.1924\n",
            "[Batch 7] Current Loss: 2.6164\n",
            "[Batch 8] Current Loss: 2.9003\n",
            "[Batch 9] Current Loss: 2.5991\n",
            "[Batch 0] Current Loss: 5.7285\n",
            "[Batch 1] Current Loss: 5.4249\n",
            "[Batch 2] Current Loss: 6.1614\n",
            "[Batch 3] Current Loss: 5.5052\n",
            "[Batch 4] Current Loss: 5.8071\n",
            "[Batch 5] Current Loss: 5.3080\n",
            "[Batch 6] Current Loss: 5.6892\n",
            "[Batch 7] Current Loss: 5.6190\n",
            "[Batch 8] Current Loss: 5.7756\n",
            "[Batch 9] Current Loss: 5.2915\n",
            "Ep 3 (Step 024820): Train loss 2.725, Val loss 5.631\n",
            "[Batch 0] Current Loss: 2.3218\n",
            "[Batch 1] Current Loss: 2.4445\n",
            "[Batch 2] Current Loss: 2.0686\n",
            "[Batch 3] Current Loss: 2.2644\n",
            "[Batch 4] Current Loss: 2.5199\n",
            "[Batch 5] Current Loss: 2.9416\n",
            "[Batch 6] Current Loss: 3.3623\n",
            "[Batch 7] Current Loss: 3.2205\n",
            "[Batch 8] Current Loss: 2.6772\n",
            "[Batch 9] Current Loss: 3.0882\n",
            "[Batch 0] Current Loss: 5.4976\n",
            "[Batch 1] Current Loss: 5.7300\n",
            "[Batch 2] Current Loss: 5.3068\n",
            "[Batch 3] Current Loss: 5.9767\n",
            "[Batch 4] Current Loss: 5.5003\n",
            "[Batch 5] Current Loss: 5.1186\n",
            "[Batch 6] Current Loss: 5.5496\n",
            "[Batch 7] Current Loss: 4.6740\n",
            "[Batch 8] Current Loss: 6.1608\n",
            "[Batch 9] Current Loss: 5.6443\n",
            "Ep 3 (Step 024840): Train loss 2.691, Val loss 5.516\n",
            "[Batch 0] Current Loss: 3.0462\n",
            "[Batch 1] Current Loss: 2.2670\n",
            "[Batch 2] Current Loss: 2.3706\n",
            "[Batch 3] Current Loss: 2.9947\n",
            "[Batch 4] Current Loss: 2.9966\n",
            "[Batch 5] Current Loss: 3.3065\n",
            "[Batch 6] Current Loss: 3.1830\n",
            "[Batch 7] Current Loss: 3.1593\n",
            "[Batch 8] Current Loss: 2.6835\n",
            "[Batch 9] Current Loss: 2.9142\n",
            "[Batch 0] Current Loss: 5.6472\n",
            "[Batch 1] Current Loss: 5.9979\n",
            "[Batch 2] Current Loss: 6.1347\n",
            "[Batch 3] Current Loss: 4.7533\n",
            "[Batch 4] Current Loss: 4.9376\n",
            "[Batch 5] Current Loss: 5.2406\n",
            "[Batch 6] Current Loss: 6.2918\n",
            "[Batch 7] Current Loss: 5.6340\n",
            "[Batch 8] Current Loss: 5.5884\n",
            "[Batch 9] Current Loss: 4.9958\n",
            "Ep 3 (Step 024860): Train loss 2.892, Val loss 5.522\n",
            "[Batch 0] Current Loss: 2.9422\n",
            "[Batch 1] Current Loss: 2.7733\n",
            "[Batch 2] Current Loss: 3.0387\n",
            "[Batch 3] Current Loss: 3.1758\n",
            "[Batch 4] Current Loss: 2.3531\n",
            "[Batch 5] Current Loss: 2.9167\n",
            "[Batch 6] Current Loss: 3.1735\n",
            "[Batch 7] Current Loss: 3.1785\n",
            "[Batch 8] Current Loss: 2.4979\n",
            "[Batch 9] Current Loss: 2.6138\n",
            "[Batch 0] Current Loss: 4.7452\n",
            "[Batch 1] Current Loss: 4.9843\n",
            "[Batch 2] Current Loss: 5.1313\n",
            "[Batch 3] Current Loss: 5.6579\n",
            "[Batch 4] Current Loss: 5.7623\n",
            "[Batch 5] Current Loss: 4.7407\n",
            "[Batch 6] Current Loss: 4.8547\n",
            "[Batch 7] Current Loss: 4.9964\n",
            "[Batch 8] Current Loss: 4.3683\n",
            "[Batch 9] Current Loss: 4.7327\n",
            "Ep 3 (Step 024880): Train loss 2.866, Val loss 4.997\n",
            "[Batch 0] Current Loss: 3.1238\n",
            "[Batch 1] Current Loss: 2.8104\n",
            "[Batch 2] Current Loss: 3.2007\n",
            "[Batch 3] Current Loss: 3.0547\n",
            "[Batch 4] Current Loss: 3.2226\n",
            "[Batch 5] Current Loss: 2.9996\n",
            "[Batch 6] Current Loss: 2.8189\n",
            "[Batch 7] Current Loss: 2.2797\n",
            "[Batch 8] Current Loss: 2.5259\n",
            "[Batch 9] Current Loss: 2.5621\n",
            "[Batch 0] Current Loss: 5.8610\n",
            "[Batch 1] Current Loss: 5.5139\n",
            "[Batch 2] Current Loss: 4.4897\n",
            "[Batch 3] Current Loss: 5.3457\n",
            "[Batch 4] Current Loss: 5.7453\n",
            "[Batch 5] Current Loss: 5.3222\n",
            "[Batch 6] Current Loss: 4.9110\n",
            "[Batch 7] Current Loss: 5.0703\n",
            "[Batch 8] Current Loss: 5.1228\n",
            "[Batch 9] Current Loss: 5.5733\n",
            "Ep 3 (Step 024900): Train loss 2.860, Val loss 5.296\n",
            "[Batch 0] Current Loss: 3.3011\n",
            "[Batch 1] Current Loss: 2.4182\n",
            "[Batch 2] Current Loss: 2.8081\n",
            "[Batch 3] Current Loss: 2.8479\n",
            "[Batch 4] Current Loss: 2.7687\n",
            "[Batch 5] Current Loss: 3.2882\n",
            "[Batch 6] Current Loss: 3.3777\n",
            "[Batch 7] Current Loss: 3.0723\n",
            "[Batch 8] Current Loss: 2.9241\n",
            "[Batch 9] Current Loss: 2.3384\n",
            "[Batch 0] Current Loss: 5.3427\n",
            "[Batch 1] Current Loss: 5.0211\n",
            "[Batch 2] Current Loss: 5.2775\n",
            "[Batch 3] Current Loss: 4.8444\n",
            "[Batch 4] Current Loss: 5.0043\n",
            "[Batch 5] Current Loss: 5.5252\n",
            "[Batch 6] Current Loss: 5.6735\n",
            "[Batch 7] Current Loss: 5.3728\n",
            "[Batch 8] Current Loss: 4.1422\n",
            "[Batch 9] Current Loss: 5.8563\n",
            "Ep 3 (Step 024920): Train loss 2.914, Val loss 5.206\n",
            "[Batch 0] Current Loss: 2.5060\n",
            "[Batch 1] Current Loss: 2.7423\n",
            "[Batch 2] Current Loss: 3.0277\n",
            "[Batch 3] Current Loss: 2.3160\n",
            "[Batch 4] Current Loss: 2.9450\n",
            "[Batch 5] Current Loss: 2.6742\n",
            "[Batch 6] Current Loss: 3.2065\n",
            "[Batch 7] Current Loss: 2.5652\n",
            "[Batch 8] Current Loss: 2.4435\n",
            "[Batch 9] Current Loss: 2.7188\n",
            "[Batch 0] Current Loss: 4.8291\n",
            "[Batch 1] Current Loss: 4.8683\n",
            "[Batch 2] Current Loss: 5.9034\n",
            "[Batch 3] Current Loss: 5.4355\n",
            "[Batch 4] Current Loss: 5.9373\n",
            "[Batch 5] Current Loss: 5.4514\n",
            "[Batch 6] Current Loss: 5.1335\n",
            "[Batch 7] Current Loss: 5.9307\n",
            "[Batch 8] Current Loss: 5.6627\n",
            "[Batch 9] Current Loss: 5.3495\n",
            "Ep 3 (Step 024940): Train loss 2.715, Val loss 5.450\n",
            "[Batch 0] Current Loss: 2.9507\n",
            "[Batch 1] Current Loss: 2.8728\n",
            "[Batch 2] Current Loss: 2.7826\n",
            "[Batch 3] Current Loss: 3.1498\n",
            "[Batch 4] Current Loss: 3.4128\n",
            "[Batch 5] Current Loss: 2.7457\n",
            "[Batch 6] Current Loss: 2.6921\n",
            "[Batch 7] Current Loss: 2.8629\n",
            "[Batch 8] Current Loss: 2.8751\n",
            "[Batch 9] Current Loss: 2.6259\n",
            "[Batch 0] Current Loss: 5.2988\n",
            "[Batch 1] Current Loss: 5.4104\n",
            "[Batch 2] Current Loss: 5.3852\n",
            "[Batch 3] Current Loss: 5.1190\n",
            "[Batch 4] Current Loss: 6.0268\n",
            "[Batch 5] Current Loss: 5.1164\n",
            "[Batch 6] Current Loss: 4.5364\n",
            "[Batch 7] Current Loss: 5.1449\n",
            "[Batch 8] Current Loss: 5.1533\n",
            "[Batch 9] Current Loss: 5.7586\n",
            "Ep 3 (Step 024960): Train loss 2.897, Val loss 5.295\n",
            "[Batch 0] Current Loss: 2.4625\n",
            "[Batch 1] Current Loss: 2.7147\n",
            "[Batch 2] Current Loss: 3.1262\n",
            "[Batch 3] Current Loss: 2.9392\n",
            "[Batch 4] Current Loss: 2.8811\n",
            "[Batch 5] Current Loss: 3.0061\n",
            "[Batch 6] Current Loss: 3.5744\n",
            "[Batch 7] Current Loss: 2.8787\n",
            "[Batch 8] Current Loss: 2.8906\n",
            "[Batch 9] Current Loss: 3.1446\n",
            "[Batch 0] Current Loss: 5.7769\n",
            "[Batch 1] Current Loss: 5.1308\n",
            "[Batch 2] Current Loss: 5.5215\n",
            "[Batch 3] Current Loss: 5.7222\n",
            "[Batch 4] Current Loss: 5.2496\n",
            "[Batch 5] Current Loss: 4.6502\n",
            "[Batch 6] Current Loss: 5.4105\n",
            "[Batch 7] Current Loss: 6.1020\n",
            "[Batch 8] Current Loss: 6.1609\n",
            "[Batch 9] Current Loss: 4.3496\n",
            "Ep 3 (Step 024980): Train loss 2.962, Val loss 5.407\n",
            "[Batch 0] Current Loss: 2.6952\n",
            "[Batch 1] Current Loss: 3.2184\n",
            "[Batch 2] Current Loss: 2.3276\n",
            "[Batch 3] Current Loss: 2.9219\n",
            "[Batch 4] Current Loss: 3.1654\n",
            "[Batch 5] Current Loss: 2.6640\n",
            "[Batch 6] Current Loss: 2.4057\n",
            "[Batch 7] Current Loss: 2.9083\n",
            "[Batch 8] Current Loss: 2.7562\n",
            "[Batch 9] Current Loss: 2.8641\n",
            "[Batch 0] Current Loss: 5.1882\n",
            "[Batch 1] Current Loss: 4.9912\n",
            "[Batch 2] Current Loss: 6.0817\n",
            "[Batch 3] Current Loss: 5.0353\n",
            "[Batch 4] Current Loss: 5.2856\n",
            "[Batch 5] Current Loss: 5.3507\n",
            "[Batch 6] Current Loss: 4.9886\n",
            "[Batch 7] Current Loss: 5.6366\n",
            "[Batch 8] Current Loss: 5.5682\n",
            "[Batch 9] Current Loss: 4.6478\n",
            "Ep 3 (Step 025000): Train loss 2.793, Val loss 5.277\n",
            "[Batch 0] Current Loss: 3.1600\n",
            "[Batch 1] Current Loss: 3.5130\n",
            "[Batch 2] Current Loss: 2.8221\n",
            "[Batch 3] Current Loss: 3.0534\n",
            "[Batch 4] Current Loss: 2.6451\n",
            "[Batch 5] Current Loss: 3.0239\n",
            "[Batch 6] Current Loss: 3.1598\n",
            "[Batch 7] Current Loss: 2.5225\n",
            "[Batch 8] Current Loss: 2.9722\n",
            "[Batch 9] Current Loss: 2.7532\n",
            "[Batch 0] Current Loss: 5.7715\n",
            "[Batch 1] Current Loss: 5.5970\n",
            "[Batch 2] Current Loss: 5.1011\n",
            "[Batch 3] Current Loss: 5.2480\n",
            "[Batch 4] Current Loss: 6.1573\n",
            "[Batch 5] Current Loss: 4.2811\n",
            "[Batch 6] Current Loss: 5.1231\n",
            "[Batch 7] Current Loss: 5.6589\n",
            "[Batch 8] Current Loss: 5.6434\n",
            "[Batch 9] Current Loss: 5.7279\n",
            "Ep 3 (Step 025020): Train loss 2.963, Val loss 5.431\n",
            "[Batch 0] Current Loss: 2.9441\n",
            "[Batch 1] Current Loss: 3.1582\n",
            "[Batch 2] Current Loss: 2.7145\n",
            "[Batch 3] Current Loss: 2.9640\n",
            "[Batch 4] Current Loss: 3.1967\n",
            "[Batch 5] Current Loss: 2.8563\n",
            "[Batch 6] Current Loss: 2.7579\n",
            "[Batch 7] Current Loss: 2.5869\n",
            "[Batch 8] Current Loss: 3.0533\n",
            "[Batch 9] Current Loss: 2.3740\n",
            "[Batch 0] Current Loss: 4.9634\n",
            "[Batch 1] Current Loss: 4.2447\n",
            "[Batch 2] Current Loss: 5.5579\n",
            "[Batch 3] Current Loss: 5.8915\n",
            "[Batch 4] Current Loss: 5.1811\n",
            "[Batch 5] Current Loss: 5.4974\n",
            "[Batch 6] Current Loss: 4.4018\n",
            "[Batch 7] Current Loss: 5.5768\n",
            "[Batch 8] Current Loss: 5.4812\n",
            "[Batch 9] Current Loss: 4.5052\n",
            "Ep 3 (Step 025040): Train loss 2.861, Val loss 5.130\n",
            "[Batch 0] Current Loss: 3.6919\n",
            "[Batch 1] Current Loss: 3.1043\n",
            "[Batch 2] Current Loss: 2.4943\n",
            "[Batch 3] Current Loss: 3.0011\n",
            "[Batch 4] Current Loss: 3.0174\n",
            "[Batch 5] Current Loss: 3.2309\n",
            "[Batch 6] Current Loss: 3.1150\n",
            "[Batch 7] Current Loss: 2.6922\n",
            "[Batch 8] Current Loss: 2.6037\n",
            "[Batch 9] Current Loss: 2.6862\n",
            "[Batch 0] Current Loss: 5.5614\n",
            "[Batch 1] Current Loss: 4.1582\n",
            "[Batch 2] Current Loss: 5.5278\n",
            "[Batch 3] Current Loss: 5.8302\n",
            "[Batch 4] Current Loss: 5.0343\n",
            "[Batch 5] Current Loss: 5.8392\n",
            "[Batch 6] Current Loss: 6.3010\n",
            "[Batch 7] Current Loss: 5.2192\n",
            "[Batch 8] Current Loss: 4.3978\n",
            "[Batch 9] Current Loss: 4.9604\n",
            "Ep 3 (Step 025060): Train loss 2.964, Val loss 5.283\n",
            "[Batch 0] Current Loss: 2.9827\n",
            "[Batch 1] Current Loss: 3.0261\n",
            "[Batch 2] Current Loss: 2.7731\n",
            "[Batch 3] Current Loss: 3.0745\n",
            "[Batch 4] Current Loss: 3.0836\n",
            "[Batch 5] Current Loss: 3.1425\n",
            "[Batch 6] Current Loss: 3.1144\n",
            "[Batch 7] Current Loss: 2.9637\n",
            "[Batch 8] Current Loss: 2.6127\n",
            "[Batch 9] Current Loss: 2.6443\n",
            "[Batch 0] Current Loss: 5.5569\n",
            "[Batch 1] Current Loss: 5.4524\n",
            "[Batch 2] Current Loss: 6.0350\n",
            "[Batch 3] Current Loss: 4.8395\n",
            "[Batch 4] Current Loss: 5.5763\n",
            "[Batch 5] Current Loss: 4.9814\n",
            "[Batch 6] Current Loss: 5.5360\n",
            "[Batch 7] Current Loss: 5.7675\n",
            "[Batch 8] Current Loss: 6.0894\n",
            "[Batch 9] Current Loss: 6.0687\n",
            "Ep 3 (Step 025080): Train loss 2.942, Val loss 5.590\n",
            "[Batch 0] Current Loss: 2.3390\n",
            "[Batch 1] Current Loss: 3.1149\n",
            "[Batch 2] Current Loss: 2.2231\n",
            "[Batch 3] Current Loss: 3.0356\n",
            "[Batch 4] Current Loss: 2.5641\n",
            "[Batch 5] Current Loss: 2.7275\n",
            "[Batch 6] Current Loss: 2.8906\n",
            "[Batch 7] Current Loss: 3.1118\n",
            "[Batch 8] Current Loss: 3.2564\n",
            "[Batch 9] Current Loss: 2.4237\n",
            "[Batch 0] Current Loss: 5.3442\n",
            "[Batch 1] Current Loss: 6.0053\n",
            "[Batch 2] Current Loss: 5.2584\n",
            "[Batch 3] Current Loss: 5.1697\n",
            "[Batch 4] Current Loss: 5.8914\n",
            "[Batch 5] Current Loss: 5.4025\n",
            "[Batch 6] Current Loss: 5.4894\n",
            "[Batch 7] Current Loss: 5.0187\n",
            "[Batch 8] Current Loss: 5.9967\n",
            "[Batch 9] Current Loss: 5.1918\n",
            "Ep 3 (Step 025100): Train loss 2.769, Val loss 5.477\n",
            "[Batch 0] Current Loss: 3.6095\n",
            "[Batch 1] Current Loss: 3.5847\n",
            "[Batch 2] Current Loss: 2.4423\n",
            "[Batch 3] Current Loss: 2.7840\n",
            "[Batch 4] Current Loss: 3.3044\n",
            "[Batch 5] Current Loss: 3.1437\n",
            "[Batch 6] Current Loss: 2.8966\n",
            "[Batch 7] Current Loss: 3.4994\n",
            "[Batch 8] Current Loss: 2.6325\n",
            "[Batch 9] Current Loss: 2.9988\n",
            "[Batch 0] Current Loss: 5.0886\n",
            "[Batch 1] Current Loss: 4.7885\n",
            "[Batch 2] Current Loss: 5.9712\n",
            "[Batch 3] Current Loss: 4.7351\n",
            "[Batch 4] Current Loss: 5.3696\n",
            "[Batch 5] Current Loss: 4.5748\n",
            "[Batch 6] Current Loss: 5.4589\n",
            "[Batch 7] Current Loss: 4.8975\n",
            "[Batch 8] Current Loss: 5.5207\n",
            "[Batch 9] Current Loss: 5.2697\n",
            "Ep 3 (Step 025120): Train loss 3.090, Val loss 5.167\n",
            "[Batch 0] Current Loss: 2.5898\n",
            "[Batch 1] Current Loss: 3.0174\n",
            "[Batch 2] Current Loss: 2.5301\n",
            "[Batch 3] Current Loss: 3.1543\n",
            "[Batch 4] Current Loss: 3.1521\n",
            "[Batch 5] Current Loss: 2.6907\n",
            "[Batch 6] Current Loss: 2.9673\n",
            "[Batch 7] Current Loss: 2.7747\n",
            "[Batch 8] Current Loss: 3.0937\n",
            "[Batch 9] Current Loss: 2.9025\n",
            "[Batch 0] Current Loss: 5.7022\n",
            "[Batch 1] Current Loss: 4.9392\n",
            "[Batch 2] Current Loss: 6.4235\n",
            "[Batch 3] Current Loss: 4.7406\n",
            "[Batch 4] Current Loss: 4.8355\n",
            "[Batch 5] Current Loss: 5.7777\n",
            "[Batch 6] Current Loss: 5.4042\n",
            "[Batch 7] Current Loss: 5.5141\n",
            "[Batch 8] Current Loss: 5.9924\n",
            "[Batch 9] Current Loss: 5.4051\n",
            "Ep 3 (Step 025140): Train loss 2.887, Val loss 5.473\n",
            "[Batch 0] Current Loss: 3.1912\n",
            "[Batch 1] Current Loss: 2.7103\n",
            "[Batch 2] Current Loss: 3.0623\n",
            "[Batch 3] Current Loss: 2.3848\n",
            "[Batch 4] Current Loss: 2.9902\n",
            "[Batch 5] Current Loss: 2.5775\n",
            "[Batch 6] Current Loss: 3.1273\n",
            "[Batch 7] Current Loss: 3.2968\n",
            "[Batch 8] Current Loss: 2.5587\n",
            "[Batch 9] Current Loss: 2.8095\n",
            "[Batch 0] Current Loss: 4.7537\n",
            "[Batch 1] Current Loss: 4.6414\n",
            "[Batch 2] Current Loss: 5.2250\n",
            "[Batch 3] Current Loss: 4.7646\n",
            "[Batch 4] Current Loss: 5.3376\n",
            "[Batch 5] Current Loss: 5.2599\n",
            "[Batch 6] Current Loss: 5.2756\n",
            "[Batch 7] Current Loss: 5.2955\n",
            "[Batch 8] Current Loss: 5.5219\n",
            "[Batch 9] Current Loss: 4.7212\n",
            "Ep 3 (Step 025160): Train loss 2.871, Val loss 5.080\n",
            "[Batch 0] Current Loss: 3.1747\n",
            "[Batch 1] Current Loss: 3.3305\n",
            "[Batch 2] Current Loss: 3.0993\n",
            "[Batch 3] Current Loss: 2.8759\n",
            "[Batch 4] Current Loss: 2.9809\n",
            "[Batch 5] Current Loss: 2.6192\n",
            "[Batch 6] Current Loss: 2.7187\n",
            "[Batch 7] Current Loss: 2.9987\n",
            "[Batch 8] Current Loss: 3.5653\n",
            "[Batch 9] Current Loss: 3.3269\n",
            "[Batch 0] Current Loss: 5.7048\n",
            "[Batch 1] Current Loss: 5.1789\n",
            "[Batch 2] Current Loss: 4.8411\n",
            "[Batch 3] Current Loss: 4.6285\n",
            "[Batch 4] Current Loss: 5.6370\n",
            "[Batch 5] Current Loss: 4.8749\n",
            "[Batch 6] Current Loss: 5.2444\n",
            "[Batch 7] Current Loss: 5.4515\n",
            "[Batch 8] Current Loss: 5.8367\n",
            "[Batch 9] Current Loss: 5.7561\n",
            "Ep 3 (Step 025180): Train loss 3.069, Val loss 5.315\n",
            "[Batch 0] Current Loss: 3.1293\n",
            "[Batch 1] Current Loss: 2.4194\n",
            "[Batch 2] Current Loss: 2.4805\n",
            "[Batch 3] Current Loss: 2.9697\n",
            "[Batch 4] Current Loss: 3.0923\n",
            "[Batch 5] Current Loss: 2.7152\n",
            "[Batch 6] Current Loss: 2.5491\n",
            "[Batch 7] Current Loss: 3.0335\n",
            "[Batch 8] Current Loss: 2.9140\n",
            "[Batch 9] Current Loss: 3.1094\n",
            "[Batch 0] Current Loss: 5.5341\n",
            "[Batch 1] Current Loss: 5.8312\n",
            "[Batch 2] Current Loss: 5.2523\n",
            "[Batch 3] Current Loss: 5.1539\n",
            "[Batch 4] Current Loss: 5.2822\n",
            "[Batch 5] Current Loss: 5.5965\n",
            "[Batch 6] Current Loss: 5.3032\n",
            "[Batch 7] Current Loss: 5.5264\n",
            "[Batch 8] Current Loss: 4.7604\n",
            "[Batch 9] Current Loss: 5.2666\n",
            "Ep 3 (Step 025200): Train loss 2.841, Val loss 5.351\n",
            "[Batch 0] Current Loss: 3.2114\n",
            "[Batch 1] Current Loss: 2.2007\n",
            "[Batch 2] Current Loss: 2.7768\n",
            "[Batch 3] Current Loss: 2.9411\n",
            "[Batch 4] Current Loss: 2.8572\n",
            "[Batch 5] Current Loss: 3.0980\n",
            "[Batch 6] Current Loss: 3.4696\n",
            "[Batch 7] Current Loss: 3.0392\n",
            "[Batch 8] Current Loss: 2.6881\n",
            "[Batch 9] Current Loss: 2.4620\n",
            "[Batch 0] Current Loss: 5.5070\n",
            "[Batch 1] Current Loss: 5.5547\n",
            "[Batch 2] Current Loss: 5.4176\n",
            "[Batch 3] Current Loss: 5.4720\n",
            "[Batch 4] Current Loss: 5.4554\n",
            "[Batch 5] Current Loss: 5.7982\n",
            "[Batch 6] Current Loss: 4.9915\n",
            "[Batch 7] Current Loss: 5.2236\n",
            "[Batch 8] Current Loss: 5.3408\n",
            "[Batch 9] Current Loss: 5.2392\n",
            "Ep 3 (Step 025220): Train loss 2.874, Val loss 5.400\n",
            "[Batch 0] Current Loss: 2.7131\n",
            "[Batch 1] Current Loss: 3.2237\n",
            "[Batch 2] Current Loss: 2.5751\n",
            "[Batch 3] Current Loss: 2.9876\n",
            "[Batch 4] Current Loss: 2.5642\n",
            "[Batch 5] Current Loss: 2.9768\n",
            "[Batch 6] Current Loss: 3.0035\n",
            "[Batch 7] Current Loss: 2.5241\n",
            "[Batch 8] Current Loss: 2.8861\n",
            "[Batch 9] Current Loss: 3.0545\n",
            "[Batch 0] Current Loss: 5.5023\n",
            "[Batch 1] Current Loss: 5.9663\n",
            "[Batch 2] Current Loss: 5.8718\n",
            "[Batch 3] Current Loss: 5.4170\n",
            "[Batch 4] Current Loss: 4.8880\n",
            "[Batch 5] Current Loss: 5.0808\n",
            "[Batch 6] Current Loss: 5.7614\n",
            "[Batch 7] Current Loss: 6.0896\n",
            "[Batch 8] Current Loss: 5.7253\n",
            "[Batch 9] Current Loss: 4.9975\n",
            "Ep 3 (Step 025240): Train loss 2.851, Val loss 5.530\n",
            "[Batch 0] Current Loss: 1.9164\n",
            "[Batch 1] Current Loss: 2.6991\n",
            "[Batch 2] Current Loss: 2.7744\n",
            "[Batch 3] Current Loss: 2.5626\n",
            "[Batch 4] Current Loss: 3.0087\n",
            "[Batch 5] Current Loss: 2.5453\n",
            "[Batch 6] Current Loss: 3.1195\n",
            "[Batch 7] Current Loss: 2.5428\n",
            "[Batch 8] Current Loss: 2.8931\n",
            "[Batch 9] Current Loss: 3.3581\n",
            "[Batch 0] Current Loss: 5.5662\n",
            "[Batch 1] Current Loss: 5.9587\n",
            "[Batch 2] Current Loss: 4.9493\n",
            "[Batch 3] Current Loss: 4.7731\n",
            "[Batch 4] Current Loss: 4.3374\n",
            "[Batch 5] Current Loss: 4.7709\n",
            "[Batch 6] Current Loss: 5.0789\n",
            "[Batch 7] Current Loss: 5.6722\n",
            "[Batch 8] Current Loss: 4.7236\n",
            "[Batch 9] Current Loss: 5.5854\n",
            "Ep 3 (Step 025260): Train loss 2.742, Val loss 5.142\n",
            "[Batch 0] Current Loss: 3.1611\n",
            "[Batch 1] Current Loss: 3.0017\n",
            "[Batch 2] Current Loss: 2.6730\n",
            "[Batch 3] Current Loss: 3.8544\n",
            "[Batch 4] Current Loss: 2.4427\n",
            "[Batch 5] Current Loss: 3.0121\n",
            "[Batch 6] Current Loss: 2.7221\n",
            "[Batch 7] Current Loss: 2.5850\n",
            "[Batch 8] Current Loss: 2.7120\n",
            "[Batch 9] Current Loss: 3.0768\n",
            "[Batch 0] Current Loss: 4.6794\n",
            "[Batch 1] Current Loss: 3.7356\n",
            "[Batch 2] Current Loss: 5.2393\n",
            "[Batch 3] Current Loss: 5.0643\n",
            "[Batch 4] Current Loss: 5.4804\n",
            "[Batch 5] Current Loss: 4.6003\n",
            "[Batch 6] Current Loss: 5.2035\n",
            "[Batch 7] Current Loss: 5.6708\n",
            "[Batch 8] Current Loss: 5.0465\n",
            "[Batch 9] Current Loss: 4.7898\n",
            "Ep 3 (Step 025280): Train loss 2.924, Val loss 4.951\n",
            "[Batch 0] Current Loss: 2.7913\n",
            "[Batch 1] Current Loss: 3.0588\n",
            "[Batch 2] Current Loss: 2.7617\n",
            "[Batch 3] Current Loss: 3.2905\n",
            "[Batch 4] Current Loss: 2.8092\n",
            "[Batch 5] Current Loss: 2.9823\n",
            "[Batch 6] Current Loss: 3.0347\n",
            "[Batch 7] Current Loss: 3.1319\n",
            "[Batch 8] Current Loss: 2.3661\n",
            "[Batch 9] Current Loss: 2.7263\n",
            "[Batch 0] Current Loss: 5.7014\n",
            "[Batch 1] Current Loss: 5.3243\n",
            "[Batch 2] Current Loss: 4.6095\n",
            "[Batch 3] Current Loss: 5.2055\n",
            "[Batch 4] Current Loss: 4.7895\n",
            "[Batch 5] Current Loss: 4.7027\n",
            "[Batch 6] Current Loss: 5.0034\n",
            "[Batch 7] Current Loss: 5.6284\n",
            "[Batch 8] Current Loss: 4.9897\n",
            "[Batch 9] Current Loss: 6.2446\n",
            "Ep 3 (Step 025300): Train loss 2.895, Val loss 5.220\n",
            "[Batch 0] Current Loss: 2.9585\n",
            "[Batch 1] Current Loss: 2.3331\n",
            "[Batch 2] Current Loss: 2.7027\n",
            "[Batch 3] Current Loss: 3.0173\n",
            "[Batch 4] Current Loss: 2.9757\n",
            "[Batch 5] Current Loss: 3.0383\n",
            "[Batch 6] Current Loss: 2.4679\n",
            "[Batch 7] Current Loss: 2.7594\n",
            "[Batch 8] Current Loss: 2.8288\n",
            "[Batch 9] Current Loss: 2.9401\n",
            "[Batch 0] Current Loss: 5.5543\n",
            "[Batch 1] Current Loss: 5.7280\n",
            "[Batch 2] Current Loss: 5.3106\n",
            "[Batch 3] Current Loss: 5.0162\n",
            "[Batch 4] Current Loss: 4.7694\n",
            "[Batch 5] Current Loss: 4.6426\n",
            "[Batch 6] Current Loss: 5.0856\n",
            "[Batch 7] Current Loss: 5.5512\n",
            "[Batch 8] Current Loss: 5.4320\n",
            "[Batch 9] Current Loss: 5.0110\n",
            "Ep 3 (Step 025320): Train loss 2.802, Val loss 5.210\n",
            "[Batch 0] Current Loss: 2.4440\n",
            "[Batch 1] Current Loss: 3.0858\n",
            "[Batch 2] Current Loss: 3.0828\n",
            "[Batch 3] Current Loss: 2.4129\n",
            "[Batch 4] Current Loss: 2.5009\n",
            "[Batch 5] Current Loss: 2.7751\n",
            "[Batch 6] Current Loss: 2.6338\n",
            "[Batch 7] Current Loss: 2.5286\n",
            "[Batch 8] Current Loss: 2.6769\n",
            "[Batch 9] Current Loss: 2.6419\n",
            "[Batch 0] Current Loss: 5.2800\n",
            "[Batch 1] Current Loss: 5.5206\n",
            "[Batch 2] Current Loss: 4.7436\n",
            "[Batch 3] Current Loss: 5.7790\n",
            "[Batch 4] Current Loss: 5.3389\n",
            "[Batch 5] Current Loss: 5.2628\n",
            "[Batch 6] Current Loss: 5.7948\n",
            "[Batch 7] Current Loss: 5.3384\n",
            "[Batch 8] Current Loss: 5.4829\n",
            "[Batch 9] Current Loss: 5.4449\n",
            "Ep 3 (Step 025340): Train loss 2.678, Val loss 5.399\n",
            "[Batch 0] Current Loss: 2.7894\n",
            "[Batch 1] Current Loss: 2.6315\n",
            "[Batch 2] Current Loss: 3.0767\n",
            "[Batch 3] Current Loss: 2.7704\n",
            "[Batch 4] Current Loss: 3.2452\n",
            "[Batch 5] Current Loss: 3.0165\n",
            "[Batch 6] Current Loss: 3.1773\n",
            "[Batch 7] Current Loss: 2.8637\n",
            "[Batch 8] Current Loss: 3.2167\n",
            "[Batch 9] Current Loss: 2.8048\n",
            "[Batch 0] Current Loss: 5.2738\n",
            "[Batch 1] Current Loss: 4.8118\n",
            "[Batch 2] Current Loss: 5.6189\n",
            "[Batch 3] Current Loss: 5.2189\n",
            "[Batch 4] Current Loss: 4.9516\n",
            "[Batch 5] Current Loss: 5.1559\n",
            "[Batch 6] Current Loss: 5.3102\n",
            "[Batch 7] Current Loss: 5.4560\n",
            "[Batch 8] Current Loss: 5.5183\n",
            "[Batch 9] Current Loss: 5.0695\n",
            "Ep 3 (Step 025360): Train loss 2.959, Val loss 5.238\n",
            "Every effort moves you'll be doing.  \"I don't know. I don't know how to say that I am a man. I am going to be able to get a proper man out of the field and the people who are going to be a man\n",
            "[Batch 0] Current Loss: 2.4587\n",
            "[Batch 1] Current Loss: 2.9153\n",
            "[Batch 2] Current Loss: 2.8026\n",
            "[Batch 3] Current Loss: 2.6256\n",
            "[Batch 4] Current Loss: 2.8417\n",
            "[Batch 5] Current Loss: 2.4510\n",
            "[Batch 6] Current Loss: 2.5790\n",
            "[Batch 7] Current Loss: 2.6879\n",
            "[Batch 8] Current Loss: 2.6650\n",
            "[Batch 9] Current Loss: 2.6674\n",
            "[Batch 0] Current Loss: 5.3477\n",
            "[Batch 1] Current Loss: 5.0634\n",
            "[Batch 2] Current Loss: 6.0443\n",
            "[Batch 3] Current Loss: 4.4148\n",
            "[Batch 4] Current Loss: 5.1220\n",
            "[Batch 5] Current Loss: 5.5344\n",
            "[Batch 6] Current Loss: 5.2330\n",
            "[Batch 7] Current Loss: 5.5203\n",
            "[Batch 8] Current Loss: 5.3942\n",
            "[Batch 9] Current Loss: 5.6065\n",
            "Ep 4 (Step 025380): Train loss 2.669, Val loss 5.328\n",
            "[Batch 0] Current Loss: 2.6809\n",
            "[Batch 1] Current Loss: 2.7825\n",
            "[Batch 2] Current Loss: 3.1813\n",
            "[Batch 3] Current Loss: 2.0420\n",
            "[Batch 4] Current Loss: 2.6232\n",
            "[Batch 5] Current Loss: 2.6915\n",
            "[Batch 6] Current Loss: 3.5206\n",
            "[Batch 7] Current Loss: 2.8158\n",
            "[Batch 8] Current Loss: 2.9240\n",
            "[Batch 9] Current Loss: 2.5251\n",
            "[Batch 0] Current Loss: 5.3149\n",
            "[Batch 1] Current Loss: 5.0305\n",
            "[Batch 2] Current Loss: 5.0465\n",
            "[Batch 3] Current Loss: 5.1882\n",
            "[Batch 4] Current Loss: 5.0191\n",
            "[Batch 5] Current Loss: 5.2437\n",
            "[Batch 6] Current Loss: 5.1723\n",
            "[Batch 7] Current Loss: 4.1485\n",
            "[Batch 8] Current Loss: 5.2356\n",
            "[Batch 9] Current Loss: 5.1642\n",
            "Ep 4 (Step 025400): Train loss 2.779, Val loss 5.056\n",
            "[Batch 0] Current Loss: 2.7393\n",
            "[Batch 1] Current Loss: 2.8083\n",
            "[Batch 2] Current Loss: 3.0019\n",
            "[Batch 3] Current Loss: 2.8458\n",
            "[Batch 4] Current Loss: 2.7302\n",
            "[Batch 5] Current Loss: 3.1076\n",
            "[Batch 6] Current Loss: 2.6647\n",
            "[Batch 7] Current Loss: 2.4083\n",
            "[Batch 8] Current Loss: 2.4745\n",
            "[Batch 9] Current Loss: 3.0886\n",
            "[Batch 0] Current Loss: 5.3734\n",
            "[Batch 1] Current Loss: 5.1528\n",
            "[Batch 2] Current Loss: 5.6705\n",
            "[Batch 3] Current Loss: 6.0787\n",
            "[Batch 4] Current Loss: 5.6442\n",
            "[Batch 5] Current Loss: 5.6570\n",
            "[Batch 6] Current Loss: 5.6465\n",
            "[Batch 7] Current Loss: 5.0446\n",
            "[Batch 8] Current Loss: 5.4924\n",
            "[Batch 9] Current Loss: 4.3718\n",
            "Ep 4 (Step 025420): Train loss 2.787, Val loss 5.413\n",
            "[Batch 0] Current Loss: 2.6212\n",
            "[Batch 1] Current Loss: 3.1400\n",
            "[Batch 2] Current Loss: 2.2624\n",
            "[Batch 3] Current Loss: 2.9245\n",
            "[Batch 4] Current Loss: 2.7842\n",
            "[Batch 5] Current Loss: 3.0026\n",
            "[Batch 6] Current Loss: 2.0675\n",
            "[Batch 7] Current Loss: 2.8671\n",
            "[Batch 8] Current Loss: 2.5274\n",
            "[Batch 9] Current Loss: 2.5958\n",
            "[Batch 0] Current Loss: 5.8975\n",
            "[Batch 1] Current Loss: 5.6716\n",
            "[Batch 2] Current Loss: 4.9917\n",
            "[Batch 3] Current Loss: 5.1963\n",
            "[Batch 4] Current Loss: 5.6838\n",
            "[Batch 5] Current Loss: 4.8135\n",
            "[Batch 6] Current Loss: 4.6589\n",
            "[Batch 7] Current Loss: 5.5337\n",
            "[Batch 8] Current Loss: 5.3080\n",
            "[Batch 9] Current Loss: 4.9777\n",
            "Ep 4 (Step 025440): Train loss 2.679, Val loss 5.273\n",
            "[Batch 0] Current Loss: 2.7677\n",
            "[Batch 1] Current Loss: 2.6592\n",
            "[Batch 2] Current Loss: 3.0465\n",
            "[Batch 3] Current Loss: 2.5252\n",
            "[Batch 4] Current Loss: 2.7594\n",
            "[Batch 5] Current Loss: 2.9306\n",
            "[Batch 6] Current Loss: 3.0555\n",
            "[Batch 7] Current Loss: 3.1128\n",
            "[Batch 8] Current Loss: 2.2940\n",
            "[Batch 9] Current Loss: 2.4410\n",
            "[Batch 0] Current Loss: 5.0098\n",
            "[Batch 1] Current Loss: 5.5643\n",
            "[Batch 2] Current Loss: 5.4779\n",
            "[Batch 3] Current Loss: 5.6436\n",
            "[Batch 4] Current Loss: 5.6392\n",
            "[Batch 5] Current Loss: 4.6959\n",
            "[Batch 6] Current Loss: 5.1603\n",
            "[Batch 7] Current Loss: 6.0066\n",
            "[Batch 8] Current Loss: 5.1550\n",
            "[Batch 9] Current Loss: 5.1911\n",
            "Ep 4 (Step 025460): Train loss 2.759, Val loss 5.354\n",
            "[Batch 0] Current Loss: 2.3219\n",
            "[Batch 1] Current Loss: 3.1248\n",
            "[Batch 2] Current Loss: 2.4629\n",
            "[Batch 3] Current Loss: 3.0134\n",
            "[Batch 4] Current Loss: 3.0580\n",
            "[Batch 5] Current Loss: 2.2860\n",
            "[Batch 6] Current Loss: 3.1866\n",
            "[Batch 7] Current Loss: 2.4198\n",
            "[Batch 8] Current Loss: 2.7086\n",
            "[Batch 9] Current Loss: 2.8828\n",
            "[Batch 0] Current Loss: 5.9347\n",
            "[Batch 1] Current Loss: 5.3802\n",
            "[Batch 2] Current Loss: 5.7168\n",
            "[Batch 3] Current Loss: 4.7656\n",
            "[Batch 4] Current Loss: 5.5950\n",
            "[Batch 5] Current Loss: 5.1764\n",
            "[Batch 6] Current Loss: 6.7539\n",
            "[Batch 7] Current Loss: 5.9304\n",
            "[Batch 8] Current Loss: 5.3193\n",
            "[Batch 9] Current Loss: 5.0324\n",
            "Ep 4 (Step 025480): Train loss 2.746, Val loss 5.560\n",
            "[Batch 0] Current Loss: 2.8678\n",
            "[Batch 1] Current Loss: 2.4214\n",
            "[Batch 2] Current Loss: 3.2696\n",
            "[Batch 3] Current Loss: 3.4477\n",
            "[Batch 4] Current Loss: 3.3551\n",
            "[Batch 5] Current Loss: 2.5163\n",
            "[Batch 6] Current Loss: 2.6137\n",
            "[Batch 7] Current Loss: 2.9007\n",
            "[Batch 8] Current Loss: 3.4920\n",
            "[Batch 9] Current Loss: 2.0669\n",
            "[Batch 0] Current Loss: 5.9150\n",
            "[Batch 1] Current Loss: 5.1785\n",
            "[Batch 2] Current Loss: 4.9849\n",
            "[Batch 3] Current Loss: 5.0350\n",
            "[Batch 4] Current Loss: 5.0831\n",
            "[Batch 5] Current Loss: 4.9488\n",
            "[Batch 6] Current Loss: 5.5989\n",
            "[Batch 7] Current Loss: 5.2995\n",
            "[Batch 8] Current Loss: 5.3089\n",
            "[Batch 9] Current Loss: 5.0670\n",
            "Ep 4 (Step 025500): Train loss 2.895, Val loss 5.242\n",
            "[Batch 0] Current Loss: 2.8163\n",
            "[Batch 1] Current Loss: 3.1152\n",
            "[Batch 2] Current Loss: 2.9668\n",
            "[Batch 3] Current Loss: 2.8689\n",
            "[Batch 4] Current Loss: 3.0377\n",
            "[Batch 5] Current Loss: 2.8293\n",
            "[Batch 6] Current Loss: 2.4430\n",
            "[Batch 7] Current Loss: 2.8575\n",
            "[Batch 8] Current Loss: 2.8027\n",
            "[Batch 9] Current Loss: 2.8397\n",
            "[Batch 0] Current Loss: 5.8475\n",
            "[Batch 1] Current Loss: 5.3720\n",
            "[Batch 2] Current Loss: 5.1930\n",
            "[Batch 3] Current Loss: 5.5241\n",
            "[Batch 4] Current Loss: 5.3863\n",
            "[Batch 5] Current Loss: 5.6118\n",
            "[Batch 6] Current Loss: 6.4537\n",
            "[Batch 7] Current Loss: 5.3035\n",
            "[Batch 8] Current Loss: 5.4298\n",
            "[Batch 9] Current Loss: 5.5244\n",
            "Ep 4 (Step 025520): Train loss 2.858, Val loss 5.565\n",
            "[Batch 0] Current Loss: 3.1077\n",
            "[Batch 1] Current Loss: 2.7801\n",
            "[Batch 2] Current Loss: 3.4901\n",
            "[Batch 3] Current Loss: 2.6958\n",
            "[Batch 4] Current Loss: 2.2698\n",
            "[Batch 5] Current Loss: 2.4610\n",
            "[Batch 6] Current Loss: 2.9053\n",
            "[Batch 7] Current Loss: 2.9696\n",
            "[Batch 8] Current Loss: 2.5879\n",
            "[Batch 9] Current Loss: 3.1013\n",
            "[Batch 0] Current Loss: 5.7172\n",
            "[Batch 1] Current Loss: 5.2128\n",
            "[Batch 2] Current Loss: 5.5081\n",
            "[Batch 3] Current Loss: 5.5663\n",
            "[Batch 4] Current Loss: 5.2384\n",
            "[Batch 5] Current Loss: 5.5554\n",
            "[Batch 6] Current Loss: 5.4769\n",
            "[Batch 7] Current Loss: 5.3724\n",
            "[Batch 8] Current Loss: 5.6277\n",
            "[Batch 9] Current Loss: 5.1516\n",
            "Ep 4 (Step 025540): Train loss 2.837, Val loss 5.443\n",
            "[Batch 0] Current Loss: 2.5392\n",
            "[Batch 1] Current Loss: 3.1143\n",
            "[Batch 2] Current Loss: 2.4841\n",
            "[Batch 3] Current Loss: 2.2982\n",
            "[Batch 4] Current Loss: 3.0349\n",
            "[Batch 5] Current Loss: 2.5585\n",
            "[Batch 6] Current Loss: 2.2542\n",
            "[Batch 7] Current Loss: 2.6166\n",
            "[Batch 8] Current Loss: 3.1661\n",
            "[Batch 9] Current Loss: 3.0927\n",
            "[Batch 0] Current Loss: 5.1796\n",
            "[Batch 1] Current Loss: 7.1597\n",
            "[Batch 2] Current Loss: 5.1390\n",
            "[Batch 3] Current Loss: 5.4175\n",
            "[Batch 4] Current Loss: 4.9141\n",
            "[Batch 5] Current Loss: 5.4330\n",
            "[Batch 6] Current Loss: 5.8636\n",
            "[Batch 7] Current Loss: 5.4041\n",
            "[Batch 8] Current Loss: 5.0698\n",
            "[Batch 9] Current Loss: 5.8495\n",
            "Ep 4 (Step 025560): Train loss 2.716, Val loss 5.543\n",
            "[Batch 0] Current Loss: 2.5867\n",
            "[Batch 1] Current Loss: 3.1713\n",
            "[Batch 2] Current Loss: 2.5356\n",
            "[Batch 3] Current Loss: 2.8860\n",
            "[Batch 4] Current Loss: 3.1451\n",
            "[Batch 5] Current Loss: 2.8699\n",
            "[Batch 6] Current Loss: 3.0212\n",
            "[Batch 7] Current Loss: 2.2811\n",
            "[Batch 8] Current Loss: 2.8020\n",
            "[Batch 9] Current Loss: 2.6064\n",
            "[Batch 0] Current Loss: 5.5711\n",
            "[Batch 1] Current Loss: 5.7214\n",
            "[Batch 2] Current Loss: 6.4388\n",
            "[Batch 3] Current Loss: 5.5004\n",
            "[Batch 4] Current Loss: 5.4926\n",
            "[Batch 5] Current Loss: 3.8354\n",
            "[Batch 6] Current Loss: 6.1521\n",
            "[Batch 7] Current Loss: 5.1750\n",
            "[Batch 8] Current Loss: 4.8669\n",
            "[Batch 9] Current Loss: 4.8757\n",
            "Ep 4 (Step 025580): Train loss 2.791, Val loss 5.363\n",
            "[Batch 0] Current Loss: 3.1356\n",
            "[Batch 1] Current Loss: 2.6035\n",
            "[Batch 2] Current Loss: 2.6644\n",
            "[Batch 3] Current Loss: 2.4232\n",
            "[Batch 4] Current Loss: 2.5423\n",
            "[Batch 5] Current Loss: 2.2981\n",
            "[Batch 6] Current Loss: 2.7505\n",
            "[Batch 7] Current Loss: 2.8605\n",
            "[Batch 8] Current Loss: 2.8169\n",
            "[Batch 9] Current Loss: 2.8382\n",
            "[Batch 0] Current Loss: 4.8689\n",
            "[Batch 1] Current Loss: 5.0016\n",
            "[Batch 2] Current Loss: 5.0006\n",
            "[Batch 3] Current Loss: 5.3935\n",
            "[Batch 4] Current Loss: 5.2422\n",
            "[Batch 5] Current Loss: 5.8925\n",
            "[Batch 6] Current Loss: 5.7875\n",
            "[Batch 7] Current Loss: 5.5916\n",
            "[Batch 8] Current Loss: 5.0569\n",
            "[Batch 9] Current Loss: 4.8695\n",
            "Ep 4 (Step 025600): Train loss 2.693, Val loss 5.270\n",
            "[Batch 0] Current Loss: 2.7275\n",
            "[Batch 1] Current Loss: 2.1182\n",
            "[Batch 2] Current Loss: 3.5473\n",
            "[Batch 3] Current Loss: 3.3483\n",
            "[Batch 4] Current Loss: 2.7781\n",
            "[Batch 5] Current Loss: 2.7206\n",
            "[Batch 6] Current Loss: 3.0078\n",
            "[Batch 7] Current Loss: 3.2240\n",
            "[Batch 8] Current Loss: 2.4787\n",
            "[Batch 9] Current Loss: 2.4729\n",
            "[Batch 0] Current Loss: 5.8740\n",
            "[Batch 1] Current Loss: 5.3849\n",
            "[Batch 2] Current Loss: 5.9286\n",
            "[Batch 3] Current Loss: 5.0769\n",
            "[Batch 4] Current Loss: 4.4856\n",
            "[Batch 5] Current Loss: 5.6984\n",
            "[Batch 6] Current Loss: 5.7303\n",
            "[Batch 7] Current Loss: 5.2206\n",
            "[Batch 8] Current Loss: 5.4651\n",
            "[Batch 9] Current Loss: 5.4599\n",
            "Ep 4 (Step 025620): Train loss 2.842, Val loss 5.432\n",
            "[Batch 0] Current Loss: 2.6956\n",
            "[Batch 1] Current Loss: 2.5425\n",
            "[Batch 2] Current Loss: 2.9770\n",
            "[Batch 3] Current Loss: 2.8372\n",
            "[Batch 4] Current Loss: 2.4256\n",
            "[Batch 5] Current Loss: 2.9893\n",
            "[Batch 6] Current Loss: 2.6838\n",
            "[Batch 7] Current Loss: 2.4386\n",
            "[Batch 8] Current Loss: 2.7423\n",
            "[Batch 9] Current Loss: 1.9984\n",
            "[Batch 0] Current Loss: 5.9941\n",
            "[Batch 1] Current Loss: 4.6199\n",
            "[Batch 2] Current Loss: 5.2299\n",
            "[Batch 3] Current Loss: 4.3494\n",
            "[Batch 4] Current Loss: 5.1319\n",
            "[Batch 5] Current Loss: 5.7077\n",
            "[Batch 6] Current Loss: 5.6400\n",
            "[Batch 7] Current Loss: 4.7220\n",
            "[Batch 8] Current Loss: 5.1851\n",
            "[Batch 9] Current Loss: 5.4455\n",
            "Ep 4 (Step 025640): Train loss 2.633, Val loss 5.203\n",
            "[Batch 0] Current Loss: 3.3559\n",
            "[Batch 1] Current Loss: 2.0160\n",
            "[Batch 2] Current Loss: 3.1906\n",
            "[Batch 3] Current Loss: 2.4414\n",
            "[Batch 4] Current Loss: 3.3589\n",
            "[Batch 5] Current Loss: 2.4694\n",
            "[Batch 6] Current Loss: 2.2270\n",
            "[Batch 7] Current Loss: 2.8260\n",
            "[Batch 8] Current Loss: 2.7392\n",
            "[Batch 9] Current Loss: 3.0474\n",
            "[Batch 0] Current Loss: 5.3604\n",
            "[Batch 1] Current Loss: 5.9689\n",
            "[Batch 2] Current Loss: 5.4916\n",
            "[Batch 3] Current Loss: 6.0618\n",
            "[Batch 4] Current Loss: 5.0307\n",
            "[Batch 5] Current Loss: 6.0397\n",
            "[Batch 6] Current Loss: 5.9362\n",
            "[Batch 7] Current Loss: 5.3825\n",
            "[Batch 8] Current Loss: 5.8497\n",
            "[Batch 9] Current Loss: 5.9800\n",
            "Ep 4 (Step 025660): Train loss 2.767, Val loss 5.710\n",
            "[Batch 0] Current Loss: 2.8334\n",
            "[Batch 1] Current Loss: 3.0850\n",
            "[Batch 2] Current Loss: 3.5200\n",
            "[Batch 3] Current Loss: 2.6504\n",
            "[Batch 4] Current Loss: 2.9895\n",
            "[Batch 5] Current Loss: 2.5958\n",
            "[Batch 6] Current Loss: 2.1911\n",
            "[Batch 7] Current Loss: 2.8262\n",
            "[Batch 8] Current Loss: 2.1712\n",
            "[Batch 9] Current Loss: 2.5303\n",
            "[Batch 0] Current Loss: 5.1913\n",
            "[Batch 1] Current Loss: 6.0497\n",
            "[Batch 2] Current Loss: 4.6527\n",
            "[Batch 3] Current Loss: 6.4367\n",
            "[Batch 4] Current Loss: 4.9082\n",
            "[Batch 5] Current Loss: 5.7178\n",
            "[Batch 6] Current Loss: 5.2194\n",
            "[Batch 7] Current Loss: 6.0811\n",
            "[Batch 8] Current Loss: 5.3909\n",
            "[Batch 9] Current Loss: 4.8856\n",
            "Ep 4 (Step 025680): Train loss 2.739, Val loss 5.453\n",
            "[Batch 0] Current Loss: 2.5667\n",
            "[Batch 1] Current Loss: 2.9269\n",
            "[Batch 2] Current Loss: 2.9451\n",
            "[Batch 3] Current Loss: 2.7306\n",
            "[Batch 4] Current Loss: 2.5016\n",
            "[Batch 5] Current Loss: 2.3683\n",
            "[Batch 6] Current Loss: 3.2562\n",
            "[Batch 7] Current Loss: 2.2067\n",
            "[Batch 8] Current Loss: 2.7216\n",
            "[Batch 9] Current Loss: 2.8281\n",
            "[Batch 0] Current Loss: 5.4572\n",
            "[Batch 1] Current Loss: 6.0205\n",
            "[Batch 2] Current Loss: 5.4847\n",
            "[Batch 3] Current Loss: 5.5004\n",
            "[Batch 4] Current Loss: 6.2170\n",
            "[Batch 5] Current Loss: 5.7125\n",
            "[Batch 6] Current Loss: 6.2525\n",
            "[Batch 7] Current Loss: 5.4001\n",
            "[Batch 8] Current Loss: 5.7444\n",
            "[Batch 9] Current Loss: 5.2962\n",
            "Ep 4 (Step 025700): Train loss 2.705, Val loss 5.709\n",
            "[Batch 0] Current Loss: 2.4841\n",
            "[Batch 1] Current Loss: 2.6568\n",
            "[Batch 2] Current Loss: 2.6197\n",
            "[Batch 3] Current Loss: 2.6635\n",
            "[Batch 4] Current Loss: 3.0210\n",
            "[Batch 5] Current Loss: 1.7911\n",
            "[Batch 6] Current Loss: 3.0677\n",
            "[Batch 7] Current Loss: 3.0817\n",
            "[Batch 8] Current Loss: 2.1858\n",
            "[Batch 9] Current Loss: 2.3428\n",
            "[Batch 0] Current Loss: 4.9190\n",
            "[Batch 1] Current Loss: 5.8433\n",
            "[Batch 2] Current Loss: 5.2788\n",
            "[Batch 3] Current Loss: 5.2474\n",
            "[Batch 4] Current Loss: 5.6688\n",
            "[Batch 5] Current Loss: 4.9519\n",
            "[Batch 6] Current Loss: 5.6036\n",
            "[Batch 7] Current Loss: 5.8983\n",
            "[Batch 8] Current Loss: 6.0857\n",
            "[Batch 9] Current Loss: 6.1274\n",
            "Ep 4 (Step 025720): Train loss 2.591, Val loss 5.562\n",
            "[Batch 0] Current Loss: 2.3547\n",
            "[Batch 1] Current Loss: 3.3696\n",
            "[Batch 2] Current Loss: 3.0794\n",
            "[Batch 3] Current Loss: 2.4012\n",
            "[Batch 4] Current Loss: 3.1684\n",
            "[Batch 5] Current Loss: 2.8215\n",
            "[Batch 6] Current Loss: 2.2030\n",
            "[Batch 7] Current Loss: 2.7263\n",
            "[Batch 8] Current Loss: 2.5549\n",
            "[Batch 9] Current Loss: 2.3670\n",
            "[Batch 0] Current Loss: 5.4774\n",
            "[Batch 1] Current Loss: 5.2227\n",
            "[Batch 2] Current Loss: 5.5725\n",
            "[Batch 3] Current Loss: 5.2658\n",
            "[Batch 4] Current Loss: 6.3342\n",
            "[Batch 5] Current Loss: 5.7782\n",
            "[Batch 6] Current Loss: 5.7037\n",
            "[Batch 7] Current Loss: 5.2850\n",
            "[Batch 8] Current Loss: 5.6763\n",
            "[Batch 9] Current Loss: 4.7449\n",
            "Ep 4 (Step 025740): Train loss 2.705, Val loss 5.506\n",
            "[Batch 0] Current Loss: 2.7089\n",
            "[Batch 1] Current Loss: 2.7517\n",
            "[Batch 2] Current Loss: 3.3530\n",
            "[Batch 3] Current Loss: 3.0302\n",
            "[Batch 4] Current Loss: 2.7419\n",
            "[Batch 5] Current Loss: 2.7181\n",
            "[Batch 6] Current Loss: 2.3984\n",
            "[Batch 7] Current Loss: 2.5674\n",
            "[Batch 8] Current Loss: 2.6212\n",
            "[Batch 9] Current Loss: 2.2053\n",
            "[Batch 0] Current Loss: 5.9434\n",
            "[Batch 1] Current Loss: 5.5891\n",
            "[Batch 2] Current Loss: 5.7678\n",
            "[Batch 3] Current Loss: 5.5938\n",
            "[Batch 4] Current Loss: 4.8929\n",
            "[Batch 5] Current Loss: 5.5771\n",
            "[Batch 6] Current Loss: 5.5731\n",
            "[Batch 7] Current Loss: 4.9919\n",
            "[Batch 8] Current Loss: 5.1651\n",
            "[Batch 9] Current Loss: 5.4264\n",
            "Ep 4 (Step 025760): Train loss 2.710, Val loss 5.452\n",
            "[Batch 0] Current Loss: 2.4199\n",
            "[Batch 1] Current Loss: 2.7797\n",
            "[Batch 2] Current Loss: 2.4570\n",
            "[Batch 3] Current Loss: 2.8981\n",
            "[Batch 4] Current Loss: 2.4748\n",
            "[Batch 5] Current Loss: 2.3725\n",
            "[Batch 6] Current Loss: 2.9404\n",
            "[Batch 7] Current Loss: 2.2777\n",
            "[Batch 8] Current Loss: 3.2353\n",
            "[Batch 9] Current Loss: 2.9482\n",
            "[Batch 0] Current Loss: 5.6903\n",
            "[Batch 1] Current Loss: 4.4367\n",
            "[Batch 2] Current Loss: 5.8289\n",
            "[Batch 3] Current Loss: 5.8529\n",
            "[Batch 4] Current Loss: 5.1099\n",
            "[Batch 5] Current Loss: 5.3449\n",
            "[Batch 6] Current Loss: 5.5761\n",
            "[Batch 7] Current Loss: 6.3615\n",
            "[Batch 8] Current Loss: 4.8680\n",
            "[Batch 9] Current Loss: 5.8481\n",
            "Ep 4 (Step 025780): Train loss 2.680, Val loss 5.492\n",
            "[Batch 0] Current Loss: 2.7282\n",
            "[Batch 1] Current Loss: 2.1955\n",
            "[Batch 2] Current Loss: 3.2861\n",
            "[Batch 3] Current Loss: 2.3903\n",
            "[Batch 4] Current Loss: 3.0854\n",
            "[Batch 5] Current Loss: 3.5864\n",
            "[Batch 6] Current Loss: 3.1971\n",
            "[Batch 7] Current Loss: 3.3775\n",
            "[Batch 8] Current Loss: 3.3123\n",
            "[Batch 9] Current Loss: 3.2295\n",
            "[Batch 0] Current Loss: 6.0523\n",
            "[Batch 1] Current Loss: 5.7953\n",
            "[Batch 2] Current Loss: 5.8188\n",
            "[Batch 3] Current Loss: 5.4628\n",
            "[Batch 4] Current Loss: 5.1020\n",
            "[Batch 5] Current Loss: 4.4480\n",
            "[Batch 6] Current Loss: 5.9323\n",
            "[Batch 7] Current Loss: 5.6093\n",
            "[Batch 8] Current Loss: 4.1749\n",
            "[Batch 9] Current Loss: 5.8113\n",
            "Ep 4 (Step 025800): Train loss 3.039, Val loss 5.421\n",
            "[Batch 0] Current Loss: 2.7908\n",
            "[Batch 1] Current Loss: 2.6805\n",
            "[Batch 2] Current Loss: 2.6621\n",
            "[Batch 3] Current Loss: 3.3435\n",
            "[Batch 4] Current Loss: 2.6619\n",
            "[Batch 5] Current Loss: 2.9159\n",
            "[Batch 6] Current Loss: 3.0654\n",
            "[Batch 7] Current Loss: 2.4884\n",
            "[Batch 8] Current Loss: 2.6289\n",
            "[Batch 9] Current Loss: 2.6801\n",
            "[Batch 0] Current Loss: 4.6944\n",
            "[Batch 1] Current Loss: 5.5997\n",
            "[Batch 2] Current Loss: 4.9041\n",
            "[Batch 3] Current Loss: 5.2614\n",
            "[Batch 4] Current Loss: 5.8117\n",
            "[Batch 5] Current Loss: 5.5458\n",
            "[Batch 6] Current Loss: 6.5962\n",
            "[Batch 7] Current Loss: 4.7728\n",
            "[Batch 8] Current Loss: 5.7628\n",
            "[Batch 9] Current Loss: 5.0070\n",
            "Ep 4 (Step 025820): Train loss 2.792, Val loss 5.396\n",
            "[Batch 0] Current Loss: 2.2120\n",
            "[Batch 1] Current Loss: 2.5643\n",
            "[Batch 2] Current Loss: 2.2568\n",
            "[Batch 3] Current Loss: 2.3052\n",
            "[Batch 4] Current Loss: 3.5399\n",
            "[Batch 5] Current Loss: 2.0151\n",
            "[Batch 6] Current Loss: 3.1708\n",
            "[Batch 7] Current Loss: 2.9413\n",
            "[Batch 8] Current Loss: 2.3069\n",
            "[Batch 9] Current Loss: 2.6849\n",
            "[Batch 0] Current Loss: 5.7389\n",
            "[Batch 1] Current Loss: 4.8834\n",
            "[Batch 2] Current Loss: 5.6444\n",
            "[Batch 3] Current Loss: 4.9708\n",
            "[Batch 4] Current Loss: 5.5630\n",
            "[Batch 5] Current Loss: 5.8818\n",
            "[Batch 6] Current Loss: 5.2880\n",
            "[Batch 7] Current Loss: 5.4091\n",
            "[Batch 8] Current Loss: 5.0020\n",
            "[Batch 9] Current Loss: 5.8169\n",
            "Ep 4 (Step 025840): Train loss 2.600, Val loss 5.420\n",
            "[Batch 0] Current Loss: 2.5498\n",
            "[Batch 1] Current Loss: 2.7934\n",
            "[Batch 2] Current Loss: 3.2602\n",
            "[Batch 3] Current Loss: 2.2522\n",
            "[Batch 4] Current Loss: 2.0208\n",
            "[Batch 5] Current Loss: 2.4474\n",
            "[Batch 6] Current Loss: 3.2584\n",
            "[Batch 7] Current Loss: 2.5079\n",
            "[Batch 8] Current Loss: 2.2036\n",
            "[Batch 9] Current Loss: 2.5130\n",
            "[Batch 0] Current Loss: 5.7161\n",
            "[Batch 1] Current Loss: 5.2789\n",
            "[Batch 2] Current Loss: 5.4313\n",
            "[Batch 3] Current Loss: 5.2962\n",
            "[Batch 4] Current Loss: 3.8742\n",
            "[Batch 5] Current Loss: 5.8490\n",
            "[Batch 6] Current Loss: 5.6733\n",
            "[Batch 7] Current Loss: 5.5353\n",
            "[Batch 8] Current Loss: 4.6297\n",
            "[Batch 9] Current Loss: 5.4903\n",
            "Ep 4 (Step 025860): Train loss 2.581, Val loss 5.277\n",
            "[Batch 0] Current Loss: 2.7970\n",
            "[Batch 1] Current Loss: 2.8340\n",
            "[Batch 2] Current Loss: 3.0777\n",
            "[Batch 3] Current Loss: 3.1375\n",
            "[Batch 4] Current Loss: 2.8134\n",
            "[Batch 5] Current Loss: 2.8984\n",
            "[Batch 6] Current Loss: 3.0715\n",
            "[Batch 7] Current Loss: 2.3984\n",
            "[Batch 8] Current Loss: 2.1951\n",
            "[Batch 9] Current Loss: 2.5591\n",
            "[Batch 0] Current Loss: 5.3438\n",
            "[Batch 1] Current Loss: 5.7234\n",
            "[Batch 2] Current Loss: 5.7918\n",
            "[Batch 3] Current Loss: 5.8897\n",
            "[Batch 4] Current Loss: 5.1122\n",
            "[Batch 5] Current Loss: 5.1616\n",
            "[Batch 6] Current Loss: 5.2271\n",
            "[Batch 7] Current Loss: 5.6724\n",
            "[Batch 8] Current Loss: 6.3444\n",
            "[Batch 9] Current Loss: 5.1793\n",
            "Ep 4 (Step 025880): Train loss 2.778, Val loss 5.545\n",
            "[Batch 0] Current Loss: 2.7152\n",
            "[Batch 1] Current Loss: 2.4362\n",
            "[Batch 2] Current Loss: 2.3307\n",
            "[Batch 3] Current Loss: 2.5711\n",
            "[Batch 4] Current Loss: 2.4757\n",
            "[Batch 5] Current Loss: 2.8618\n",
            "[Batch 6] Current Loss: 3.2858\n",
            "[Batch 7] Current Loss: 2.8582\n",
            "[Batch 8] Current Loss: 2.6249\n",
            "[Batch 9] Current Loss: 2.9802\n",
            "[Batch 0] Current Loss: 6.1331\n",
            "[Batch 1] Current Loss: 5.2787\n",
            "[Batch 2] Current Loss: 5.2688\n",
            "[Batch 3] Current Loss: 5.4062\n",
            "[Batch 4] Current Loss: 5.8438\n",
            "[Batch 5] Current Loss: 4.8513\n",
            "[Batch 6] Current Loss: 5.8664\n",
            "[Batch 7] Current Loss: 6.0195\n",
            "[Batch 8] Current Loss: 6.2176\n",
            "[Batch 9] Current Loss: 5.6858\n",
            "Ep 4 (Step 025900): Train loss 2.714, Val loss 5.657\n",
            "[Batch 0] Current Loss: 2.7922\n",
            "[Batch 1] Current Loss: 2.6029\n",
            "[Batch 2] Current Loss: 3.3719\n",
            "[Batch 3] Current Loss: 2.9213\n",
            "[Batch 4] Current Loss: 3.3320\n",
            "[Batch 5] Current Loss: 3.0066\n",
            "[Batch 6] Current Loss: 3.0254\n",
            "[Batch 7] Current Loss: 2.8889\n",
            "[Batch 8] Current Loss: 2.1405\n",
            "[Batch 9] Current Loss: 2.8087\n",
            "[Batch 0] Current Loss: 5.5559\n",
            "[Batch 1] Current Loss: 5.3804\n",
            "[Batch 2] Current Loss: 6.7775\n",
            "[Batch 3] Current Loss: 4.5700\n",
            "[Batch 4] Current Loss: 4.9235\n",
            "[Batch 5] Current Loss: 5.5646\n",
            "[Batch 6] Current Loss: 4.6870\n",
            "[Batch 7] Current Loss: 5.8426\n",
            "[Batch 8] Current Loss: 5.9754\n",
            "[Batch 9] Current Loss: 5.6982\n",
            "Ep 4 (Step 025920): Train loss 2.889, Val loss 5.498\n",
            "[Batch 0] Current Loss: 3.0698\n",
            "[Batch 1] Current Loss: 2.4166\n",
            "[Batch 2] Current Loss: 2.1912\n",
            "[Batch 3] Current Loss: 2.8998\n",
            "[Batch 4] Current Loss: 2.8795\n",
            "[Batch 5] Current Loss: 2.1322\n",
            "[Batch 6] Current Loss: 2.4741\n",
            "[Batch 7] Current Loss: 2.1248\n",
            "[Batch 8] Current Loss: 3.4132\n",
            "[Batch 9] Current Loss: 3.0553\n",
            "[Batch 0] Current Loss: 5.2007\n",
            "[Batch 1] Current Loss: 5.1611\n",
            "[Batch 2] Current Loss: 5.7487\n",
            "[Batch 3] Current Loss: 4.3969\n",
            "[Batch 4] Current Loss: 6.3961\n",
            "[Batch 5] Current Loss: 5.4611\n",
            "[Batch 6] Current Loss: 6.1351\n",
            "[Batch 7] Current Loss: 5.1403\n",
            "[Batch 8] Current Loss: 4.5424\n",
            "[Batch 9] Current Loss: 4.8829\n",
            "Ep 4 (Step 025940): Train loss 2.666, Val loss 5.307\n",
            "[Batch 0] Current Loss: 2.6547\n",
            "[Batch 1] Current Loss: 2.2663\n",
            "[Batch 2] Current Loss: 2.6318\n",
            "[Batch 3] Current Loss: 2.3580\n",
            "[Batch 4] Current Loss: 3.1841\n",
            "[Batch 5] Current Loss: 2.8999\n",
            "[Batch 6] Current Loss: 2.4990\n",
            "[Batch 7] Current Loss: 2.7196\n",
            "[Batch 8] Current Loss: 2.3145\n",
            "[Batch 9] Current Loss: 2.5165\n",
            "[Batch 0] Current Loss: 5.2770\n",
            "[Batch 1] Current Loss: 5.6601\n",
            "[Batch 2] Current Loss: 5.6241\n",
            "[Batch 3] Current Loss: 5.3821\n",
            "[Batch 4] Current Loss: 4.3721\n",
            "[Batch 5] Current Loss: 5.6489\n",
            "[Batch 6] Current Loss: 5.9973\n",
            "[Batch 7] Current Loss: 5.6965\n",
            "[Batch 8] Current Loss: 5.7168\n",
            "[Batch 9] Current Loss: 5.1472\n",
            "Ep 4 (Step 025960): Train loss 2.604, Val loss 5.452\n",
            "[Batch 0] Current Loss: 2.5806\n",
            "[Batch 1] Current Loss: 2.1787\n",
            "[Batch 2] Current Loss: 2.6991\n",
            "[Batch 3] Current Loss: 2.9325\n",
            "[Batch 4] Current Loss: 2.5237\n",
            "[Batch 5] Current Loss: 3.0581\n",
            "[Batch 6] Current Loss: 2.7320\n",
            "[Batch 7] Current Loss: 2.6227\n",
            "[Batch 8] Current Loss: 2.2945\n",
            "[Batch 9] Current Loss: 2.3734\n",
            "[Batch 0] Current Loss: 5.5384\n",
            "[Batch 1] Current Loss: 4.6486\n",
            "[Batch 2] Current Loss: 5.0564\n",
            "[Batch 3] Current Loss: 5.0124\n",
            "[Batch 4] Current Loss: 5.3139\n",
            "[Batch 5] Current Loss: 6.1064\n",
            "[Batch 6] Current Loss: 5.7258\n",
            "[Batch 7] Current Loss: 5.5875\n",
            "[Batch 8] Current Loss: 6.0097\n",
            "[Batch 9] Current Loss: 5.7358\n",
            "Ep 4 (Step 025980): Train loss 2.600, Val loss 5.474\n",
            "[Batch 0] Current Loss: 3.1644\n",
            "[Batch 1] Current Loss: 3.0209\n",
            "[Batch 2] Current Loss: 2.3032\n",
            "[Batch 3] Current Loss: 2.7290\n",
            "[Batch 4] Current Loss: 2.7011\n",
            "[Batch 5] Current Loss: 3.1209\n",
            "[Batch 6] Current Loss: 2.8813\n",
            "[Batch 7] Current Loss: 2.8644\n",
            "[Batch 8] Current Loss: 2.7711\n",
            "[Batch 9] Current Loss: 2.1123\n",
            "[Batch 0] Current Loss: 5.3298\n",
            "[Batch 1] Current Loss: 5.2060\n",
            "[Batch 2] Current Loss: 6.3053\n",
            "[Batch 3] Current Loss: 6.3530\n",
            "[Batch 4] Current Loss: 4.8378\n",
            "[Batch 5] Current Loss: 4.6632\n",
            "[Batch 6] Current Loss: 5.1182\n",
            "[Batch 7] Current Loss: 5.3629\n",
            "[Batch 8] Current Loss: 5.4482\n",
            "[Batch 9] Current Loss: 5.0160\n",
            "Ep 4 (Step 026000): Train loss 2.767, Val loss 5.364\n",
            "[Batch 0] Current Loss: 2.2986\n",
            "[Batch 1] Current Loss: 2.7961\n",
            "[Batch 2] Current Loss: 3.0403\n",
            "[Batch 3] Current Loss: 3.1117\n",
            "[Batch 4] Current Loss: 1.8393\n",
            "[Batch 5] Current Loss: 2.8451\n",
            "[Batch 6] Current Loss: 2.4734\n",
            "[Batch 7] Current Loss: 2.9081\n",
            "[Batch 8] Current Loss: 2.7916\n",
            "[Batch 9] Current Loss: 2.8221\n",
            "[Batch 0] Current Loss: 5.9511\n",
            "[Batch 1] Current Loss: 5.3144\n",
            "[Batch 2] Current Loss: 6.1068\n",
            "[Batch 3] Current Loss: 5.1095\n",
            "[Batch 4] Current Loss: 5.6111\n",
            "[Batch 5] Current Loss: 5.1850\n",
            "[Batch 6] Current Loss: 6.0139\n",
            "[Batch 7] Current Loss: 5.8488\n",
            "[Batch 8] Current Loss: 6.0305\n",
            "[Batch 9] Current Loss: 5.6871\n",
            "Ep 4 (Step 026020): Train loss 2.693, Val loss 5.686\n",
            "[Batch 0] Current Loss: 2.7497\n",
            "[Batch 1] Current Loss: 3.0818\n",
            "[Batch 2] Current Loss: 2.7676\n",
            "[Batch 3] Current Loss: 2.3287\n",
            "[Batch 4] Current Loss: 2.5435\n",
            "[Batch 5] Current Loss: 2.1875\n",
            "[Batch 6] Current Loss: 3.0418\n",
            "[Batch 7] Current Loss: 3.1640\n",
            "[Batch 8] Current Loss: 3.0784\n",
            "[Batch 9] Current Loss: 2.4454\n",
            "[Batch 0] Current Loss: 4.1342\n",
            "[Batch 1] Current Loss: 5.6807\n",
            "[Batch 2] Current Loss: 4.8563\n",
            "[Batch 3] Current Loss: 5.1333\n",
            "[Batch 4] Current Loss: 5.4812\n",
            "[Batch 5] Current Loss: 6.0519\n",
            "[Batch 6] Current Loss: 5.2007\n",
            "[Batch 7] Current Loss: 4.7529\n",
            "[Batch 8] Current Loss: 5.6091\n",
            "[Batch 9] Current Loss: 5.1577\n",
            "Ep 4 (Step 026040): Train loss 2.739, Val loss 5.206\n",
            "[Batch 0] Current Loss: 3.5128\n",
            "[Batch 1] Current Loss: 2.8335\n",
            "[Batch 2] Current Loss: 2.6469\n",
            "[Batch 3] Current Loss: 2.8562\n",
            "[Batch 4] Current Loss: 2.8830\n",
            "[Batch 5] Current Loss: 2.5042\n",
            "[Batch 6] Current Loss: 2.2902\n",
            "[Batch 7] Current Loss: 2.6695\n",
            "[Batch 8] Current Loss: 3.8977\n",
            "[Batch 9] Current Loss: 2.8573\n",
            "[Batch 0] Current Loss: 5.4736\n",
            "[Batch 1] Current Loss: 4.3935\n",
            "[Batch 2] Current Loss: 4.6290\n",
            "[Batch 3] Current Loss: 4.7753\n",
            "[Batch 4] Current Loss: 5.7570\n",
            "[Batch 5] Current Loss: 5.2665\n",
            "[Batch 6] Current Loss: 5.0909\n",
            "[Batch 7] Current Loss: 5.8647\n",
            "[Batch 8] Current Loss: 5.0077\n",
            "[Batch 9] Current Loss: 5.3531\n",
            "Ep 4 (Step 026060): Train loss 2.895, Val loss 5.161\n",
            "[Batch 0] Current Loss: 2.7817\n",
            "[Batch 1] Current Loss: 2.5505\n",
            "[Batch 2] Current Loss: 3.0077\n",
            "[Batch 3] Current Loss: 2.6773\n",
            "[Batch 4] Current Loss: 3.2190\n",
            "[Batch 5] Current Loss: 3.0434\n",
            "[Batch 6] Current Loss: 2.7511\n",
            "[Batch 7] Current Loss: 2.6641\n",
            "[Batch 8] Current Loss: 1.2802\n",
            "[Batch 9] Current Loss: 2.9183\n",
            "[Batch 0] Current Loss: 5.6728\n",
            "[Batch 1] Current Loss: 5.0869\n",
            "[Batch 2] Current Loss: 5.2036\n",
            "[Batch 3] Current Loss: 5.3611\n",
            "[Batch 4] Current Loss: 5.4323\n",
            "[Batch 5] Current Loss: 5.8906\n",
            "[Batch 6] Current Loss: 5.2850\n",
            "[Batch 7] Current Loss: 4.2944\n",
            "[Batch 8] Current Loss: 5.3236\n",
            "[Batch 9] Current Loss: 5.4025\n",
            "Ep 4 (Step 026080): Train loss 2.689, Val loss 5.295\n",
            "[Batch 0] Current Loss: 2.6832\n",
            "[Batch 1] Current Loss: 2.8341\n",
            "[Batch 2] Current Loss: 2.6437\n",
            "[Batch 3] Current Loss: 2.6617\n",
            "[Batch 4] Current Loss: 2.8145\n",
            "[Batch 5] Current Loss: 2.2548\n",
            "[Batch 6] Current Loss: 2.1717\n",
            "[Batch 7] Current Loss: 2.7495\n",
            "[Batch 8] Current Loss: 2.3546\n",
            "[Batch 9] Current Loss: 3.1382\n",
            "[Batch 0] Current Loss: 5.8349\n",
            "[Batch 1] Current Loss: 6.4812\n",
            "[Batch 2] Current Loss: 4.9882\n",
            "[Batch 3] Current Loss: 5.0799\n",
            "[Batch 4] Current Loss: 5.7198\n",
            "[Batch 5] Current Loss: 5.4214\n",
            "[Batch 6] Current Loss: 6.0982\n",
            "[Batch 7] Current Loss: 5.9735\n",
            "[Batch 8] Current Loss: 5.2275\n",
            "[Batch 9] Current Loss: 5.7129\n",
            "Ep 4 (Step 026100): Train loss 2.631, Val loss 5.654\n",
            "[Batch 0] Current Loss: 2.7260\n",
            "[Batch 1] Current Loss: 3.2239\n",
            "[Batch 2] Current Loss: 3.2631\n",
            "[Batch 3] Current Loss: 2.5131\n",
            "[Batch 4] Current Loss: 2.7836\n",
            "[Batch 5] Current Loss: 3.1937\n",
            "[Batch 6] Current Loss: 2.9816\n",
            "[Batch 7] Current Loss: 2.5083\n",
            "[Batch 8] Current Loss: 2.6862\n",
            "[Batch 9] Current Loss: 3.3773\n",
            "[Batch 0] Current Loss: 5.1813\n",
            "[Batch 1] Current Loss: 4.8096\n",
            "[Batch 2] Current Loss: 5.1063\n",
            "[Batch 3] Current Loss: 4.6776\n",
            "[Batch 4] Current Loss: 5.3577\n",
            "[Batch 5] Current Loss: 5.2068\n",
            "[Batch 6] Current Loss: 4.8288\n",
            "[Batch 7] Current Loss: 6.3317\n",
            "[Batch 8] Current Loss: 5.7416\n",
            "[Batch 9] Current Loss: 5.4704\n",
            "Ep 4 (Step 026120): Train loss 2.926, Val loss 5.271\n",
            "[Batch 0] Current Loss: 2.3366\n",
            "[Batch 1] Current Loss: 3.2711\n",
            "[Batch 2] Current Loss: 3.1846\n",
            "[Batch 3] Current Loss: 3.1029\n",
            "[Batch 4] Current Loss: 2.2221\n",
            "[Batch 5] Current Loss: 2.4879\n",
            "[Batch 6] Current Loss: 2.7392\n",
            "[Batch 7] Current Loss: 2.8611\n",
            "[Batch 8] Current Loss: 2.4568\n",
            "[Batch 9] Current Loss: 1.9656\n",
            "[Batch 0] Current Loss: 6.0659\n",
            "[Batch 1] Current Loss: 4.9241\n",
            "[Batch 2] Current Loss: 4.8518\n",
            "[Batch 3] Current Loss: 5.4932\n",
            "[Batch 4] Current Loss: 4.9974\n",
            "[Batch 5] Current Loss: 4.5531\n",
            "[Batch 6] Current Loss: 5.2282\n",
            "[Batch 7] Current Loss: 5.4696\n",
            "[Batch 8] Current Loss: 5.3233\n",
            "[Batch 9] Current Loss: 5.6317\n",
            "Ep 4 (Step 026140): Train loss 2.663, Val loss 5.254\n",
            "[Batch 0] Current Loss: 2.7260\n",
            "[Batch 1] Current Loss: 2.6542\n",
            "[Batch 2] Current Loss: 2.7451\n",
            "[Batch 3] Current Loss: 3.1697\n",
            "[Batch 4] Current Loss: 2.4650\n",
            "[Batch 5] Current Loss: 2.9967\n",
            "[Batch 6] Current Loss: 3.3309\n",
            "[Batch 7] Current Loss: 2.4511\n",
            "[Batch 8] Current Loss: 3.2338\n",
            "[Batch 9] Current Loss: 2.9529\n",
            "[Batch 0] Current Loss: 5.6836\n",
            "[Batch 1] Current Loss: 5.6564\n",
            "[Batch 2] Current Loss: 5.6537\n",
            "[Batch 3] Current Loss: 4.7086\n",
            "[Batch 4] Current Loss: 5.6094\n",
            "[Batch 5] Current Loss: 5.2392\n",
            "[Batch 6] Current Loss: 6.1761\n",
            "[Batch 7] Current Loss: 5.0963\n",
            "[Batch 8] Current Loss: 5.2069\n",
            "[Batch 9] Current Loss: 6.1604\n",
            "Ep 4 (Step 026160): Train loss 2.873, Val loss 5.519\n",
            "[Batch 0] Current Loss: 2.4586\n",
            "[Batch 1] Current Loss: 2.8947\n",
            "[Batch 2] Current Loss: 2.4462\n",
            "[Batch 3] Current Loss: 2.2484\n",
            "[Batch 4] Current Loss: 2.9679\n",
            "[Batch 5] Current Loss: 2.9478\n",
            "[Batch 6] Current Loss: 2.5846\n",
            "[Batch 7] Current Loss: 2.5183\n",
            "[Batch 8] Current Loss: 2.6474\n",
            "[Batch 9] Current Loss: 2.3217\n",
            "[Batch 0] Current Loss: 5.9023\n",
            "[Batch 1] Current Loss: 4.7187\n",
            "[Batch 2] Current Loss: 5.5568\n",
            "[Batch 3] Current Loss: 5.9150\n",
            "[Batch 4] Current Loss: 5.7461\n",
            "[Batch 5] Current Loss: 5.7317\n",
            "[Batch 6] Current Loss: 5.5129\n",
            "[Batch 7] Current Loss: 5.0413\n",
            "[Batch 8] Current Loss: 5.2313\n",
            "[Batch 9] Current Loss: 5.3685\n",
            "Ep 4 (Step 026180): Train loss 2.604, Val loss 5.472\n",
            "[Batch 0] Current Loss: 2.3127\n",
            "[Batch 1] Current Loss: 2.6374\n",
            "[Batch 2] Current Loss: 2.8751\n",
            "[Batch 3] Current Loss: 2.3864\n",
            "[Batch 4] Current Loss: 2.5416\n",
            "[Batch 5] Current Loss: 2.4956\n",
            "[Batch 6] Current Loss: 2.8708\n",
            "[Batch 7] Current Loss: 3.2417\n",
            "[Batch 8] Current Loss: 2.5589\n",
            "[Batch 9] Current Loss: 3.3208\n",
            "[Batch 0] Current Loss: 5.9051\n",
            "[Batch 1] Current Loss: 4.8789\n",
            "[Batch 2] Current Loss: 6.5048\n",
            "[Batch 3] Current Loss: 5.6837\n",
            "[Batch 4] Current Loss: 5.7121\n",
            "[Batch 5] Current Loss: 5.8023\n",
            "[Batch 6] Current Loss: 6.0395\n",
            "[Batch 7] Current Loss: 5.7690\n",
            "[Batch 8] Current Loss: 5.3166\n",
            "[Batch 9] Current Loss: 5.3545\n",
            "Ep 4 (Step 026200): Train loss 2.724, Val loss 5.697\n",
            "[Batch 0] Current Loss: 3.3273\n",
            "[Batch 1] Current Loss: 2.7344\n",
            "[Batch 2] Current Loss: 2.9179\n",
            "[Batch 3] Current Loss: 2.8350\n",
            "[Batch 4] Current Loss: 2.7081\n",
            "[Batch 5] Current Loss: 2.8046\n",
            "[Batch 6] Current Loss: 2.4243\n",
            "[Batch 7] Current Loss: 2.3474\n",
            "[Batch 8] Current Loss: 2.4402\n",
            "[Batch 9] Current Loss: 2.8734\n",
            "[Batch 0] Current Loss: 5.8693\n",
            "[Batch 1] Current Loss: 5.3298\n",
            "[Batch 2] Current Loss: 5.2429\n",
            "[Batch 3] Current Loss: 5.9091\n",
            "[Batch 4] Current Loss: 5.1749\n",
            "[Batch 5] Current Loss: 5.6787\n",
            "[Batch 6] Current Loss: 6.0966\n",
            "[Batch 7] Current Loss: 5.6554\n",
            "[Batch 8] Current Loss: 5.0988\n",
            "[Batch 9] Current Loss: 5.3589\n",
            "Ep 4 (Step 026220): Train loss 2.741, Val loss 5.541\n",
            "[Batch 0] Current Loss: 2.1762\n",
            "[Batch 1] Current Loss: 2.6637\n",
            "[Batch 2] Current Loss: 2.5436\n",
            "[Batch 3] Current Loss: 2.9712\n",
            "[Batch 4] Current Loss: 2.5748\n",
            "[Batch 5] Current Loss: 3.4140\n",
            "[Batch 6] Current Loss: 2.3060\n",
            "[Batch 7] Current Loss: 2.5365\n",
            "[Batch 8] Current Loss: 3.4682\n",
            "[Batch 9] Current Loss: 2.3036\n",
            "[Batch 0] Current Loss: 5.5386\n",
            "[Batch 1] Current Loss: 5.9295\n",
            "[Batch 2] Current Loss: 5.1260\n",
            "[Batch 3] Current Loss: 5.4887\n",
            "[Batch 4] Current Loss: 5.0875\n",
            "[Batch 5] Current Loss: 5.6744\n",
            "[Batch 6] Current Loss: 5.5852\n",
            "[Batch 7] Current Loss: 5.9886\n",
            "[Batch 8] Current Loss: 5.7880\n",
            "[Batch 9] Current Loss: 5.9222\n",
            "Ep 4 (Step 026240): Train loss 2.696, Val loss 5.613\n",
            "[Batch 0] Current Loss: 3.4335\n",
            "[Batch 1] Current Loss: 3.1235\n",
            "[Batch 2] Current Loss: 2.7572\n",
            "[Batch 3] Current Loss: 2.2278\n",
            "[Batch 4] Current Loss: 2.5719\n",
            "[Batch 5] Current Loss: 2.4629\n",
            "[Batch 6] Current Loss: 2.5122\n",
            "[Batch 7] Current Loss: 2.7560\n",
            "[Batch 8] Current Loss: 2.4866\n",
            "[Batch 9] Current Loss: 1.9646\n",
            "[Batch 0] Current Loss: 5.3081\n",
            "[Batch 1] Current Loss: 5.4724\n",
            "[Batch 2] Current Loss: 5.0774\n",
            "[Batch 3] Current Loss: 5.5276\n",
            "[Batch 4] Current Loss: 5.9685\n",
            "[Batch 5] Current Loss: 5.5832\n",
            "[Batch 6] Current Loss: 5.7813\n",
            "[Batch 7] Current Loss: 5.9783\n",
            "[Batch 8] Current Loss: 5.2922\n",
            "[Batch 9] Current Loss: 4.9933\n",
            "Ep 4 (Step 026260): Train loss 2.630, Val loss 5.498\n",
            "[Batch 0] Current Loss: 2.8590\n",
            "[Batch 1] Current Loss: 2.7868\n",
            "[Batch 2] Current Loss: 1.8767\n",
            "[Batch 3] Current Loss: 2.9859\n",
            "[Batch 4] Current Loss: 2.8891\n",
            "[Batch 5] Current Loss: 3.0790\n",
            "[Batch 6] Current Loss: 2.7486\n",
            "[Batch 7] Current Loss: 2.9310\n",
            "[Batch 8] Current Loss: 2.6674\n",
            "[Batch 9] Current Loss: 2.2847\n",
            "[Batch 0] Current Loss: 5.3936\n",
            "[Batch 1] Current Loss: 5.1356\n",
            "[Batch 2] Current Loss: 5.3933\n",
            "[Batch 3] Current Loss: 6.0229\n",
            "[Batch 4] Current Loss: 5.5705\n",
            "[Batch 5] Current Loss: 5.9587\n",
            "[Batch 6] Current Loss: 5.7333\n",
            "[Batch 7] Current Loss: 5.1833\n",
            "[Batch 8] Current Loss: 5.5220\n",
            "[Batch 9] Current Loss: 4.6561\n",
            "Ep 4 (Step 026280): Train loss 2.711, Val loss 5.457\n",
            "[Batch 0] Current Loss: 2.9410\n",
            "[Batch 1] Current Loss: 2.8203\n",
            "[Batch 2] Current Loss: 3.1256\n",
            "[Batch 3] Current Loss: 3.0940\n",
            "[Batch 4] Current Loss: 2.6776\n",
            "[Batch 5] Current Loss: 2.2944\n",
            "[Batch 6] Current Loss: 2.0847\n",
            "[Batch 7] Current Loss: 2.2189\n",
            "[Batch 8] Current Loss: 2.3183\n",
            "[Batch 9] Current Loss: 3.0484\n",
            "[Batch 0] Current Loss: 4.9501\n",
            "[Batch 1] Current Loss: 5.3662\n",
            "[Batch 2] Current Loss: 5.8044\n",
            "[Batch 3] Current Loss: 5.2300\n",
            "[Batch 4] Current Loss: 5.9932\n",
            "[Batch 5] Current Loss: 5.2164\n",
            "[Batch 6] Current Loss: 6.0729\n",
            "[Batch 7] Current Loss: 4.8187\n",
            "[Batch 8] Current Loss: 5.5180\n",
            "[Batch 9] Current Loss: 5.5745\n",
            "Ep 4 (Step 026300): Train loss 2.662, Val loss 5.454\n",
            "[Batch 0] Current Loss: 2.8994\n",
            "[Batch 1] Current Loss: 2.7136\n",
            "[Batch 2] Current Loss: 2.9788\n",
            "[Batch 3] Current Loss: 2.2838\n",
            "[Batch 4] Current Loss: 2.6988\n",
            "[Batch 5] Current Loss: 3.2221\n",
            "[Batch 6] Current Loss: 3.1472\n",
            "[Batch 7] Current Loss: 2.7591\n",
            "[Batch 8] Current Loss: 2.5242\n",
            "[Batch 9] Current Loss: 2.6757\n",
            "[Batch 0] Current Loss: 6.0349\n",
            "[Batch 1] Current Loss: 6.2238\n",
            "[Batch 2] Current Loss: 5.7660\n",
            "[Batch 3] Current Loss: 5.4067\n",
            "[Batch 4] Current Loss: 5.2047\n",
            "[Batch 5] Current Loss: 5.3084\n",
            "[Batch 6] Current Loss: 4.4326\n",
            "[Batch 7] Current Loss: 5.6903\n",
            "[Batch 8] Current Loss: 6.2138\n",
            "[Batch 9] Current Loss: 4.7648\n",
            "Ep 4 (Step 026320): Train loss 2.790, Val loss 5.505\n",
            "[Batch 0] Current Loss: 2.7159\n",
            "[Batch 1] Current Loss: 2.8256\n",
            "[Batch 2] Current Loss: 3.2419\n",
            "[Batch 3] Current Loss: 2.6982\n",
            "[Batch 4] Current Loss: 2.8419\n",
            "[Batch 5] Current Loss: 2.2904\n",
            "[Batch 6] Current Loss: 2.5572\n",
            "[Batch 7] Current Loss: 3.4906\n",
            "[Batch 8] Current Loss: 2.8818\n",
            "[Batch 9] Current Loss: 3.1154\n",
            "[Batch 0] Current Loss: 5.0764\n",
            "[Batch 1] Current Loss: 5.8338\n",
            "[Batch 2] Current Loss: 5.2490\n",
            "[Batch 3] Current Loss: 5.6863\n",
            "[Batch 4] Current Loss: 5.7980\n",
            "[Batch 5] Current Loss: 5.3706\n",
            "[Batch 6] Current Loss: 5.3027\n",
            "[Batch 7] Current Loss: 4.9365\n",
            "[Batch 8] Current Loss: 5.8249\n",
            "[Batch 9] Current Loss: 5.6729\n",
            "Ep 4 (Step 026340): Train loss 2.866, Val loss 5.475\n",
            "[Batch 0] Current Loss: 2.3705\n",
            "[Batch 1] Current Loss: 1.9874\n",
            "[Batch 2] Current Loss: 3.0257\n",
            "[Batch 3] Current Loss: 3.1945\n",
            "[Batch 4] Current Loss: 3.2012\n",
            "[Batch 5] Current Loss: 2.6202\n",
            "[Batch 6] Current Loss: 2.7463\n",
            "[Batch 7] Current Loss: 3.0327\n",
            "[Batch 8] Current Loss: 2.8215\n",
            "[Batch 9] Current Loss: 2.9377\n",
            "[Batch 0] Current Loss: 4.9292\n",
            "[Batch 1] Current Loss: 5.0914\n",
            "[Batch 2] Current Loss: 5.3861\n",
            "[Batch 3] Current Loss: 5.0724\n",
            "[Batch 4] Current Loss: 5.9330\n",
            "[Batch 5] Current Loss: 5.4217\n",
            "[Batch 6] Current Loss: 5.6152\n",
            "[Batch 7] Current Loss: 5.0522\n",
            "[Batch 8] Current Loss: 5.7646\n",
            "[Batch 9] Current Loss: 6.0888\n",
            "Ep 4 (Step 026360): Train loss 2.794, Val loss 5.435\n",
            "[Batch 0] Current Loss: 2.9624\n",
            "[Batch 1] Current Loss: 3.1447\n",
            "[Batch 2] Current Loss: 2.8875\n",
            "[Batch 3] Current Loss: 2.3720\n",
            "[Batch 4] Current Loss: 3.1767\n",
            "[Batch 5] Current Loss: 3.5730\n",
            "[Batch 6] Current Loss: 3.2218\n",
            "[Batch 7] Current Loss: 2.4837\n",
            "[Batch 8] Current Loss: 2.7893\n",
            "[Batch 9] Current Loss: 2.2818\n",
            "[Batch 0] Current Loss: 5.2244\n",
            "[Batch 1] Current Loss: 5.4652\n",
            "[Batch 2] Current Loss: 6.0600\n",
            "[Batch 3] Current Loss: 5.7551\n",
            "[Batch 4] Current Loss: 5.9926\n",
            "[Batch 5] Current Loss: 4.7076\n",
            "[Batch 6] Current Loss: 5.7991\n",
            "[Batch 7] Current Loss: 5.7822\n",
            "[Batch 8] Current Loss: 4.5729\n",
            "[Batch 9] Current Loss: 5.6818\n",
            "Ep 4 (Step 026380): Train loss 2.889, Val loss 5.504\n",
            "[Batch 0] Current Loss: 3.2258\n",
            "[Batch 1] Current Loss: 2.5394\n",
            "[Batch 2] Current Loss: 2.6078\n",
            "[Batch 3] Current Loss: 2.8234\n",
            "[Batch 4] Current Loss: 1.8289\n",
            "[Batch 5] Current Loss: 3.3602\n",
            "[Batch 6] Current Loss: 3.2768\n",
            "[Batch 7] Current Loss: 2.8013\n",
            "[Batch 8] Current Loss: 2.3367\n",
            "[Batch 9] Current Loss: 2.7662\n",
            "[Batch 0] Current Loss: 6.0004\n",
            "[Batch 1] Current Loss: 5.9838\n",
            "[Batch 2] Current Loss: 4.9349\n",
            "[Batch 3] Current Loss: 5.7985\n",
            "[Batch 4] Current Loss: 5.1292\n",
            "[Batch 5] Current Loss: 5.6263\n",
            "[Batch 6] Current Loss: 5.6322\n",
            "[Batch 7] Current Loss: 6.3196\n",
            "[Batch 8] Current Loss: 4.8413\n",
            "[Batch 9] Current Loss: 5.3749\n",
            "Ep 4 (Step 026400): Train loss 2.757, Val loss 5.564\n",
            "[Batch 0] Current Loss: 2.7873\n",
            "[Batch 1] Current Loss: 2.4333\n",
            "[Batch 2] Current Loss: 2.7020\n",
            "[Batch 3] Current Loss: 2.2047\n",
            "[Batch 4] Current Loss: 2.8244\n",
            "[Batch 5] Current Loss: 2.7166\n",
            "[Batch 6] Current Loss: 2.6367\n",
            "[Batch 7] Current Loss: 3.6137\n",
            "[Batch 8] Current Loss: 3.0825\n",
            "[Batch 9] Current Loss: 2.8914\n",
            "[Batch 0] Current Loss: 4.9134\n",
            "[Batch 1] Current Loss: 5.5254\n",
            "[Batch 2] Current Loss: 4.6974\n",
            "[Batch 3] Current Loss: 4.9177\n",
            "[Batch 4] Current Loss: 5.4326\n",
            "[Batch 5] Current Loss: 5.3778\n",
            "[Batch 6] Current Loss: 4.9822\n",
            "[Batch 7] Current Loss: 5.3319\n",
            "[Batch 8] Current Loss: 5.5602\n",
            "[Batch 9] Current Loss: 5.0501\n",
            "Ep 4 (Step 026420): Train loss 2.789, Val loss 5.179\n",
            "[Batch 0] Current Loss: 2.7362\n",
            "[Batch 1] Current Loss: 2.6010\n",
            "[Batch 2] Current Loss: 1.7778\n",
            "[Batch 3] Current Loss: 2.7477\n",
            "[Batch 4] Current Loss: 2.3157\n",
            "[Batch 5] Current Loss: 2.9947\n",
            "[Batch 6] Current Loss: 2.0964\n",
            "[Batch 7] Current Loss: 2.0860\n",
            "[Batch 8] Current Loss: 3.3461\n",
            "[Batch 9] Current Loss: 2.7693\n",
            "[Batch 0] Current Loss: 5.5073\n",
            "[Batch 1] Current Loss: 5.2035\n",
            "[Batch 2] Current Loss: 5.7444\n",
            "[Batch 3] Current Loss: 5.4260\n",
            "[Batch 4] Current Loss: 5.2310\n",
            "[Batch 5] Current Loss: 5.8677\n",
            "[Batch 6] Current Loss: 4.9410\n",
            "[Batch 7] Current Loss: 5.5773\n",
            "[Batch 8] Current Loss: 4.0193\n",
            "[Batch 9] Current Loss: 5.4433\n",
            "Ep 4 (Step 026440): Train loss 2.547, Val loss 5.296\n",
            "[Batch 0] Current Loss: 2.9437\n",
            "[Batch 1] Current Loss: 2.5221\n",
            "[Batch 2] Current Loss: 2.7446\n",
            "[Batch 3] Current Loss: 2.1848\n",
            "[Batch 4] Current Loss: 2.9228\n",
            "[Batch 5] Current Loss: 2.6046\n",
            "[Batch 6] Current Loss: 3.0285\n",
            "[Batch 7] Current Loss: 2.9070\n",
            "[Batch 8] Current Loss: 2.6683\n",
            "[Batch 9] Current Loss: 3.4339\n",
            "[Batch 0] Current Loss: 5.4715\n",
            "[Batch 1] Current Loss: 6.1533\n",
            "[Batch 2] Current Loss: 4.7270\n",
            "[Batch 3] Current Loss: 5.5698\n",
            "[Batch 4] Current Loss: 5.4513\n",
            "[Batch 5] Current Loss: 5.9729\n",
            "[Batch 6] Current Loss: 4.9660\n",
            "[Batch 7] Current Loss: 6.0392\n",
            "[Batch 8] Current Loss: 4.2123\n",
            "[Batch 9] Current Loss: 5.3176\n",
            "Ep 4 (Step 026460): Train loss 2.796, Val loss 5.388\n",
            "[Batch 0] Current Loss: 3.3672\n",
            "[Batch 1] Current Loss: 2.1967\n",
            "[Batch 2] Current Loss: 2.2114\n",
            "[Batch 3] Current Loss: 2.5265\n",
            "[Batch 4] Current Loss: 3.3413\n",
            "[Batch 5] Current Loss: 2.6583\n",
            "[Batch 6] Current Loss: 3.0368\n",
            "[Batch 7] Current Loss: 2.8208\n",
            "[Batch 8] Current Loss: 2.2207\n",
            "[Batch 9] Current Loss: 2.7629\n",
            "[Batch 0] Current Loss: 6.3033\n",
            "[Batch 1] Current Loss: 5.1646\n",
            "[Batch 2] Current Loss: 5.5652\n",
            "[Batch 3] Current Loss: 5.1302\n",
            "[Batch 4] Current Loss: 6.2494\n",
            "[Batch 5] Current Loss: 5.7994\n",
            "[Batch 6] Current Loss: 5.5777\n",
            "[Batch 7] Current Loss: 5.1760\n",
            "[Batch 8] Current Loss: 6.0777\n",
            "[Batch 9] Current Loss: 4.7373\n",
            "Ep 4 (Step 026480): Train loss 2.714, Val loss 5.578\n",
            "[Batch 0] Current Loss: 2.9852\n",
            "[Batch 1] Current Loss: 2.5074\n",
            "[Batch 2] Current Loss: 2.9349\n",
            "[Batch 3] Current Loss: 2.8339\n",
            "[Batch 4] Current Loss: 2.7746\n",
            "[Batch 5] Current Loss: 2.4048\n",
            "[Batch 6] Current Loss: 2.7688\n",
            "[Batch 7] Current Loss: 2.7244\n",
            "[Batch 8] Current Loss: 2.8820\n",
            "[Batch 9] Current Loss: 2.5802\n",
            "[Batch 0] Current Loss: 5.4844\n",
            "[Batch 1] Current Loss: 5.6094\n",
            "[Batch 2] Current Loss: 5.0218\n",
            "[Batch 3] Current Loss: 5.4353\n",
            "[Batch 4] Current Loss: 5.5158\n",
            "[Batch 5] Current Loss: 5.3801\n",
            "[Batch 6] Current Loss: 5.6491\n",
            "[Batch 7] Current Loss: 5.8394\n",
            "[Batch 8] Current Loss: 5.3576\n",
            "[Batch 9] Current Loss: 4.6795\n",
            "Ep 4 (Step 026500): Train loss 2.740, Val loss 5.397\n",
            "[Batch 0] Current Loss: 2.6888\n",
            "[Batch 1] Current Loss: 2.7778\n",
            "[Batch 2] Current Loss: 2.6334\n",
            "[Batch 3] Current Loss: 3.2090\n",
            "[Batch 4] Current Loss: 2.9272\n",
            "[Batch 5] Current Loss: 2.8744\n",
            "[Batch 6] Current Loss: 2.8181\n",
            "[Batch 7] Current Loss: 2.7634\n",
            "[Batch 8] Current Loss: 2.3956\n",
            "[Batch 9] Current Loss: 3.0830\n",
            "[Batch 0] Current Loss: 5.7521\n",
            "[Batch 1] Current Loss: 3.5352\n",
            "[Batch 2] Current Loss: 5.5690\n",
            "[Batch 3] Current Loss: 5.6276\n",
            "[Batch 4] Current Loss: 5.4163\n",
            "[Batch 5] Current Loss: 5.6839\n",
            "[Batch 6] Current Loss: 6.2635\n",
            "[Batch 7] Current Loss: 5.7657\n",
            "[Batch 8] Current Loss: 5.3639\n",
            "[Batch 9] Current Loss: 5.3227\n",
            "Ep 4 (Step 026520): Train loss 2.817, Val loss 5.430\n",
            "[Batch 0] Current Loss: 3.1683\n",
            "[Batch 1] Current Loss: 2.3883\n",
            "[Batch 2] Current Loss: 2.8956\n",
            "[Batch 3] Current Loss: 2.2468\n",
            "[Batch 4] Current Loss: 1.9392\n",
            "[Batch 5] Current Loss: 2.7507\n",
            "[Batch 6] Current Loss: 2.3038\n",
            "[Batch 7] Current Loss: 3.4488\n",
            "[Batch 8] Current Loss: 2.7361\n",
            "[Batch 9] Current Loss: 2.9464\n",
            "[Batch 0] Current Loss: 4.5337\n",
            "[Batch 1] Current Loss: 6.0884\n",
            "[Batch 2] Current Loss: 5.9243\n",
            "[Batch 3] Current Loss: 4.8391\n",
            "[Batch 4] Current Loss: 6.2842\n",
            "[Batch 5] Current Loss: 5.1932\n",
            "[Batch 6] Current Loss: 5.8918\n",
            "[Batch 7] Current Loss: 5.5297\n",
            "[Batch 8] Current Loss: 5.2529\n",
            "[Batch 9] Current Loss: 4.6573\n",
            "Ep 4 (Step 026540): Train loss 2.682, Val loss 5.419\n",
            "[Batch 0] Current Loss: 2.5659\n",
            "[Batch 1] Current Loss: 2.7098\n",
            "[Batch 2] Current Loss: 2.9885\n",
            "[Batch 3] Current Loss: 2.5167\n",
            "[Batch 4] Current Loss: 3.0272\n",
            "[Batch 5] Current Loss: 2.7302\n",
            "[Batch 6] Current Loss: 2.6943\n",
            "[Batch 7] Current Loss: 2.1314\n",
            "[Batch 8] Current Loss: 2.3711\n",
            "[Batch 9] Current Loss: 2.3685\n",
            "[Batch 0] Current Loss: 5.7436\n",
            "[Batch 1] Current Loss: 5.4433\n",
            "[Batch 2] Current Loss: 5.4083\n",
            "[Batch 3] Current Loss: 5.0126\n",
            "[Batch 4] Current Loss: 5.5100\n",
            "[Batch 5] Current Loss: 6.1957\n",
            "[Batch 6] Current Loss: 5.6748\n",
            "[Batch 7] Current Loss: 5.5675\n",
            "[Batch 8] Current Loss: 5.4962\n",
            "[Batch 9] Current Loss: 5.6349\n",
            "Ep 4 (Step 026560): Train loss 2.610, Val loss 5.569\n",
            "[Batch 0] Current Loss: 2.8197\n",
            "[Batch 1] Current Loss: 2.4603\n",
            "[Batch 2] Current Loss: 2.5725\n",
            "[Batch 3] Current Loss: 2.6272\n",
            "[Batch 4] Current Loss: 2.7207\n",
            "[Batch 5] Current Loss: 1.8936\n",
            "[Batch 6] Current Loss: 2.8269\n",
            "[Batch 7] Current Loss: 2.2004\n",
            "[Batch 8] Current Loss: 3.8267\n",
            "[Batch 9] Current Loss: 3.0030\n",
            "[Batch 0] Current Loss: 5.7616\n",
            "[Batch 1] Current Loss: 5.4236\n",
            "[Batch 2] Current Loss: 5.2584\n",
            "[Batch 3] Current Loss: 5.2258\n",
            "[Batch 4] Current Loss: 5.3148\n",
            "[Batch 5] Current Loss: 5.5841\n",
            "[Batch 6] Current Loss: 5.6524\n",
            "[Batch 7] Current Loss: 5.7570\n",
            "[Batch 8] Current Loss: 5.8436\n",
            "[Batch 9] Current Loss: 5.0437\n",
            "Ep 4 (Step 026580): Train loss 2.695, Val loss 5.486\n",
            "[Batch 0] Current Loss: 2.1955\n",
            "[Batch 1] Current Loss: 2.2006\n",
            "[Batch 2] Current Loss: 2.7439\n",
            "[Batch 3] Current Loss: 2.5473\n",
            "[Batch 4] Current Loss: 2.5337\n",
            "[Batch 5] Current Loss: 2.6606\n",
            "[Batch 6] Current Loss: 2.0579\n",
            "[Batch 7] Current Loss: 2.3241\n",
            "[Batch 8] Current Loss: 2.8553\n",
            "[Batch 9] Current Loss: 1.8780\n",
            "[Batch 0] Current Loss: 5.8619\n",
            "[Batch 1] Current Loss: 4.8074\n",
            "[Batch 2] Current Loss: 3.9671\n",
            "[Batch 3] Current Loss: 5.3179\n",
            "[Batch 4] Current Loss: 6.1898\n",
            "[Batch 5] Current Loss: 5.4193\n",
            "[Batch 6] Current Loss: 4.4186\n",
            "[Batch 7] Current Loss: 6.2878\n",
            "[Batch 8] Current Loss: 5.6783\n",
            "[Batch 9] Current Loss: 5.4282\n",
            "Ep 4 (Step 026600): Train loss 2.400, Val loss 5.338\n",
            "[Batch 0] Current Loss: 3.0066\n",
            "[Batch 1] Current Loss: 2.7196\n",
            "[Batch 2] Current Loss: 3.1161\n",
            "[Batch 3] Current Loss: 2.6364\n",
            "[Batch 4] Current Loss: 3.3518\n",
            "[Batch 5] Current Loss: 2.4537\n",
            "[Batch 6] Current Loss: 2.9709\n",
            "[Batch 7] Current Loss: 2.3672\n",
            "[Batch 8] Current Loss: 2.9304\n",
            "[Batch 9] Current Loss: 2.5080\n",
            "[Batch 0] Current Loss: 5.0677\n",
            "[Batch 1] Current Loss: 4.4637\n",
            "[Batch 2] Current Loss: 5.6532\n",
            "[Batch 3] Current Loss: 6.1305\n",
            "[Batch 4] Current Loss: 5.1406\n",
            "[Batch 5] Current Loss: 4.8967\n",
            "[Batch 6] Current Loss: 5.1450\n",
            "[Batch 7] Current Loss: 5.3284\n",
            "[Batch 8] Current Loss: 5.1934\n",
            "[Batch 9] Current Loss: 5.8663\n",
            "Ep 4 (Step 026620): Train loss 2.806, Val loss 5.289\n",
            "[Batch 0] Current Loss: 2.9016\n",
            "[Batch 1] Current Loss: 2.4507\n",
            "[Batch 2] Current Loss: 2.5191\n",
            "[Batch 3] Current Loss: 2.6883\n",
            "[Batch 4] Current Loss: 2.6763\n",
            "[Batch 5] Current Loss: 2.9023\n",
            "[Batch 6] Current Loss: 2.8662\n",
            "[Batch 7] Current Loss: 2.6437\n",
            "[Batch 8] Current Loss: 3.4943\n",
            "[Batch 9] Current Loss: 2.8959\n",
            "[Batch 0] Current Loss: 4.8400\n",
            "[Batch 1] Current Loss: 5.1458\n",
            "[Batch 2] Current Loss: 5.2862\n",
            "[Batch 3] Current Loss: 5.2579\n",
            "[Batch 4] Current Loss: 5.3335\n",
            "[Batch 5] Current Loss: 5.4427\n",
            "[Batch 6] Current Loss: 5.0006\n",
            "[Batch 7] Current Loss: 5.5031\n",
            "[Batch 8] Current Loss: 6.0356\n",
            "[Batch 9] Current Loss: 5.7922\n",
            "Ep 4 (Step 026640): Train loss 2.804, Val loss 5.364\n",
            "[Batch 0] Current Loss: 2.1799\n",
            "[Batch 1] Current Loss: 2.3312\n",
            "[Batch 2] Current Loss: 2.5291\n",
            "[Batch 3] Current Loss: 2.4939\n",
            "[Batch 4] Current Loss: 2.4808\n",
            "[Batch 5] Current Loss: 2.4241\n",
            "[Batch 6] Current Loss: 2.6104\n",
            "[Batch 7] Current Loss: 3.1991\n",
            "[Batch 8] Current Loss: 2.7395\n",
            "[Batch 9] Current Loss: 2.6104\n",
            "[Batch 0] Current Loss: 4.8344\n",
            "[Batch 1] Current Loss: 5.4563\n",
            "[Batch 2] Current Loss: 5.1402\n",
            "[Batch 3] Current Loss: 5.4424\n",
            "[Batch 4] Current Loss: 5.9930\n",
            "[Batch 5] Current Loss: 5.8468\n",
            "[Batch 6] Current Loss: 6.2993\n",
            "[Batch 7] Current Loss: 5.4431\n",
            "[Batch 8] Current Loss: 5.9186\n",
            "[Batch 9] Current Loss: 6.2317\n",
            "Ep 4 (Step 026660): Train loss 2.560, Val loss 5.661\n",
            "[Batch 0] Current Loss: 2.0088\n",
            "[Batch 1] Current Loss: 3.5733\n",
            "[Batch 2] Current Loss: 2.4431\n",
            "[Batch 3] Current Loss: 2.3194\n",
            "[Batch 4] Current Loss: 2.7362\n",
            "[Batch 5] Current Loss: 3.1284\n",
            "[Batch 6] Current Loss: 2.7692\n",
            "[Batch 7] Current Loss: 2.8193\n",
            "[Batch 8] Current Loss: 2.8775\n",
            "[Batch 9] Current Loss: 2.5480\n",
            "[Batch 0] Current Loss: 4.6697\n",
            "[Batch 1] Current Loss: 6.0680\n",
            "[Batch 2] Current Loss: 5.4627\n",
            "[Batch 3] Current Loss: 5.7774\n",
            "[Batch 4] Current Loss: 5.7845\n",
            "[Batch 5] Current Loss: 5.4067\n",
            "[Batch 6] Current Loss: 5.8004\n",
            "[Batch 7] Current Loss: 5.2362\n",
            "[Batch 8] Current Loss: 5.6837\n",
            "[Batch 9] Current Loss: 5.2412\n",
            "Ep 4 (Step 026680): Train loss 2.722, Val loss 5.513\n",
            "[Batch 0] Current Loss: 3.1135\n",
            "[Batch 1] Current Loss: 3.0493\n",
            "[Batch 2] Current Loss: 2.8941\n",
            "[Batch 3] Current Loss: 2.8575\n",
            "[Batch 4] Current Loss: 2.4362\n",
            "[Batch 5] Current Loss: 2.2841\n",
            "[Batch 6] Current Loss: 3.3956\n",
            "[Batch 7] Current Loss: 2.4740\n",
            "[Batch 8] Current Loss: 3.0798\n",
            "[Batch 9] Current Loss: 2.4770\n",
            "[Batch 0] Current Loss: 4.9217\n",
            "[Batch 1] Current Loss: 5.9684\n",
            "[Batch 2] Current Loss: 5.0487\n",
            "[Batch 3] Current Loss: 5.1941\n",
            "[Batch 4] Current Loss: 4.4872\n",
            "[Batch 5] Current Loss: 5.2974\n",
            "[Batch 6] Current Loss: 5.5326\n",
            "[Batch 7] Current Loss: 6.0750\n",
            "[Batch 8] Current Loss: 5.5490\n",
            "[Batch 9] Current Loss: 5.9369\n",
            "Ep 4 (Step 026700): Train loss 2.806, Val loss 5.401\n",
            "[Batch 0] Current Loss: 2.1726\n",
            "[Batch 1] Current Loss: 2.5245\n",
            "[Batch 2] Current Loss: 3.0896\n",
            "[Batch 3] Current Loss: 2.6982\n",
            "[Batch 4] Current Loss: 2.4807\n",
            "[Batch 5] Current Loss: 2.3397\n",
            "[Batch 6] Current Loss: 3.0878\n",
            "[Batch 7] Current Loss: 2.8981\n",
            "[Batch 8] Current Loss: 2.6769\n",
            "[Batch 9] Current Loss: 2.3976\n",
            "[Batch 0] Current Loss: 5.9671\n",
            "[Batch 1] Current Loss: 5.6356\n",
            "[Batch 2] Current Loss: 5.7710\n",
            "[Batch 3] Current Loss: 4.5892\n",
            "[Batch 4] Current Loss: 4.8191\n",
            "[Batch 5] Current Loss: 6.0243\n",
            "[Batch 6] Current Loss: 4.9642\n",
            "[Batch 7] Current Loss: 5.4516\n",
            "[Batch 8] Current Loss: 5.5696\n",
            "[Batch 9] Current Loss: 6.0805\n",
            "Ep 4 (Step 026720): Train loss 2.637, Val loss 5.487\n",
            "[Batch 0] Current Loss: 2.7425\n",
            "[Batch 1] Current Loss: 2.9070\n",
            "[Batch 2] Current Loss: 2.9185\n",
            "[Batch 3] Current Loss: 2.3059\n",
            "[Batch 4] Current Loss: 3.1813\n",
            "[Batch 5] Current Loss: 1.6723\n",
            "[Batch 6] Current Loss: 3.0387\n",
            "[Batch 7] Current Loss: 2.5644\n",
            "[Batch 8] Current Loss: 2.1181\n",
            "[Batch 9] Current Loss: 2.8498\n",
            "[Batch 0] Current Loss: 5.1684\n",
            "[Batch 1] Current Loss: 4.3333\n",
            "[Batch 2] Current Loss: 6.1243\n",
            "[Batch 3] Current Loss: 5.2861\n",
            "[Batch 4] Current Loss: 4.9601\n",
            "[Batch 5] Current Loss: 6.4685\n",
            "[Batch 6] Current Loss: 5.8077\n",
            "[Batch 7] Current Loss: 4.2077\n",
            "[Batch 8] Current Loss: 4.4002\n",
            "[Batch 9] Current Loss: 6.3499\n",
            "Ep 4 (Step 026740): Train loss 2.630, Val loss 5.311\n",
            "[Batch 0] Current Loss: 2.3002\n",
            "[Batch 1] Current Loss: 2.2558\n",
            "[Batch 2] Current Loss: 2.2564\n",
            "[Batch 3] Current Loss: 2.6597\n",
            "[Batch 4] Current Loss: 2.6912\n",
            "[Batch 5] Current Loss: 2.8613\n",
            "[Batch 6] Current Loss: 2.5756\n",
            "[Batch 7] Current Loss: 2.9648\n",
            "[Batch 8] Current Loss: 2.7462\n",
            "[Batch 9] Current Loss: 1.9466\n",
            "[Batch 0] Current Loss: 5.2171\n",
            "[Batch 1] Current Loss: 6.6043\n",
            "[Batch 2] Current Loss: 5.7618\n",
            "[Batch 3] Current Loss: 5.6077\n",
            "[Batch 4] Current Loss: 5.3823\n",
            "[Batch 5] Current Loss: 5.6122\n",
            "[Batch 6] Current Loss: 6.3018\n",
            "[Batch 7] Current Loss: 5.8263\n",
            "[Batch 8] Current Loss: 5.7135\n",
            "[Batch 9] Current Loss: 4.6138\n",
            "Ep 4 (Step 026760): Train loss 2.526, Val loss 5.664\n",
            "[Batch 0] Current Loss: 2.8240\n",
            "[Batch 1] Current Loss: 2.5167\n",
            "[Batch 2] Current Loss: 2.7805\n",
            "[Batch 3] Current Loss: 3.0619\n",
            "[Batch 4] Current Loss: 2.1457\n",
            "[Batch 5] Current Loss: 2.4618\n",
            "[Batch 6] Current Loss: 3.1640\n",
            "[Batch 7] Current Loss: 3.2473\n",
            "[Batch 8] Current Loss: 2.7012\n",
            "[Batch 9] Current Loss: 2.8916\n",
            "[Batch 0] Current Loss: 6.3353\n",
            "[Batch 1] Current Loss: 5.3191\n",
            "[Batch 2] Current Loss: 5.9528\n",
            "[Batch 3] Current Loss: 6.0713\n",
            "[Batch 4] Current Loss: 4.6233\n",
            "[Batch 5] Current Loss: 4.8870\n",
            "[Batch 6] Current Loss: 4.8599\n",
            "[Batch 7] Current Loss: 5.0620\n",
            "[Batch 8] Current Loss: 5.2489\n",
            "[Batch 9] Current Loss: 5.2712\n",
            "Ep 4 (Step 026780): Train loss 2.779, Val loss 5.363\n",
            "[Batch 0] Current Loss: 3.0572\n",
            "[Batch 1] Current Loss: 2.6934\n",
            "[Batch 2] Current Loss: 2.4944\n",
            "[Batch 3] Current Loss: 2.6088\n",
            "[Batch 4] Current Loss: 2.7288\n",
            "[Batch 5] Current Loss: 2.6834\n",
            "[Batch 6] Current Loss: 2.7503\n",
            "[Batch 7] Current Loss: 2.5372\n",
            "[Batch 8] Current Loss: 2.9064\n",
            "[Batch 9] Current Loss: 2.3746\n",
            "[Batch 0] Current Loss: 6.2487\n",
            "[Batch 1] Current Loss: 5.2522\n",
            "[Batch 2] Current Loss: 5.4950\n",
            "[Batch 3] Current Loss: 6.1542\n",
            "[Batch 4] Current Loss: 5.5942\n",
            "[Batch 5] Current Loss: 5.0202\n",
            "[Batch 6] Current Loss: 5.4485\n",
            "[Batch 7] Current Loss: 4.6287\n",
            "[Batch 8] Current Loss: 5.6693\n",
            "[Batch 9] Current Loss: 4.5805\n",
            "Ep 4 (Step 026800): Train loss 2.683, Val loss 5.409\n",
            "[Batch 0] Current Loss: 3.0353\n",
            "[Batch 1] Current Loss: 2.3609\n",
            "[Batch 2] Current Loss: 3.4451\n",
            "[Batch 3] Current Loss: 2.9398\n",
            "[Batch 4] Current Loss: 3.0417\n",
            "[Batch 5] Current Loss: 2.3426\n",
            "[Batch 6] Current Loss: 3.1361\n",
            "[Batch 7] Current Loss: 2.0282\n",
            "[Batch 8] Current Loss: 2.7538\n",
            "[Batch 9] Current Loss: 2.7443\n",
            "[Batch 0] Current Loss: 4.8417\n",
            "[Batch 1] Current Loss: 5.2872\n",
            "[Batch 2] Current Loss: 5.4567\n",
            "[Batch 3] Current Loss: 6.2467\n",
            "[Batch 4] Current Loss: 5.9759\n",
            "[Batch 5] Current Loss: 5.7077\n",
            "[Batch 6] Current Loss: 5.8995\n",
            "[Batch 7] Current Loss: 5.7484\n",
            "[Batch 8] Current Loss: 6.1859\n",
            "[Batch 9] Current Loss: 5.5934\n",
            "Ep 4 (Step 026820): Train loss 2.783, Val loss 5.694\n",
            "[Batch 0] Current Loss: 3.1740\n",
            "[Batch 1] Current Loss: 2.2698\n",
            "[Batch 2] Current Loss: 3.0387\n",
            "[Batch 3] Current Loss: 2.7814\n",
            "[Batch 4] Current Loss: 2.6221\n",
            "[Batch 5] Current Loss: 2.5859\n",
            "[Batch 6] Current Loss: 3.1567\n",
            "[Batch 7] Current Loss: 2.6381\n",
            "[Batch 8] Current Loss: 2.6927\n",
            "[Batch 9] Current Loss: 3.3992\n",
            "[Batch 0] Current Loss: 6.0375\n",
            "[Batch 1] Current Loss: 5.4524\n",
            "[Batch 2] Current Loss: 6.1164\n",
            "[Batch 3] Current Loss: 5.1521\n",
            "[Batch 4] Current Loss: 5.6233\n",
            "[Batch 5] Current Loss: 6.0401\n",
            "[Batch 6] Current Loss: 5.6833\n",
            "[Batch 7] Current Loss: 5.9423\n",
            "[Batch 8] Current Loss: 6.0080\n",
            "[Batch 9] Current Loss: 5.6357\n",
            "Ep 4 (Step 026840): Train loss 2.836, Val loss 5.769\n",
            "[Batch 0] Current Loss: 2.8964\n",
            "[Batch 1] Current Loss: 2.9329\n",
            "[Batch 2] Current Loss: 3.1996\n",
            "[Batch 3] Current Loss: 2.4573\n",
            "[Batch 4] Current Loss: 2.4728\n",
            "[Batch 5] Current Loss: 3.4347\n",
            "[Batch 6] Current Loss: 2.9976\n",
            "[Batch 7] Current Loss: 2.8671\n",
            "[Batch 8] Current Loss: 2.6703\n",
            "[Batch 9] Current Loss: 2.1811\n",
            "[Batch 0] Current Loss: 5.7395\n",
            "[Batch 1] Current Loss: 5.6697\n",
            "[Batch 2] Current Loss: 5.9271\n",
            "[Batch 3] Current Loss: 5.3506\n",
            "[Batch 4] Current Loss: 5.3398\n",
            "[Batch 5] Current Loss: 5.6223\n",
            "[Batch 6] Current Loss: 5.2644\n",
            "[Batch 7] Current Loss: 5.8150\n",
            "[Batch 8] Current Loss: 5.1256\n",
            "[Batch 9] Current Loss: 6.4676\n",
            "Ep 4 (Step 026860): Train loss 2.811, Val loss 5.632\n",
            "[Batch 0] Current Loss: 2.1855\n",
            "[Batch 1] Current Loss: 1.9433\n",
            "[Batch 2] Current Loss: 2.5977\n",
            "[Batch 3] Current Loss: 2.5648\n",
            "[Batch 4] Current Loss: 2.7886\n",
            "[Batch 5] Current Loss: 2.3983\n",
            "[Batch 6] Current Loss: 2.6669\n",
            "[Batch 7] Current Loss: 2.5999\n",
            "[Batch 8] Current Loss: 2.9368\n",
            "[Batch 9] Current Loss: 2.6391\n",
            "[Batch 0] Current Loss: 4.8567\n",
            "[Batch 1] Current Loss: 5.6779\n",
            "[Batch 2] Current Loss: 5.1461\n",
            "[Batch 3] Current Loss: 5.4225\n",
            "[Batch 4] Current Loss: 4.9057\n",
            "[Batch 5] Current Loss: 5.2867\n",
            "[Batch 6] Current Loss: 5.4635\n",
            "[Batch 7] Current Loss: 5.7423\n",
            "[Batch 8] Current Loss: 5.3442\n",
            "[Batch 9] Current Loss: 4.4840\n",
            "Ep 4 (Step 026880): Train loss 2.532, Val loss 5.233\n",
            "[Batch 0] Current Loss: 2.9247\n",
            "[Batch 1] Current Loss: 2.0839\n",
            "[Batch 2] Current Loss: 2.6558\n",
            "[Batch 3] Current Loss: 2.2457\n",
            "[Batch 4] Current Loss: 2.2116\n",
            "[Batch 5] Current Loss: 2.7768\n",
            "[Batch 6] Current Loss: 2.9725\n",
            "[Batch 7] Current Loss: 2.7878\n",
            "[Batch 8] Current Loss: 3.2867\n",
            "[Batch 9] Current Loss: 2.6448\n",
            "[Batch 0] Current Loss: 5.7132\n",
            "[Batch 1] Current Loss: 5.6369\n",
            "[Batch 2] Current Loss: 5.6693\n",
            "[Batch 3] Current Loss: 4.6196\n",
            "[Batch 4] Current Loss: 5.8927\n",
            "[Batch 5] Current Loss: 5.3564\n",
            "[Batch 6] Current Loss: 5.3291\n",
            "[Batch 7] Current Loss: 6.1020\n",
            "[Batch 8] Current Loss: 5.8063\n",
            "[Batch 9] Current Loss: 4.9910\n",
            "Ep 4 (Step 026900): Train loss 2.659, Val loss 5.512\n",
            "[Batch 0] Current Loss: 2.9287\n",
            "[Batch 1] Current Loss: 2.0626\n",
            "[Batch 2] Current Loss: 2.8164\n",
            "[Batch 3] Current Loss: 2.6928\n",
            "[Batch 4] Current Loss: 2.4026\n",
            "[Batch 5] Current Loss: 2.4274\n",
            "[Batch 6] Current Loss: 3.2648\n",
            "[Batch 7] Current Loss: 2.5026\n",
            "[Batch 8] Current Loss: 2.1939\n",
            "[Batch 9] Current Loss: 3.6687\n",
            "[Batch 0] Current Loss: 5.2422\n",
            "[Batch 1] Current Loss: 6.0108\n",
            "[Batch 2] Current Loss: 5.0719\n",
            "[Batch 3] Current Loss: 5.5282\n",
            "[Batch 4] Current Loss: 4.7190\n",
            "[Batch 5] Current Loss: 5.4635\n",
            "[Batch 6] Current Loss: 6.0554\n",
            "[Batch 7] Current Loss: 5.6725\n",
            "[Batch 8] Current Loss: 5.8358\n",
            "[Batch 9] Current Loss: 5.3674\n",
            "Ep 4 (Step 026920): Train loss 2.696, Val loss 5.497\n",
            "[Batch 0] Current Loss: 2.7419\n",
            "[Batch 1] Current Loss: 2.4843\n",
            "[Batch 2] Current Loss: 2.7589\n",
            "[Batch 3] Current Loss: 3.0373\n",
            "[Batch 4] Current Loss: 2.3557\n",
            "[Batch 5] Current Loss: 2.5617\n",
            "[Batch 6] Current Loss: 2.5269\n",
            "[Batch 7] Current Loss: 2.4614\n",
            "[Batch 8] Current Loss: 2.5756\n",
            "[Batch 9] Current Loss: 2.6842\n",
            "[Batch 0] Current Loss: 6.3244\n",
            "[Batch 1] Current Loss: 5.4714\n",
            "[Batch 2] Current Loss: 6.4305\n",
            "[Batch 3] Current Loss: 5.6855\n",
            "[Batch 4] Current Loss: 4.5467\n",
            "[Batch 5] Current Loss: 5.0791\n",
            "[Batch 6] Current Loss: 5.4942\n",
            "[Batch 7] Current Loss: 5.7560\n",
            "[Batch 8] Current Loss: 5.9524\n",
            "[Batch 9] Current Loss: 5.4491\n",
            "Ep 4 (Step 026940): Train loss 2.619, Val loss 5.619\n",
            "[Batch 0] Current Loss: 2.3092\n",
            "[Batch 1] Current Loss: 2.4584\n",
            "[Batch 2] Current Loss: 3.1341\n",
            "[Batch 3] Current Loss: 2.7685\n",
            "[Batch 4] Current Loss: 2.4643\n",
            "[Batch 5] Current Loss: 2.8644\n",
            "[Batch 6] Current Loss: 2.6297\n",
            "[Batch 7] Current Loss: 3.2705\n",
            "[Batch 8] Current Loss: 2.1034\n",
            "[Batch 9] Current Loss: 2.7792\n",
            "[Batch 0] Current Loss: 5.8855\n",
            "[Batch 1] Current Loss: 5.5115\n",
            "[Batch 2] Current Loss: 5.7787\n",
            "[Batch 3] Current Loss: 4.9926\n",
            "[Batch 4] Current Loss: 6.4968\n",
            "[Batch 5] Current Loss: 6.3135\n",
            "[Batch 6] Current Loss: 5.1239\n",
            "[Batch 7] Current Loss: 5.4857\n",
            "[Batch 8] Current Loss: 5.0500\n",
            "[Batch 9] Current Loss: 6.1360\n",
            "Ep 4 (Step 026960): Train loss 2.678, Val loss 5.677\n",
            "[Batch 0] Current Loss: 2.6785\n",
            "[Batch 1] Current Loss: 2.4464\n",
            "[Batch 2] Current Loss: 2.4626\n",
            "[Batch 3] Current Loss: 3.2398\n",
            "[Batch 4] Current Loss: 2.7073\n",
            "[Batch 5] Current Loss: 2.5915\n",
            "[Batch 6] Current Loss: 2.2242\n",
            "[Batch 7] Current Loss: 2.5594\n",
            "[Batch 8] Current Loss: 2.6124\n",
            "[Batch 9] Current Loss: 2.5892\n",
            "[Batch 0] Current Loss: 5.6098\n",
            "[Batch 1] Current Loss: 5.4601\n",
            "[Batch 2] Current Loss: 5.6307\n",
            "[Batch 3] Current Loss: 4.6354\n",
            "[Batch 4] Current Loss: 4.5903\n",
            "[Batch 5] Current Loss: 5.3173\n",
            "[Batch 6] Current Loss: 5.2860\n",
            "[Batch 7] Current Loss: 6.3736\n",
            "[Batch 8] Current Loss: 5.2583\n",
            "[Batch 9] Current Loss: 4.8190\n",
            "Ep 4 (Step 026980): Train loss 2.611, Val loss 5.298\n",
            "[Batch 0] Current Loss: 2.4629\n",
            "[Batch 1] Current Loss: 3.4895\n",
            "[Batch 2] Current Loss: 2.9271\n",
            "[Batch 3] Current Loss: 2.8889\n",
            "[Batch 4] Current Loss: 2.4368\n",
            "[Batch 5] Current Loss: 2.5470\n",
            "[Batch 6] Current Loss: 3.0404\n",
            "[Batch 7] Current Loss: 3.6124\n",
            "[Batch 8] Current Loss: 2.1323\n",
            "[Batch 9] Current Loss: 2.7263\n",
            "[Batch 0] Current Loss: 5.5850\n",
            "[Batch 1] Current Loss: 6.0397\n",
            "[Batch 2] Current Loss: 5.3320\n",
            "[Batch 3] Current Loss: 5.5124\n",
            "[Batch 4] Current Loss: 6.3365\n",
            "[Batch 5] Current Loss: 5.2387\n",
            "[Batch 6] Current Loss: 5.2593\n",
            "[Batch 7] Current Loss: 5.4920\n",
            "[Batch 8] Current Loss: 5.2938\n",
            "[Batch 9] Current Loss: 5.1195\n",
            "Ep 4 (Step 027000): Train loss 2.826, Val loss 5.521\n",
            "[Batch 0] Current Loss: 3.0779\n",
            "[Batch 1] Current Loss: 2.6036\n",
            "[Batch 2] Current Loss: 2.7321\n",
            "[Batch 3] Current Loss: 2.3754\n",
            "[Batch 4] Current Loss: 2.5101\n",
            "[Batch 5] Current Loss: 2.5470\n",
            "[Batch 6] Current Loss: 2.9984\n",
            "[Batch 7] Current Loss: 2.6191\n",
            "[Batch 8] Current Loss: 2.9922\n",
            "[Batch 9] Current Loss: 2.5161\n",
            "[Batch 0] Current Loss: 5.6922\n",
            "[Batch 1] Current Loss: 5.0669\n",
            "[Batch 2] Current Loss: 4.9376\n",
            "[Batch 3] Current Loss: 5.3909\n",
            "[Batch 4] Current Loss: 6.4892\n",
            "[Batch 5] Current Loss: 5.5918\n",
            "[Batch 6] Current Loss: 5.6889\n",
            "[Batch 7] Current Loss: 6.5857\n",
            "[Batch 8] Current Loss: 4.8388\n",
            "[Batch 9] Current Loss: 6.3808\n",
            "Ep 4 (Step 027020): Train loss 2.697, Val loss 5.666\n",
            "[Batch 0] Current Loss: 2.6231\n",
            "[Batch 1] Current Loss: 2.7786\n",
            "[Batch 2] Current Loss: 2.8805\n",
            "[Batch 3] Current Loss: 2.4787\n",
            "[Batch 4] Current Loss: 2.9692\n",
            "[Batch 5] Current Loss: 3.0189\n",
            "[Batch 6] Current Loss: 2.8406\n",
            "[Batch 7] Current Loss: 2.8512\n",
            "[Batch 8] Current Loss: 2.4991\n",
            "[Batch 9] Current Loss: 2.2677\n",
            "[Batch 0] Current Loss: 5.7155\n",
            "[Batch 1] Current Loss: 4.8577\n",
            "[Batch 2] Current Loss: 4.4592\n",
            "[Batch 3] Current Loss: 5.3763\n",
            "[Batch 4] Current Loss: 5.3087\n",
            "[Batch 5] Current Loss: 5.6676\n",
            "[Batch 6] Current Loss: 5.4352\n",
            "[Batch 7] Current Loss: 5.2170\n",
            "[Batch 8] Current Loss: 5.4929\n",
            "[Batch 9] Current Loss: 6.0852\n",
            "Ep 4 (Step 027040): Train loss 2.721, Val loss 5.362\n",
            "[Batch 0] Current Loss: 2.3565\n",
            "[Batch 1] Current Loss: 2.8919\n",
            "[Batch 2] Current Loss: 2.5713\n",
            "[Batch 3] Current Loss: 2.7309\n",
            "[Batch 4] Current Loss: 2.3561\n",
            "[Batch 5] Current Loss: 1.9621\n",
            "[Batch 6] Current Loss: 2.5349\n",
            "[Batch 7] Current Loss: 2.4614\n",
            "[Batch 8] Current Loss: 2.4457\n",
            "[Batch 9] Current Loss: 2.9747\n",
            "[Batch 0] Current Loss: 6.0054\n",
            "[Batch 1] Current Loss: 5.9836\n",
            "[Batch 2] Current Loss: 5.3090\n",
            "[Batch 3] Current Loss: 5.7551\n",
            "[Batch 4] Current Loss: 5.5461\n",
            "[Batch 5] Current Loss: 5.4410\n",
            "[Batch 6] Current Loss: 5.7356\n",
            "[Batch 7] Current Loss: 5.7697\n",
            "[Batch 8] Current Loss: 5.0036\n",
            "[Batch 9] Current Loss: 5.6229\n",
            "Ep 4 (Step 027060): Train loss 2.529, Val loss 5.617\n",
            "[Batch 0] Current Loss: 2.4850\n",
            "[Batch 1] Current Loss: 2.4029\n",
            "[Batch 2] Current Loss: 2.3088\n",
            "[Batch 3] Current Loss: 2.3069\n",
            "[Batch 4] Current Loss: 2.3505\n",
            "[Batch 5] Current Loss: 2.5113\n",
            "[Batch 6] Current Loss: 2.5468\n",
            "[Batch 7] Current Loss: 2.3401\n",
            "[Batch 8] Current Loss: 2.0613\n",
            "[Batch 9] Current Loss: 2.5293\n",
            "[Batch 0] Current Loss: 5.6417\n",
            "[Batch 1] Current Loss: 5.9034\n",
            "[Batch 2] Current Loss: 5.4858\n",
            "[Batch 3] Current Loss: 5.1167\n",
            "[Batch 4] Current Loss: 4.9638\n",
            "[Batch 5] Current Loss: 5.9992\n",
            "[Batch 6] Current Loss: 5.1859\n",
            "[Batch 7] Current Loss: 4.9702\n",
            "[Batch 8] Current Loss: 4.5379\n",
            "[Batch 9] Current Loss: 4.8137\n",
            "Ep 4 (Step 027080): Train loss 2.384, Val loss 5.262\n",
            "[Batch 0] Current Loss: 2.9061\n",
            "[Batch 1] Current Loss: 3.1397\n",
            "[Batch 2] Current Loss: 2.8161\n",
            "[Batch 3] Current Loss: 2.2948\n",
            "[Batch 4] Current Loss: 2.9601\n",
            "[Batch 5] Current Loss: 2.3641\n",
            "[Batch 6] Current Loss: 2.2156\n",
            "[Batch 7] Current Loss: 2.2829\n",
            "[Batch 8] Current Loss: 2.3737\n",
            "[Batch 9] Current Loss: 2.8273\n",
            "[Batch 0] Current Loss: 5.6051\n",
            "[Batch 1] Current Loss: 5.6432\n",
            "[Batch 2] Current Loss: 5.7443\n",
            "[Batch 3] Current Loss: 5.7346\n",
            "[Batch 4] Current Loss: 5.4995\n",
            "[Batch 5] Current Loss: 6.2504\n",
            "[Batch 6] Current Loss: 5.6995\n",
            "[Batch 7] Current Loss: 5.0920\n",
            "[Batch 8] Current Loss: 5.1239\n",
            "[Batch 9] Current Loss: 5.1632\n",
            "Ep 4 (Step 027100): Train loss 2.618, Val loss 5.556\n",
            "[Batch 0] Current Loss: 2.7284\n",
            "[Batch 1] Current Loss: 2.8838\n",
            "[Batch 2] Current Loss: 2.5238\n",
            "[Batch 3] Current Loss: 2.7820\n",
            "[Batch 4] Current Loss: 1.9672\n",
            "[Batch 5] Current Loss: 2.6947\n",
            "[Batch 6] Current Loss: 2.0813\n",
            "[Batch 7] Current Loss: 2.4546\n",
            "[Batch 8] Current Loss: 2.9701\n",
            "[Batch 9] Current Loss: 2.5195\n",
            "[Batch 0] Current Loss: 5.0886\n",
            "[Batch 1] Current Loss: 4.7026\n",
            "[Batch 2] Current Loss: 5.0340\n",
            "[Batch 3] Current Loss: 5.4851\n",
            "[Batch 4] Current Loss: 6.6632\n",
            "[Batch 5] Current Loss: 4.8648\n",
            "[Batch 6] Current Loss: 4.7357\n",
            "[Batch 7] Current Loss: 5.5700\n",
            "[Batch 8] Current Loss: 5.6555\n",
            "[Batch 9] Current Loss: 5.8317\n",
            "Ep 4 (Step 027120): Train loss 2.561, Val loss 5.363\n",
            "[Batch 0] Current Loss: 2.5374\n",
            "[Batch 1] Current Loss: 2.9317\n",
            "[Batch 2] Current Loss: 2.8733\n",
            "[Batch 3] Current Loss: 3.5626\n",
            "[Batch 4] Current Loss: 2.7593\n",
            "[Batch 5] Current Loss: 2.5365\n",
            "[Batch 6] Current Loss: 3.3339\n",
            "[Batch 7] Current Loss: 2.7557\n",
            "[Batch 8] Current Loss: 3.5787\n",
            "[Batch 9] Current Loss: 2.9453\n",
            "[Batch 0] Current Loss: 5.4255\n",
            "[Batch 1] Current Loss: 5.1382\n",
            "[Batch 2] Current Loss: 5.5762\n",
            "[Batch 3] Current Loss: 5.8436\n",
            "[Batch 4] Current Loss: 5.6115\n",
            "[Batch 5] Current Loss: 6.0367\n",
            "[Batch 6] Current Loss: 5.8914\n",
            "[Batch 7] Current Loss: 4.6413\n",
            "[Batch 8] Current Loss: 6.2584\n",
            "[Batch 9] Current Loss: 6.0098\n",
            "Ep 4 (Step 027140): Train loss 2.981, Val loss 5.643\n",
            "[Batch 0] Current Loss: 2.4102\n",
            "[Batch 1] Current Loss: 2.5745\n",
            "[Batch 2] Current Loss: 2.7825\n",
            "[Batch 3] Current Loss: 3.0998\n",
            "[Batch 4] Current Loss: 2.5791\n",
            "[Batch 5] Current Loss: 2.5105\n",
            "[Batch 6] Current Loss: 2.3676\n",
            "[Batch 7] Current Loss: 3.2352\n",
            "[Batch 8] Current Loss: 2.3910\n",
            "[Batch 9] Current Loss: 2.9378\n",
            "[Batch 0] Current Loss: 5.5576\n",
            "[Batch 1] Current Loss: 4.9177\n",
            "[Batch 2] Current Loss: 5.1010\n",
            "[Batch 3] Current Loss: 5.5388\n",
            "[Batch 4] Current Loss: 5.5952\n",
            "[Batch 5] Current Loss: 5.7869\n",
            "[Batch 6] Current Loss: 6.0424\n",
            "[Batch 7] Current Loss: 4.9115\n",
            "[Batch 8] Current Loss: 5.8763\n",
            "[Batch 9] Current Loss: 5.1279\n",
            "Ep 4 (Step 027160): Train loss 2.689, Val loss 5.446\n",
            "[Batch 0] Current Loss: 3.1013\n",
            "[Batch 1] Current Loss: 3.0671\n",
            "[Batch 2] Current Loss: 2.4610\n",
            "[Batch 3] Current Loss: 2.6529\n",
            "[Batch 4] Current Loss: 2.7705\n",
            "[Batch 5] Current Loss: 3.0850\n",
            "[Batch 6] Current Loss: 3.3644\n",
            "[Batch 7] Current Loss: 2.6869\n",
            "[Batch 8] Current Loss: 3.1349\n",
            "[Batch 9] Current Loss: 2.1743\n",
            "[Batch 0] Current Loss: 5.9084\n",
            "[Batch 1] Current Loss: 5.5861\n",
            "[Batch 2] Current Loss: 5.2074\n",
            "[Batch 3] Current Loss: 5.7789\n",
            "[Batch 4] Current Loss: 4.8714\n",
            "[Batch 5] Current Loss: 5.5193\n",
            "[Batch 6] Current Loss: 6.5517\n",
            "[Batch 7] Current Loss: 5.2003\n",
            "[Batch 8] Current Loss: 4.5128\n",
            "[Batch 9] Current Loss: 5.3176\n",
            "Ep 4 (Step 027180): Train loss 2.850, Val loss 5.445\n",
            "[Batch 0] Current Loss: 2.6291\n",
            "[Batch 1] Current Loss: 2.3444\n",
            "[Batch 2] Current Loss: 2.3951\n",
            "[Batch 3] Current Loss: 2.4761\n",
            "[Batch 4] Current Loss: 2.7965\n",
            "[Batch 5] Current Loss: 2.5305\n",
            "[Batch 6] Current Loss: 2.7169\n",
            "[Batch 7] Current Loss: 2.4768\n",
            "[Batch 8] Current Loss: 3.0168\n",
            "[Batch 9] Current Loss: 3.1858\n",
            "[Batch 0] Current Loss: 5.5073\n",
            "[Batch 1] Current Loss: 6.2202\n",
            "[Batch 2] Current Loss: 6.0514\n",
            "[Batch 3] Current Loss: 4.6587\n",
            "[Batch 4] Current Loss: 6.0554\n",
            "[Batch 5] Current Loss: 5.1812\n",
            "[Batch 6] Current Loss: 4.8645\n",
            "[Batch 7] Current Loss: 6.0220\n",
            "[Batch 8] Current Loss: 5.0046\n",
            "[Batch 9] Current Loss: 5.1043\n",
            "Ep 4 (Step 027200): Train loss 2.657, Val loss 5.467\n",
            "[Batch 0] Current Loss: 3.3415\n",
            "[Batch 1] Current Loss: 3.0306\n",
            "[Batch 2] Current Loss: 3.0134\n",
            "[Batch 3] Current Loss: 2.7267\n",
            "[Batch 4] Current Loss: 2.4281\n",
            "[Batch 5] Current Loss: 2.0587\n",
            "[Batch 6] Current Loss: 2.1824\n",
            "[Batch 7] Current Loss: 2.1492\n",
            "[Batch 8] Current Loss: 3.0250\n",
            "[Batch 9] Current Loss: 2.7794\n",
            "[Batch 0] Current Loss: 5.7858\n",
            "[Batch 1] Current Loss: 6.0360\n",
            "[Batch 2] Current Loss: 4.9977\n",
            "[Batch 3] Current Loss: 5.6172\n",
            "[Batch 4] Current Loss: 5.6239\n",
            "[Batch 5] Current Loss: 5.4481\n",
            "[Batch 6] Current Loss: 5.1875\n",
            "[Batch 7] Current Loss: 5.6305\n",
            "[Batch 8] Current Loss: 5.9807\n",
            "[Batch 9] Current Loss: 5.1875\n",
            "Ep 4 (Step 027220): Train loss 2.674, Val loss 5.549\n",
            "[Batch 0] Current Loss: 2.5301\n",
            "[Batch 1] Current Loss: 2.3188\n",
            "[Batch 2] Current Loss: 3.4973\n",
            "[Batch 3] Current Loss: 2.7652\n",
            "[Batch 4] Current Loss: 2.5272\n",
            "[Batch 5] Current Loss: 2.6914\n",
            "[Batch 6] Current Loss: 3.0729\n",
            "[Batch 7] Current Loss: 2.9084\n",
            "[Batch 8] Current Loss: 2.6457\n",
            "[Batch 9] Current Loss: 2.6257\n",
            "[Batch 0] Current Loss: 4.9694\n",
            "[Batch 1] Current Loss: 5.1464\n",
            "[Batch 2] Current Loss: 5.2246\n",
            "[Batch 3] Current Loss: 5.1628\n",
            "[Batch 4] Current Loss: 5.2990\n",
            "[Batch 5] Current Loss: 5.5313\n",
            "[Batch 6] Current Loss: 5.7357\n",
            "[Batch 7] Current Loss: 5.5389\n",
            "[Batch 8] Current Loss: 5.8865\n",
            "[Batch 9] Current Loss: 6.1447\n",
            "Ep 4 (Step 027240): Train loss 2.758, Val loss 5.464\n",
            "[Batch 0] Current Loss: 2.5239\n",
            "[Batch 1] Current Loss: 2.4551\n",
            "[Batch 2] Current Loss: 2.5935\n",
            "[Batch 3] Current Loss: 2.5914\n",
            "[Batch 4] Current Loss: 2.6068\n",
            "[Batch 5] Current Loss: 2.2521\n",
            "[Batch 6] Current Loss: 2.4334\n",
            "[Batch 7] Current Loss: 2.5033\n",
            "[Batch 8] Current Loss: 3.5126\n",
            "[Batch 9] Current Loss: 2.4979\n",
            "[Batch 0] Current Loss: 5.4454\n",
            "[Batch 1] Current Loss: 5.4873\n",
            "[Batch 2] Current Loss: 6.1227\n",
            "[Batch 3] Current Loss: 6.1375\n",
            "[Batch 4] Current Loss: 5.2185\n",
            "[Batch 5] Current Loss: 5.9990\n",
            "[Batch 6] Current Loss: 5.3857\n",
            "[Batch 7] Current Loss: 6.5221\n",
            "[Batch 8] Current Loss: 5.3739\n",
            "[Batch 9] Current Loss: 5.8248\n",
            "Ep 4 (Step 027260): Train loss 2.597, Val loss 5.752\n",
            "[Batch 0] Current Loss: 2.5396\n",
            "[Batch 1] Current Loss: 2.6784\n",
            "[Batch 2] Current Loss: 2.8964\n",
            "[Batch 3] Current Loss: 2.3782\n",
            "[Batch 4] Current Loss: 2.4571\n",
            "[Batch 5] Current Loss: 2.7187\n",
            "[Batch 6] Current Loss: 1.9772\n",
            "[Batch 7] Current Loss: 3.0924\n",
            "[Batch 8] Current Loss: 3.0694\n",
            "[Batch 9] Current Loss: 2.9178\n",
            "[Batch 0] Current Loss: 6.0870\n",
            "[Batch 1] Current Loss: 5.9644\n",
            "[Batch 2] Current Loss: 5.2614\n",
            "[Batch 3] Current Loss: 5.6421\n",
            "[Batch 4] Current Loss: 4.7612\n",
            "[Batch 5] Current Loss: 5.2590\n",
            "[Batch 6] Current Loss: 5.2386\n",
            "[Batch 7] Current Loss: 5.6961\n",
            "[Batch 8] Current Loss: 5.5987\n",
            "[Batch 9] Current Loss: 5.0244\n",
            "Ep 4 (Step 027280): Train loss 2.673, Val loss 5.453\n",
            "[Batch 0] Current Loss: 2.8699\n",
            "[Batch 1] Current Loss: 2.4142\n",
            "[Batch 2] Current Loss: 3.0749\n",
            "[Batch 3] Current Loss: 2.4566\n",
            "[Batch 4] Current Loss: 2.5292\n",
            "[Batch 5] Current Loss: 2.6417\n",
            "[Batch 6] Current Loss: 1.6896\n",
            "[Batch 7] Current Loss: 2.6269\n",
            "[Batch 8] Current Loss: 2.4632\n",
            "[Batch 9] Current Loss: 2.5525\n",
            "[Batch 0] Current Loss: 5.8572\n",
            "[Batch 1] Current Loss: 4.9933\n",
            "[Batch 2] Current Loss: 5.1160\n",
            "[Batch 3] Current Loss: 5.8049\n",
            "[Batch 4] Current Loss: 5.7278\n",
            "[Batch 5] Current Loss: 5.8939\n",
            "[Batch 6] Current Loss: 6.3603\n",
            "[Batch 7] Current Loss: 5.4727\n",
            "[Batch 8] Current Loss: 5.0254\n",
            "[Batch 9] Current Loss: 4.8633\n",
            "Ep 4 (Step 027300): Train loss 2.532, Val loss 5.511\n",
            "[Batch 0] Current Loss: 2.5855\n",
            "[Batch 1] Current Loss: 3.1450\n",
            "[Batch 2] Current Loss: 2.8123\n",
            "[Batch 3] Current Loss: 2.3318\n",
            "[Batch 4] Current Loss: 2.7996\n",
            "[Batch 5] Current Loss: 2.5738\n",
            "[Batch 6] Current Loss: 2.5617\n",
            "[Batch 7] Current Loss: 2.4188\n",
            "[Batch 8] Current Loss: 3.3842\n",
            "[Batch 9] Current Loss: 2.3445\n",
            "[Batch 0] Current Loss: 5.3220\n",
            "[Batch 1] Current Loss: 4.5597\n",
            "[Batch 2] Current Loss: 5.2497\n",
            "[Batch 3] Current Loss: 5.5256\n",
            "[Batch 4] Current Loss: 5.7914\n",
            "[Batch 5] Current Loss: 5.5710\n",
            "[Batch 6] Current Loss: 5.4321\n",
            "[Batch 7] Current Loss: 5.5318\n",
            "[Batch 8] Current Loss: 5.0124\n",
            "[Batch 9] Current Loss: 4.8866\n",
            "Ep 4 (Step 027320): Train loss 2.696, Val loss 5.288\n",
            "[Batch 0] Current Loss: 2.4959\n",
            "[Batch 1] Current Loss: 2.7975\n",
            "[Batch 2] Current Loss: 2.6253\n",
            "[Batch 3] Current Loss: 2.3153\n",
            "[Batch 4] Current Loss: 2.4333\n",
            "[Batch 5] Current Loss: 2.7957\n",
            "[Batch 6] Current Loss: 3.1173\n",
            "[Batch 7] Current Loss: 2.9347\n",
            "[Batch 8] Current Loss: 2.3565\n",
            "[Batch 9] Current Loss: 2.4738\n",
            "[Batch 0] Current Loss: 6.2463\n",
            "[Batch 1] Current Loss: 6.2776\n",
            "[Batch 2] Current Loss: 5.5021\n",
            "[Batch 3] Current Loss: 5.8501\n",
            "[Batch 4] Current Loss: 5.6567\n",
            "[Batch 5] Current Loss: 5.9839\n",
            "[Batch 6] Current Loss: 5.8475\n",
            "[Batch 7] Current Loss: 5.4464\n",
            "[Batch 8] Current Loss: 4.8616\n",
            "[Batch 9] Current Loss: 5.1186\n",
            "Ep 4 (Step 027340): Train loss 2.635, Val loss 5.679\n",
            "[Batch 0] Current Loss: 2.5153\n",
            "[Batch 1] Current Loss: 2.1754\n",
            "[Batch 2] Current Loss: 2.8397\n",
            "[Batch 3] Current Loss: 2.9377\n",
            "[Batch 4] Current Loss: 2.7887\n",
            "[Batch 5] Current Loss: 2.4937\n",
            "[Batch 6] Current Loss: 2.9540\n",
            "[Batch 7] Current Loss: 2.0788\n",
            "[Batch 8] Current Loss: 3.0022\n",
            "[Batch 9] Current Loss: 2.6434\n",
            "[Batch 0] Current Loss: 5.6858\n",
            "[Batch 1] Current Loss: 5.1103\n",
            "[Batch 2] Current Loss: 5.8505\n",
            "[Batch 3] Current Loss: 5.4720\n",
            "[Batch 4] Current Loss: 5.9082\n",
            "[Batch 5] Current Loss: 5.4113\n",
            "[Batch 6] Current Loss: 5.6120\n",
            "[Batch 7] Current Loss: 5.5776\n",
            "[Batch 8] Current Loss: 5.5171\n",
            "[Batch 9] Current Loss: 4.6767\n",
            "Ep 4 (Step 027360): Train loss 2.643, Val loss 5.482\n",
            "[Batch 0] Current Loss: 2.7968\n",
            "[Batch 1] Current Loss: 3.0335\n",
            "[Batch 2] Current Loss: 2.4528\n",
            "[Batch 3] Current Loss: 2.6228\n",
            "[Batch 4] Current Loss: 2.7690\n",
            "[Batch 5] Current Loss: 2.4406\n",
            "[Batch 6] Current Loss: 2.7521\n",
            "[Batch 7] Current Loss: 2.9440\n",
            "[Batch 8] Current Loss: 2.5576\n",
            "[Batch 9] Current Loss: 2.8652\n",
            "[Batch 0] Current Loss: 5.7368\n",
            "[Batch 1] Current Loss: 5.8852\n",
            "[Batch 2] Current Loss: 6.3634\n",
            "[Batch 3] Current Loss: 5.8031\n",
            "[Batch 4] Current Loss: 5.5323\n",
            "[Batch 5] Current Loss: 5.2450\n",
            "[Batch 6] Current Loss: 5.4428\n",
            "[Batch 7] Current Loss: 5.4900\n",
            "[Batch 8] Current Loss: 5.3182\n",
            "[Batch 9] Current Loss: 5.3834\n",
            "Ep 4 (Step 027380): Train loss 2.723, Val loss 5.620\n",
            "[Batch 0] Current Loss: 3.1155\n",
            "[Batch 1] Current Loss: 2.7126\n",
            "[Batch 2] Current Loss: 3.1824\n",
            "[Batch 3] Current Loss: 2.6143\n",
            "[Batch 4] Current Loss: 2.9624\n",
            "[Batch 5] Current Loss: 2.9972\n",
            "[Batch 6] Current Loss: 2.8435\n",
            "[Batch 7] Current Loss: 3.0130\n",
            "[Batch 8] Current Loss: 2.9502\n",
            "[Batch 9] Current Loss: 2.8636\n",
            "[Batch 0] Current Loss: 6.0982\n",
            "[Batch 1] Current Loss: 5.0558\n",
            "[Batch 2] Current Loss: 6.0942\n",
            "[Batch 3] Current Loss: 5.2034\n",
            "[Batch 4] Current Loss: 6.5662\n",
            "[Batch 5] Current Loss: 5.7461\n",
            "[Batch 6] Current Loss: 6.5470\n",
            "[Batch 7] Current Loss: 5.8421\n",
            "[Batch 8] Current Loss: 5.3973\n",
            "[Batch 9] Current Loss: 5.5364\n",
            "Ep 4 (Step 027400): Train loss 2.925, Val loss 5.809\n",
            "[Batch 0] Current Loss: 3.4047\n",
            "[Batch 1] Current Loss: 2.8140\n",
            "[Batch 2] Current Loss: 2.5407\n",
            "[Batch 3] Current Loss: 2.7213\n",
            "[Batch 4] Current Loss: 2.4217\n",
            "[Batch 5] Current Loss: 2.5481\n",
            "[Batch 6] Current Loss: 2.9148\n",
            "[Batch 7] Current Loss: 3.0567\n",
            "[Batch 8] Current Loss: 2.3309\n",
            "[Batch 9] Current Loss: 2.5613\n",
            "[Batch 0] Current Loss: 5.0427\n",
            "[Batch 1] Current Loss: 4.7492\n",
            "[Batch 2] Current Loss: 5.2325\n",
            "[Batch 3] Current Loss: 5.7596\n",
            "[Batch 4] Current Loss: 5.3280\n",
            "[Batch 5] Current Loss: 4.9760\n",
            "[Batch 6] Current Loss: 6.3101\n",
            "[Batch 7] Current Loss: 5.7569\n",
            "[Batch 8] Current Loss: 5.1313\n",
            "[Batch 9] Current Loss: 5.3816\n",
            "Ep 4 (Step 027420): Train loss 2.731, Val loss 5.367\n",
            "[Batch 0] Current Loss: 3.2585\n",
            "[Batch 1] Current Loss: 1.8990\n",
            "[Batch 2] Current Loss: 2.4055\n",
            "[Batch 3] Current Loss: 2.5407\n",
            "[Batch 4] Current Loss: 3.2435\n",
            "[Batch 5] Current Loss: 3.6267\n",
            "[Batch 6] Current Loss: 3.1033\n",
            "[Batch 7] Current Loss: 2.3903\n",
            "[Batch 8] Current Loss: 3.0397\n",
            "[Batch 9] Current Loss: 2.7578\n",
            "[Batch 0] Current Loss: 5.6642\n",
            "[Batch 1] Current Loss: 4.9529\n",
            "[Batch 2] Current Loss: 5.3913\n",
            "[Batch 3] Current Loss: 5.6344\n",
            "[Batch 4] Current Loss: 5.4005\n",
            "[Batch 5] Current Loss: 4.9254\n",
            "[Batch 6] Current Loss: 5.6198\n",
            "[Batch 7] Current Loss: 5.3807\n",
            "[Batch 8] Current Loss: 5.4586\n",
            "[Batch 9] Current Loss: 5.9512\n",
            "Ep 4 (Step 027440): Train loss 2.827, Val loss 5.438\n",
            "[Batch 0] Current Loss: 2.0561\n",
            "[Batch 1] Current Loss: 2.0236\n",
            "[Batch 2] Current Loss: 2.2623\n",
            "[Batch 3] Current Loss: 2.6222\n",
            "[Batch 4] Current Loss: 2.6090\n",
            "[Batch 5] Current Loss: 2.4974\n",
            "[Batch 6] Current Loss: 2.4838\n",
            "[Batch 7] Current Loss: 2.5943\n",
            "[Batch 8] Current Loss: 2.8178\n",
            "[Batch 9] Current Loss: 2.2799\n",
            "[Batch 0] Current Loss: 5.5186\n",
            "[Batch 1] Current Loss: 6.0887\n",
            "[Batch 2] Current Loss: 5.8095\n",
            "[Batch 3] Current Loss: 5.5969\n",
            "[Batch 4] Current Loss: 5.6282\n",
            "[Batch 5] Current Loss: 4.9535\n",
            "[Batch 6] Current Loss: 4.4162\n",
            "[Batch 7] Current Loss: 5.2705\n",
            "[Batch 8] Current Loss: 5.5842\n",
            "[Batch 9] Current Loss: 5.9346\n",
            "Ep 4 (Step 027460): Train loss 2.425, Val loss 5.480\n",
            "[Batch 0] Current Loss: 2.8751\n",
            "[Batch 1] Current Loss: 2.5824\n",
            "[Batch 2] Current Loss: 2.6784\n",
            "[Batch 3] Current Loss: 2.7624\n",
            "[Batch 4] Current Loss: 2.9638\n",
            "[Batch 5] Current Loss: 3.2843\n",
            "[Batch 6] Current Loss: 2.4816\n",
            "[Batch 7] Current Loss: 1.9074\n",
            "[Batch 8] Current Loss: 2.3929\n",
            "[Batch 9] Current Loss: 2.8834\n",
            "[Batch 0] Current Loss: 6.2420\n",
            "[Batch 1] Current Loss: 4.9802\n",
            "[Batch 2] Current Loss: 5.7307\n",
            "[Batch 3] Current Loss: 4.6364\n",
            "[Batch 4] Current Loss: 5.1871\n",
            "[Batch 5] Current Loss: 6.0660\n",
            "[Batch 6] Current Loss: 4.8540\n",
            "[Batch 7] Current Loss: 5.4484\n",
            "[Batch 8] Current Loss: 5.3796\n",
            "[Batch 9] Current Loss: 5.6727\n",
            "Ep 4 (Step 027480): Train loss 2.681, Val loss 5.420\n",
            "[Batch 0] Current Loss: 2.5594\n",
            "[Batch 1] Current Loss: 3.6818\n",
            "[Batch 2] Current Loss: 2.8513\n",
            "[Batch 3] Current Loss: 3.1271\n",
            "[Batch 4] Current Loss: 2.7454\n",
            "[Batch 5] Current Loss: 1.9624\n",
            "[Batch 6] Current Loss: 2.3246\n",
            "[Batch 7] Current Loss: 3.2609\n",
            "[Batch 8] Current Loss: 2.2019\n",
            "[Batch 9] Current Loss: 2.5405\n",
            "[Batch 0] Current Loss: 4.9714\n",
            "[Batch 1] Current Loss: 6.0041\n",
            "[Batch 2] Current Loss: 4.8431\n",
            "[Batch 3] Current Loss: 5.6785\n",
            "[Batch 4] Current Loss: 5.3405\n",
            "[Batch 5] Current Loss: 5.5829\n",
            "[Batch 6] Current Loss: 6.2506\n",
            "[Batch 7] Current Loss: 6.4128\n",
            "[Batch 8] Current Loss: 5.9098\n",
            "[Batch 9] Current Loss: 5.0343\n",
            "Ep 4 (Step 027500): Train loss 2.726, Val loss 5.603\n",
            "[Batch 0] Current Loss: 1.9951\n",
            "[Batch 1] Current Loss: 2.2159\n",
            "[Batch 2] Current Loss: 3.4763\n",
            "[Batch 3] Current Loss: 2.7236\n",
            "[Batch 4] Current Loss: 2.6566\n",
            "[Batch 5] Current Loss: 3.0640\n",
            "[Batch 6] Current Loss: 2.2256\n",
            "[Batch 7] Current Loss: 2.7591\n",
            "[Batch 8] Current Loss: 3.2058\n",
            "[Batch 9] Current Loss: 3.1298\n",
            "[Batch 0] Current Loss: 5.7093\n",
            "[Batch 1] Current Loss: 5.2445\n",
            "[Batch 2] Current Loss: 5.4857\n",
            "[Batch 3] Current Loss: 5.9342\n",
            "[Batch 4] Current Loss: 5.2858\n",
            "[Batch 5] Current Loss: 4.3225\n",
            "[Batch 6] Current Loss: 5.6564\n",
            "[Batch 7] Current Loss: 5.3390\n",
            "[Batch 8] Current Loss: 5.6464\n",
            "[Batch 9] Current Loss: 5.5264\n",
            "Ep 4 (Step 027520): Train loss 2.745, Val loss 5.415\n",
            "[Batch 0] Current Loss: 2.4492\n",
            "[Batch 1] Current Loss: 2.9125\n",
            "[Batch 2] Current Loss: 3.2769\n",
            "[Batch 3] Current Loss: 2.8456\n",
            "[Batch 4] Current Loss: 2.0136\n",
            "[Batch 5] Current Loss: 2.5921\n",
            "[Batch 6] Current Loss: 3.1678\n",
            "[Batch 7] Current Loss: 2.1107\n",
            "[Batch 8] Current Loss: 2.8577\n",
            "[Batch 9] Current Loss: 2.6336\n",
            "[Batch 0] Current Loss: 6.0425\n",
            "[Batch 1] Current Loss: 5.5117\n",
            "[Batch 2] Current Loss: 5.9360\n",
            "[Batch 3] Current Loss: 5.4492\n",
            "[Batch 4] Current Loss: 5.3777\n",
            "[Batch 5] Current Loss: 6.9268\n",
            "[Batch 6] Current Loss: 4.6440\n",
            "[Batch 7] Current Loss: 5.8012\n",
            "[Batch 8] Current Loss: 5.3580\n",
            "[Batch 9] Current Loss: 5.3258\n",
            "Ep 4 (Step 027540): Train loss 2.686, Val loss 5.637\n",
            "[Batch 0] Current Loss: 3.0297\n",
            "[Batch 1] Current Loss: 2.5159\n",
            "[Batch 2] Current Loss: 3.0164\n",
            "[Batch 3] Current Loss: 3.4169\n",
            "[Batch 4] Current Loss: 2.1009\n",
            "[Batch 5] Current Loss: 2.7472\n",
            "[Batch 6] Current Loss: 2.9351\n",
            "[Batch 7] Current Loss: 3.3728\n",
            "[Batch 8] Current Loss: 2.3348\n",
            "[Batch 9] Current Loss: 2.4376\n",
            "[Batch 0] Current Loss: 5.8194\n",
            "[Batch 1] Current Loss: 5.5011\n",
            "[Batch 2] Current Loss: 5.4388\n",
            "[Batch 3] Current Loss: 5.6190\n",
            "[Batch 4] Current Loss: 5.3557\n",
            "[Batch 5] Current Loss: 5.1753\n",
            "[Batch 6] Current Loss: 4.3445\n",
            "[Batch 7] Current Loss: 5.7125\n",
            "[Batch 8] Current Loss: 5.2201\n",
            "[Batch 9] Current Loss: 5.3988\n",
            "Ep 4 (Step 027560): Train loss 2.791, Val loss 5.359\n",
            "[Batch 0] Current Loss: 3.0915\n",
            "[Batch 1] Current Loss: 2.5248\n",
            "[Batch 2] Current Loss: 2.6144\n",
            "[Batch 3] Current Loss: 2.5203\n",
            "[Batch 4] Current Loss: 2.9109\n",
            "[Batch 5] Current Loss: 2.1683\n",
            "[Batch 6] Current Loss: 2.2896\n",
            "[Batch 7] Current Loss: 2.5424\n",
            "[Batch 8] Current Loss: 2.7806\n",
            "[Batch 9] Current Loss: 2.4397\n",
            "[Batch 0] Current Loss: 6.0114\n",
            "[Batch 1] Current Loss: 4.9901\n",
            "[Batch 2] Current Loss: 5.5602\n",
            "[Batch 3] Current Loss: 5.9523\n",
            "[Batch 4] Current Loss: 6.1895\n",
            "[Batch 5] Current Loss: 6.0299\n",
            "[Batch 6] Current Loss: 5.9815\n",
            "[Batch 7] Current Loss: 4.8690\n",
            "[Batch 8] Current Loss: 5.4752\n",
            "[Batch 9] Current Loss: 4.5288\n",
            "Ep 4 (Step 027580): Train loss 2.588, Val loss 5.559\n",
            "[Batch 0] Current Loss: 2.4595\n",
            "[Batch 1] Current Loss: 2.7386\n",
            "[Batch 2] Current Loss: 2.7050\n",
            "[Batch 3] Current Loss: 2.9705\n",
            "[Batch 4] Current Loss: 2.7634\n",
            "[Batch 5] Current Loss: 2.9913\n",
            "[Batch 6] Current Loss: 3.7492\n",
            "[Batch 7] Current Loss: 2.8626\n",
            "[Batch 8] Current Loss: 2.1286\n",
            "[Batch 9] Current Loss: 2.7481\n",
            "[Batch 0] Current Loss: 4.7351\n",
            "[Batch 1] Current Loss: 5.7638\n",
            "[Batch 2] Current Loss: 4.7641\n",
            "[Batch 3] Current Loss: 5.9104\n",
            "[Batch 4] Current Loss: 5.6687\n",
            "[Batch 5] Current Loss: 5.0632\n",
            "[Batch 6] Current Loss: 5.6224\n",
            "[Batch 7] Current Loss: 4.7933\n",
            "[Batch 8] Current Loss: 6.0550\n",
            "[Batch 9] Current Loss: 6.1494\n",
            "Ep 4 (Step 027600): Train loss 2.812, Val loss 5.453\n",
            "[Batch 0] Current Loss: 2.2012\n",
            "[Batch 1] Current Loss: 3.0604\n",
            "[Batch 2] Current Loss: 2.9594\n",
            "[Batch 3] Current Loss: 3.8323\n",
            "[Batch 4] Current Loss: 2.4952\n",
            "[Batch 5] Current Loss: 2.4284\n",
            "[Batch 6] Current Loss: 2.2227\n",
            "[Batch 7] Current Loss: 2.8139\n",
            "[Batch 8] Current Loss: 2.6307\n",
            "[Batch 9] Current Loss: 2.0311\n",
            "[Batch 0] Current Loss: 5.7086\n",
            "[Batch 1] Current Loss: 6.0199\n",
            "[Batch 2] Current Loss: 5.6224\n",
            "[Batch 3] Current Loss: 5.6676\n",
            "[Batch 4] Current Loss: 5.8408\n",
            "[Batch 5] Current Loss: 5.0180\n",
            "[Batch 6] Current Loss: 4.8399\n",
            "[Batch 7] Current Loss: 5.9605\n",
            "[Batch 8] Current Loss: 5.9782\n",
            "[Batch 9] Current Loss: 4.9498\n",
            "Ep 4 (Step 027620): Train loss 2.668, Val loss 5.561\n",
            "[Batch 0] Current Loss: 3.1200\n",
            "[Batch 1] Current Loss: 3.1158\n",
            "[Batch 2] Current Loss: 2.6365\n",
            "[Batch 3] Current Loss: 2.1683\n",
            "[Batch 4] Current Loss: 2.7031\n",
            "[Batch 5] Current Loss: 2.2798\n",
            "[Batch 6] Current Loss: 2.3584\n",
            "[Batch 7] Current Loss: 2.1818\n",
            "[Batch 8] Current Loss: 2.1664\n",
            "[Batch 9] Current Loss: 3.1098\n",
            "[Batch 0] Current Loss: 5.2327\n",
            "[Batch 1] Current Loss: 5.8914\n",
            "[Batch 2] Current Loss: 5.0587\n",
            "[Batch 3] Current Loss: 6.1678\n",
            "[Batch 4] Current Loss: 5.6173\n",
            "[Batch 5] Current Loss: 5.7688\n",
            "[Batch 6] Current Loss: 6.2218\n",
            "[Batch 7] Current Loss: 5.8169\n",
            "[Batch 8] Current Loss: 4.8436\n",
            "[Batch 9] Current Loss: 5.7085\n",
            "Ep 4 (Step 027640): Train loss 2.584, Val loss 5.633\n",
            "[Batch 0] Current Loss: 2.7584\n",
            "[Batch 1] Current Loss: 2.4628\n",
            "[Batch 2] Current Loss: 2.4712\n",
            "[Batch 3] Current Loss: 2.4852\n",
            "[Batch 4] Current Loss: 2.4062\n",
            "[Batch 5] Current Loss: 2.7806\n",
            "[Batch 6] Current Loss: 3.1059\n",
            "[Batch 7] Current Loss: 2.8254\n",
            "[Batch 8] Current Loss: 2.3163\n",
            "[Batch 9] Current Loss: 2.3170\n",
            "[Batch 0] Current Loss: 5.7893\n",
            "[Batch 1] Current Loss: 5.7332\n",
            "[Batch 2] Current Loss: 4.7262\n",
            "[Batch 3] Current Loss: 5.4388\n",
            "[Batch 4] Current Loss: 5.8169\n",
            "[Batch 5] Current Loss: 5.0671\n",
            "[Batch 6] Current Loss: 5.8578\n",
            "[Batch 7] Current Loss: 5.9078\n",
            "[Batch 8] Current Loss: 5.4558\n",
            "[Batch 9] Current Loss: 5.5401\n",
            "Ep 4 (Step 027660): Train loss 2.593, Val loss 5.533\n",
            "[Batch 0] Current Loss: 2.8754\n",
            "[Batch 1] Current Loss: 2.8318\n",
            "[Batch 2] Current Loss: 2.4043\n",
            "[Batch 3] Current Loss: 2.9409\n",
            "[Batch 4] Current Loss: 2.5062\n",
            "[Batch 5] Current Loss: 2.4670\n",
            "[Batch 6] Current Loss: 2.8202\n",
            "[Batch 7] Current Loss: 2.4658\n",
            "[Batch 8] Current Loss: 2.5724\n",
            "[Batch 9] Current Loss: 1.9604\n",
            "[Batch 0] Current Loss: 5.4160\n",
            "[Batch 1] Current Loss: 6.4268\n",
            "[Batch 2] Current Loss: 5.7084\n",
            "[Batch 3] Current Loss: 5.4816\n",
            "[Batch 4] Current Loss: 5.7661\n",
            "[Batch 5] Current Loss: 6.7676\n",
            "[Batch 6] Current Loss: 4.4777\n",
            "[Batch 7] Current Loss: 4.0416\n",
            "[Batch 8] Current Loss: 4.9705\n",
            "[Batch 9] Current Loss: 6.7274\n",
            "Ep 4 (Step 027680): Train loss 2.584, Val loss 5.578\n",
            "[Batch 0] Current Loss: 3.3306\n",
            "[Batch 1] Current Loss: 2.3856\n",
            "[Batch 2] Current Loss: 2.9121\n",
            "[Batch 3] Current Loss: 3.0827\n",
            "[Batch 4] Current Loss: 2.0547\n",
            "[Batch 5] Current Loss: 2.5846\n",
            "[Batch 6] Current Loss: 1.8609\n",
            "[Batch 7] Current Loss: 1.9536\n",
            "[Batch 8] Current Loss: 2.8223\n",
            "[Batch 9] Current Loss: 2.5559\n",
            "[Batch 0] Current Loss: 5.6934\n",
            "[Batch 1] Current Loss: 4.4950\n",
            "[Batch 2] Current Loss: 5.8484\n",
            "[Batch 3] Current Loss: 5.3477\n",
            "[Batch 4] Current Loss: 5.8116\n",
            "[Batch 5] Current Loss: 5.1164\n",
            "[Batch 6] Current Loss: 5.8487\n",
            "[Batch 7] Current Loss: 5.0306\n",
            "[Batch 8] Current Loss: 5.7431\n",
            "[Batch 9] Current Loss: 5.7198\n",
            "Ep 4 (Step 027700): Train loss 2.554, Val loss 5.465\n",
            "[Batch 0] Current Loss: 2.2251\n",
            "[Batch 1] Current Loss: 3.1225\n",
            "[Batch 2] Current Loss: 3.4061\n",
            "[Batch 3] Current Loss: 3.4270\n",
            "[Batch 4] Current Loss: 3.3561\n",
            "[Batch 5] Current Loss: 2.7515\n",
            "[Batch 6] Current Loss: 2.8787\n",
            "[Batch 7] Current Loss: 2.3269\n",
            "[Batch 8] Current Loss: 3.0757\n",
            "[Batch 9] Current Loss: 2.9144\n",
            "[Batch 0] Current Loss: 6.6283\n",
            "[Batch 1] Current Loss: 4.5151\n",
            "[Batch 2] Current Loss: 4.6162\n",
            "[Batch 3] Current Loss: 5.6238\n",
            "[Batch 4] Current Loss: 6.2139\n",
            "[Batch 5] Current Loss: 5.1395\n",
            "[Batch 6] Current Loss: 5.7199\n",
            "[Batch 7] Current Loss: 5.6873\n",
            "[Batch 8] Current Loss: 5.3753\n",
            "[Batch 9] Current Loss: 5.0931\n",
            "Ep 4 (Step 027720): Train loss 2.948, Val loss 5.461\n",
            "[Batch 0] Current Loss: 2.9410\n",
            "[Batch 1] Current Loss: 2.6794\n",
            "[Batch 2] Current Loss: 2.6788\n",
            "[Batch 3] Current Loss: 2.1565\n",
            "[Batch 4] Current Loss: 2.5141\n",
            "[Batch 5] Current Loss: 3.5667\n",
            "[Batch 6] Current Loss: 3.0027\n",
            "[Batch 7] Current Loss: 2.0291\n",
            "[Batch 8] Current Loss: 3.0793\n",
            "[Batch 9] Current Loss: 2.5946\n",
            "[Batch 0] Current Loss: 5.3038\n",
            "[Batch 1] Current Loss: 5.8735\n",
            "[Batch 2] Current Loss: 5.7119\n",
            "[Batch 3] Current Loss: 5.1770\n",
            "[Batch 4] Current Loss: 4.3729\n",
            "[Batch 5] Current Loss: 5.1852\n",
            "[Batch 6] Current Loss: 6.0249\n",
            "[Batch 7] Current Loss: 5.1225\n",
            "[Batch 8] Current Loss: 5.9710\n",
            "[Batch 9] Current Loss: 5.4340\n",
            "Ep 4 (Step 027740): Train loss 2.724, Val loss 5.418\n",
            "[Batch 0] Current Loss: 2.7402\n",
            "[Batch 1] Current Loss: 3.0923\n",
            "[Batch 2] Current Loss: 3.2993\n",
            "[Batch 3] Current Loss: 2.8917\n",
            "[Batch 4] Current Loss: 2.8043\n",
            "[Batch 5] Current Loss: 3.0568\n",
            "[Batch 6] Current Loss: 2.5425\n",
            "[Batch 7] Current Loss: 1.8456\n",
            "[Batch 8] Current Loss: 2.3380\n",
            "[Batch 9] Current Loss: 2.3271\n",
            "[Batch 0] Current Loss: 5.2123\n",
            "[Batch 1] Current Loss: 5.7203\n",
            "[Batch 2] Current Loss: 6.2603\n",
            "[Batch 3] Current Loss: 6.0946\n",
            "[Batch 4] Current Loss: 6.0025\n",
            "[Batch 5] Current Loss: 5.6872\n",
            "[Batch 6] Current Loss: 5.8144\n",
            "[Batch 7] Current Loss: 5.9189\n",
            "[Batch 8] Current Loss: 5.9220\n",
            "[Batch 9] Current Loss: 5.7844\n",
            "Ep 4 (Step 027760): Train loss 2.694, Val loss 5.842\n",
            "[Batch 0] Current Loss: 3.1403\n",
            "[Batch 1] Current Loss: 3.0319\n",
            "[Batch 2] Current Loss: 2.4709\n",
            "[Batch 3] Current Loss: 2.8405\n",
            "[Batch 4] Current Loss: 3.0113\n",
            "[Batch 5] Current Loss: 2.9734\n",
            "[Batch 6] Current Loss: 2.2917\n",
            "[Batch 7] Current Loss: 2.8655\n",
            "[Batch 8] Current Loss: 2.4614\n",
            "[Batch 9] Current Loss: 2.4380\n",
            "[Batch 0] Current Loss: 5.7645\n",
            "[Batch 1] Current Loss: 4.9908\n",
            "[Batch 2] Current Loss: 5.8202\n",
            "[Batch 3] Current Loss: 4.8136\n",
            "[Batch 4] Current Loss: 5.7729\n",
            "[Batch 5] Current Loss: 5.5169\n",
            "[Batch 6] Current Loss: 5.4829\n",
            "[Batch 7] Current Loss: 5.6573\n",
            "[Batch 8] Current Loss: 5.9740\n",
            "[Batch 9] Current Loss: 5.5979\n",
            "Ep 4 (Step 027780): Train loss 2.752, Val loss 5.539\n",
            "[Batch 0] Current Loss: 2.3430\n",
            "[Batch 1] Current Loss: 3.2127\n",
            "[Batch 2] Current Loss: 2.5292\n",
            "[Batch 3] Current Loss: 2.5066\n",
            "[Batch 4] Current Loss: 2.0686\n",
            "[Batch 5] Current Loss: 2.9018\n",
            "[Batch 6] Current Loss: 2.8933\n",
            "[Batch 7] Current Loss: 3.6098\n",
            "[Batch 8] Current Loss: 2.3201\n",
            "[Batch 9] Current Loss: 2.8738\n",
            "[Batch 0] Current Loss: 5.7528\n",
            "[Batch 1] Current Loss: 5.8157\n",
            "[Batch 2] Current Loss: 6.1623\n",
            "[Batch 3] Current Loss: 5.8794\n",
            "[Batch 4] Current Loss: 4.6640\n",
            "[Batch 5] Current Loss: 5.9742\n",
            "[Batch 6] Current Loss: 5.2510\n",
            "[Batch 7] Current Loss: 5.6844\n",
            "[Batch 8] Current Loss: 5.8206\n",
            "[Batch 9] Current Loss: 5.5951\n",
            "Ep 4 (Step 027800): Train loss 2.726, Val loss 5.660\n",
            "[Batch 0] Current Loss: 2.8539\n",
            "[Batch 1] Current Loss: 2.0403\n",
            "[Batch 2] Current Loss: 2.4114\n",
            "[Batch 3] Current Loss: 2.8405\n",
            "[Batch 4] Current Loss: 2.3383\n",
            "[Batch 5] Current Loss: 2.1998\n",
            "[Batch 6] Current Loss: 2.5317\n",
            "[Batch 7] Current Loss: 2.9037\n",
            "[Batch 8] Current Loss: 3.1167\n",
            "[Batch 9] Current Loss: 3.0951\n",
            "[Batch 0] Current Loss: 5.3074\n",
            "[Batch 1] Current Loss: 5.1377\n",
            "[Batch 2] Current Loss: 6.4339\n",
            "[Batch 3] Current Loss: 5.1888\n",
            "[Batch 4] Current Loss: 5.0573\n",
            "[Batch 5] Current Loss: 6.2404\n",
            "[Batch 6] Current Loss: 5.1547\n",
            "[Batch 7] Current Loss: 5.3261\n",
            "[Batch 8] Current Loss: 5.6758\n",
            "[Batch 9] Current Loss: 5.6362\n",
            "Ep 4 (Step 027820): Train loss 2.633, Val loss 5.516\n",
            "[Batch 0] Current Loss: 2.8571\n",
            "[Batch 1] Current Loss: 2.6813\n",
            "[Batch 2] Current Loss: 2.2208\n",
            "[Batch 3] Current Loss: 2.7002\n",
            "[Batch 4] Current Loss: 2.3131\n",
            "[Batch 5] Current Loss: 2.5316\n",
            "[Batch 6] Current Loss: 2.2763\n",
            "[Batch 7] Current Loss: 2.3849\n",
            "[Batch 8] Current Loss: 2.2410\n",
            "[Batch 9] Current Loss: 2.8844\n",
            "[Batch 0] Current Loss: 5.1124\n",
            "[Batch 1] Current Loss: 5.3565\n",
            "[Batch 2] Current Loss: 5.6336\n",
            "[Batch 3] Current Loss: 5.4685\n",
            "[Batch 4] Current Loss: 5.4925\n",
            "[Batch 5] Current Loss: 5.8919\n",
            "[Batch 6] Current Loss: 5.3613\n",
            "[Batch 7] Current Loss: 5.6041\n",
            "[Batch 8] Current Loss: 5.6822\n",
            "[Batch 9] Current Loss: 5.3790\n",
            "Ep 4 (Step 027840): Train loss 2.509, Val loss 5.498\n",
            "[Batch 0] Current Loss: 2.7992\n",
            "[Batch 1] Current Loss: 2.8404\n",
            "[Batch 2] Current Loss: 2.8141\n",
            "[Batch 3] Current Loss: 2.4888\n",
            "[Batch 4] Current Loss: 3.4560\n",
            "[Batch 5] Current Loss: 2.5273\n",
            "[Batch 6] Current Loss: 2.5093\n",
            "[Batch 7] Current Loss: 2.8573\n",
            "[Batch 8] Current Loss: 2.6350\n",
            "[Batch 9] Current Loss: 2.6330\n",
            "[Batch 0] Current Loss: 5.7758\n",
            "[Batch 1] Current Loss: 5.5502\n",
            "[Batch 2] Current Loss: 5.9713\n",
            "[Batch 3] Current Loss: 6.1160\n",
            "[Batch 4] Current Loss: 5.6780\n",
            "[Batch 5] Current Loss: 5.2885\n",
            "[Batch 6] Current Loss: 6.4384\n",
            "[Batch 7] Current Loss: 5.6078\n",
            "[Batch 8] Current Loss: 5.4652\n",
            "[Batch 9] Current Loss: 5.5213\n",
            "Ep 4 (Step 027860): Train loss 2.756, Val loss 5.741\n",
            "[Batch 0] Current Loss: 3.3369\n",
            "[Batch 1] Current Loss: 2.8005\n",
            "[Batch 2] Current Loss: 2.7613\n",
            "[Batch 3] Current Loss: 2.5485\n",
            "[Batch 4] Current Loss: 2.3558\n",
            "[Batch 5] Current Loss: 2.9841\n",
            "[Batch 6] Current Loss: 2.4618\n",
            "[Batch 7] Current Loss: 2.1981\n",
            "[Batch 8] Current Loss: 2.4369\n",
            "[Batch 9] Current Loss: 2.4503\n",
            "[Batch 0] Current Loss: 5.4879\n",
            "[Batch 1] Current Loss: 4.8375\n",
            "[Batch 2] Current Loss: 5.8283\n",
            "[Batch 3] Current Loss: 5.1328\n",
            "[Batch 4] Current Loss: 4.6258\n",
            "[Batch 5] Current Loss: 5.0482\n",
            "[Batch 6] Current Loss: 5.1158\n",
            "[Batch 7] Current Loss: 6.0845\n",
            "[Batch 8] Current Loss: 5.8194\n",
            "[Batch 9] Current Loss: 5.9603\n",
            "Ep 4 (Step 027880): Train loss 2.633, Val loss 5.394\n",
            "[Batch 0] Current Loss: 2.5921\n",
            "[Batch 1] Current Loss: 2.4865\n",
            "[Batch 2] Current Loss: 3.0954\n",
            "[Batch 3] Current Loss: 1.9389\n",
            "[Batch 4] Current Loss: 2.2675\n",
            "[Batch 5] Current Loss: 2.6312\n",
            "[Batch 6] Current Loss: 2.2374\n",
            "[Batch 7] Current Loss: 2.7821\n",
            "[Batch 8] Current Loss: 2.7254\n",
            "[Batch 9] Current Loss: 2.8469\n",
            "[Batch 0] Current Loss: 4.9926\n",
            "[Batch 1] Current Loss: 5.4063\n",
            "[Batch 2] Current Loss: 6.1722\n",
            "[Batch 3] Current Loss: 5.5461\n",
            "[Batch 4] Current Loss: 5.9931\n",
            "[Batch 5] Current Loss: 5.3712\n",
            "[Batch 6] Current Loss: 5.7130\n",
            "[Batch 7] Current Loss: 5.1191\n",
            "[Batch 8] Current Loss: 5.4534\n",
            "[Batch 9] Current Loss: 6.2651\n",
            "Ep 4 (Step 027900): Train loss 2.560, Val loss 5.603\n",
            "[Batch 0] Current Loss: 3.0978\n",
            "[Batch 1] Current Loss: 2.7777\n",
            "[Batch 2] Current Loss: 2.4307\n",
            "[Batch 3] Current Loss: 2.8667\n",
            "[Batch 4] Current Loss: 2.5506\n",
            "[Batch 5] Current Loss: 3.0415\n",
            "[Batch 6] Current Loss: 2.9411\n",
            "[Batch 7] Current Loss: 3.0913\n",
            "[Batch 8] Current Loss: 2.5872\n",
            "[Batch 9] Current Loss: 2.5175\n",
            "[Batch 0] Current Loss: 4.8710\n",
            "[Batch 1] Current Loss: 5.7844\n",
            "[Batch 2] Current Loss: 5.6231\n",
            "[Batch 3] Current Loss: 5.4348\n",
            "[Batch 4] Current Loss: 5.4145\n",
            "[Batch 5] Current Loss: 5.6868\n",
            "[Batch 6] Current Loss: 5.8505\n",
            "[Batch 7] Current Loss: 4.9433\n",
            "[Batch 8] Current Loss: 5.7086\n",
            "[Batch 9] Current Loss: 4.1601\n",
            "Ep 4 (Step 027920): Train loss 2.790, Val loss 5.348\n",
            "[Batch 0] Current Loss: 2.7563\n",
            "[Batch 1] Current Loss: 2.7219\n",
            "[Batch 2] Current Loss: 2.9194\n",
            "[Batch 3] Current Loss: 2.4237\n",
            "[Batch 4] Current Loss: 2.3479\n",
            "[Batch 5] Current Loss: 2.2896\n",
            "[Batch 6] Current Loss: 3.0610\n",
            "[Batch 7] Current Loss: 2.9939\n",
            "[Batch 8] Current Loss: 2.7070\n",
            "[Batch 9] Current Loss: 2.8038\n",
            "[Batch 0] Current Loss: 4.9802\n",
            "[Batch 1] Current Loss: 5.6975\n",
            "[Batch 2] Current Loss: 5.1983\n",
            "[Batch 3] Current Loss: 5.7997\n",
            "[Batch 4] Current Loss: 4.5217\n",
            "[Batch 5] Current Loss: 4.6021\n",
            "[Batch 6] Current Loss: 4.9710\n",
            "[Batch 7] Current Loss: 5.5787\n",
            "[Batch 8] Current Loss: 5.8460\n",
            "[Batch 9] Current Loss: 4.7140\n",
            "Ep 4 (Step 027940): Train loss 2.702, Val loss 5.191\n",
            "[Batch 0] Current Loss: 2.8014\n",
            "[Batch 1] Current Loss: 3.0912\n",
            "[Batch 2] Current Loss: 2.6474\n",
            "[Batch 3] Current Loss: 2.4393\n",
            "[Batch 4] Current Loss: 2.7188\n",
            "[Batch 5] Current Loss: 3.0486\n",
            "[Batch 6] Current Loss: 2.1499\n",
            "[Batch 7] Current Loss: 2.4869\n",
            "[Batch 8] Current Loss: 2.8767\n",
            "[Batch 9] Current Loss: 2.6441\n",
            "[Batch 0] Current Loss: 6.0193\n",
            "[Batch 1] Current Loss: 6.3260\n",
            "[Batch 2] Current Loss: 5.3262\n",
            "[Batch 3] Current Loss: 5.7860\n",
            "[Batch 4] Current Loss: 5.4764\n",
            "[Batch 5] Current Loss: 5.5656\n",
            "[Batch 6] Current Loss: 5.6994\n",
            "[Batch 7] Current Loss: 5.0477\n",
            "[Batch 8] Current Loss: 5.7020\n",
            "[Batch 9] Current Loss: 5.7199\n",
            "Ep 4 (Step 027960): Train loss 2.690, Val loss 5.667\n",
            "[Batch 0] Current Loss: 3.2238\n",
            "[Batch 1] Current Loss: 2.1232\n",
            "[Batch 2] Current Loss: 2.2206\n",
            "[Batch 3] Current Loss: 2.4314\n",
            "[Batch 4] Current Loss: 2.4929\n",
            "[Batch 5] Current Loss: 3.0924\n",
            "[Batch 6] Current Loss: 2.9703\n",
            "[Batch 7] Current Loss: 2.3713\n",
            "[Batch 8] Current Loss: 2.8834\n",
            "[Batch 9] Current Loss: 2.6774\n",
            "[Batch 0] Current Loss: 5.1259\n",
            "[Batch 1] Current Loss: 5.3383\n",
            "[Batch 2] Current Loss: 5.4428\n",
            "[Batch 3] Current Loss: 5.3080\n",
            "[Batch 4] Current Loss: 5.9115\n",
            "[Batch 5] Current Loss: 6.2396\n",
            "[Batch 6] Current Loss: 5.1772\n",
            "[Batch 7] Current Loss: 5.6163\n",
            "[Batch 8] Current Loss: 5.6716\n",
            "[Batch 9] Current Loss: 5.6390\n",
            "Ep 4 (Step 027980): Train loss 2.649, Val loss 5.547\n",
            "[Batch 0] Current Loss: 2.3256\n",
            "[Batch 1] Current Loss: 2.2730\n",
            "[Batch 2] Current Loss: 2.0542\n",
            "[Batch 3] Current Loss: 2.6696\n",
            "[Batch 4] Current Loss: 2.8252\n",
            "[Batch 5] Current Loss: 2.1240\n",
            "[Batch 6] Current Loss: 2.1173\n",
            "[Batch 7] Current Loss: 2.8881\n",
            "[Batch 8] Current Loss: 2.2712\n",
            "[Batch 9] Current Loss: 3.0504\n",
            "[Batch 0] Current Loss: 5.9695\n",
            "[Batch 1] Current Loss: 5.6109\n",
            "[Batch 2] Current Loss: 5.5163\n",
            "[Batch 3] Current Loss: 5.5324\n",
            "[Batch 4] Current Loss: 5.3403\n",
            "[Batch 5] Current Loss: 6.0186\n",
            "[Batch 6] Current Loss: 5.6347\n",
            "[Batch 7] Current Loss: 6.2194\n",
            "[Batch 8] Current Loss: 6.1726\n",
            "[Batch 9] Current Loss: 5.2806\n",
            "Ep 4 (Step 028000): Train loss 2.460, Val loss 5.730\n",
            "[Batch 0] Current Loss: 2.4269\n",
            "[Batch 1] Current Loss: 2.4940\n",
            "[Batch 2] Current Loss: 2.0301\n",
            "[Batch 3] Current Loss: 2.7258\n",
            "[Batch 4] Current Loss: 2.8647\n",
            "[Batch 5] Current Loss: 2.8222\n",
            "[Batch 6] Current Loss: 2.6695\n",
            "[Batch 7] Current Loss: 2.9838\n",
            "[Batch 8] Current Loss: 2.8924\n",
            "[Batch 9] Current Loss: 2.3994\n",
            "[Batch 0] Current Loss: 5.4458\n",
            "[Batch 1] Current Loss: 5.3760\n",
            "[Batch 2] Current Loss: 6.3224\n",
            "[Batch 3] Current Loss: 5.0906\n",
            "[Batch 4] Current Loss: 5.3684\n",
            "[Batch 5] Current Loss: 5.5315\n",
            "[Batch 6] Current Loss: 5.3161\n",
            "[Batch 7] Current Loss: 5.3876\n",
            "[Batch 8] Current Loss: 5.5753\n",
            "[Batch 9] Current Loss: 5.3101\n",
            "Ep 4 (Step 028020): Train loss 2.631, Val loss 5.472\n",
            "[Batch 0] Current Loss: 2.0772\n",
            "[Batch 1] Current Loss: 2.7762\n",
            "[Batch 2] Current Loss: 2.5377\n",
            "[Batch 3] Current Loss: 3.1326\n",
            "[Batch 4] Current Loss: 2.1817\n",
            "[Batch 5] Current Loss: 2.9134\n",
            "[Batch 6] Current Loss: 2.7604\n",
            "[Batch 7] Current Loss: 2.0535\n",
            "[Batch 8] Current Loss: 2.2699\n",
            "[Batch 9] Current Loss: 2.0848\n",
            "[Batch 0] Current Loss: 5.8176\n",
            "[Batch 1] Current Loss: 5.5872\n",
            "[Batch 2] Current Loss: 5.0757\n",
            "[Batch 3] Current Loss: 5.8196\n",
            "[Batch 4] Current Loss: 5.4143\n",
            "[Batch 5] Current Loss: 5.6855\n",
            "[Batch 6] Current Loss: 5.5547\n",
            "[Batch 7] Current Loss: 5.2231\n",
            "[Batch 8] Current Loss: 6.0246\n",
            "[Batch 9] Current Loss: 5.4424\n",
            "Ep 4 (Step 028040): Train loss 2.479, Val loss 5.564\n",
            "[Batch 0] Current Loss: 2.5113\n",
            "[Batch 1] Current Loss: 1.8538\n",
            "[Batch 2] Current Loss: 3.1825\n",
            "[Batch 3] Current Loss: 2.9131\n",
            "[Batch 4] Current Loss: 2.8998\n",
            "[Batch 5] Current Loss: 2.6543\n",
            "[Batch 6] Current Loss: 3.0004\n",
            "[Batch 7] Current Loss: 3.1006\n",
            "[Batch 8] Current Loss: 2.1784\n",
            "[Batch 9] Current Loss: 2.8175\n",
            "[Batch 0] Current Loss: 5.1119\n",
            "[Batch 1] Current Loss: 4.7783\n",
            "[Batch 2] Current Loss: 5.3914\n",
            "[Batch 3] Current Loss: 5.4866\n",
            "[Batch 4] Current Loss: 5.4387\n",
            "[Batch 5] Current Loss: 5.9732\n",
            "[Batch 6] Current Loss: 5.7303\n",
            "[Batch 7] Current Loss: 4.7049\n",
            "[Batch 8] Current Loss: 5.5128\n",
            "[Batch 9] Current Loss: 5.1376\n",
            "Ep 4 (Step 028060): Train loss 2.711, Val loss 5.327\n",
            "[Batch 0] Current Loss: 2.8866\n",
            "[Batch 1] Current Loss: 2.4660\n",
            "[Batch 2] Current Loss: 2.1180\n",
            "[Batch 3] Current Loss: 2.2411\n",
            "[Batch 4] Current Loss: 2.7187\n",
            "[Batch 5] Current Loss: 2.4639\n",
            "[Batch 6] Current Loss: 2.3466\n",
            "[Batch 7] Current Loss: 2.5707\n",
            "[Batch 8] Current Loss: 2.6149\n",
            "[Batch 9] Current Loss: 2.6989\n",
            "[Batch 0] Current Loss: 6.2142\n",
            "[Batch 1] Current Loss: 5.7454\n",
            "[Batch 2] Current Loss: 5.6726\n",
            "[Batch 3] Current Loss: 6.3943\n",
            "[Batch 4] Current Loss: 5.7417\n",
            "[Batch 5] Current Loss: 4.8692\n",
            "[Batch 6] Current Loss: 5.4399\n",
            "[Batch 7] Current Loss: 5.4148\n",
            "[Batch 8] Current Loss: 5.6118\n",
            "[Batch 9] Current Loss: 5.3815\n",
            "Ep 4 (Step 028080): Train loss 2.513, Val loss 5.649\n",
            "[Batch 0] Current Loss: 3.3504\n",
            "[Batch 1] Current Loss: 2.7715\n",
            "[Batch 2] Current Loss: 2.4122\n",
            "[Batch 3] Current Loss: 2.6082\n",
            "[Batch 4] Current Loss: 2.8217\n",
            "[Batch 5] Current Loss: 3.6431\n",
            "[Batch 6] Current Loss: 3.1946\n",
            "[Batch 7] Current Loss: 2.9796\n",
            "[Batch 8] Current Loss: 2.5925\n",
            "[Batch 9] Current Loss: 3.1090\n",
            "[Batch 0] Current Loss: 5.4402\n",
            "[Batch 1] Current Loss: 5.1050\n",
            "[Batch 2] Current Loss: 5.7193\n",
            "[Batch 3] Current Loss: 5.9165\n",
            "[Batch 4] Current Loss: 5.7507\n",
            "[Batch 5] Current Loss: 5.2843\n",
            "[Batch 6] Current Loss: 5.8752\n",
            "[Batch 7] Current Loss: 5.6700\n",
            "[Batch 8] Current Loss: 5.5317\n",
            "[Batch 9] Current Loss: 6.0212\n",
            "Ep 4 (Step 028100): Train loss 2.948, Val loss 5.631\n",
            "[Batch 0] Current Loss: 2.9020\n",
            "[Batch 1] Current Loss: 2.2948\n",
            "[Batch 2] Current Loss: 2.9172\n",
            "[Batch 3] Current Loss: 2.4082\n",
            "[Batch 4] Current Loss: 3.2872\n",
            "[Batch 5] Current Loss: 2.9123\n",
            "[Batch 6] Current Loss: 2.9554\n",
            "[Batch 7] Current Loss: 3.1027\n",
            "[Batch 8] Current Loss: 2.8911\n",
            "[Batch 9] Current Loss: 2.5374\n",
            "[Batch 0] Current Loss: 5.6323\n",
            "[Batch 1] Current Loss: 5.7334\n",
            "[Batch 2] Current Loss: 6.0206\n",
            "[Batch 3] Current Loss: 5.1735\n",
            "[Batch 4] Current Loss: 4.8596\n",
            "[Batch 5] Current Loss: 5.8744\n",
            "[Batch 6] Current Loss: 5.1909\n",
            "[Batch 7] Current Loss: 4.9503\n",
            "[Batch 8] Current Loss: 5.7711\n",
            "[Batch 9] Current Loss: 5.5867\n",
            "Ep 4 (Step 028120): Train loss 2.821, Val loss 5.479\n",
            "[Batch 0] Current Loss: 2.6175\n",
            "[Batch 1] Current Loss: 2.8846\n",
            "[Batch 2] Current Loss: 1.9726\n",
            "[Batch 3] Current Loss: 3.0348\n",
            "[Batch 4] Current Loss: 2.5712\n",
            "[Batch 5] Current Loss: 2.7753\n",
            "[Batch 6] Current Loss: 2.2082\n",
            "[Batch 7] Current Loss: 2.8551\n",
            "[Batch 8] Current Loss: 3.2103\n",
            "[Batch 9] Current Loss: 2.6203\n",
            "[Batch 0] Current Loss: 5.5019\n",
            "[Batch 1] Current Loss: 5.6895\n",
            "[Batch 2] Current Loss: 4.6226\n",
            "[Batch 3] Current Loss: 5.1589\n",
            "[Batch 4] Current Loss: 5.1170\n",
            "[Batch 5] Current Loss: 5.0187\n",
            "[Batch 6] Current Loss: 5.6425\n",
            "[Batch 7] Current Loss: 4.8139\n",
            "[Batch 8] Current Loss: 5.1173\n",
            "[Batch 9] Current Loss: 5.8242\n",
            "Ep 4 (Step 028140): Train loss 2.675, Val loss 5.251\n",
            "[Batch 0] Current Loss: 2.5918\n",
            "[Batch 1] Current Loss: 2.7950\n",
            "[Batch 2] Current Loss: 2.6860\n",
            "[Batch 3] Current Loss: 2.6125\n",
            "[Batch 4] Current Loss: 2.4722\n",
            "[Batch 5] Current Loss: 2.8099\n",
            "[Batch 6] Current Loss: 2.8075\n",
            "[Batch 7] Current Loss: 2.4531\n",
            "[Batch 8] Current Loss: 2.5661\n",
            "[Batch 9] Current Loss: 2.7488\n",
            "[Batch 0] Current Loss: 4.6117\n",
            "[Batch 1] Current Loss: 5.9920\n",
            "[Batch 2] Current Loss: 6.4117\n",
            "[Batch 3] Current Loss: 5.0258\n",
            "[Batch 4] Current Loss: 5.3833\n",
            "[Batch 5] Current Loss: 6.0341\n",
            "[Batch 6] Current Loss: 5.6772\n",
            "[Batch 7] Current Loss: 5.1932\n",
            "[Batch 8] Current Loss: 5.9936\n",
            "[Batch 9] Current Loss: 5.6418\n",
            "Ep 4 (Step 028160): Train loss 2.654, Val loss 5.596\n",
            "[Batch 0] Current Loss: 2.7758\n",
            "[Batch 1] Current Loss: 2.1368\n",
            "[Batch 2] Current Loss: 2.1939\n",
            "[Batch 3] Current Loss: 2.8515\n",
            "[Batch 4] Current Loss: 2.7255\n",
            "[Batch 5] Current Loss: 3.5188\n",
            "[Batch 6] Current Loss: 3.1462\n",
            "[Batch 7] Current Loss: 2.3574\n",
            "[Batch 8] Current Loss: 2.0969\n",
            "[Batch 9] Current Loss: 2.4469\n",
            "[Batch 0] Current Loss: 5.4704\n",
            "[Batch 1] Current Loss: 5.1362\n",
            "[Batch 2] Current Loss: 5.6861\n",
            "[Batch 3] Current Loss: 4.9991\n",
            "[Batch 4] Current Loss: 5.8599\n",
            "[Batch 5] Current Loss: 5.4628\n",
            "[Batch 6] Current Loss: 5.0879\n",
            "[Batch 7] Current Loss: 5.4821\n",
            "[Batch 8] Current Loss: 4.9532\n",
            "[Batch 9] Current Loss: 4.5076\n",
            "Ep 4 (Step 028180): Train loss 2.625, Val loss 5.265\n",
            "[Batch 0] Current Loss: 2.2198\n",
            "[Batch 1] Current Loss: 2.7343\n",
            "[Batch 2] Current Loss: 2.4219\n",
            "[Batch 3] Current Loss: 3.4785\n",
            "[Batch 4] Current Loss: 2.5552\n",
            "[Batch 5] Current Loss: 2.4398\n",
            "[Batch 6] Current Loss: 2.3422\n",
            "[Batch 7] Current Loss: 2.3908\n",
            "[Batch 8] Current Loss: 2.8467\n",
            "[Batch 9] Current Loss: 2.3845\n",
            "[Batch 0] Current Loss: 6.2986\n",
            "[Batch 1] Current Loss: 4.8259\n",
            "[Batch 2] Current Loss: 4.6895\n",
            "[Batch 3] Current Loss: 4.5361\n",
            "[Batch 4] Current Loss: 5.0720\n",
            "[Batch 5] Current Loss: 5.7082\n",
            "[Batch 6] Current Loss: 4.6761\n",
            "[Batch 7] Current Loss: 5.3477\n",
            "[Batch 8] Current Loss: 6.2097\n",
            "[Batch 9] Current Loss: 5.7095\n",
            "Ep 4 (Step 028200): Train loss 2.581, Val loss 5.307\n",
            "[Batch 0] Current Loss: 2.2098\n",
            "[Batch 1] Current Loss: 3.2655\n",
            "[Batch 2] Current Loss: 2.9562\n",
            "[Batch 3] Current Loss: 2.7954\n",
            "[Batch 4] Current Loss: 3.1520\n",
            "[Batch 5] Current Loss: 3.1138\n",
            "[Batch 6] Current Loss: 2.8230\n",
            "[Batch 7] Current Loss: 2.7940\n",
            "[Batch 8] Current Loss: 1.7717\n",
            "[Batch 9] Current Loss: 2.3384\n",
            "[Batch 0] Current Loss: 5.1913\n",
            "[Batch 1] Current Loss: 6.2465\n",
            "[Batch 2] Current Loss: 5.5838\n",
            "[Batch 3] Current Loss: 4.2789\n",
            "[Batch 4] Current Loss: 5.9279\n",
            "[Batch 5] Current Loss: 5.3963\n",
            "[Batch 6] Current Loss: 4.6516\n",
            "[Batch 7] Current Loss: 5.9861\n",
            "[Batch 8] Current Loss: 5.1215\n",
            "[Batch 9] Current Loss: 6.2545\n",
            "Ep 4 (Step 028220): Train loss 2.722, Val loss 5.464\n",
            "[Batch 0] Current Loss: 1.9437\n",
            "[Batch 1] Current Loss: 2.9975\n",
            "[Batch 2] Current Loss: 3.3795\n",
            "[Batch 3] Current Loss: 3.2059\n",
            "[Batch 4] Current Loss: 2.1153\n",
            "[Batch 5] Current Loss: 3.0530\n",
            "[Batch 6] Current Loss: 2.4790\n",
            "[Batch 7] Current Loss: 2.0121\n",
            "[Batch 8] Current Loss: 3.0362\n",
            "[Batch 9] Current Loss: 2.9464\n",
            "[Batch 0] Current Loss: 5.3258\n",
            "[Batch 1] Current Loss: 5.4857\n",
            "[Batch 2] Current Loss: 5.3132\n",
            "[Batch 3] Current Loss: 5.0796\n",
            "[Batch 4] Current Loss: 5.2354\n",
            "[Batch 5] Current Loss: 6.3407\n",
            "[Batch 6] Current Loss: 5.5750\n",
            "[Batch 7] Current Loss: 5.6847\n",
            "[Batch 8] Current Loss: 5.7537\n",
            "[Batch 9] Current Loss: 5.4095\n",
            "Ep 4 (Step 028240): Train loss 2.717, Val loss 5.520\n",
            "[Batch 0] Current Loss: 2.4700\n",
            "[Batch 1] Current Loss: 2.9691\n",
            "[Batch 2] Current Loss: 2.1754\n",
            "[Batch 3] Current Loss: 2.4519\n",
            "[Batch 4] Current Loss: 2.9112\n",
            "[Batch 5] Current Loss: 2.4240\n",
            "[Batch 6] Current Loss: 3.2283\n",
            "[Batch 7] Current Loss: 2.5647\n",
            "[Batch 8] Current Loss: 2.4371\n",
            "[Batch 9] Current Loss: 2.3193\n",
            "[Batch 0] Current Loss: 5.3573\n",
            "[Batch 1] Current Loss: 5.7229\n",
            "[Batch 2] Current Loss: 4.5493\n",
            "[Batch 3] Current Loss: 5.1621\n",
            "[Batch 4] Current Loss: 4.4988\n",
            "[Batch 5] Current Loss: 5.2127\n",
            "[Batch 6] Current Loss: 4.9100\n",
            "[Batch 7] Current Loss: 5.5407\n",
            "[Batch 8] Current Loss: 5.7977\n",
            "[Batch 9] Current Loss: 6.6322\n",
            "Ep 4 (Step 028260): Train loss 2.595, Val loss 5.338\n",
            "[Batch 0] Current Loss: 2.0996\n",
            "[Batch 1] Current Loss: 2.6341\n",
            "[Batch 2] Current Loss: 2.8337\n",
            "[Batch 3] Current Loss: 2.6235\n",
            "[Batch 4] Current Loss: 2.4946\n",
            "[Batch 5] Current Loss: 2.7234\n",
            "[Batch 6] Current Loss: 2.6696\n",
            "[Batch 7] Current Loss: 2.5828\n",
            "[Batch 8] Current Loss: 2.8676\n",
            "[Batch 9] Current Loss: 3.3976\n",
            "[Batch 0] Current Loss: 5.9302\n",
            "[Batch 1] Current Loss: 6.1967\n",
            "[Batch 2] Current Loss: 5.8528\n",
            "[Batch 3] Current Loss: 6.0353\n",
            "[Batch 4] Current Loss: 5.1100\n",
            "[Batch 5] Current Loss: 5.8313\n",
            "[Batch 6] Current Loss: 5.4050\n",
            "[Batch 7] Current Loss: 5.3294\n",
            "[Batch 8] Current Loss: 5.6472\n",
            "[Batch 9] Current Loss: 6.1423\n",
            "Ep 4 (Step 028280): Train loss 2.693, Val loss 5.748\n",
            "[Batch 0] Current Loss: 2.7088\n",
            "[Batch 1] Current Loss: 2.1604\n",
            "[Batch 2] Current Loss: 2.0802\n",
            "[Batch 3] Current Loss: 2.5244\n",
            "[Batch 4] Current Loss: 2.1179\n",
            "[Batch 5] Current Loss: 2.8116\n",
            "[Batch 6] Current Loss: 3.0328\n",
            "[Batch 7] Current Loss: 2.5490\n",
            "[Batch 8] Current Loss: 2.9421\n",
            "[Batch 9] Current Loss: 2.6164\n",
            "[Batch 0] Current Loss: 5.6729\n",
            "[Batch 1] Current Loss: 5.5533\n",
            "[Batch 2] Current Loss: 4.6210\n",
            "[Batch 3] Current Loss: 5.1113\n",
            "[Batch 4] Current Loss: 5.4841\n",
            "[Batch 5] Current Loss: 5.7381\n",
            "[Batch 6] Current Loss: 6.0470\n",
            "[Batch 7] Current Loss: 6.1269\n",
            "[Batch 8] Current Loss: 6.0331\n",
            "[Batch 9] Current Loss: 5.4462\n",
            "Ep 4 (Step 028300): Train loss 2.554, Val loss 5.583\n",
            "[Batch 0] Current Loss: 2.7312\n",
            "[Batch 1] Current Loss: 3.4469\n",
            "[Batch 2] Current Loss: 2.0889\n",
            "[Batch 3] Current Loss: 2.2749\n",
            "[Batch 4] Current Loss: 2.1242\n",
            "[Batch 5] Current Loss: 2.3513\n",
            "[Batch 6] Current Loss: 2.7477\n",
            "[Batch 7] Current Loss: 2.9000\n",
            "[Batch 8] Current Loss: 2.8815\n",
            "[Batch 9] Current Loss: 2.1463\n",
            "[Batch 0] Current Loss: 5.6478\n",
            "[Batch 1] Current Loss: 5.0730\n",
            "[Batch 2] Current Loss: 5.8167\n",
            "[Batch 3] Current Loss: 5.4174\n",
            "[Batch 4] Current Loss: 5.5203\n",
            "[Batch 5] Current Loss: 5.5941\n",
            "[Batch 6] Current Loss: 5.7518\n",
            "[Batch 7] Current Loss: 4.8949\n",
            "[Batch 8] Current Loss: 5.3597\n",
            "[Batch 9] Current Loss: 5.4186\n",
            "Ep 4 (Step 028320): Train loss 2.569, Val loss 5.449\n",
            "[Batch 0] Current Loss: 2.8935\n",
            "[Batch 1] Current Loss: 3.3843\n",
            "[Batch 2] Current Loss: 2.6990\n",
            "[Batch 3] Current Loss: 2.3676\n",
            "[Batch 4] Current Loss: 3.0309\n",
            "[Batch 5] Current Loss: 2.6940\n",
            "[Batch 6] Current Loss: 3.3397\n",
            "[Batch 7] Current Loss: 2.1984\n",
            "[Batch 8] Current Loss: 2.7096\n",
            "[Batch 9] Current Loss: 2.3740\n",
            "[Batch 0] Current Loss: 5.1609\n",
            "[Batch 1] Current Loss: 6.1558\n",
            "[Batch 2] Current Loss: 5.0452\n",
            "[Batch 3] Current Loss: 5.0567\n",
            "[Batch 4] Current Loss: 5.1770\n",
            "[Batch 5] Current Loss: 5.4089\n",
            "[Batch 6] Current Loss: 5.5547\n",
            "[Batch 7] Current Loss: 5.1838\n",
            "[Batch 8] Current Loss: 5.6665\n",
            "[Batch 9] Current Loss: 4.8140\n",
            "Ep 4 (Step 028340): Train loss 2.769, Val loss 5.322\n",
            "[Batch 0] Current Loss: 3.0653\n",
            "[Batch 1] Current Loss: 2.4594\n",
            "[Batch 2] Current Loss: 3.0759\n",
            "[Batch 3] Current Loss: 3.3679\n",
            "[Batch 4] Current Loss: 2.4216\n",
            "[Batch 5] Current Loss: 2.4416\n",
            "[Batch 6] Current Loss: 2.4482\n",
            "[Batch 7] Current Loss: 2.1066\n",
            "[Batch 8] Current Loss: 2.2502\n",
            "[Batch 9] Current Loss: 2.4133\n",
            "[Batch 0] Current Loss: 5.8688\n",
            "[Batch 1] Current Loss: 5.5573\n",
            "[Batch 2] Current Loss: 5.6106\n",
            "[Batch 3] Current Loss: 6.4406\n",
            "[Batch 4] Current Loss: 5.9602\n",
            "[Batch 5] Current Loss: 5.3576\n",
            "[Batch 6] Current Loss: 4.5823\n",
            "[Batch 7] Current Loss: 7.0373\n",
            "[Batch 8] Current Loss: 6.2562\n",
            "[Batch 9] Current Loss: 5.4114\n",
            "Ep 4 (Step 028360): Train loss 2.605, Val loss 5.808\n",
            "[Batch 0] Current Loss: 2.3728\n",
            "[Batch 1] Current Loss: 2.1244\n",
            "[Batch 2] Current Loss: 2.2543\n",
            "[Batch 3] Current Loss: 2.2904\n",
            "[Batch 4] Current Loss: 2.2680\n",
            "[Batch 5] Current Loss: 2.9796\n",
            "[Batch 6] Current Loss: 2.1779\n",
            "[Batch 7] Current Loss: 2.4649\n",
            "[Batch 8] Current Loss: 2.5494\n",
            "[Batch 9] Current Loss: 3.0769\n",
            "[Batch 0] Current Loss: 6.2452\n",
            "[Batch 1] Current Loss: 5.8811\n",
            "[Batch 2] Current Loss: 5.2341\n",
            "[Batch 3] Current Loss: 5.2580\n",
            "[Batch 4] Current Loss: 4.9791\n",
            "[Batch 5] Current Loss: 6.1721\n",
            "[Batch 6] Current Loss: 5.0907\n",
            "[Batch 7] Current Loss: 4.7402\n",
            "[Batch 8] Current Loss: 5.6370\n",
            "[Batch 9] Current Loss: 5.6749\n",
            "Ep 4 (Step 028380): Train loss 2.456, Val loss 5.491\n",
            "[Batch 0] Current Loss: 2.5818\n",
            "[Batch 1] Current Loss: 2.8414\n",
            "[Batch 2] Current Loss: 2.3623\n",
            "[Batch 3] Current Loss: 2.5237\n",
            "[Batch 4] Current Loss: 2.6587\n",
            "[Batch 5] Current Loss: 2.7878\n",
            "[Batch 6] Current Loss: 2.2732\n",
            "[Batch 7] Current Loss: 2.8297\n",
            "[Batch 8] Current Loss: 3.2337\n",
            "[Batch 9] Current Loss: 2.4726\n",
            "[Batch 0] Current Loss: 6.8998\n",
            "[Batch 1] Current Loss: 5.0361\n",
            "[Batch 2] Current Loss: 5.7849\n",
            "[Batch 3] Current Loss: 5.6581\n",
            "[Batch 4] Current Loss: 5.3931\n",
            "[Batch 5] Current Loss: 5.3750\n",
            "[Batch 6] Current Loss: 6.0470\n",
            "[Batch 7] Current Loss: 5.3231\n",
            "[Batch 8] Current Loss: 5.1074\n",
            "[Batch 9] Current Loss: 5.9125\n",
            "Ep 4 (Step 028400): Train loss 2.656, Val loss 5.654\n",
            "[Batch 0] Current Loss: 2.3452\n",
            "[Batch 1] Current Loss: 2.8531\n",
            "[Batch 2] Current Loss: 2.9051\n",
            "[Batch 3] Current Loss: 2.6191\n",
            "[Batch 4] Current Loss: 2.5273\n",
            "[Batch 5] Current Loss: 3.3269\n",
            "[Batch 6] Current Loss: 2.1301\n",
            "[Batch 7] Current Loss: 2.9752\n",
            "[Batch 8] Current Loss: 2.3184\n",
            "[Batch 9] Current Loss: 2.2171\n",
            "[Batch 0] Current Loss: 5.4342\n",
            "[Batch 1] Current Loss: 6.0672\n",
            "[Batch 2] Current Loss: 5.6712\n",
            "[Batch 3] Current Loss: 5.2959\n",
            "[Batch 4] Current Loss: 5.8409\n",
            "[Batch 5] Current Loss: 6.4390\n",
            "[Batch 6] Current Loss: 5.7538\n",
            "[Batch 7] Current Loss: 5.7882\n",
            "[Batch 8] Current Loss: 5.4590\n",
            "[Batch 9] Current Loss: 5.1434\n",
            "Ep 4 (Step 028420): Train loss 2.622, Val loss 5.689\n",
            "[Batch 0] Current Loss: 3.0485\n",
            "[Batch 1] Current Loss: 2.4704\n",
            "[Batch 2] Current Loss: 2.5216\n",
            "[Batch 3] Current Loss: 2.9236\n",
            "[Batch 4] Current Loss: 2.5097\n",
            "[Batch 5] Current Loss: 3.0816\n",
            "[Batch 6] Current Loss: 2.8498\n",
            "[Batch 7] Current Loss: 3.0807\n",
            "[Batch 8] Current Loss: 2.6473\n",
            "[Batch 9] Current Loss: 2.1351\n",
            "[Batch 0] Current Loss: 5.3193\n",
            "[Batch 1] Current Loss: 5.4796\n",
            "[Batch 2] Current Loss: 5.5962\n",
            "[Batch 3] Current Loss: 5.7618\n",
            "[Batch 4] Current Loss: 5.1324\n",
            "[Batch 5] Current Loss: 4.8524\n",
            "[Batch 6] Current Loss: 5.7105\n",
            "[Batch 7] Current Loss: 4.9084\n",
            "[Batch 8] Current Loss: 6.0181\n",
            "[Batch 9] Current Loss: 5.6200\n",
            "Ep 4 (Step 028440): Train loss 2.727, Val loss 5.440\n",
            "[Batch 0] Current Loss: 3.1139\n",
            "[Batch 1] Current Loss: 2.2192\n",
            "[Batch 2] Current Loss: 2.4372\n",
            "[Batch 3] Current Loss: 2.4126\n",
            "[Batch 4] Current Loss: 2.6489\n",
            "[Batch 5] Current Loss: 2.1596\n",
            "[Batch 6] Current Loss: 3.4809\n",
            "[Batch 7] Current Loss: 2.8763\n",
            "[Batch 8] Current Loss: 2.4684\n",
            "[Batch 9] Current Loss: 3.5217\n",
            "[Batch 0] Current Loss: 5.5834\n",
            "[Batch 1] Current Loss: 5.6778\n",
            "[Batch 2] Current Loss: 5.6924\n",
            "[Batch 3] Current Loss: 6.1826\n",
            "[Batch 4] Current Loss: 5.4447\n",
            "[Batch 5] Current Loss: 5.6914\n",
            "[Batch 6] Current Loss: 5.2953\n",
            "[Batch 7] Current Loss: 5.7106\n",
            "[Batch 8] Current Loss: 4.3895\n",
            "[Batch 9] Current Loss: 5.1021\n",
            "Ep 4 (Step 028460): Train loss 2.734, Val loss 5.477\n",
            "[Batch 0] Current Loss: 2.6487\n",
            "[Batch 1] Current Loss: 2.0140\n",
            "[Batch 2] Current Loss: 2.5490\n",
            "[Batch 3] Current Loss: 2.7853\n",
            "[Batch 4] Current Loss: 3.3229\n",
            "[Batch 5] Current Loss: 2.4750\n",
            "[Batch 6] Current Loss: 2.6012\n",
            "[Batch 7] Current Loss: 2.2416\n",
            "[Batch 8] Current Loss: 3.1065\n",
            "[Batch 9] Current Loss: 2.8382\n",
            "[Batch 0] Current Loss: 5.8698\n",
            "[Batch 1] Current Loss: 5.2784\n",
            "[Batch 2] Current Loss: 4.6766\n",
            "[Batch 3] Current Loss: 5.8022\n",
            "[Batch 4] Current Loss: 5.3314\n",
            "[Batch 5] Current Loss: 6.0952\n",
            "[Batch 6] Current Loss: 5.9049\n",
            "[Batch 7] Current Loss: 6.3406\n",
            "[Batch 8] Current Loss: 5.8485\n",
            "[Batch 9] Current Loss: 6.0555\n",
            "Ep 4 (Step 028480): Train loss 2.658, Val loss 5.720\n",
            "[Batch 0] Current Loss: 2.3516\n",
            "[Batch 1] Current Loss: 2.6609\n",
            "[Batch 2] Current Loss: 2.6925\n",
            "[Batch 3] Current Loss: 2.6894\n",
            "[Batch 4] Current Loss: 2.4813\n",
            "[Batch 5] Current Loss: 2.9986\n",
            "[Batch 6] Current Loss: 2.8458\n",
            "[Batch 7] Current Loss: 3.6657\n",
            "[Batch 8] Current Loss: 2.7210\n",
            "[Batch 9] Current Loss: 2.7799\n",
            "[Batch 0] Current Loss: 5.8864\n",
            "[Batch 1] Current Loss: 5.0045\n",
            "[Batch 2] Current Loss: 5.6707\n",
            "[Batch 3] Current Loss: 4.7365\n",
            "[Batch 4] Current Loss: 5.4915\n",
            "[Batch 5] Current Loss: 4.6231\n",
            "[Batch 6] Current Loss: 5.6909\n",
            "[Batch 7] Current Loss: 5.1342\n",
            "[Batch 8] Current Loss: 5.7893\n",
            "[Batch 9] Current Loss: 4.9203\n",
            "Ep 4 (Step 028500): Train loss 2.789, Val loss 5.295\n",
            "[Batch 0] Current Loss: 1.8044\n",
            "[Batch 1] Current Loss: 2.4099\n",
            "[Batch 2] Current Loss: 3.1912\n",
            "[Batch 3] Current Loss: 3.4163\n",
            "[Batch 4] Current Loss: 2.0805\n",
            "[Batch 5] Current Loss: 2.5408\n",
            "[Batch 6] Current Loss: 2.2811\n",
            "[Batch 7] Current Loss: 2.8028\n",
            "[Batch 8] Current Loss: 2.4425\n",
            "[Batch 9] Current Loss: 3.0337\n",
            "[Batch 0] Current Loss: 5.4095\n",
            "[Batch 1] Current Loss: 5.6684\n",
            "[Batch 2] Current Loss: 5.8427\n",
            "[Batch 3] Current Loss: 5.5358\n",
            "[Batch 4] Current Loss: 5.2448\n",
            "[Batch 5] Current Loss: 6.3500\n",
            "[Batch 6] Current Loss: 5.4870\n",
            "[Batch 7] Current Loss: 5.8850\n",
            "[Batch 8] Current Loss: 6.1800\n",
            "[Batch 9] Current Loss: 5.6731\n",
            "Ep 4 (Step 028520): Train loss 2.600, Val loss 5.728\n",
            "[Batch 0] Current Loss: 2.7948\n",
            "[Batch 1] Current Loss: 2.4429\n",
            "[Batch 2] Current Loss: 2.8221\n",
            "[Batch 3] Current Loss: 2.5606\n",
            "[Batch 4] Current Loss: 2.6173\n",
            "[Batch 5] Current Loss: 2.9400\n",
            "[Batch 6] Current Loss: 3.2835\n",
            "[Batch 7] Current Loss: 2.0315\n",
            "[Batch 8] Current Loss: 3.1009\n",
            "[Batch 9] Current Loss: 2.7041\n",
            "[Batch 0] Current Loss: 5.9917\n",
            "[Batch 1] Current Loss: 5.8353\n",
            "[Batch 2] Current Loss: 5.3664\n",
            "[Batch 3] Current Loss: 5.9654\n",
            "[Batch 4] Current Loss: 5.7455\n",
            "[Batch 5] Current Loss: 5.9348\n",
            "[Batch 6] Current Loss: 6.0802\n",
            "[Batch 7] Current Loss: 5.8732\n",
            "[Batch 8] Current Loss: 6.0863\n",
            "[Batch 9] Current Loss: 5.4831\n",
            "Ep 4 (Step 028540): Train loss 2.730, Val loss 5.836\n",
            "[Batch 0] Current Loss: 2.3038\n",
            "[Batch 1] Current Loss: 1.8727\n",
            "[Batch 2] Current Loss: 2.6412\n",
            "[Batch 3] Current Loss: 2.5888\n",
            "[Batch 4] Current Loss: 2.9860\n",
            "[Batch 5] Current Loss: 2.4554\n",
            "[Batch 6] Current Loss: 2.3152\n",
            "[Batch 7] Current Loss: 2.6713\n",
            "[Batch 8] Current Loss: 2.2666\n",
            "[Batch 9] Current Loss: 2.9193\n",
            "[Batch 0] Current Loss: 5.8893\n",
            "[Batch 1] Current Loss: 5.5328\n",
            "[Batch 2] Current Loss: 6.0809\n",
            "[Batch 3] Current Loss: 5.0107\n",
            "[Batch 4] Current Loss: 5.2301\n",
            "[Batch 5] Current Loss: 5.8231\n",
            "[Batch 6] Current Loss: 5.4178\n",
            "[Batch 7] Current Loss: 5.2039\n",
            "[Batch 8] Current Loss: 5.3399\n",
            "[Batch 9] Current Loss: 6.1203\n",
            "Ep 4 (Step 028560): Train loss 2.502, Val loss 5.565\n",
            "[Batch 0] Current Loss: 3.0218\n",
            "[Batch 1] Current Loss: 1.7271\n",
            "[Batch 2] Current Loss: 2.7170\n",
            "[Batch 3] Current Loss: 3.0197\n",
            "[Batch 4] Current Loss: 2.4590\n",
            "[Batch 5] Current Loss: 2.9370\n",
            "[Batch 6] Current Loss: 2.6516\n",
            "[Batch 7] Current Loss: 2.7486\n",
            "[Batch 8] Current Loss: 2.3261\n",
            "[Batch 9] Current Loss: 3.1646\n",
            "[Batch 0] Current Loss: 5.7671\n",
            "[Batch 1] Current Loss: 4.6091\n",
            "[Batch 2] Current Loss: 6.0523\n",
            "[Batch 3] Current Loss: 5.3197\n",
            "[Batch 4] Current Loss: 5.4431\n",
            "[Batch 5] Current Loss: 6.1661\n",
            "[Batch 6] Current Loss: 5.0840\n",
            "[Batch 7] Current Loss: 6.1989\n",
            "[Batch 8] Current Loss: 5.9501\n",
            "[Batch 9] Current Loss: 5.0639\n",
            "Ep 4 (Step 028580): Train loss 2.677, Val loss 5.565\n",
            "[Batch 0] Current Loss: 2.8067\n",
            "[Batch 1] Current Loss: 3.2440\n",
            "[Batch 2] Current Loss: 3.3260\n",
            "[Batch 3] Current Loss: 2.4886\n",
            "[Batch 4] Current Loss: 2.6320\n",
            "[Batch 5] Current Loss: 1.9200\n",
            "[Batch 6] Current Loss: 3.4094\n",
            "[Batch 7] Current Loss: 2.8242\n",
            "[Batch 8] Current Loss: 2.9106\n",
            "[Batch 9] Current Loss: 2.4320\n",
            "[Batch 0] Current Loss: 5.1884\n",
            "[Batch 1] Current Loss: 5.2524\n",
            "[Batch 2] Current Loss: 5.5595\n",
            "[Batch 3] Current Loss: 5.4700\n",
            "[Batch 4] Current Loss: 5.1308\n",
            "[Batch 5] Current Loss: 6.0646\n",
            "[Batch 6] Current Loss: 4.9772\n",
            "[Batch 7] Current Loss: 5.5133\n",
            "[Batch 8] Current Loss: 6.0873\n",
            "[Batch 9] Current Loss: 5.3391\n",
            "Ep 4 (Step 028600): Train loss 2.799, Val loss 5.458\n",
            "[Batch 0] Current Loss: 2.2605\n",
            "[Batch 1] Current Loss: 2.1626\n",
            "[Batch 2] Current Loss: 2.4497\n",
            "[Batch 3] Current Loss: 1.7631\n",
            "[Batch 4] Current Loss: 2.9042\n",
            "[Batch 5] Current Loss: 2.0753\n",
            "[Batch 6] Current Loss: 2.3148\n",
            "[Batch 7] Current Loss: 2.8052\n",
            "[Batch 8] Current Loss: 2.4212\n",
            "[Batch 9] Current Loss: 3.3006\n",
            "[Batch 0] Current Loss: 5.5038\n",
            "[Batch 1] Current Loss: 5.7146\n",
            "[Batch 2] Current Loss: 5.0748\n",
            "[Batch 3] Current Loss: 5.1665\n",
            "[Batch 4] Current Loss: 5.0985\n",
            "[Batch 5] Current Loss: 4.9642\n",
            "[Batch 6] Current Loss: 4.8493\n",
            "[Batch 7] Current Loss: 5.3734\n",
            "[Batch 8] Current Loss: 5.8991\n",
            "[Batch 9] Current Loss: 6.3000\n",
            "Ep 4 (Step 028620): Train loss 2.446, Val loss 5.394\n",
            "[Batch 0] Current Loss: 2.2890\n",
            "[Batch 1] Current Loss: 2.5561\n",
            "[Batch 2] Current Loss: 2.7780\n",
            "[Batch 3] Current Loss: 3.2006\n",
            "[Batch 4] Current Loss: 2.6370\n",
            "[Batch 5] Current Loss: 3.0265\n",
            "[Batch 6] Current Loss: 2.7548\n",
            "[Batch 7] Current Loss: 2.5410\n",
            "[Batch 8] Current Loss: 2.7271\n",
            "[Batch 9] Current Loss: 3.2084\n",
            "[Batch 0] Current Loss: 4.9727\n",
            "[Batch 1] Current Loss: 5.3304\n",
            "[Batch 2] Current Loss: 5.4858\n",
            "[Batch 3] Current Loss: 5.0061\n",
            "[Batch 4] Current Loss: 4.8378\n",
            "[Batch 5] Current Loss: 5.8606\n",
            "[Batch 6] Current Loss: 6.5083\n",
            "[Batch 7] Current Loss: 5.3514\n",
            "[Batch 8] Current Loss: 4.5506\n",
            "[Batch 9] Current Loss: 5.4000\n",
            "Ep 4 (Step 028640): Train loss 2.772, Val loss 5.330\n",
            "[Batch 0] Current Loss: 2.8113\n",
            "[Batch 1] Current Loss: 2.9832\n",
            "[Batch 2] Current Loss: 2.7131\n",
            "[Batch 3] Current Loss: 2.5951\n",
            "[Batch 4] Current Loss: 2.6127\n",
            "[Batch 5] Current Loss: 3.1351\n",
            "[Batch 6] Current Loss: 2.2465\n",
            "[Batch 7] Current Loss: 2.3587\n",
            "[Batch 8] Current Loss: 2.9101\n",
            "[Batch 9] Current Loss: 3.5420\n",
            "[Batch 0] Current Loss: 6.0842\n",
            "[Batch 1] Current Loss: 4.6581\n",
            "[Batch 2] Current Loss: 5.5196\n",
            "[Batch 3] Current Loss: 5.1631\n",
            "[Batch 4] Current Loss: 5.3624\n",
            "[Batch 5] Current Loss: 5.9632\n",
            "[Batch 6] Current Loss: 4.8979\n",
            "[Batch 7] Current Loss: 5.1301\n",
            "[Batch 8] Current Loss: 5.9074\n",
            "[Batch 9] Current Loss: 5.2369\n",
            "Ep 4 (Step 028660): Train loss 2.791, Val loss 5.392\n",
            "[Batch 0] Current Loss: 2.9754\n",
            "[Batch 1] Current Loss: 2.6995\n",
            "[Batch 2] Current Loss: 2.3722\n",
            "[Batch 3] Current Loss: 2.3181\n",
            "[Batch 4] Current Loss: 2.3298\n",
            "[Batch 5] Current Loss: 2.4975\n",
            "[Batch 6] Current Loss: 2.1362\n",
            "[Batch 7] Current Loss: 3.6457\n",
            "[Batch 8] Current Loss: 2.9117\n",
            "[Batch 9] Current Loss: 2.4181\n",
            "[Batch 0] Current Loss: 5.1044\n",
            "[Batch 1] Current Loss: 5.6700\n",
            "[Batch 2] Current Loss: 4.8989\n",
            "[Batch 3] Current Loss: 5.6415\n",
            "[Batch 4] Current Loss: 5.0476\n",
            "[Batch 5] Current Loss: 5.4820\n",
            "[Batch 6] Current Loss: 5.1624\n",
            "[Batch 7] Current Loss: 5.6681\n",
            "[Batch 8] Current Loss: 5.1202\n",
            "[Batch 9] Current Loss: 5.7790\n",
            "Ep 4 (Step 028680): Train loss 2.630, Val loss 5.357\n",
            "[Batch 0] Current Loss: 2.4336\n",
            "[Batch 1] Current Loss: 3.0750\n",
            "[Batch 2] Current Loss: 3.4032\n",
            "[Batch 3] Current Loss: 2.4527\n",
            "[Batch 4] Current Loss: 1.8204\n",
            "[Batch 5] Current Loss: 2.2414\n",
            "[Batch 6] Current Loss: 2.3244\n",
            "[Batch 7] Current Loss: 1.7955\n",
            "[Batch 8] Current Loss: 2.1551\n",
            "[Batch 9] Current Loss: 2.6189\n",
            "[Batch 0] Current Loss: 6.4646\n",
            "[Batch 1] Current Loss: 5.1395\n",
            "[Batch 2] Current Loss: 5.4875\n",
            "[Batch 3] Current Loss: 5.7712\n",
            "[Batch 4] Current Loss: 4.7940\n",
            "[Batch 5] Current Loss: 5.1957\n",
            "[Batch 6] Current Loss: 5.6840\n",
            "[Batch 7] Current Loss: 5.5759\n",
            "[Batch 8] Current Loss: 5.7681\n",
            "[Batch 9] Current Loss: 5.3193\n",
            "Ep 4 (Step 028700): Train loss 2.432, Val loss 5.520\n",
            "[Batch 0] Current Loss: 2.7810\n",
            "[Batch 1] Current Loss: 2.7096\n",
            "[Batch 2] Current Loss: 2.4265\n",
            "[Batch 3] Current Loss: 2.8928\n",
            "[Batch 4] Current Loss: 2.7218\n",
            "[Batch 5] Current Loss: 2.8125\n",
            "[Batch 6] Current Loss: 1.8930\n",
            "[Batch 7] Current Loss: 3.2406\n",
            "[Batch 8] Current Loss: 2.2363\n",
            "[Batch 9] Current Loss: 2.5944\n",
            "[Batch 0] Current Loss: 4.7549\n",
            "[Batch 1] Current Loss: 5.7247\n",
            "[Batch 2] Current Loss: 6.2592\n",
            "[Batch 3] Current Loss: 6.0629\n",
            "[Batch 4] Current Loss: 5.0443\n",
            "[Batch 5] Current Loss: 5.4450\n",
            "[Batch 6] Current Loss: 6.1502\n",
            "[Batch 7] Current Loss: 5.3274\n",
            "[Batch 8] Current Loss: 5.8064\n",
            "[Batch 9] Current Loss: 4.9969\n",
            "Ep 4 (Step 028720): Train loss 2.631, Val loss 5.557\n",
            "[Batch 0] Current Loss: 2.8817\n",
            "[Batch 1] Current Loss: 2.3187\n",
            "[Batch 2] Current Loss: 2.3229\n",
            "[Batch 3] Current Loss: 3.2898\n",
            "[Batch 4] Current Loss: 3.1919\n",
            "[Batch 5] Current Loss: 2.8898\n",
            "[Batch 6] Current Loss: 2.8417\n",
            "[Batch 7] Current Loss: 3.4466\n",
            "[Batch 8] Current Loss: 3.2848\n",
            "[Batch 9] Current Loss: 2.8269\n",
            "[Batch 0] Current Loss: 5.5752\n",
            "[Batch 1] Current Loss: 5.4333\n",
            "[Batch 2] Current Loss: 5.7865\n",
            "[Batch 3] Current Loss: 5.5132\n",
            "[Batch 4] Current Loss: 5.3171\n",
            "[Batch 5] Current Loss: 5.1440\n",
            "[Batch 6] Current Loss: 5.5836\n",
            "[Batch 7] Current Loss: 5.4648\n",
            "[Batch 8] Current Loss: 5.9116\n",
            "[Batch 9] Current Loss: 5.6465\n",
            "Ep 4 (Step 028740): Train loss 2.929, Val loss 5.538\n",
            "[Batch 0] Current Loss: 2.2547\n",
            "[Batch 1] Current Loss: 2.6302\n",
            "[Batch 2] Current Loss: 3.1299\n",
            "[Batch 3] Current Loss: 2.6134\n",
            "[Batch 4] Current Loss: 1.9090\n",
            "[Batch 5] Current Loss: 2.4136\n",
            "[Batch 6] Current Loss: 2.6330\n",
            "[Batch 7] Current Loss: 2.4833\n",
            "[Batch 8] Current Loss: 2.7300\n",
            "[Batch 9] Current Loss: 3.0110\n",
            "[Batch 0] Current Loss: 5.2062\n",
            "[Batch 1] Current Loss: 6.5035\n",
            "[Batch 2] Current Loss: 5.1183\n",
            "[Batch 3] Current Loss: 5.6588\n",
            "[Batch 4] Current Loss: 5.8413\n",
            "[Batch 5] Current Loss: 5.1514\n",
            "[Batch 6] Current Loss: 5.1120\n",
            "[Batch 7] Current Loss: 4.4502\n",
            "[Batch 8] Current Loss: 5.3051\n",
            "[Batch 9] Current Loss: 4.5036\n",
            "Ep 4 (Step 028760): Train loss 2.581, Val loss 5.285\n",
            "[Batch 0] Current Loss: 2.0371\n",
            "[Batch 1] Current Loss: 3.0194\n",
            "[Batch 2] Current Loss: 3.1061\n",
            "[Batch 3] Current Loss: 2.6547\n",
            "[Batch 4] Current Loss: 2.2402\n",
            "[Batch 5] Current Loss: 1.9209\n",
            "[Batch 6] Current Loss: 2.4991\n",
            "[Batch 7] Current Loss: 2.4303\n",
            "[Batch 8] Current Loss: 2.5694\n",
            "[Batch 9] Current Loss: 2.8532\n",
            "[Batch 0] Current Loss: 5.4879\n",
            "[Batch 1] Current Loss: 5.5617\n",
            "[Batch 2] Current Loss: 5.7411\n",
            "[Batch 3] Current Loss: 5.9497\n",
            "[Batch 4] Current Loss: 5.1458\n",
            "[Batch 5] Current Loss: 5.2185\n",
            "[Batch 6] Current Loss: 4.9473\n",
            "[Batch 7] Current Loss: 6.0978\n",
            "[Batch 8] Current Loss: 5.0696\n",
            "[Batch 9] Current Loss: 5.8009\n",
            "Ep 4 (Step 028780): Train loss 2.533, Val loss 5.502\n",
            "[Batch 0] Current Loss: 2.5567\n",
            "[Batch 1] Current Loss: 3.0833\n",
            "[Batch 2] Current Loss: 3.0282\n",
            "[Batch 3] Current Loss: 2.4116\n",
            "[Batch 4] Current Loss: 3.0792\n",
            "[Batch 5] Current Loss: 2.2907\n",
            "[Batch 6] Current Loss: 2.3677\n",
            "[Batch 7] Current Loss: 2.8683\n",
            "[Batch 8] Current Loss: 3.0299\n",
            "[Batch 9] Current Loss: 2.7045\n",
            "[Batch 0] Current Loss: 5.9536\n",
            "[Batch 1] Current Loss: 6.0008\n",
            "[Batch 2] Current Loss: 5.3502\n",
            "[Batch 3] Current Loss: 5.0044\n",
            "[Batch 4] Current Loss: 5.3996\n",
            "[Batch 5] Current Loss: 6.1291\n",
            "[Batch 6] Current Loss: 5.1653\n",
            "[Batch 7] Current Loss: 5.1460\n",
            "[Batch 8] Current Loss: 6.4521\n",
            "[Batch 9] Current Loss: 5.1948\n",
            "Ep 4 (Step 028800): Train loss 2.742, Val loss 5.580\n",
            "[Batch 0] Current Loss: 2.5808\n",
            "[Batch 1] Current Loss: 2.3917\n",
            "[Batch 2] Current Loss: 2.1231\n",
            "[Batch 3] Current Loss: 2.8256\n",
            "[Batch 4] Current Loss: 2.4087\n",
            "[Batch 5] Current Loss: 2.1760\n",
            "[Batch 6] Current Loss: 2.4213\n",
            "[Batch 7] Current Loss: 2.7696\n",
            "[Batch 8] Current Loss: 2.2990\n",
            "[Batch 9] Current Loss: 2.1213\n",
            "[Batch 0] Current Loss: 5.4966\n",
            "[Batch 1] Current Loss: 5.2555\n",
            "[Batch 2] Current Loss: 5.2303\n",
            "[Batch 3] Current Loss: 5.0799\n",
            "[Batch 4] Current Loss: 4.7334\n",
            "[Batch 5] Current Loss: 5.6971\n",
            "[Batch 6] Current Loss: 5.5231\n",
            "[Batch 7] Current Loss: 5.0776\n",
            "[Batch 8] Current Loss: 5.2805\n",
            "[Batch 9] Current Loss: 4.6624\n",
            "Ep 4 (Step 028820): Train loss 2.412, Val loss 5.204\n",
            "[Batch 0] Current Loss: 3.0942\n",
            "[Batch 1] Current Loss: 2.5893\n",
            "[Batch 2] Current Loss: 3.1018\n",
            "[Batch 3] Current Loss: 2.6720\n",
            "[Batch 4] Current Loss: 3.0648\n",
            "[Batch 5] Current Loss: 2.2230\n",
            "[Batch 6] Current Loss: 2.8441\n",
            "[Batch 7] Current Loss: 2.9958\n",
            "[Batch 8] Current Loss: 2.5195\n",
            "[Batch 9] Current Loss: 2.1580\n",
            "[Batch 0] Current Loss: 5.3604\n",
            "[Batch 1] Current Loss: 5.9492\n",
            "[Batch 2] Current Loss: 4.8071\n",
            "[Batch 3] Current Loss: 4.7941\n",
            "[Batch 4] Current Loss: 5.1998\n",
            "[Batch 5] Current Loss: 4.8452\n",
            "[Batch 6] Current Loss: 5.2217\n",
            "[Batch 7] Current Loss: 6.1107\n",
            "[Batch 8] Current Loss: 5.0880\n",
            "[Batch 9] Current Loss: 5.4811\n",
            "Ep 4 (Step 028840): Train loss 2.726, Val loss 5.286\n",
            "[Batch 0] Current Loss: 2.6824\n",
            "[Batch 1] Current Loss: 2.8159\n",
            "[Batch 2] Current Loss: 2.7009\n",
            "[Batch 3] Current Loss: 2.1033\n",
            "[Batch 4] Current Loss: 3.1359\n",
            "[Batch 5] Current Loss: 2.5104\n",
            "[Batch 6] Current Loss: 2.4778\n",
            "[Batch 7] Current Loss: 3.0649\n",
            "[Batch 8] Current Loss: 3.3138\n",
            "[Batch 9] Current Loss: 2.2957\n",
            "[Batch 0] Current Loss: 5.6814\n",
            "[Batch 1] Current Loss: 4.9328\n",
            "[Batch 2] Current Loss: 5.5405\n",
            "[Batch 3] Current Loss: 5.7785\n",
            "[Batch 4] Current Loss: 4.8122\n",
            "[Batch 5] Current Loss: 5.5327\n",
            "[Batch 6] Current Loss: 5.7965\n",
            "[Batch 7] Current Loss: 5.6114\n",
            "[Batch 8] Current Loss: 4.8012\n",
            "[Batch 9] Current Loss: 5.6512\n",
            "Ep 4 (Step 028860): Train loss 2.710, Val loss 5.414\n",
            "[Batch 0] Current Loss: 2.1239\n",
            "[Batch 1] Current Loss: 2.9078\n",
            "[Batch 2] Current Loss: 2.7566\n",
            "[Batch 3] Current Loss: 2.4244\n",
            "[Batch 4] Current Loss: 2.9570\n",
            "[Batch 5] Current Loss: 2.1161\n",
            "[Batch 6] Current Loss: 2.5685\n",
            "[Batch 7] Current Loss: 2.8944\n",
            "[Batch 8] Current Loss: 3.2722\n",
            "[Batch 9] Current Loss: 2.2691\n",
            "[Batch 0] Current Loss: 5.2024\n",
            "[Batch 1] Current Loss: 5.7699\n",
            "[Batch 2] Current Loss: 4.9105\n",
            "[Batch 3] Current Loss: 5.3429\n",
            "[Batch 4] Current Loss: 4.8845\n",
            "[Batch 5] Current Loss: 5.6190\n",
            "[Batch 6] Current Loss: 5.0635\n",
            "[Batch 7] Current Loss: 5.3418\n",
            "[Batch 8] Current Loss: 5.3836\n",
            "[Batch 9] Current Loss: 6.1562\n",
            "Ep 4 (Step 028880): Train loss 2.629, Val loss 5.367\n",
            "[Batch 0] Current Loss: 2.5890\n",
            "[Batch 1] Current Loss: 2.5244\n",
            "[Batch 2] Current Loss: 3.1780\n",
            "[Batch 3] Current Loss: 2.5812\n",
            "[Batch 4] Current Loss: 2.9943\n",
            "[Batch 5] Current Loss: 2.4099\n",
            "[Batch 6] Current Loss: 2.1881\n",
            "[Batch 7] Current Loss: 2.4006\n",
            "[Batch 8] Current Loss: 2.6406\n",
            "[Batch 9] Current Loss: 2.6711\n",
            "[Batch 0] Current Loss: 5.8567\n",
            "[Batch 1] Current Loss: 6.2498\n",
            "[Batch 2] Current Loss: 5.7120\n",
            "[Batch 3] Current Loss: 4.9896\n",
            "[Batch 4] Current Loss: 4.9565\n",
            "[Batch 5] Current Loss: 5.3652\n",
            "[Batch 6] Current Loss: 5.3756\n",
            "[Batch 7] Current Loss: 4.9852\n",
            "[Batch 8] Current Loss: 5.8787\n",
            "[Batch 9] Current Loss: 5.2394\n",
            "Ep 4 (Step 028900): Train loss 2.618, Val loss 5.461\n",
            "[Batch 0] Current Loss: 2.5556\n",
            "[Batch 1] Current Loss: 2.5692\n",
            "[Batch 2] Current Loss: 2.9404\n",
            "[Batch 3] Current Loss: 2.2371\n",
            "[Batch 4] Current Loss: 2.4103\n",
            "[Batch 5] Current Loss: 2.8220\n",
            "[Batch 6] Current Loss: 2.7810\n",
            "[Batch 7] Current Loss: 2.6938\n",
            "[Batch 8] Current Loss: 2.2333\n",
            "[Batch 9] Current Loss: 2.7413\n",
            "[Batch 0] Current Loss: 6.5190\n",
            "[Batch 1] Current Loss: 4.8203\n",
            "[Batch 2] Current Loss: 5.6187\n",
            "[Batch 3] Current Loss: 5.3627\n",
            "[Batch 4] Current Loss: 6.2914\n",
            "[Batch 5] Current Loss: 5.7309\n",
            "[Batch 6] Current Loss: 5.2727\n",
            "[Batch 7] Current Loss: 5.4660\n",
            "[Batch 8] Current Loss: 5.4685\n",
            "[Batch 9] Current Loss: 6.0731\n",
            "Ep 4 (Step 028920): Train loss 2.598, Val loss 5.662\n",
            "[Batch 0] Current Loss: 2.5379\n",
            "[Batch 1] Current Loss: 2.7252\n",
            "[Batch 2] Current Loss: 2.6737\n",
            "[Batch 3] Current Loss: 2.9991\n",
            "[Batch 4] Current Loss: 2.5360\n",
            "[Batch 5] Current Loss: 3.2849\n",
            "[Batch 6] Current Loss: 2.3202\n",
            "[Batch 7] Current Loss: 2.5958\n",
            "[Batch 8] Current Loss: 2.5309\n",
            "[Batch 9] Current Loss: 2.4020\n",
            "[Batch 0] Current Loss: 6.1419\n",
            "[Batch 1] Current Loss: 5.6063\n",
            "[Batch 2] Current Loss: 5.5845\n",
            "[Batch 3] Current Loss: 4.9617\n",
            "[Batch 4] Current Loss: 5.8244\n",
            "[Batch 5] Current Loss: 5.2876\n",
            "[Batch 6] Current Loss: 5.0293\n",
            "[Batch 7] Current Loss: 5.7451\n",
            "[Batch 8] Current Loss: 5.2684\n",
            "[Batch 9] Current Loss: 5.3145\n",
            "Ep 4 (Step 028940): Train loss 2.661, Val loss 5.476\n",
            "[Batch 0] Current Loss: 2.6595\n",
            "[Batch 1] Current Loss: 2.3266\n",
            "[Batch 2] Current Loss: 3.2539\n",
            "[Batch 3] Current Loss: 2.0267\n",
            "[Batch 4] Current Loss: 2.9204\n",
            "[Batch 5] Current Loss: 2.5530\n",
            "[Batch 6] Current Loss: 2.7051\n",
            "[Batch 7] Current Loss: 2.4619\n",
            "[Batch 8] Current Loss: 2.1785\n",
            "[Batch 9] Current Loss: 2.9323\n",
            "[Batch 0] Current Loss: 5.7708\n",
            "[Batch 1] Current Loss: 5.3364\n",
            "[Batch 2] Current Loss: 4.8109\n",
            "[Batch 3] Current Loss: 5.4522\n",
            "[Batch 4] Current Loss: 4.6647\n",
            "[Batch 5] Current Loss: 5.3404\n",
            "[Batch 6] Current Loss: 5.4641\n",
            "[Batch 7] Current Loss: 5.6968\n",
            "[Batch 8] Current Loss: 5.1044\n",
            "[Batch 9] Current Loss: 5.3962\n",
            "Ep 4 (Step 028960): Train loss 2.602, Val loss 5.304\n",
            "[Batch 0] Current Loss: 2.5945\n",
            "[Batch 1] Current Loss: 2.3120\n",
            "[Batch 2] Current Loss: 2.7931\n",
            "[Batch 3] Current Loss: 2.6923\n",
            "[Batch 4] Current Loss: 2.2417\n",
            "[Batch 5] Current Loss: 2.5017\n",
            "[Batch 6] Current Loss: 2.8742\n",
            "[Batch 7] Current Loss: 2.8501\n",
            "[Batch 8] Current Loss: 2.8053\n",
            "[Batch 9] Current Loss: 2.6262\n",
            "[Batch 0] Current Loss: 5.2637\n",
            "[Batch 1] Current Loss: 5.9121\n",
            "[Batch 2] Current Loss: 6.0439\n",
            "[Batch 3] Current Loss: 5.0874\n",
            "[Batch 4] Current Loss: 5.3259\n",
            "[Batch 5] Current Loss: 5.7986\n",
            "[Batch 6] Current Loss: 5.0245\n",
            "[Batch 7] Current Loss: 6.3409\n",
            "[Batch 8] Current Loss: 6.0767\n",
            "[Batch 9] Current Loss: 6.0306\n",
            "Ep 4 (Step 028980): Train loss 2.629, Val loss 5.690\n",
            "[Batch 0] Current Loss: 2.3320\n",
            "[Batch 1] Current Loss: 2.1731\n",
            "[Batch 2] Current Loss: 3.0610\n",
            "[Batch 3] Current Loss: 2.9570\n",
            "[Batch 4] Current Loss: 2.7726\n",
            "[Batch 5] Current Loss: 2.4378\n",
            "[Batch 6] Current Loss: 3.1143\n",
            "[Batch 7] Current Loss: 2.5701\n",
            "[Batch 8] Current Loss: 2.4360\n",
            "[Batch 9] Current Loss: 2.5008\n",
            "[Batch 0] Current Loss: 6.2895\n",
            "[Batch 1] Current Loss: 5.9454\n",
            "[Batch 2] Current Loss: 4.7384\n",
            "[Batch 3] Current Loss: 6.0268\n",
            "[Batch 4] Current Loss: 4.8125\n",
            "[Batch 5] Current Loss: 5.0458\n",
            "[Batch 6] Current Loss: 5.4543\n",
            "[Batch 7] Current Loss: 5.2244\n",
            "[Batch 8] Current Loss: 5.6050\n",
            "[Batch 9] Current Loss: 6.1049\n",
            "Ep 4 (Step 029000): Train loss 2.635, Val loss 5.525\n",
            "[Batch 0] Current Loss: 2.3531\n",
            "[Batch 1] Current Loss: 2.6466\n",
            "[Batch 2] Current Loss: 3.1318\n",
            "[Batch 3] Current Loss: 2.2535\n",
            "[Batch 4] Current Loss: 2.5320\n",
            "[Batch 5] Current Loss: 2.2041\n",
            "[Batch 6] Current Loss: 2.5162\n",
            "[Batch 7] Current Loss: 2.9554\n",
            "[Batch 8] Current Loss: 3.3555\n",
            "[Batch 9] Current Loss: 3.1490\n",
            "[Batch 0] Current Loss: 4.7378\n",
            "[Batch 1] Current Loss: 5.4085\n",
            "[Batch 2] Current Loss: 5.1274\n",
            "[Batch 3] Current Loss: 4.9744\n",
            "[Batch 4] Current Loss: 5.8033\n",
            "[Batch 5] Current Loss: 5.4755\n",
            "[Batch 6] Current Loss: 5.9547\n",
            "[Batch 7] Current Loss: 4.9444\n",
            "[Batch 8] Current Loss: 6.1768\n",
            "[Batch 9] Current Loss: 5.4214\n",
            "Ep 4 (Step 029020): Train loss 2.710, Val loss 5.402\n",
            "[Batch 0] Current Loss: 2.6377\n",
            "[Batch 1] Current Loss: 2.0979\n",
            "[Batch 2] Current Loss: 2.9672\n",
            "[Batch 3] Current Loss: 2.7493\n",
            "[Batch 4] Current Loss: 1.7709\n",
            "[Batch 5] Current Loss: 3.3928\n",
            "[Batch 6] Current Loss: 2.9990\n",
            "[Batch 7] Current Loss: 2.2641\n",
            "[Batch 8] Current Loss: 2.2858\n",
            "[Batch 9] Current Loss: 2.0974\n",
            "[Batch 0] Current Loss: 6.2643\n",
            "[Batch 1] Current Loss: 5.3022\n",
            "[Batch 2] Current Loss: 5.7590\n",
            "[Batch 3] Current Loss: 5.0803\n",
            "[Batch 4] Current Loss: 6.0101\n",
            "[Batch 5] Current Loss: 5.3966\n",
            "[Batch 6] Current Loss: 5.9751\n",
            "[Batch 7] Current Loss: 5.5203\n",
            "[Batch 8] Current Loss: 5.2372\n",
            "[Batch 9] Current Loss: 4.7727\n",
            "Ep 4 (Step 029040): Train loss 2.526, Val loss 5.532\n",
            "[Batch 0] Current Loss: 2.6812\n",
            "[Batch 1] Current Loss: 2.5169\n",
            "[Batch 2] Current Loss: 2.4739\n",
            "[Batch 3] Current Loss: 2.8711\n",
            "[Batch 4] Current Loss: 3.5587\n",
            "[Batch 5] Current Loss: 2.7116\n",
            "[Batch 6] Current Loss: 2.4865\n",
            "[Batch 7] Current Loss: 2.6234\n",
            "[Batch 8] Current Loss: 2.3023\n",
            "[Batch 9] Current Loss: 2.4183\n",
            "[Batch 0] Current Loss: 5.6503\n",
            "[Batch 1] Current Loss: 5.0822\n",
            "[Batch 2] Current Loss: 5.7610\n",
            "[Batch 3] Current Loss: 5.5310\n",
            "[Batch 4] Current Loss: 5.2787\n",
            "[Batch 5] Current Loss: 5.4552\n",
            "[Batch 6] Current Loss: 4.5523\n",
            "[Batch 7] Current Loss: 5.0335\n",
            "[Batch 8] Current Loss: 4.5926\n",
            "[Batch 9] Current Loss: 5.3226\n",
            "Ep 4 (Step 029060): Train loss 2.664, Val loss 5.226\n",
            "[Batch 0] Current Loss: 2.4685\n",
            "[Batch 1] Current Loss: 2.8071\n",
            "[Batch 2] Current Loss: 2.7681\n",
            "[Batch 3] Current Loss: 2.3223\n",
            "[Batch 4] Current Loss: 2.7805\n",
            "[Batch 5] Current Loss: 2.1036\n",
            "[Batch 6] Current Loss: 2.9901\n",
            "[Batch 7] Current Loss: 2.3852\n",
            "[Batch 8] Current Loss: 2.6918\n",
            "[Batch 9] Current Loss: 2.3053\n",
            "[Batch 0] Current Loss: 5.3633\n",
            "[Batch 1] Current Loss: 5.2086\n",
            "[Batch 2] Current Loss: 5.4965\n",
            "[Batch 3] Current Loss: 6.0479\n",
            "[Batch 4] Current Loss: 6.3105\n",
            "[Batch 5] Current Loss: 5.4382\n",
            "[Batch 6] Current Loss: 5.8379\n",
            "[Batch 7] Current Loss: 5.3103\n",
            "[Batch 8] Current Loss: 5.3869\n",
            "[Batch 9] Current Loss: 5.6846\n",
            "Ep 4 (Step 029080): Train loss 2.562, Val loss 5.608\n",
            "[Batch 0] Current Loss: 2.4797\n",
            "[Batch 1] Current Loss: 1.9897\n",
            "[Batch 2] Current Loss: 2.2443\n",
            "[Batch 3] Current Loss: 3.1714\n",
            "[Batch 4] Current Loss: 2.8441\n",
            "[Batch 5] Current Loss: 2.6768\n",
            "[Batch 6] Current Loss: 3.0644\n",
            "[Batch 7] Current Loss: 2.5126\n",
            "[Batch 8] Current Loss: 1.5829\n",
            "[Batch 9] Current Loss: 2.8525\n",
            "[Batch 0] Current Loss: 5.6509\n",
            "[Batch 1] Current Loss: 6.0418\n",
            "[Batch 2] Current Loss: 5.9829\n",
            "[Batch 3] Current Loss: 5.2193\n",
            "[Batch 4] Current Loss: 5.2647\n",
            "[Batch 5] Current Loss: 5.8595\n",
            "[Batch 6] Current Loss: 5.5851\n",
            "[Batch 7] Current Loss: 6.0878\n",
            "[Batch 8] Current Loss: 6.0365\n",
            "[Batch 9] Current Loss: 4.5980\n",
            "Ep 4 (Step 029100): Train loss 2.542, Val loss 5.633\n",
            "[Batch 0] Current Loss: 2.3048\n",
            "[Batch 1] Current Loss: 2.5763\n",
            "[Batch 2] Current Loss: 2.5951\n",
            "[Batch 3] Current Loss: 2.7571\n",
            "[Batch 4] Current Loss: 3.1250\n",
            "[Batch 5] Current Loss: 3.1384\n",
            "[Batch 6] Current Loss: 2.8605\n",
            "[Batch 7] Current Loss: 2.7051\n",
            "[Batch 8] Current Loss: 3.0894\n",
            "[Batch 9] Current Loss: 1.9616\n",
            "[Batch 0] Current Loss: 5.7541\n",
            "[Batch 1] Current Loss: 5.3736\n",
            "[Batch 2] Current Loss: 6.0434\n",
            "[Batch 3] Current Loss: 5.3558\n",
            "[Batch 4] Current Loss: 5.1179\n",
            "[Batch 5] Current Loss: 5.8971\n",
            "[Batch 6] Current Loss: 5.6249\n",
            "[Batch 7] Current Loss: 6.1940\n",
            "[Batch 8] Current Loss: 5.6732\n",
            "[Batch 9] Current Loss: 5.4770\n",
            "Ep 4 (Step 029120): Train loss 2.711, Val loss 5.651\n",
            "[Batch 0] Current Loss: 2.3602\n",
            "[Batch 1] Current Loss: 2.5723\n",
            "[Batch 2] Current Loss: 2.5620\n",
            "[Batch 3] Current Loss: 2.0252\n",
            "[Batch 4] Current Loss: 2.0805\n",
            "[Batch 5] Current Loss: 2.5443\n",
            "[Batch 6] Current Loss: 2.1700\n",
            "[Batch 7] Current Loss: 2.8538\n",
            "[Batch 8] Current Loss: 2.9802\n",
            "[Batch 9] Current Loss: 2.7136\n",
            "[Batch 0] Current Loss: 5.8572\n",
            "[Batch 1] Current Loss: 5.8383\n",
            "[Batch 2] Current Loss: 5.7255\n",
            "[Batch 3] Current Loss: 5.8148\n",
            "[Batch 4] Current Loss: 5.6221\n",
            "[Batch 5] Current Loss: 6.2490\n",
            "[Batch 6] Current Loss: 6.1080\n",
            "[Batch 7] Current Loss: 5.5272\n",
            "[Batch 8] Current Loss: 5.5850\n",
            "[Batch 9] Current Loss: 4.8775\n",
            "Ep 4 (Step 029140): Train loss 2.486, Val loss 5.720\n",
            "[Batch 0] Current Loss: 2.6613\n",
            "[Batch 1] Current Loss: 3.5056\n",
            "[Batch 2] Current Loss: 2.9831\n",
            "[Batch 3] Current Loss: 1.7529\n",
            "[Batch 4] Current Loss: 2.1497\n",
            "[Batch 5] Current Loss: 3.3606\n",
            "[Batch 6] Current Loss: 2.6548\n",
            "[Batch 7] Current Loss: 2.4740\n",
            "[Batch 8] Current Loss: 2.2460\n",
            "[Batch 9] Current Loss: 2.3709\n",
            "[Batch 0] Current Loss: 6.0841\n",
            "[Batch 1] Current Loss: 5.1257\n",
            "[Batch 2] Current Loss: 5.9543\n",
            "[Batch 3] Current Loss: 5.3243\n",
            "[Batch 4] Current Loss: 6.7095\n",
            "[Batch 5] Current Loss: 5.3556\n",
            "[Batch 6] Current Loss: 4.8701\n",
            "[Batch 7] Current Loss: 5.2766\n",
            "[Batch 8] Current Loss: 6.8471\n",
            "[Batch 9] Current Loss: 5.5358\n",
            "Ep 4 (Step 029160): Train loss 2.616, Val loss 5.708\n",
            "[Batch 0] Current Loss: 2.4246\n",
            "[Batch 1] Current Loss: 2.4960\n",
            "[Batch 2] Current Loss: 2.5701\n",
            "[Batch 3] Current Loss: 2.4023\n",
            "[Batch 4] Current Loss: 2.3581\n",
            "[Batch 5] Current Loss: 2.4555\n",
            "[Batch 6] Current Loss: 2.9691\n",
            "[Batch 7] Current Loss: 2.6295\n",
            "[Batch 8] Current Loss: 2.4547\n",
            "[Batch 9] Current Loss: 2.2326\n",
            "[Batch 0] Current Loss: 5.8873\n",
            "[Batch 1] Current Loss: 4.8543\n",
            "[Batch 2] Current Loss: 5.4065\n",
            "[Batch 3] Current Loss: 5.4586\n",
            "[Batch 4] Current Loss: 5.2665\n",
            "[Batch 5] Current Loss: 5.4010\n",
            "[Batch 6] Current Loss: 5.4745\n",
            "[Batch 7] Current Loss: 5.6026\n",
            "[Batch 8] Current Loss: 5.2747\n",
            "[Batch 9] Current Loss: 5.7888\n",
            "Ep 4 (Step 029180): Train loss 2.499, Val loss 5.441\n",
            "[Batch 0] Current Loss: 2.4753\n",
            "[Batch 1] Current Loss: 2.0395\n",
            "[Batch 2] Current Loss: 3.1781\n",
            "[Batch 3] Current Loss: 2.2557\n",
            "[Batch 4] Current Loss: 3.0619\n",
            "[Batch 5] Current Loss: 2.4775\n",
            "[Batch 6] Current Loss: 2.8259\n",
            "[Batch 7] Current Loss: 3.1846\n",
            "[Batch 8] Current Loss: 1.9573\n",
            "[Batch 9] Current Loss: 2.7186\n",
            "[Batch 0] Current Loss: 6.2287\n",
            "[Batch 1] Current Loss: 5.7170\n",
            "[Batch 2] Current Loss: 4.8478\n",
            "[Batch 3] Current Loss: 5.4103\n",
            "[Batch 4] Current Loss: 5.6398\n",
            "[Batch 5] Current Loss: 5.8854\n",
            "[Batch 6] Current Loss: 5.3179\n",
            "[Batch 7] Current Loss: 5.1835\n",
            "[Batch 8] Current Loss: 5.6568\n",
            "[Batch 9] Current Loss: 5.3266\n",
            "Ep 4 (Step 029200): Train loss 2.617, Val loss 5.521\n",
            "[Batch 0] Current Loss: 2.5363\n",
            "[Batch 1] Current Loss: 2.2809\n",
            "[Batch 2] Current Loss: 2.0641\n",
            "[Batch 3] Current Loss: 2.4701\n",
            "[Batch 4] Current Loss: 3.3447\n",
            "[Batch 5] Current Loss: 2.5825\n",
            "[Batch 6] Current Loss: 2.2378\n",
            "[Batch 7] Current Loss: 2.9012\n",
            "[Batch 8] Current Loss: 2.0539\n",
            "[Batch 9] Current Loss: 2.6278\n",
            "[Batch 0] Current Loss: 6.1013\n",
            "[Batch 1] Current Loss: 5.1683\n",
            "[Batch 2] Current Loss: 5.3957\n",
            "[Batch 3] Current Loss: 5.5945\n",
            "[Batch 4] Current Loss: 4.8441\n",
            "[Batch 5] Current Loss: 6.4087\n",
            "[Batch 6] Current Loss: 5.6846\n",
            "[Batch 7] Current Loss: 6.2320\n",
            "[Batch 8] Current Loss: 5.9504\n",
            "[Batch 9] Current Loss: 5.3359\n",
            "Ep 4 (Step 029220): Train loss 2.510, Val loss 5.672\n",
            "[Batch 0] Current Loss: 3.0146\n",
            "[Batch 1] Current Loss: 3.5338\n",
            "[Batch 2] Current Loss: 2.1517\n",
            "[Batch 3] Current Loss: 2.9205\n",
            "[Batch 4] Current Loss: 3.0153\n",
            "[Batch 5] Current Loss: 1.9590\n",
            "[Batch 6] Current Loss: 2.1942\n",
            "[Batch 7] Current Loss: 3.7174\n",
            "[Batch 8] Current Loss: 2.1963\n",
            "[Batch 9] Current Loss: 2.4121\n",
            "[Batch 0] Current Loss: 5.2662\n",
            "[Batch 1] Current Loss: 5.5561\n",
            "[Batch 2] Current Loss: 5.3806\n",
            "[Batch 3] Current Loss: 5.7227\n",
            "[Batch 4] Current Loss: 5.1560\n",
            "[Batch 5] Current Loss: 4.3991\n",
            "[Batch 6] Current Loss: 5.9938\n",
            "[Batch 7] Current Loss: 6.0913\n",
            "[Batch 8] Current Loss: 6.0595\n",
            "[Batch 9] Current Loss: 5.2315\n",
            "Ep 4 (Step 029240): Train loss 2.711, Val loss 5.486\n",
            "[Batch 0] Current Loss: 2.5450\n",
            "[Batch 1] Current Loss: 2.4508\n",
            "[Batch 2] Current Loss: 2.3781\n",
            "[Batch 3] Current Loss: 2.5887\n",
            "[Batch 4] Current Loss: 2.7280\n",
            "[Batch 5] Current Loss: 2.9965\n",
            "[Batch 6] Current Loss: 2.5757\n",
            "[Batch 7] Current Loss: 2.6046\n",
            "[Batch 8] Current Loss: 2.2012\n",
            "[Batch 9] Current Loss: 2.9752\n",
            "[Batch 0] Current Loss: 5.7329\n",
            "[Batch 1] Current Loss: 5.0833\n",
            "[Batch 2] Current Loss: 5.9693\n",
            "[Batch 3] Current Loss: 5.4661\n",
            "[Batch 4] Current Loss: 5.3359\n",
            "[Batch 5] Current Loss: 5.1106\n",
            "[Batch 6] Current Loss: 5.5590\n",
            "[Batch 7] Current Loss: 5.3433\n",
            "[Batch 8] Current Loss: 5.5831\n",
            "[Batch 9] Current Loss: 5.4582\n",
            "Ep 4 (Step 029260): Train loss 2.604, Val loss 5.464\n",
            "[Batch 0] Current Loss: 3.2429\n",
            "[Batch 1] Current Loss: 3.3169\n",
            "[Batch 2] Current Loss: 2.5953\n",
            "[Batch 3] Current Loss: 2.6196\n",
            "[Batch 4] Current Loss: 3.3454\n",
            "[Batch 5] Current Loss: 2.4317\n",
            "[Batch 6] Current Loss: 2.7210\n",
            "[Batch 7] Current Loss: 2.4143\n",
            "[Batch 8] Current Loss: 2.4919\n",
            "[Batch 9] Current Loss: 2.6058\n",
            "[Batch 0] Current Loss: 4.9402\n",
            "[Batch 1] Current Loss: 5.5620\n",
            "[Batch 2] Current Loss: 5.5840\n",
            "[Batch 3] Current Loss: 4.9990\n",
            "[Batch 4] Current Loss: 5.2540\n",
            "[Batch 5] Current Loss: 5.8446\n",
            "[Batch 6] Current Loss: 4.3780\n",
            "[Batch 7] Current Loss: 6.1845\n",
            "[Batch 8] Current Loss: 5.5902\n",
            "[Batch 9] Current Loss: 5.3334\n",
            "Ep 4 (Step 029280): Train loss 2.778, Val loss 5.367\n",
            "[Batch 0] Current Loss: 3.0640\n",
            "[Batch 1] Current Loss: 2.1243\n",
            "[Batch 2] Current Loss: 2.1676\n",
            "[Batch 3] Current Loss: 2.7719\n",
            "[Batch 4] Current Loss: 2.4118\n",
            "[Batch 5] Current Loss: 2.7185\n",
            "[Batch 6] Current Loss: 2.4667\n",
            "[Batch 7] Current Loss: 2.8993\n",
            "[Batch 8] Current Loss: 2.2801\n",
            "[Batch 9] Current Loss: 2.5962\n",
            "[Batch 0] Current Loss: 5.7837\n",
            "[Batch 1] Current Loss: 5.7118\n",
            "[Batch 2] Current Loss: 5.1363\n",
            "[Batch 3] Current Loss: 5.8741\n",
            "[Batch 4] Current Loss: 5.8788\n",
            "[Batch 5] Current Loss: 6.4398\n",
            "[Batch 6] Current Loss: 6.0105\n",
            "[Batch 7] Current Loss: 6.0595\n",
            "[Batch 8] Current Loss: 5.3696\n",
            "[Batch 9] Current Loss: 4.7763\n",
            "Ep 4 (Step 029300): Train loss 2.550, Val loss 5.704\n",
            "[Batch 0] Current Loss: 2.9111\n",
            "[Batch 1] Current Loss: 2.6912\n",
            "[Batch 2] Current Loss: 2.7394\n",
            "[Batch 3] Current Loss: 2.6534\n",
            "[Batch 4] Current Loss: 2.3942\n",
            "[Batch 5] Current Loss: 2.3426\n",
            "[Batch 6] Current Loss: 2.7217\n",
            "[Batch 7] Current Loss: 2.8920\n",
            "[Batch 8] Current Loss: 1.8552\n",
            "[Batch 9] Current Loss: 2.4516\n",
            "[Batch 0] Current Loss: 5.4137\n",
            "[Batch 1] Current Loss: 6.5014\n",
            "[Batch 2] Current Loss: 5.2360\n",
            "[Batch 3] Current Loss: 5.5021\n",
            "[Batch 4] Current Loss: 4.6665\n",
            "[Batch 5] Current Loss: 5.8197\n",
            "[Batch 6] Current Loss: 4.3282\n",
            "[Batch 7] Current Loss: 5.8296\n",
            "[Batch 8] Current Loss: 6.1927\n",
            "[Batch 9] Current Loss: 5.1983\n",
            "Ep 4 (Step 029320): Train loss 2.565, Val loss 5.469\n",
            "[Batch 0] Current Loss: 3.0734\n",
            "[Batch 1] Current Loss: 2.1091\n",
            "[Batch 2] Current Loss: 2.2768\n",
            "[Batch 3] Current Loss: 2.6185\n",
            "[Batch 4] Current Loss: 2.9678\n",
            "[Batch 5] Current Loss: 3.1173\n",
            "[Batch 6] Current Loss: 2.2006\n",
            "[Batch 7] Current Loss: 3.0340\n",
            "[Batch 8] Current Loss: 2.7998\n",
            "[Batch 9] Current Loss: 2.4430\n",
            "[Batch 0] Current Loss: 5.4816\n",
            "[Batch 1] Current Loss: 5.5592\n",
            "[Batch 2] Current Loss: 5.1968\n",
            "[Batch 3] Current Loss: 4.8413\n",
            "[Batch 4] Current Loss: 5.1532\n",
            "[Batch 5] Current Loss: 5.2565\n",
            "[Batch 6] Current Loss: 5.2759\n",
            "[Batch 7] Current Loss: 5.4733\n",
            "[Batch 8] Current Loss: 4.8867\n",
            "[Batch 9] Current Loss: 6.4932\n",
            "Ep 4 (Step 029340): Train loss 2.664, Val loss 5.362\n",
            "[Batch 0] Current Loss: 2.5122\n",
            "[Batch 1] Current Loss: 2.6371\n",
            "[Batch 2] Current Loss: 2.3626\n",
            "[Batch 3] Current Loss: 2.6007\n",
            "[Batch 4] Current Loss: 2.5784\n",
            "[Batch 5] Current Loss: 2.1790\n",
            "[Batch 6] Current Loss: 2.7653\n",
            "[Batch 7] Current Loss: 1.9733\n",
            "[Batch 8] Current Loss: 1.6390\n",
            "[Batch 9] Current Loss: 2.6247\n",
            "[Batch 0] Current Loss: 5.6623\n",
            "[Batch 1] Current Loss: 5.8821\n",
            "[Batch 2] Current Loss: 5.6034\n",
            "[Batch 3] Current Loss: 5.2434\n",
            "[Batch 4] Current Loss: 5.7578\n",
            "[Batch 5] Current Loss: 5.0910\n",
            "[Batch 6] Current Loss: 5.3828\n",
            "[Batch 7] Current Loss: 5.5434\n",
            "[Batch 8] Current Loss: 5.6871\n",
            "[Batch 9] Current Loss: 5.9744\n",
            "Ep 4 (Step 029360): Train loss 2.387, Val loss 5.583\n",
            "[Batch 0] Current Loss: 2.0627\n",
            "[Batch 1] Current Loss: 1.9793\n",
            "[Batch 2] Current Loss: 3.0016\n",
            "[Batch 3] Current Loss: 2.0582\n",
            "[Batch 4] Current Loss: 2.8233\n",
            "[Batch 5] Current Loss: 3.3389\n",
            "[Batch 6] Current Loss: 2.9842\n",
            "[Batch 7] Current Loss: 2.7788\n",
            "[Batch 8] Current Loss: 3.1063\n",
            "[Batch 9] Current Loss: 2.5824\n",
            "[Batch 0] Current Loss: 5.4712\n",
            "[Batch 1] Current Loss: 5.8740\n",
            "[Batch 2] Current Loss: 5.1990\n",
            "[Batch 3] Current Loss: 5.3729\n",
            "[Batch 4] Current Loss: 5.5332\n",
            "[Batch 5] Current Loss: 5.4450\n",
            "[Batch 6] Current Loss: 5.6465\n",
            "[Batch 7] Current Loss: 5.6595\n",
            "[Batch 8] Current Loss: 6.0061\n",
            "[Batch 9] Current Loss: 5.4858\n",
            "Ep 4 (Step 029380): Train loss 2.672, Val loss 5.569\n",
            "[Batch 0] Current Loss: 2.4292\n",
            "[Batch 1] Current Loss: 2.5146\n",
            "[Batch 2] Current Loss: 2.5910\n",
            "[Batch 3] Current Loss: 2.1997\n",
            "[Batch 4] Current Loss: 2.5704\n",
            "[Batch 5] Current Loss: 2.5684\n",
            "[Batch 6] Current Loss: 2.5774\n",
            "[Batch 7] Current Loss: 2.1064\n",
            "[Batch 8] Current Loss: 2.3677\n",
            "[Batch 9] Current Loss: 2.4101\n",
            "[Batch 0] Current Loss: 5.1119\n",
            "[Batch 1] Current Loss: 6.2649\n",
            "[Batch 2] Current Loss: 5.2305\n",
            "[Batch 3] Current Loss: 5.9243\n",
            "[Batch 4] Current Loss: 5.0777\n",
            "[Batch 5] Current Loss: 5.6893\n",
            "[Batch 6] Current Loss: 5.4882\n",
            "[Batch 7] Current Loss: 5.6230\n",
            "[Batch 8] Current Loss: 4.3841\n",
            "[Batch 9] Current Loss: 5.2817\n",
            "Ep 4 (Step 029400): Train loss 2.434, Val loss 5.408\n",
            "[Batch 0] Current Loss: 2.8753\n",
            "[Batch 1] Current Loss: 2.1725\n",
            "[Batch 2] Current Loss: 3.8767\n",
            "[Batch 3] Current Loss: 2.3470\n",
            "[Batch 4] Current Loss: 2.5143\n",
            "[Batch 5] Current Loss: 2.3576\n",
            "[Batch 6] Current Loss: 3.2167\n",
            "[Batch 7] Current Loss: 2.0728\n",
            "[Batch 8] Current Loss: 2.8019\n",
            "[Batch 9] Current Loss: 2.7021\n",
            "[Batch 0] Current Loss: 6.6405\n",
            "[Batch 1] Current Loss: 5.2276\n",
            "[Batch 2] Current Loss: 5.5562\n",
            "[Batch 3] Current Loss: 5.6633\n",
            "[Batch 4] Current Loss: 5.0593\n",
            "[Batch 5] Current Loss: 5.6781\n",
            "[Batch 6] Current Loss: 4.8306\n",
            "[Batch 7] Current Loss: 5.4946\n",
            "[Batch 8] Current Loss: 5.3142\n",
            "[Batch 9] Current Loss: 5.3385\n",
            "Ep 4 (Step 029420): Train loss 2.694, Val loss 5.480\n",
            "[Batch 0] Current Loss: 2.7852\n",
            "[Batch 1] Current Loss: 2.7618\n",
            "[Batch 2] Current Loss: 1.9709\n",
            "[Batch 3] Current Loss: 2.3391\n",
            "[Batch 4] Current Loss: 2.5371\n",
            "[Batch 5] Current Loss: 2.1534\n",
            "[Batch 6] Current Loss: 1.8734\n",
            "[Batch 7] Current Loss: 3.0719\n",
            "[Batch 8] Current Loss: 2.7587\n",
            "[Batch 9] Current Loss: 2.6852\n",
            "[Batch 0] Current Loss: 5.3517\n",
            "[Batch 1] Current Loss: 5.1588\n",
            "[Batch 2] Current Loss: 5.2121\n",
            "[Batch 3] Current Loss: 5.8495\n",
            "[Batch 4] Current Loss: 5.3640\n",
            "[Batch 5] Current Loss: 5.1158\n",
            "[Batch 6] Current Loss: 6.0619\n",
            "[Batch 7] Current Loss: 5.2867\n",
            "[Batch 8] Current Loss: 4.9296\n",
            "[Batch 9] Current Loss: 5.7292\n",
            "Ep 4 (Step 029440): Train loss 2.494, Val loss 5.406\n",
            "[Batch 0] Current Loss: 2.1789\n",
            "[Batch 1] Current Loss: 3.7797\n",
            "[Batch 2] Current Loss: 2.7144\n",
            "[Batch 3] Current Loss: 3.0441\n",
            "[Batch 4] Current Loss: 2.8314\n",
            "[Batch 5] Current Loss: 2.7122\n",
            "[Batch 6] Current Loss: 2.7470\n",
            "[Batch 7] Current Loss: 2.3838\n",
            "[Batch 8] Current Loss: 2.3307\n",
            "[Batch 9] Current Loss: 2.4578\n",
            "[Batch 0] Current Loss: 5.3843\n",
            "[Batch 1] Current Loss: 4.6236\n",
            "[Batch 2] Current Loss: 6.2167\n",
            "[Batch 3] Current Loss: 5.0331\n",
            "[Batch 4] Current Loss: 5.1694\n",
            "[Batch 5] Current Loss: 5.3459\n",
            "[Batch 6] Current Loss: 4.9287\n",
            "[Batch 7] Current Loss: 4.9418\n",
            "[Batch 8] Current Loss: 5.9085\n",
            "[Batch 9] Current Loss: 5.8247\n",
            "Ep 4 (Step 029460): Train loss 2.718, Val loss 5.338\n",
            "[Batch 0] Current Loss: 3.5268\n",
            "[Batch 1] Current Loss: 2.7823\n",
            "[Batch 2] Current Loss: 2.2953\n",
            "[Batch 3] Current Loss: 2.3592\n",
            "[Batch 4] Current Loss: 2.5563\n",
            "[Batch 5] Current Loss: 2.4723\n",
            "[Batch 6] Current Loss: 2.8027\n",
            "[Batch 7] Current Loss: 2.7875\n",
            "[Batch 8] Current Loss: 2.5235\n",
            "[Batch 9] Current Loss: 2.2254\n",
            "[Batch 0] Current Loss: 5.7789\n",
            "[Batch 1] Current Loss: 5.1273\n",
            "[Batch 2] Current Loss: 5.0359\n",
            "[Batch 3] Current Loss: 5.9716\n",
            "[Batch 4] Current Loss: 5.6942\n",
            "[Batch 5] Current Loss: 5.4884\n",
            "[Batch 6] Current Loss: 5.3115\n",
            "[Batch 7] Current Loss: 6.1393\n",
            "[Batch 8] Current Loss: 5.8912\n",
            "[Batch 9] Current Loss: 5.8475\n",
            "Ep 4 (Step 029480): Train loss 2.633, Val loss 5.629\n",
            "[Batch 0] Current Loss: 2.4506\n",
            "[Batch 1] Current Loss: 2.8636\n",
            "[Batch 2] Current Loss: 2.5558\n",
            "[Batch 3] Current Loss: 2.9109\n",
            "[Batch 4] Current Loss: 2.6143\n",
            "[Batch 5] Current Loss: 2.2213\n",
            "[Batch 6] Current Loss: 2.5946\n",
            "[Batch 7] Current Loss: 2.7308\n",
            "[Batch 8] Current Loss: 2.3936\n",
            "[Batch 9] Current Loss: 2.6171\n",
            "[Batch 0] Current Loss: 5.2183\n",
            "[Batch 1] Current Loss: 5.9489\n",
            "[Batch 2] Current Loss: 4.7760\n",
            "[Batch 3] Current Loss: 5.0626\n",
            "[Batch 4] Current Loss: 5.3205\n",
            "[Batch 5] Current Loss: 5.3700\n",
            "[Batch 6] Current Loss: 5.7541\n",
            "[Batch 7] Current Loss: 5.6987\n",
            "[Batch 8] Current Loss: 5.6305\n",
            "[Batch 9] Current Loss: 5.1955\n",
            "Ep 4 (Step 029500): Train loss 2.595, Val loss 5.398\n",
            "[Batch 0] Current Loss: 2.9310\n",
            "[Batch 1] Current Loss: 2.3572\n",
            "[Batch 2] Current Loss: 2.2281\n",
            "[Batch 3] Current Loss: 2.0917\n",
            "[Batch 4] Current Loss: 2.8758\n",
            "[Batch 5] Current Loss: 2.4099\n",
            "[Batch 6] Current Loss: 2.6395\n",
            "[Batch 7] Current Loss: 2.7174\n",
            "[Batch 8] Current Loss: 2.4394\n",
            "[Batch 9] Current Loss: 2.6064\n",
            "[Batch 0] Current Loss: 5.2994\n",
            "[Batch 1] Current Loss: 5.8208\n",
            "[Batch 2] Current Loss: 5.6117\n",
            "[Batch 3] Current Loss: 5.8902\n",
            "[Batch 4] Current Loss: 5.5501\n",
            "[Batch 5] Current Loss: 5.6481\n",
            "[Batch 6] Current Loss: 6.1221\n",
            "[Batch 7] Current Loss: 5.5657\n",
            "[Batch 8] Current Loss: 5.3538\n",
            "[Batch 9] Current Loss: 5.0286\n",
            "Ep 4 (Step 029520): Train loss 2.530, Val loss 5.589\n",
            "[Batch 0] Current Loss: 2.5050\n",
            "[Batch 1] Current Loss: 2.9914\n",
            "[Batch 2] Current Loss: 2.7664\n",
            "[Batch 3] Current Loss: 2.4753\n",
            "[Batch 4] Current Loss: 2.5240\n",
            "[Batch 5] Current Loss: 2.3247\n",
            "[Batch 6] Current Loss: 3.2658\n",
            "[Batch 7] Current Loss: 2.0563\n",
            "[Batch 8] Current Loss: 2.9133\n",
            "[Batch 9] Current Loss: 3.0125\n",
            "[Batch 0] Current Loss: 5.8155\n",
            "[Batch 1] Current Loss: 5.3832\n",
            "[Batch 2] Current Loss: 5.7698\n",
            "[Batch 3] Current Loss: 6.2255\n",
            "[Batch 4] Current Loss: 5.1515\n",
            "[Batch 5] Current Loss: 5.8272\n",
            "[Batch 6] Current Loss: 5.9208\n",
            "[Batch 7] Current Loss: 5.8006\n",
            "[Batch 8] Current Loss: 5.5265\n",
            "[Batch 9] Current Loss: 5.9702\n",
            "Ep 4 (Step 029540): Train loss 2.683, Val loss 5.739\n",
            "[Batch 0] Current Loss: 2.8039\n",
            "[Batch 1] Current Loss: 2.4965\n",
            "[Batch 2] Current Loss: 2.4131\n",
            "[Batch 3] Current Loss: 2.5153\n",
            "[Batch 4] Current Loss: 2.3490\n",
            "[Batch 5] Current Loss: 2.7844\n",
            "[Batch 6] Current Loss: 2.9009\n",
            "[Batch 7] Current Loss: 3.0718\n",
            "[Batch 8] Current Loss: 2.7494\n",
            "[Batch 9] Current Loss: 2.6804\n",
            "[Batch 0] Current Loss: 5.6889\n",
            "[Batch 1] Current Loss: 5.2620\n",
            "[Batch 2] Current Loss: 5.4265\n",
            "[Batch 3] Current Loss: 5.1831\n",
            "[Batch 4] Current Loss: 5.7403\n",
            "[Batch 5] Current Loss: 5.2508\n",
            "[Batch 6] Current Loss: 5.1850\n",
            "[Batch 7] Current Loss: 5.9784\n",
            "[Batch 8] Current Loss: 5.9510\n",
            "[Batch 9] Current Loss: 4.8628\n",
            "Ep 4 (Step 029560): Train loss 2.676, Val loss 5.453\n",
            "[Batch 0] Current Loss: 2.7901\n",
            "[Batch 1] Current Loss: 2.4466\n",
            "[Batch 2] Current Loss: 2.2348\n",
            "[Batch 3] Current Loss: 2.2716\n",
            "[Batch 4] Current Loss: 2.7022\n",
            "[Batch 5] Current Loss: 2.6788\n",
            "[Batch 6] Current Loss: 2.3159\n",
            "[Batch 7] Current Loss: 2.7788\n",
            "[Batch 8] Current Loss: 3.1577\n",
            "[Batch 9] Current Loss: 2.7455\n",
            "[Batch 0] Current Loss: 4.7652\n",
            "[Batch 1] Current Loss: 5.7390\n",
            "[Batch 2] Current Loss: 4.9557\n",
            "[Batch 3] Current Loss: 5.4398\n",
            "[Batch 4] Current Loss: 5.2200\n",
            "[Batch 5] Current Loss: 5.0543\n",
            "[Batch 6] Current Loss: 5.4958\n",
            "[Batch 7] Current Loss: 5.2056\n",
            "[Batch 8] Current Loss: 5.0674\n",
            "[Batch 9] Current Loss: 5.9011\n",
            "Ep 4 (Step 029580): Train loss 2.612, Val loss 5.284\n",
            "[Batch 0] Current Loss: 2.5501\n",
            "[Batch 1] Current Loss: 2.1492\n",
            "[Batch 2] Current Loss: 3.2936\n",
            "[Batch 3] Current Loss: 2.3568\n",
            "[Batch 4] Current Loss: 2.4534\n",
            "[Batch 5] Current Loss: 2.6930\n",
            "[Batch 6] Current Loss: 2.1162\n",
            "[Batch 7] Current Loss: 2.7153\n",
            "[Batch 8] Current Loss: 2.8456\n",
            "[Batch 9] Current Loss: 2.4484\n",
            "[Batch 0] Current Loss: 5.2098\n",
            "[Batch 1] Current Loss: 5.8055\n",
            "[Batch 2] Current Loss: 5.4573\n",
            "[Batch 3] Current Loss: 5.6135\n",
            "[Batch 4] Current Loss: 5.8818\n",
            "[Batch 5] Current Loss: 5.6717\n",
            "[Batch 6] Current Loss: 5.8131\n",
            "[Batch 7] Current Loss: 5.4689\n",
            "[Batch 8] Current Loss: 5.6632\n",
            "[Batch 9] Current Loss: 5.8927\n",
            "Ep 4 (Step 029600): Train loss 2.562, Val loss 5.648\n",
            "[Batch 0] Current Loss: 3.3612\n",
            "[Batch 1] Current Loss: 2.3049\n",
            "[Batch 2] Current Loss: 2.8030\n",
            "[Batch 3] Current Loss: 2.5247\n",
            "[Batch 4] Current Loss: 2.6400\n",
            "[Batch 5] Current Loss: 2.4951\n",
            "[Batch 6] Current Loss: 2.6718\n",
            "[Batch 7] Current Loss: 3.0672\n",
            "[Batch 8] Current Loss: 2.4894\n",
            "[Batch 9] Current Loss: 1.8240\n",
            "[Batch 0] Current Loss: 5.7293\n",
            "[Batch 1] Current Loss: 5.3053\n",
            "[Batch 2] Current Loss: 4.9301\n",
            "[Batch 3] Current Loss: 5.1533\n",
            "[Batch 4] Current Loss: 4.8378\n",
            "[Batch 5] Current Loss: 5.1051\n",
            "[Batch 6] Current Loss: 5.2982\n",
            "[Batch 7] Current Loss: 6.1933\n",
            "[Batch 8] Current Loss: 5.0524\n",
            "[Batch 9] Current Loss: 4.8099\n",
            "Ep 4 (Step 029620): Train loss 2.618, Val loss 5.241\n",
            "[Batch 0] Current Loss: 2.5180\n",
            "[Batch 1] Current Loss: 2.5608\n",
            "[Batch 2] Current Loss: 2.4571\n",
            "[Batch 3] Current Loss: 2.2792\n",
            "[Batch 4] Current Loss: 2.9759\n",
            "[Batch 5] Current Loss: 2.5715\n",
            "[Batch 6] Current Loss: 2.6800\n",
            "[Batch 7] Current Loss: 3.2872\n",
            "[Batch 8] Current Loss: 2.0933\n",
            "[Batch 9] Current Loss: 2.5750\n",
            "[Batch 0] Current Loss: 6.0369\n",
            "[Batch 1] Current Loss: 3.7156\n",
            "[Batch 2] Current Loss: 4.8931\n",
            "[Batch 3] Current Loss: 5.9055\n",
            "[Batch 4] Current Loss: 4.5223\n",
            "[Batch 5] Current Loss: 5.0883\n",
            "[Batch 6] Current Loss: 5.5265\n",
            "[Batch 7] Current Loss: 4.7846\n",
            "[Batch 8] Current Loss: 4.8058\n",
            "[Batch 9] Current Loss: 5.6044\n",
            "Ep 4 (Step 029640): Train loss 2.600, Val loss 5.088\n",
            "[Batch 0] Current Loss: 2.4390\n",
            "[Batch 1] Current Loss: 3.0717\n",
            "[Batch 2] Current Loss: 2.9678\n",
            "[Batch 3] Current Loss: 2.5072\n",
            "[Batch 4] Current Loss: 2.8545\n",
            "[Batch 5] Current Loss: 2.0889\n",
            "[Batch 6] Current Loss: 2.7483\n",
            "[Batch 7] Current Loss: 2.4874\n",
            "[Batch 8] Current Loss: 2.2205\n",
            "[Batch 9] Current Loss: 1.9614\n",
            "[Batch 0] Current Loss: 5.3972\n",
            "[Batch 1] Current Loss: 5.6100\n",
            "[Batch 2] Current Loss: 4.6106\n",
            "[Batch 3] Current Loss: 5.3575\n",
            "[Batch 4] Current Loss: 5.7035\n",
            "[Batch 5] Current Loss: 5.7321\n",
            "[Batch 6] Current Loss: 5.4406\n",
            "[Batch 7] Current Loss: 5.9248\n",
            "[Batch 8] Current Loss: 5.8556\n",
            "[Batch 9] Current Loss: 5.4943\n",
            "Ep 4 (Step 029660): Train loss 2.535, Val loss 5.513\n",
            "[Batch 0] Current Loss: 1.8224\n",
            "[Batch 1] Current Loss: 2.8973\n",
            "[Batch 2] Current Loss: 2.8098\n",
            "[Batch 3] Current Loss: 2.7649\n",
            "[Batch 4] Current Loss: 2.1987\n",
            "[Batch 5] Current Loss: 3.1303\n",
            "[Batch 6] Current Loss: 2.3626\n",
            "[Batch 7] Current Loss: 2.8384\n",
            "[Batch 8] Current Loss: 2.3767\n",
            "[Batch 9] Current Loss: 3.0031\n",
            "[Batch 0] Current Loss: 5.9804\n",
            "[Batch 1] Current Loss: 6.0262\n",
            "[Batch 2] Current Loss: 5.7991\n",
            "[Batch 3] Current Loss: 5.9710\n",
            "[Batch 4] Current Loss: 5.5167\n",
            "[Batch 5] Current Loss: 4.6829\n",
            "[Batch 6] Current Loss: 5.6290\n",
            "[Batch 7] Current Loss: 5.2356\n",
            "[Batch 8] Current Loss: 5.9187\n",
            "[Batch 9] Current Loss: 4.8454\n",
            "Ep 4 (Step 029680): Train loss 2.620, Val loss 5.561\n",
            "[Batch 0] Current Loss: 2.2764\n",
            "[Batch 1] Current Loss: 2.8467\n",
            "[Batch 2] Current Loss: 2.6194\n",
            "[Batch 3] Current Loss: 1.9459\n",
            "[Batch 4] Current Loss: 2.3955\n",
            "[Batch 5] Current Loss: 2.0352\n",
            "[Batch 6] Current Loss: 2.0444\n",
            "[Batch 7] Current Loss: 2.6762\n",
            "[Batch 8] Current Loss: 2.7102\n",
            "[Batch 9] Current Loss: 2.5083\n",
            "[Batch 0] Current Loss: 6.1431\n",
            "[Batch 1] Current Loss: 5.9569\n",
            "[Batch 2] Current Loss: 5.5823\n",
            "[Batch 3] Current Loss: 5.2925\n",
            "[Batch 4] Current Loss: 5.7052\n",
            "[Batch 5] Current Loss: 5.7853\n",
            "[Batch 6] Current Loss: 5.4961\n",
            "[Batch 7] Current Loss: 4.8045\n",
            "[Batch 8] Current Loss: 5.0782\n",
            "[Batch 9] Current Loss: 4.3025\n",
            "Ep 4 (Step 029700): Train loss 2.406, Val loss 5.415\n",
            "[Batch 0] Current Loss: 2.5252\n",
            "[Batch 1] Current Loss: 2.8817\n",
            "[Batch 2] Current Loss: 2.3899\n",
            "[Batch 3] Current Loss: 2.7907\n",
            "[Batch 4] Current Loss: 1.9444\n",
            "[Batch 5] Current Loss: 2.6818\n",
            "[Batch 6] Current Loss: 2.5574\n",
            "[Batch 7] Current Loss: 2.3058\n",
            "[Batch 8] Current Loss: 2.3974\n",
            "[Batch 9] Current Loss: 1.8530\n",
            "[Batch 0] Current Loss: 5.6706\n",
            "[Batch 1] Current Loss: 5.7635\n",
            "[Batch 2] Current Loss: 5.1451\n",
            "[Batch 3] Current Loss: 5.3235\n",
            "[Batch 4] Current Loss: 5.7013\n",
            "[Batch 5] Current Loss: 6.4630\n",
            "[Batch 6] Current Loss: 5.5353\n",
            "[Batch 7] Current Loss: 5.8516\n",
            "[Batch 8] Current Loss: 6.4045\n",
            "[Batch 9] Current Loss: 5.0753\n",
            "Ep 4 (Step 029720): Train loss 2.433, Val loss 5.693\n",
            "[Batch 0] Current Loss: 2.4574\n",
            "[Batch 1] Current Loss: 2.8893\n",
            "[Batch 2] Current Loss: 2.5773\n",
            "[Batch 3] Current Loss: 2.0933\n",
            "[Batch 4] Current Loss: 2.8476\n",
            "[Batch 5] Current Loss: 2.6021\n",
            "[Batch 6] Current Loss: 2.4779\n",
            "[Batch 7] Current Loss: 2.4448\n",
            "[Batch 8] Current Loss: 2.8855\n",
            "[Batch 9] Current Loss: 2.3824\n",
            "[Batch 0] Current Loss: 5.1266\n",
            "[Batch 1] Current Loss: 4.7459\n",
            "[Batch 2] Current Loss: 6.2816\n",
            "[Batch 3] Current Loss: 5.1821\n",
            "[Batch 4] Current Loss: 5.2375\n",
            "[Batch 5] Current Loss: 5.3026\n",
            "[Batch 6] Current Loss: 4.8438\n",
            "[Batch 7] Current Loss: 5.6343\n",
            "[Batch 8] Current Loss: 5.3040\n",
            "[Batch 9] Current Loss: 5.3541\n",
            "Ep 4 (Step 029740): Train loss 2.566, Val loss 5.301\n",
            "[Batch 0] Current Loss: 2.0672\n",
            "[Batch 1] Current Loss: 2.4742\n",
            "[Batch 2] Current Loss: 2.5786\n",
            "[Batch 3] Current Loss: 2.8161\n",
            "[Batch 4] Current Loss: 2.7703\n",
            "[Batch 5] Current Loss: 2.7093\n",
            "[Batch 6] Current Loss: 2.3718\n",
            "[Batch 7] Current Loss: 2.7495\n",
            "[Batch 8] Current Loss: 2.3069\n",
            "[Batch 9] Current Loss: 2.6930\n",
            "[Batch 0] Current Loss: 5.4705\n",
            "[Batch 1] Current Loss: 4.7399\n",
            "[Batch 2] Current Loss: 4.6306\n",
            "[Batch 3] Current Loss: 4.7084\n",
            "[Batch 4] Current Loss: 5.0316\n",
            "[Batch 5] Current Loss: 5.0262\n",
            "[Batch 6] Current Loss: 5.8137\n",
            "[Batch 7] Current Loss: 5.0969\n",
            "[Batch 8] Current Loss: 5.4297\n",
            "[Batch 9] Current Loss: 4.6224\n",
            "Ep 4 (Step 029760): Train loss 2.554, Val loss 5.057\n",
            "[Batch 0] Current Loss: 2.7370\n",
            "[Batch 1] Current Loss: 2.5467\n",
            "[Batch 2] Current Loss: 1.9747\n",
            "[Batch 3] Current Loss: 2.3233\n",
            "[Batch 4] Current Loss: 2.5560\n",
            "[Batch 5] Current Loss: 2.3781\n",
            "[Batch 6] Current Loss: 3.0344\n",
            "[Batch 7] Current Loss: 2.3595\n",
            "[Batch 8] Current Loss: 2.2043\n",
            "[Batch 9] Current Loss: 2.1388\n",
            "[Batch 0] Current Loss: 5.9434\n",
            "[Batch 1] Current Loss: 4.8106\n",
            "[Batch 2] Current Loss: 5.8549\n",
            "[Batch 3] Current Loss: 4.8901\n",
            "[Batch 4] Current Loss: 5.7910\n",
            "[Batch 5] Current Loss: 4.9073\n",
            "[Batch 6] Current Loss: 5.5620\n",
            "[Batch 7] Current Loss: 5.9008\n",
            "[Batch 8] Current Loss: 5.4434\n",
            "[Batch 9] Current Loss: 5.0549\n",
            "Ep 4 (Step 029780): Train loss 2.425, Val loss 5.416\n",
            "[Batch 0] Current Loss: 3.3670\n",
            "[Batch 1] Current Loss: 2.3765\n",
            "[Batch 2] Current Loss: 2.8754\n",
            "[Batch 3] Current Loss: 2.7985\n",
            "[Batch 4] Current Loss: 1.9654\n",
            "[Batch 5] Current Loss: 2.5071\n",
            "[Batch 6] Current Loss: 2.2807\n",
            "[Batch 7] Current Loss: 2.4951\n",
            "[Batch 8] Current Loss: 2.3392\n",
            "[Batch 9] Current Loss: 2.6575\n",
            "[Batch 0] Current Loss: 5.2356\n",
            "[Batch 1] Current Loss: 5.2343\n",
            "[Batch 2] Current Loss: 5.9773\n",
            "[Batch 3] Current Loss: 5.1791\n",
            "[Batch 4] Current Loss: 5.4192\n",
            "[Batch 5] Current Loss: 5.9538\n",
            "[Batch 6] Current Loss: 5.7337\n",
            "[Batch 7] Current Loss: 5.9074\n",
            "[Batch 8] Current Loss: 5.1986\n",
            "[Batch 9] Current Loss: 4.8393\n",
            "Ep 4 (Step 029800): Train loss 2.566, Val loss 5.468\n",
            "[Batch 0] Current Loss: 2.7752\n",
            "[Batch 1] Current Loss: 3.0655\n",
            "[Batch 2] Current Loss: 2.2189\n",
            "[Batch 3] Current Loss: 2.1959\n",
            "[Batch 4] Current Loss: 2.9383\n",
            "[Batch 5] Current Loss: 2.9719\n",
            "[Batch 6] Current Loss: 2.7655\n",
            "[Batch 7] Current Loss: 2.4818\n",
            "[Batch 8] Current Loss: 2.5926\n",
            "[Batch 9] Current Loss: 2.7744\n",
            "[Batch 0] Current Loss: 5.6019\n",
            "[Batch 1] Current Loss: 5.0341\n",
            "[Batch 2] Current Loss: 5.6078\n",
            "[Batch 3] Current Loss: 6.1108\n",
            "[Batch 4] Current Loss: 5.7784\n",
            "[Batch 5] Current Loss: 5.3997\n",
            "[Batch 6] Current Loss: 6.0607\n",
            "[Batch 7] Current Loss: 5.9493\n",
            "[Batch 8] Current Loss: 5.6831\n",
            "[Batch 9] Current Loss: 5.9925\n",
            "Ep 4 (Step 029820): Train loss 2.678, Val loss 5.722\n",
            "[Batch 0] Current Loss: 2.5031\n",
            "[Batch 1] Current Loss: 3.0397\n",
            "[Batch 2] Current Loss: 2.1965\n",
            "[Batch 3] Current Loss: 2.0198\n",
            "[Batch 4] Current Loss: 2.1877\n",
            "[Batch 5] Current Loss: 1.8957\n",
            "[Batch 6] Current Loss: 2.6148\n",
            "[Batch 7] Current Loss: 1.9827\n",
            "[Batch 8] Current Loss: 2.4059\n",
            "[Batch 9] Current Loss: 2.1711\n",
            "[Batch 0] Current Loss: 4.9041\n",
            "[Batch 1] Current Loss: 5.5114\n",
            "[Batch 2] Current Loss: 5.0663\n",
            "[Batch 3] Current Loss: 4.5750\n",
            "[Batch 4] Current Loss: 5.7781\n",
            "[Batch 5] Current Loss: 4.7708\n",
            "[Batch 6] Current Loss: 5.2657\n",
            "[Batch 7] Current Loss: 5.7903\n",
            "[Batch 8] Current Loss: 5.5264\n",
            "[Batch 9] Current Loss: 5.5436\n",
            "Ep 4 (Step 029840): Train loss 2.302, Val loss 5.273\n",
            "[Batch 0] Current Loss: 2.1520\n",
            "[Batch 1] Current Loss: 2.7871\n",
            "[Batch 2] Current Loss: 2.8680\n",
            "[Batch 3] Current Loss: 2.8069\n",
            "[Batch 4] Current Loss: 2.8104\n",
            "[Batch 5] Current Loss: 2.4600\n",
            "[Batch 6] Current Loss: 2.3506\n",
            "[Batch 7] Current Loss: 2.5190\n",
            "[Batch 8] Current Loss: 2.4255\n",
            "[Batch 9] Current Loss: 2.4720\n",
            "[Batch 0] Current Loss: 5.0334\n",
            "[Batch 1] Current Loss: 5.0414\n",
            "[Batch 2] Current Loss: 5.3324\n",
            "[Batch 3] Current Loss: 5.0734\n",
            "[Batch 4] Current Loss: 4.8252\n",
            "[Batch 5] Current Loss: 5.2070\n",
            "[Batch 6] Current Loss: 6.0115\n",
            "[Batch 7] Current Loss: 4.7574\n",
            "[Batch 8] Current Loss: 5.8161\n",
            "[Batch 9] Current Loss: 5.1907\n",
            "Ep 4 (Step 029860): Train loss 2.565, Val loss 5.229\n",
            "[Batch 0] Current Loss: 2.6050\n",
            "[Batch 1] Current Loss: 2.1269\n",
            "[Batch 2] Current Loss: 2.2049\n",
            "[Batch 3] Current Loss: 2.3090\n",
            "[Batch 4] Current Loss: 2.0491\n",
            "[Batch 5] Current Loss: 2.9075\n",
            "[Batch 6] Current Loss: 2.9461\n",
            "[Batch 7] Current Loss: 2.4466\n",
            "[Batch 8] Current Loss: 2.1496\n",
            "[Batch 9] Current Loss: 2.1643\n",
            "[Batch 0] Current Loss: 5.4574\n",
            "[Batch 1] Current Loss: 5.4084\n",
            "[Batch 2] Current Loss: 5.5509\n",
            "[Batch 3] Current Loss: 5.6837\n",
            "[Batch 4] Current Loss: 4.7442\n",
            "[Batch 5] Current Loss: 5.7018\n",
            "[Batch 6] Current Loss: 5.5073\n",
            "[Batch 7] Current Loss: 5.3672\n",
            "[Batch 8] Current Loss: 4.5235\n",
            "[Batch 9] Current Loss: 5.3228\n",
            "Ep 4 (Step 029880): Train loss 2.391, Val loss 5.327\n",
            "[Batch 0] Current Loss: 2.2234\n",
            "[Batch 1] Current Loss: 3.0626\n",
            "[Batch 2] Current Loss: 2.3772\n",
            "[Batch 3] Current Loss: 2.1426\n",
            "[Batch 4] Current Loss: 1.9278\n",
            "[Batch 5] Current Loss: 2.7485\n",
            "[Batch 6] Current Loss: 3.2168\n",
            "[Batch 7] Current Loss: 2.6457\n",
            "[Batch 8] Current Loss: 2.2773\n",
            "[Batch 9] Current Loss: 2.8669\n",
            "[Batch 0] Current Loss: 5.4734\n",
            "[Batch 1] Current Loss: 5.5785\n",
            "[Batch 2] Current Loss: 4.4887\n",
            "[Batch 3] Current Loss: 5.4488\n",
            "[Batch 4] Current Loss: 5.0646\n",
            "[Batch 5] Current Loss: 4.7481\n",
            "[Batch 6] Current Loss: 5.2169\n",
            "[Batch 7] Current Loss: 5.8444\n",
            "[Batch 8] Current Loss: 5.5212\n",
            "[Batch 9] Current Loss: 4.3358\n",
            "Ep 4 (Step 029900): Train loss 2.549, Val loss 5.172\n",
            "[Batch 0] Current Loss: 2.4318\n",
            "[Batch 1] Current Loss: 1.8708\n",
            "[Batch 2] Current Loss: 2.8018\n",
            "[Batch 3] Current Loss: 2.3491\n",
            "[Batch 4] Current Loss: 1.9835\n",
            "[Batch 5] Current Loss: 2.7631\n",
            "[Batch 6] Current Loss: 2.4763\n",
            "[Batch 7] Current Loss: 2.4495\n",
            "[Batch 8] Current Loss: 3.3301\n",
            "[Batch 9] Current Loss: 2.5213\n",
            "[Batch 0] Current Loss: 6.0559\n",
            "[Batch 1] Current Loss: 5.8240\n",
            "[Batch 2] Current Loss: 6.0097\n",
            "[Batch 3] Current Loss: 5.3322\n",
            "[Batch 4] Current Loss: 4.9414\n",
            "[Batch 5] Current Loss: 6.7993\n",
            "[Batch 6] Current Loss: 5.7320\n",
            "[Batch 7] Current Loss: 5.6831\n",
            "[Batch 8] Current Loss: 5.7486\n",
            "[Batch 9] Current Loss: 5.8349\n",
            "Ep 4 (Step 029920): Train loss 2.498, Val loss 5.796\n",
            "[Batch 0] Current Loss: 2.1069\n",
            "[Batch 1] Current Loss: 2.2121\n",
            "[Batch 2] Current Loss: 3.0449\n",
            "[Batch 3] Current Loss: 3.1395\n",
            "[Batch 4] Current Loss: 2.2248\n",
            "[Batch 5] Current Loss: 1.8736\n",
            "[Batch 6] Current Loss: 2.7586\n",
            "[Batch 7] Current Loss: 2.7230\n",
            "[Batch 8] Current Loss: 2.6889\n",
            "[Batch 9] Current Loss: 2.5537\n",
            "[Batch 0] Current Loss: 5.7225\n",
            "[Batch 1] Current Loss: 6.0009\n",
            "[Batch 2] Current Loss: 6.3950\n",
            "[Batch 3] Current Loss: 5.7555\n",
            "[Batch 4] Current Loss: 4.8358\n",
            "[Batch 5] Current Loss: 6.1926\n",
            "[Batch 6] Current Loss: 5.0835\n",
            "[Batch 7] Current Loss: 5.7997\n",
            "[Batch 8] Current Loss: 5.7050\n",
            "[Batch 9] Current Loss: 5.3155\n",
            "Ep 4 (Step 029940): Train loss 2.533, Val loss 5.681\n",
            "[Batch 0] Current Loss: 3.1280\n",
            "[Batch 1] Current Loss: 2.9193\n",
            "[Batch 2] Current Loss: 3.0609\n",
            "[Batch 3] Current Loss: 2.3531\n",
            "[Batch 4] Current Loss: 3.2862\n",
            "[Batch 5] Current Loss: 3.2116\n",
            "[Batch 6] Current Loss: 2.0550\n",
            "[Batch 7] Current Loss: 2.1562\n",
            "[Batch 8] Current Loss: 2.5576\n",
            "[Batch 9] Current Loss: 2.8955\n",
            "[Batch 0] Current Loss: 5.9037\n",
            "[Batch 1] Current Loss: 5.4229\n",
            "[Batch 2] Current Loss: 5.4275\n",
            "[Batch 3] Current Loss: 5.2259\n",
            "[Batch 4] Current Loss: 4.4995\n",
            "[Batch 5] Current Loss: 5.2939\n",
            "[Batch 6] Current Loss: 5.3740\n",
            "[Batch 7] Current Loss: 5.6564\n",
            "[Batch 8] Current Loss: 5.3507\n",
            "[Batch 9] Current Loss: 5.6930\n",
            "Ep 4 (Step 029960): Train loss 2.762, Val loss 5.385\n",
            "[Batch 0] Current Loss: 2.7504\n",
            "[Batch 1] Current Loss: 2.7352\n",
            "[Batch 2] Current Loss: 2.7560\n",
            "[Batch 3] Current Loss: 1.7489\n",
            "[Batch 4] Current Loss: 2.2883\n",
            "[Batch 5] Current Loss: 2.6840\n",
            "[Batch 6] Current Loss: 2.8278\n",
            "[Batch 7] Current Loss: 2.8130\n",
            "[Batch 8] Current Loss: 2.3642\n",
            "[Batch 9] Current Loss: 3.2629\n",
            "[Batch 0] Current Loss: 6.1107\n",
            "[Batch 1] Current Loss: 5.4810\n",
            "[Batch 2] Current Loss: 5.4055\n",
            "[Batch 3] Current Loss: 5.3906\n",
            "[Batch 4] Current Loss: 5.2975\n",
            "[Batch 5] Current Loss: 6.4271\n",
            "[Batch 6] Current Loss: 5.3933\n",
            "[Batch 7] Current Loss: 5.5345\n",
            "[Batch 8] Current Loss: 5.8999\n",
            "[Batch 9] Current Loss: 5.2354\n",
            "Ep 4 (Step 029980): Train loss 2.623, Val loss 5.618\n",
            "[Batch 0] Current Loss: 2.6963\n",
            "[Batch 1] Current Loss: 2.6888\n",
            "[Batch 2] Current Loss: 3.2432\n",
            "[Batch 3] Current Loss: 2.9640\n",
            "[Batch 4] Current Loss: 3.1598\n",
            "[Batch 5] Current Loss: 2.4229\n",
            "[Batch 6] Current Loss: 2.4018\n",
            "[Batch 7] Current Loss: 2.4471\n",
            "[Batch 8] Current Loss: 2.6871\n",
            "[Batch 9] Current Loss: 1.6159\n",
            "[Batch 0] Current Loss: 5.5229\n",
            "[Batch 1] Current Loss: 5.7751\n",
            "[Batch 2] Current Loss: 5.8352\n",
            "[Batch 3] Current Loss: 5.3559\n",
            "[Batch 4] Current Loss: 5.8266\n",
            "[Batch 5] Current Loss: 4.5103\n",
            "[Batch 6] Current Loss: 5.4224\n",
            "[Batch 7] Current Loss: 4.7867\n",
            "[Batch 8] Current Loss: 5.3651\n",
            "[Batch 9] Current Loss: 4.9510\n",
            "Ep 4 (Step 030000): Train loss 2.633, Val loss 5.335\n",
            "[Batch 0] Current Loss: 2.4979\n",
            "[Batch 1] Current Loss: 1.9602\n",
            "[Batch 2] Current Loss: 3.3969\n",
            "[Batch 3] Current Loss: 1.9253\n",
            "[Batch 4] Current Loss: 2.8080\n",
            "[Batch 5] Current Loss: 2.8505\n",
            "[Batch 6] Current Loss: 3.3097\n",
            "[Batch 7] Current Loss: 2.5642\n",
            "[Batch 8] Current Loss: 1.9504\n",
            "[Batch 9] Current Loss: 2.5145\n",
            "[Batch 0] Current Loss: 5.7305\n",
            "[Batch 1] Current Loss: 5.1304\n",
            "[Batch 2] Current Loss: 5.2317\n",
            "[Batch 3] Current Loss: 5.4585\n",
            "[Batch 4] Current Loss: 5.9715\n",
            "[Batch 5] Current Loss: 5.6468\n",
            "[Batch 6] Current Loss: 5.0141\n",
            "[Batch 7] Current Loss: 5.1840\n",
            "[Batch 8] Current Loss: 5.1917\n",
            "[Batch 9] Current Loss: 6.3818\n",
            "Ep 4 (Step 030020): Train loss 2.578, Val loss 5.494\n",
            "[Batch 0] Current Loss: 2.3992\n",
            "[Batch 1] Current Loss: 2.5899\n",
            "[Batch 2] Current Loss: 2.5081\n",
            "[Batch 3] Current Loss: 2.0644\n",
            "[Batch 4] Current Loss: 2.2488\n",
            "[Batch 5] Current Loss: 2.1506\n",
            "[Batch 6] Current Loss: 2.4306\n",
            "[Batch 7] Current Loss: 2.1307\n",
            "[Batch 8] Current Loss: 3.0284\n",
            "[Batch 9] Current Loss: 2.6971\n",
            "[Batch 0] Current Loss: 6.2615\n",
            "[Batch 1] Current Loss: 6.1254\n",
            "[Batch 2] Current Loss: 6.4030\n",
            "[Batch 3] Current Loss: 5.0715\n",
            "[Batch 4] Current Loss: 5.5558\n",
            "[Batch 5] Current Loss: 4.8066\n",
            "[Batch 6] Current Loss: 4.7601\n",
            "[Batch 7] Current Loss: 5.9323\n",
            "[Batch 8] Current Loss: 5.8829\n",
            "[Batch 9] Current Loss: 4.7265\n",
            "Ep 4 (Step 030040): Train loss 2.425, Val loss 5.553\n",
            "[Batch 0] Current Loss: 2.9888\n",
            "[Batch 1] Current Loss: 2.6724\n",
            "[Batch 2] Current Loss: 2.2139\n",
            "[Batch 3] Current Loss: 2.7550\n",
            "[Batch 4] Current Loss: 2.9836\n",
            "[Batch 5] Current Loss: 2.2514\n",
            "[Batch 6] Current Loss: 2.4276\n",
            "[Batch 7] Current Loss: 2.4089\n",
            "[Batch 8] Current Loss: 1.8628\n",
            "[Batch 9] Current Loss: 2.5159\n",
            "[Batch 0] Current Loss: 5.3303\n",
            "[Batch 1] Current Loss: 5.6008\n",
            "[Batch 2] Current Loss: 5.2366\n",
            "[Batch 3] Current Loss: 5.9132\n",
            "[Batch 4] Current Loss: 5.4246\n",
            "[Batch 5] Current Loss: 5.9092\n",
            "[Batch 6] Current Loss: 5.7259\n",
            "[Batch 7] Current Loss: 5.2963\n",
            "[Batch 8] Current Loss: 5.6771\n",
            "[Batch 9] Current Loss: 5.4225\n",
            "Ep 4 (Step 030060): Train loss 2.508, Val loss 5.554\n",
            "[Batch 0] Current Loss: 2.6947\n",
            "[Batch 1] Current Loss: 2.4397\n",
            "[Batch 2] Current Loss: 3.0842\n",
            "[Batch 3] Current Loss: 2.4499\n",
            "[Batch 4] Current Loss: 2.7583\n",
            "[Batch 5] Current Loss: 2.4635\n",
            "[Batch 6] Current Loss: 2.6493\n",
            "[Batch 7] Current Loss: 2.7697\n",
            "[Batch 8] Current Loss: 3.1733\n",
            "[Batch 9] Current Loss: 2.9507\n",
            "[Batch 0] Current Loss: 4.6447\n",
            "[Batch 1] Current Loss: 5.5240\n",
            "[Batch 2] Current Loss: 5.7114\n",
            "[Batch 3] Current Loss: 4.4558\n",
            "[Batch 4] Current Loss: 5.9173\n",
            "[Batch 5] Current Loss: 6.1640\n",
            "[Batch 6] Current Loss: 5.9188\n",
            "[Batch 7] Current Loss: 5.0056\n",
            "[Batch 8] Current Loss: 5.1113\n",
            "[Batch 9] Current Loss: 5.7624\n",
            "Ep 4 (Step 030080): Train loss 2.743, Val loss 5.422\n",
            "[Batch 0] Current Loss: 2.3863\n",
            "[Batch 1] Current Loss: 2.1099\n",
            "[Batch 2] Current Loss: 2.0990\n",
            "[Batch 3] Current Loss: 2.6232\n",
            "[Batch 4] Current Loss: 2.9102\n",
            "[Batch 5] Current Loss: 2.5312\n",
            "[Batch 6] Current Loss: 2.7685\n",
            "[Batch 7] Current Loss: 2.9111\n",
            "[Batch 8] Current Loss: 2.4372\n",
            "[Batch 9] Current Loss: 2.2139\n",
            "[Batch 0] Current Loss: 6.1095\n",
            "[Batch 1] Current Loss: 4.2296\n",
            "[Batch 2] Current Loss: 5.7971\n",
            "[Batch 3] Current Loss: 4.4344\n",
            "[Batch 4] Current Loss: 5.0166\n",
            "[Batch 5] Current Loss: 5.5266\n",
            "[Batch 6] Current Loss: 4.6959\n",
            "[Batch 7] Current Loss: 5.9515\n",
            "[Batch 8] Current Loss: 5.0772\n",
            "[Batch 9] Current Loss: 4.5431\n",
            "Ep 4 (Step 030100): Train loss 2.499, Val loss 5.138\n",
            "[Batch 0] Current Loss: 2.6866\n",
            "[Batch 1] Current Loss: 2.8068\n",
            "[Batch 2] Current Loss: 1.8507\n",
            "[Batch 3] Current Loss: 2.0565\n",
            "[Batch 4] Current Loss: 2.9658\n",
            "[Batch 5] Current Loss: 2.8874\n",
            "[Batch 6] Current Loss: 2.7398\n",
            "[Batch 7] Current Loss: 2.4294\n",
            "[Batch 8] Current Loss: 1.9220\n",
            "[Batch 9] Current Loss: 2.3218\n",
            "[Batch 0] Current Loss: 5.8227\n",
            "[Batch 1] Current Loss: 5.4185\n",
            "[Batch 2] Current Loss: 5.2909\n",
            "[Batch 3] Current Loss: 5.0604\n",
            "[Batch 4] Current Loss: 4.6658\n",
            "[Batch 5] Current Loss: 4.9752\n",
            "[Batch 6] Current Loss: 5.3624\n",
            "[Batch 7] Current Loss: 5.6598\n",
            "[Batch 8] Current Loss: 5.5495\n",
            "[Batch 9] Current Loss: 6.0576\n",
            "Ep 4 (Step 030120): Train loss 2.467, Val loss 5.386\n",
            "[Batch 0] Current Loss: 2.1184\n",
            "[Batch 1] Current Loss: 2.1779\n",
            "[Batch 2] Current Loss: 2.2653\n",
            "[Batch 3] Current Loss: 3.1164\n",
            "[Batch 4] Current Loss: 2.1383\n",
            "[Batch 5] Current Loss: 3.1418\n",
            "[Batch 6] Current Loss: 3.0835\n",
            "[Batch 7] Current Loss: 2.0244\n",
            "[Batch 8] Current Loss: 2.8934\n",
            "[Batch 9] Current Loss: 3.0279\n",
            "[Batch 0] Current Loss: 5.1274\n",
            "[Batch 1] Current Loss: 4.9839\n",
            "[Batch 2] Current Loss: 5.8948\n",
            "[Batch 3] Current Loss: 5.3134\n",
            "[Batch 4] Current Loss: 5.2492\n",
            "[Batch 5] Current Loss: 5.6224\n",
            "[Batch 6] Current Loss: 5.8865\n",
            "[Batch 7] Current Loss: 6.1051\n",
            "[Batch 8] Current Loss: 5.7173\n",
            "[Batch 9] Current Loss: 5.2328\n",
            "Ep 4 (Step 030140): Train loss 2.599, Val loss 5.513\n",
            "[Batch 0] Current Loss: 2.6324\n",
            "[Batch 1] Current Loss: 2.1213\n",
            "[Batch 2] Current Loss: 3.0116\n",
            "[Batch 3] Current Loss: 2.0322\n",
            "[Batch 4] Current Loss: 2.2149\n",
            "[Batch 5] Current Loss: 2.8278\n",
            "[Batch 6] Current Loss: 2.5821\n",
            "[Batch 7] Current Loss: 2.7297\n",
            "[Batch 8] Current Loss: 2.3372\n",
            "[Batch 9] Current Loss: 2.5235\n",
            "[Batch 0] Current Loss: 5.7580\n",
            "[Batch 1] Current Loss: 5.1862\n",
            "[Batch 2] Current Loss: 5.2424\n",
            "[Batch 3] Current Loss: 6.5234\n",
            "[Batch 4] Current Loss: 4.9051\n",
            "[Batch 5] Current Loss: 5.5519\n",
            "[Batch 6] Current Loss: 5.2138\n",
            "[Batch 7] Current Loss: 5.6514\n",
            "[Batch 8] Current Loss: 5.2493\n",
            "[Batch 9] Current Loss: 5.2901\n",
            "Ep 4 (Step 030160): Train loss 2.501, Val loss 5.457\n",
            "[Batch 0] Current Loss: 2.7206\n",
            "[Batch 1] Current Loss: 2.7020\n",
            "[Batch 2] Current Loss: 2.7604\n",
            "[Batch 3] Current Loss: 2.3297\n",
            "[Batch 4] Current Loss: 2.3431\n",
            "[Batch 5] Current Loss: 2.1094\n",
            "[Batch 6] Current Loss: 2.4253\n",
            "[Batch 7] Current Loss: 2.2072\n",
            "[Batch 8] Current Loss: 2.5497\n",
            "[Batch 9] Current Loss: 3.1735\n",
            "[Batch 0] Current Loss: 5.8639\n",
            "[Batch 1] Current Loss: 5.2805\n",
            "[Batch 2] Current Loss: 5.0270\n",
            "[Batch 3] Current Loss: 5.9044\n",
            "[Batch 4] Current Loss: 4.2075\n",
            "[Batch 5] Current Loss: 5.3646\n",
            "[Batch 6] Current Loss: 5.6891\n",
            "[Batch 7] Current Loss: 5.5038\n",
            "[Batch 8] Current Loss: 6.4250\n",
            "[Batch 9] Current Loss: 5.0377\n",
            "Ep 4 (Step 030180): Train loss 2.532, Val loss 5.430\n",
            "[Batch 0] Current Loss: 2.3956\n",
            "[Batch 1] Current Loss: 2.4695\n",
            "[Batch 2] Current Loss: 2.5314\n",
            "[Batch 3] Current Loss: 2.9049\n",
            "[Batch 4] Current Loss: 2.1069\n",
            "[Batch 5] Current Loss: 2.3435\n",
            "[Batch 6] Current Loss: 1.8430\n",
            "[Batch 7] Current Loss: 2.4849\n",
            "[Batch 8] Current Loss: 2.9469\n",
            "[Batch 9] Current Loss: 2.2487\n",
            "[Batch 0] Current Loss: 5.6758\n",
            "[Batch 1] Current Loss: 4.7068\n",
            "[Batch 2] Current Loss: 5.2704\n",
            "[Batch 3] Current Loss: 5.5503\n",
            "[Batch 4] Current Loss: 5.9817\n",
            "[Batch 5] Current Loss: 5.7401\n",
            "[Batch 6] Current Loss: 5.2661\n",
            "[Batch 7] Current Loss: 5.4468\n",
            "[Batch 8] Current Loss: 4.8424\n",
            "[Batch 9] Current Loss: 5.5210\n",
            "Ep 4 (Step 030200): Train loss 2.428, Val loss 5.400\n",
            "[Batch 0] Current Loss: 2.2106\n",
            "[Batch 1] Current Loss: 2.4055\n",
            "[Batch 2] Current Loss: 2.2729\n",
            "[Batch 3] Current Loss: 2.4674\n",
            "[Batch 4] Current Loss: 3.4915\n",
            "[Batch 5] Current Loss: 2.1686\n",
            "[Batch 6] Current Loss: 2.6639\n",
            "[Batch 7] Current Loss: 2.0956\n",
            "[Batch 8] Current Loss: 2.7344\n",
            "[Batch 9] Current Loss: 2.7066\n",
            "[Batch 0] Current Loss: 5.3652\n",
            "[Batch 1] Current Loss: 6.2498\n",
            "[Batch 2] Current Loss: 5.4283\n",
            "[Batch 3] Current Loss: 5.5037\n",
            "[Batch 4] Current Loss: 5.0329\n",
            "[Batch 5] Current Loss: 5.0326\n",
            "[Batch 6] Current Loss: 6.0826\n",
            "[Batch 7] Current Loss: 5.2119\n",
            "[Batch 8] Current Loss: 6.1135\n",
            "[Batch 9] Current Loss: 5.6762\n",
            "Ep 4 (Step 030220): Train loss 2.522, Val loss 5.570\n",
            "[Batch 0] Current Loss: 2.1665\n",
            "[Batch 1] Current Loss: 2.4052\n",
            "[Batch 2] Current Loss: 2.3361\n",
            "[Batch 3] Current Loss: 2.2952\n",
            "[Batch 4] Current Loss: 2.9354\n",
            "[Batch 5] Current Loss: 2.6384\n",
            "[Batch 6] Current Loss: 2.0614\n",
            "[Batch 7] Current Loss: 2.2509\n",
            "[Batch 8] Current Loss: 2.0716\n",
            "[Batch 9] Current Loss: 2.4954\n",
            "[Batch 0] Current Loss: 5.8947\n",
            "[Batch 1] Current Loss: 5.2025\n",
            "[Batch 2] Current Loss: 6.1720\n",
            "[Batch 3] Current Loss: 5.6005\n",
            "[Batch 4] Current Loss: 5.7404\n",
            "[Batch 5] Current Loss: 5.0656\n",
            "[Batch 6] Current Loss: 5.2741\n",
            "[Batch 7] Current Loss: 5.1641\n",
            "[Batch 8] Current Loss: 4.7151\n",
            "[Batch 9] Current Loss: 5.9138\n",
            "Ep 4 (Step 030240): Train loss 2.366, Val loss 5.474\n",
            "[Batch 0] Current Loss: 2.0443\n",
            "[Batch 1] Current Loss: 2.4654\n",
            "[Batch 2] Current Loss: 2.4342\n",
            "[Batch 3] Current Loss: 2.7619\n",
            "[Batch 4] Current Loss: 2.5489\n",
            "[Batch 5] Current Loss: 2.3178\n",
            "[Batch 6] Current Loss: 3.2971\n",
            "[Batch 7] Current Loss: 2.2218\n",
            "[Batch 8] Current Loss: 2.4020\n",
            "[Batch 9] Current Loss: 2.7200\n",
            "[Batch 0] Current Loss: 5.2062\n",
            "[Batch 1] Current Loss: 5.2854\n",
            "[Batch 2] Current Loss: 5.8221\n",
            "[Batch 3] Current Loss: 5.2374\n",
            "[Batch 4] Current Loss: 5.6380\n",
            "[Batch 5] Current Loss: 5.9679\n",
            "[Batch 6] Current Loss: 5.4134\n",
            "[Batch 7] Current Loss: 5.7833\n",
            "[Batch 8] Current Loss: 5.7095\n",
            "[Batch 9] Current Loss: 5.7202\n",
            "Ep 4 (Step 030260): Train loss 2.521, Val loss 5.578\n",
            "[Batch 0] Current Loss: 3.2362\n",
            "[Batch 1] Current Loss: 2.1251\n",
            "[Batch 2] Current Loss: 3.1438\n",
            "[Batch 3] Current Loss: 2.9585\n",
            "[Batch 4] Current Loss: 2.4248\n",
            "[Batch 5] Current Loss: 2.1395\n",
            "[Batch 6] Current Loss: 2.5228\n",
            "[Batch 7] Current Loss: 2.7071\n",
            "[Batch 8] Current Loss: 2.5777\n",
            "[Batch 9] Current Loss: 2.5508\n",
            "[Batch 0] Current Loss: 6.3840\n",
            "[Batch 1] Current Loss: 5.3642\n",
            "[Batch 2] Current Loss: 4.6639\n",
            "[Batch 3] Current Loss: 5.3480\n",
            "[Batch 4] Current Loss: 4.6550\n",
            "[Batch 5] Current Loss: 5.2341\n",
            "[Batch 6] Current Loss: 5.7784\n",
            "[Batch 7] Current Loss: 4.4538\n",
            "[Batch 8] Current Loss: 6.2993\n",
            "[Batch 9] Current Loss: 4.6418\n",
            "Ep 4 (Step 030280): Train loss 2.639, Val loss 5.282\n",
            "[Batch 0] Current Loss: 2.3362\n",
            "[Batch 1] Current Loss: 2.0663\n",
            "[Batch 2] Current Loss: 2.5144\n",
            "[Batch 3] Current Loss: 3.3132\n",
            "[Batch 4] Current Loss: 2.5995\n",
            "[Batch 5] Current Loss: 2.2074\n",
            "[Batch 6] Current Loss: 2.0330\n",
            "[Batch 7] Current Loss: 2.5215\n",
            "[Batch 8] Current Loss: 2.5790\n",
            "[Batch 9] Current Loss: 2.4486\n",
            "[Batch 0] Current Loss: 5.7521\n",
            "[Batch 1] Current Loss: 5.6938\n",
            "[Batch 2] Current Loss: 5.5645\n",
            "[Batch 3] Current Loss: 5.0003\n",
            "[Batch 4] Current Loss: 4.7797\n",
            "[Batch 5] Current Loss: 5.6813\n",
            "[Batch 6] Current Loss: 5.3888\n",
            "[Batch 7] Current Loss: 5.7424\n",
            "[Batch 8] Current Loss: 6.2581\n",
            "[Batch 9] Current Loss: 5.6405\n",
            "Ep 4 (Step 030300): Train loss 2.462, Val loss 5.550\n",
            "[Batch 0] Current Loss: 2.4293\n",
            "[Batch 1] Current Loss: 2.6894\n",
            "[Batch 2] Current Loss: 2.0467\n",
            "[Batch 3] Current Loss: 2.5324\n",
            "[Batch 4] Current Loss: 2.1993\n",
            "[Batch 5] Current Loss: 2.1723\n",
            "[Batch 6] Current Loss: 2.4449\n",
            "[Batch 7] Current Loss: 2.6094\n",
            "[Batch 8] Current Loss: 1.9738\n",
            "[Batch 9] Current Loss: 2.2913\n",
            "[Batch 0] Current Loss: 6.2726\n",
            "[Batch 1] Current Loss: 5.6245\n",
            "[Batch 2] Current Loss: 5.5819\n",
            "[Batch 3] Current Loss: 5.7559\n",
            "[Batch 4] Current Loss: 5.4883\n",
            "[Batch 5] Current Loss: 5.1822\n",
            "[Batch 6] Current Loss: 4.1289\n",
            "[Batch 7] Current Loss: 5.1715\n",
            "[Batch 8] Current Loss: 5.0841\n",
            "[Batch 9] Current Loss: 5.6143\n",
            "Ep 4 (Step 030320): Train loss 2.339, Val loss 5.390\n",
            "[Batch 0] Current Loss: 2.2716\n",
            "[Batch 1] Current Loss: 2.5637\n",
            "[Batch 2] Current Loss: 1.8078\n",
            "[Batch 3] Current Loss: 3.1072\n",
            "[Batch 4] Current Loss: 2.4283\n",
            "[Batch 5] Current Loss: 2.6885\n",
            "[Batch 6] Current Loss: 2.8064\n",
            "[Batch 7] Current Loss: 2.6498\n",
            "[Batch 8] Current Loss: 2.9233\n",
            "[Batch 9] Current Loss: 2.8797\n",
            "[Batch 0] Current Loss: 5.7375\n",
            "[Batch 1] Current Loss: 5.4077\n",
            "[Batch 2] Current Loss: 5.4160\n",
            "[Batch 3] Current Loss: 5.2471\n",
            "[Batch 4] Current Loss: 5.1673\n",
            "[Batch 5] Current Loss: 5.2455\n",
            "[Batch 6] Current Loss: 5.3584\n",
            "[Batch 7] Current Loss: 5.4524\n",
            "[Batch 8] Current Loss: 5.7755\n",
            "[Batch 9] Current Loss: 4.9061\n",
            "Ep 4 (Step 030340): Train loss 2.613, Val loss 5.371\n",
            "[Batch 0] Current Loss: 2.6694\n",
            "[Batch 1] Current Loss: 3.0331\n",
            "[Batch 2] Current Loss: 2.6777\n",
            "[Batch 3] Current Loss: 2.5901\n",
            "[Batch 4] Current Loss: 2.5037\n",
            "[Batch 5] Current Loss: 2.3946\n",
            "[Batch 6] Current Loss: 2.4125\n",
            "[Batch 7] Current Loss: 1.7683\n",
            "[Batch 8] Current Loss: 2.3145\n",
            "[Batch 9] Current Loss: 2.5066\n",
            "[Batch 0] Current Loss: 4.7660\n",
            "[Batch 1] Current Loss: 5.2045\n",
            "[Batch 2] Current Loss: 5.1479\n",
            "[Batch 3] Current Loss: 5.8877\n",
            "[Batch 4] Current Loss: 5.0712\n",
            "[Batch 5] Current Loss: 5.4586\n",
            "[Batch 6] Current Loss: 5.7666\n",
            "[Batch 7] Current Loss: 5.2437\n",
            "[Batch 8] Current Loss: 5.7200\n",
            "[Batch 9] Current Loss: 5.7967\n",
            "Ep 4 (Step 030360): Train loss 2.487, Val loss 5.406\n",
            "[Batch 0] Current Loss: 1.8974\n",
            "[Batch 1] Current Loss: 2.4074\n",
            "[Batch 2] Current Loss: 2.2361\n",
            "[Batch 3] Current Loss: 2.2483\n",
            "[Batch 4] Current Loss: 1.8743\n",
            "[Batch 5] Current Loss: 2.0605\n",
            "[Batch 6] Current Loss: 1.6924\n",
            "[Batch 7] Current Loss: 2.3027\n",
            "[Batch 8] Current Loss: 2.6586\n",
            "[Batch 9] Current Loss: 2.1785\n",
            "[Batch 0] Current Loss: 5.7362\n",
            "[Batch 1] Current Loss: 5.8554\n",
            "[Batch 2] Current Loss: 5.4269\n",
            "[Batch 3] Current Loss: 5.6344\n",
            "[Batch 4] Current Loss: 4.6256\n",
            "[Batch 5] Current Loss: 5.4360\n",
            "[Batch 6] Current Loss: 5.6308\n",
            "[Batch 7] Current Loss: 4.7667\n",
            "[Batch 8] Current Loss: 6.2537\n",
            "[Batch 9] Current Loss: 5.6416\n",
            "Ep 4 (Step 030380): Train loss 2.156, Val loss 5.501\n",
            "[Batch 0] Current Loss: 2.0626\n",
            "[Batch 1] Current Loss: 2.8306\n",
            "[Batch 2] Current Loss: 2.7339\n",
            "[Batch 3] Current Loss: 2.4798\n",
            "[Batch 4] Current Loss: 2.0972\n",
            "[Batch 5] Current Loss: 2.8899\n",
            "[Batch 6] Current Loss: 3.0090\n",
            "[Batch 7] Current Loss: 3.0859\n",
            "[Batch 8] Current Loss: 2.9692\n",
            "[Batch 9] Current Loss: 3.2769\n",
            "[Batch 0] Current Loss: 6.0659\n",
            "[Batch 1] Current Loss: 5.5000\n",
            "[Batch 2] Current Loss: 5.8437\n",
            "[Batch 3] Current Loss: 5.4351\n",
            "[Batch 4] Current Loss: 5.1730\n",
            "[Batch 5] Current Loss: 5.4070\n",
            "[Batch 6] Current Loss: 4.3962\n",
            "[Batch 7] Current Loss: 6.0483\n",
            "[Batch 8] Current Loss: 4.7868\n",
            "[Batch 9] Current Loss: 5.3756\n",
            "Ep 4 (Step 030400): Train loss 2.744, Val loss 5.403\n",
            "[Batch 0] Current Loss: 2.2698\n",
            "[Batch 1] Current Loss: 2.4798\n",
            "[Batch 2] Current Loss: 2.7244\n",
            "[Batch 3] Current Loss: 2.1705\n",
            "[Batch 4] Current Loss: 2.1466\n",
            "[Batch 5] Current Loss: 2.7629\n",
            "[Batch 6] Current Loss: 2.6419\n",
            "[Batch 7] Current Loss: 2.5627\n",
            "[Batch 8] Current Loss: 2.7180\n",
            "[Batch 9] Current Loss: 2.2479\n",
            "[Batch 0] Current Loss: 5.6457\n",
            "[Batch 1] Current Loss: 5.2123\n",
            "[Batch 2] Current Loss: 5.3942\n",
            "[Batch 3] Current Loss: 5.0640\n",
            "[Batch 4] Current Loss: 5.1007\n",
            "[Batch 5] Current Loss: 5.0510\n",
            "[Batch 6] Current Loss: 5.6055\n",
            "[Batch 7] Current Loss: 6.4387\n",
            "[Batch 8] Current Loss: 5.7572\n",
            "[Batch 9] Current Loss: 5.2023\n",
            "Ep 4 (Step 030420): Train loss 2.472, Val loss 5.447\n",
            "[Batch 0] Current Loss: 2.0753\n",
            "[Batch 1] Current Loss: 2.1895\n",
            "[Batch 2] Current Loss: 2.7060\n",
            "[Batch 3] Current Loss: 2.7087\n",
            "[Batch 4] Current Loss: 2.5363\n",
            "[Batch 5] Current Loss: 2.7391\n",
            "[Batch 6] Current Loss: 2.7812\n",
            "[Batch 7] Current Loss: 2.5203\n",
            "[Batch 8] Current Loss: 2.2392\n",
            "[Batch 9] Current Loss: 3.2719\n",
            "[Batch 0] Current Loss: 4.7479\n",
            "[Batch 1] Current Loss: 5.2867\n",
            "[Batch 2] Current Loss: 6.1795\n",
            "[Batch 3] Current Loss: 5.6364\n",
            "[Batch 4] Current Loss: 4.8659\n",
            "[Batch 5] Current Loss: 5.4194\n",
            "[Batch 6] Current Loss: 4.9786\n",
            "[Batch 7] Current Loss: 5.3946\n",
            "[Batch 8] Current Loss: 5.2992\n",
            "[Batch 9] Current Loss: 5.2682\n",
            "Ep 4 (Step 030440): Train loss 2.577, Val loss 5.308\n",
            "[Batch 0] Current Loss: 2.5781\n",
            "[Batch 1] Current Loss: 2.2512\n",
            "[Batch 2] Current Loss: 2.4528\n",
            "[Batch 3] Current Loss: 2.6149\n",
            "[Batch 4] Current Loss: 2.6306\n",
            "[Batch 5] Current Loss: 2.5568\n",
            "[Batch 6] Current Loss: 2.4195\n",
            "[Batch 7] Current Loss: 2.2002\n",
            "[Batch 8] Current Loss: 1.9531\n",
            "[Batch 9] Current Loss: 1.9857\n",
            "[Batch 0] Current Loss: 5.3550\n",
            "[Batch 1] Current Loss: 6.1319\n",
            "[Batch 2] Current Loss: 5.3461\n",
            "[Batch 3] Current Loss: 5.4166\n",
            "[Batch 4] Current Loss: 5.7891\n",
            "[Batch 5] Current Loss: 5.4375\n",
            "[Batch 6] Current Loss: 6.0186\n",
            "[Batch 7] Current Loss: 5.1057\n",
            "[Batch 8] Current Loss: 5.8914\n",
            "[Batch 9] Current Loss: 5.9585\n",
            "Ep 4 (Step 030460): Train loss 2.364, Val loss 5.645\n",
            "[Batch 0] Current Loss: 2.2475\n",
            "[Batch 1] Current Loss: 2.3544\n",
            "[Batch 2] Current Loss: 2.6696\n",
            "[Batch 3] Current Loss: 2.1931\n",
            "[Batch 4] Current Loss: 2.8363\n",
            "[Batch 5] Current Loss: 2.6984\n",
            "[Batch 6] Current Loss: 2.9711\n",
            "[Batch 7] Current Loss: 2.4898\n",
            "[Batch 8] Current Loss: 2.6589\n",
            "[Batch 9] Current Loss: 2.4544\n",
            "[Batch 0] Current Loss: 5.1257\n",
            "[Batch 1] Current Loss: 4.5146\n",
            "[Batch 2] Current Loss: 5.9472\n",
            "[Batch 3] Current Loss: 4.8975\n",
            "[Batch 4] Current Loss: 5.3226\n",
            "[Batch 5] Current Loss: 5.2247\n",
            "[Batch 6] Current Loss: 5.6928\n",
            "[Batch 7] Current Loss: 5.2793\n",
            "[Batch 8] Current Loss: 5.5981\n",
            "[Batch 9] Current Loss: 6.4372\n",
            "Ep 4 (Step 030480): Train loss 2.557, Val loss 5.404\n",
            "[Batch 0] Current Loss: 2.8970\n",
            "[Batch 1] Current Loss: 2.5923\n",
            "[Batch 2] Current Loss: 2.6527\n",
            "[Batch 3] Current Loss: 2.4567\n",
            "[Batch 4] Current Loss: 2.7557\n",
            "[Batch 5] Current Loss: 2.3132\n",
            "[Batch 6] Current Loss: 1.9798\n",
            "[Batch 7] Current Loss: 2.1819\n",
            "[Batch 8] Current Loss: 2.0837\n",
            "[Batch 9] Current Loss: 2.4661\n",
            "[Batch 0] Current Loss: 4.7007\n",
            "[Batch 1] Current Loss: 5.5505\n",
            "[Batch 2] Current Loss: 5.3968\n",
            "[Batch 3] Current Loss: 4.9662\n",
            "[Batch 4] Current Loss: 5.8613\n",
            "[Batch 5] Current Loss: 4.5812\n",
            "[Batch 6] Current Loss: 4.9771\n",
            "[Batch 7] Current Loss: 5.1558\n",
            "[Batch 8] Current Loss: 6.3248\n",
            "[Batch 9] Current Loss: 5.5990\n",
            "Ep 4 (Step 030500): Train loss 2.438, Val loss 5.311\n",
            "[Batch 0] Current Loss: 2.2011\n",
            "[Batch 1] Current Loss: 2.5943\n",
            "[Batch 2] Current Loss: 2.1951\n",
            "[Batch 3] Current Loss: 2.6723\n",
            "[Batch 4] Current Loss: 2.2848\n",
            "[Batch 5] Current Loss: 2.5134\n",
            "[Batch 6] Current Loss: 2.6420\n",
            "[Batch 7] Current Loss: 2.2141\n",
            "[Batch 8] Current Loss: 3.1191\n",
            "[Batch 9] Current Loss: 2.7229\n",
            "[Batch 0] Current Loss: 5.8732\n",
            "[Batch 1] Current Loss: 4.6511\n",
            "[Batch 2] Current Loss: 5.2087\n",
            "[Batch 3] Current Loss: 5.3021\n",
            "[Batch 4] Current Loss: 4.3693\n",
            "[Batch 5] Current Loss: 5.5812\n",
            "[Batch 6] Current Loss: 6.0620\n",
            "[Batch 7] Current Loss: 5.4900\n",
            "[Batch 8] Current Loss: 5.6296\n",
            "[Batch 9] Current Loss: 5.5393\n",
            "Ep 4 (Step 030520): Train loss 2.516, Val loss 5.371\n",
            "[Batch 0] Current Loss: 3.0205\n",
            "[Batch 1] Current Loss: 2.3522\n",
            "[Batch 2] Current Loss: 2.4250\n",
            "[Batch 3] Current Loss: 2.7365\n",
            "[Batch 4] Current Loss: 2.1903\n",
            "[Batch 5] Current Loss: 1.8272\n",
            "[Batch 6] Current Loss: 2.8396\n",
            "[Batch 7] Current Loss: 2.5495\n",
            "[Batch 8] Current Loss: 2.3523\n",
            "[Batch 9] Current Loss: 2.7029\n",
            "[Batch 0] Current Loss: 6.0438\n",
            "[Batch 1] Current Loss: 5.6949\n",
            "[Batch 2] Current Loss: 5.3518\n",
            "[Batch 3] Current Loss: 5.3075\n",
            "[Batch 4] Current Loss: 5.8516\n",
            "[Batch 5] Current Loss: 5.8955\n",
            "[Batch 6] Current Loss: 5.2807\n",
            "[Batch 7] Current Loss: 4.9404\n",
            "[Batch 8] Current Loss: 6.1778\n",
            "[Batch 9] Current Loss: 5.4269\n",
            "Ep 4 (Step 030540): Train loss 2.500, Val loss 5.597\n",
            "[Batch 0] Current Loss: 2.5194\n",
            "[Batch 1] Current Loss: 2.0885\n",
            "[Batch 2] Current Loss: 1.9035\n",
            "[Batch 3] Current Loss: 2.8887\n",
            "[Batch 4] Current Loss: 2.3644\n",
            "[Batch 5] Current Loss: 2.2956\n",
            "[Batch 6] Current Loss: 1.7948\n",
            "[Batch 7] Current Loss: 2.6513\n",
            "[Batch 8] Current Loss: 2.5974\n",
            "[Batch 9] Current Loss: 2.3356\n",
            "[Batch 0] Current Loss: 5.1336\n",
            "[Batch 1] Current Loss: 6.4357\n",
            "[Batch 2] Current Loss: 6.9666\n",
            "[Batch 3] Current Loss: 5.4294\n",
            "[Batch 4] Current Loss: 5.1135\n",
            "[Batch 5] Current Loss: 5.5117\n",
            "[Batch 6] Current Loss: 6.3465\n",
            "[Batch 7] Current Loss: 6.1009\n",
            "[Batch 8] Current Loss: 5.3868\n",
            "[Batch 9] Current Loss: 5.7343\n",
            "Ep 4 (Step 030560): Train loss 2.344, Val loss 5.816\n",
            "[Batch 0] Current Loss: 2.4754\n",
            "[Batch 1] Current Loss: 2.5679\n",
            "[Batch 2] Current Loss: 2.9617\n",
            "[Batch 3] Current Loss: 2.8713\n",
            "[Batch 4] Current Loss: 3.0319\n",
            "[Batch 5] Current Loss: 2.8037\n",
            "[Batch 6] Current Loss: 2.4572\n",
            "[Batch 7] Current Loss: 2.3236\n",
            "[Batch 8] Current Loss: 2.4668\n",
            "[Batch 9] Current Loss: 2.6421\n",
            "[Batch 0] Current Loss: 5.9836\n",
            "[Batch 1] Current Loss: 5.5023\n",
            "[Batch 2] Current Loss: 5.7296\n",
            "[Batch 3] Current Loss: 5.4616\n",
            "[Batch 4] Current Loss: 6.0245\n",
            "[Batch 5] Current Loss: 5.2844\n",
            "[Batch 6] Current Loss: 5.0804\n",
            "[Batch 7] Current Loss: 6.0327\n",
            "[Batch 8] Current Loss: 5.8468\n",
            "[Batch 9] Current Loss: 5.3163\n",
            "Ep 4 (Step 030580): Train loss 2.660, Val loss 5.626\n",
            "[Batch 0] Current Loss: 2.3117\n",
            "[Batch 1] Current Loss: 2.8486\n",
            "[Batch 2] Current Loss: 2.7606\n",
            "[Batch 3] Current Loss: 2.7527\n",
            "[Batch 4] Current Loss: 3.3872\n",
            "[Batch 5] Current Loss: 2.8247\n",
            "[Batch 6] Current Loss: 2.1554\n",
            "[Batch 7] Current Loss: 2.3669\n",
            "[Batch 8] Current Loss: 2.4258\n",
            "[Batch 9] Current Loss: 2.5943\n",
            "[Batch 0] Current Loss: 5.9342\n",
            "[Batch 1] Current Loss: 5.2858\n",
            "[Batch 2] Current Loss: 5.7781\n",
            "[Batch 3] Current Loss: 4.4340\n",
            "[Batch 4] Current Loss: 5.1315\n",
            "[Batch 5] Current Loss: 5.6004\n",
            "[Batch 6] Current Loss: 5.9569\n",
            "[Batch 7] Current Loss: 5.5862\n",
            "[Batch 8] Current Loss: 5.2275\n",
            "[Batch 9] Current Loss: 6.0193\n",
            "Ep 4 (Step 030600): Train loss 2.643, Val loss 5.495\n",
            "[Batch 0] Current Loss: 2.4410\n",
            "[Batch 1] Current Loss: 2.4254\n",
            "[Batch 2] Current Loss: 2.4470\n",
            "[Batch 3] Current Loss: 2.0505\n",
            "[Batch 4] Current Loss: 2.2103\n",
            "[Batch 5] Current Loss: 2.1770\n",
            "[Batch 6] Current Loss: 2.4375\n",
            "[Batch 7] Current Loss: 2.7582\n",
            "[Batch 8] Current Loss: 2.5691\n",
            "[Batch 9] Current Loss: 2.5518\n",
            "[Batch 0] Current Loss: 4.9821\n",
            "[Batch 1] Current Loss: 5.3075\n",
            "[Batch 2] Current Loss: 5.4121\n",
            "[Batch 3] Current Loss: 4.7948\n",
            "[Batch 4] Current Loss: 5.7869\n",
            "[Batch 5] Current Loss: 5.6461\n",
            "[Batch 6] Current Loss: 5.1273\n",
            "[Batch 7] Current Loss: 5.1035\n",
            "[Batch 8] Current Loss: 5.7252\n",
            "[Batch 9] Current Loss: 5.5377\n",
            "Ep 4 (Step 030620): Train loss 2.407, Val loss 5.342\n",
            "[Batch 0] Current Loss: 2.9857\n",
            "[Batch 1] Current Loss: 2.5496\n",
            "[Batch 2] Current Loss: 1.8526\n",
            "[Batch 3] Current Loss: 2.3614\n",
            "[Batch 4] Current Loss: 3.3820\n",
            "[Batch 5] Current Loss: 2.0301\n",
            "[Batch 6] Current Loss: 2.2793\n",
            "[Batch 7] Current Loss: 2.2058\n",
            "[Batch 8] Current Loss: 2.5483\n",
            "[Batch 9] Current Loss: 2.2692\n",
            "[Batch 0] Current Loss: 5.7514\n",
            "[Batch 1] Current Loss: 5.6323\n",
            "[Batch 2] Current Loss: 5.4042\n",
            "[Batch 3] Current Loss: 6.1092\n",
            "[Batch 4] Current Loss: 5.5985\n",
            "[Batch 5] Current Loss: 5.0209\n",
            "[Batch 6] Current Loss: 4.7729\n",
            "[Batch 7] Current Loss: 5.4901\n",
            "[Batch 8] Current Loss: 5.8561\n",
            "[Batch 9] Current Loss: 5.7282\n",
            "Ep 4 (Step 030640): Train loss 2.446, Val loss 5.536\n",
            "[Batch 0] Current Loss: 2.6560\n",
            "[Batch 1] Current Loss: 2.3256\n",
            "[Batch 2] Current Loss: 2.4844\n",
            "[Batch 3] Current Loss: 3.0494\n",
            "[Batch 4] Current Loss: 2.5287\n",
            "[Batch 5] Current Loss: 2.2060\n",
            "[Batch 6] Current Loss: 2.2124\n",
            "[Batch 7] Current Loss: 2.2426\n",
            "[Batch 8] Current Loss: 2.6823\n",
            "[Batch 9] Current Loss: 2.0582\n",
            "[Batch 0] Current Loss: 4.9836\n",
            "[Batch 1] Current Loss: 4.7464\n",
            "[Batch 2] Current Loss: 4.9758\n",
            "[Batch 3] Current Loss: 4.6301\n",
            "[Batch 4] Current Loss: 5.0674\n",
            "[Batch 5] Current Loss: 5.8547\n",
            "[Batch 6] Current Loss: 5.0151\n",
            "[Batch 7] Current Loss: 5.7426\n",
            "[Batch 8] Current Loss: 5.5296\n",
            "[Batch 9] Current Loss: 5.0932\n",
            "Ep 4 (Step 030660): Train loss 2.445, Val loss 5.164\n",
            "[Batch 0] Current Loss: 2.3483\n",
            "[Batch 1] Current Loss: 2.3349\n",
            "[Batch 2] Current Loss: 2.5780\n",
            "[Batch 3] Current Loss: 2.0649\n",
            "[Batch 4] Current Loss: 2.4463\n",
            "[Batch 5] Current Loss: 1.9677\n",
            "[Batch 6] Current Loss: 2.5069\n",
            "[Batch 7] Current Loss: 2.0205\n",
            "[Batch 8] Current Loss: 2.1577\n",
            "[Batch 9] Current Loss: 2.5188\n",
            "[Batch 0] Current Loss: 6.0831\n",
            "[Batch 1] Current Loss: 5.9585\n",
            "[Batch 2] Current Loss: 4.8740\n",
            "[Batch 3] Current Loss: 6.0553\n",
            "[Batch 4] Current Loss: 5.1235\n",
            "[Batch 5] Current Loss: 5.8509\n",
            "[Batch 6] Current Loss: 6.0011\n",
            "[Batch 7] Current Loss: 5.1201\n",
            "[Batch 8] Current Loss: 4.8644\n",
            "[Batch 9] Current Loss: 5.5883\n",
            "Ep 4 (Step 030680): Train loss 2.294, Val loss 5.552\n",
            "[Batch 0] Current Loss: 1.9890\n",
            "[Batch 1] Current Loss: 2.4040\n",
            "[Batch 2] Current Loss: 1.9417\n",
            "[Batch 3] Current Loss: 1.6692\n",
            "[Batch 4] Current Loss: 3.0262\n",
            "[Batch 5] Current Loss: 2.3890\n",
            "[Batch 6] Current Loss: 2.6177\n",
            "[Batch 7] Current Loss: 2.9436\n",
            "[Batch 8] Current Loss: 2.9345\n",
            "[Batch 9] Current Loss: 2.6582\n",
            "[Batch 0] Current Loss: 5.4044\n",
            "[Batch 1] Current Loss: 4.9166\n",
            "[Batch 2] Current Loss: 5.5540\n",
            "[Batch 3] Current Loss: 5.5176\n",
            "[Batch 4] Current Loss: 5.8969\n",
            "[Batch 5] Current Loss: 5.5827\n",
            "[Batch 6] Current Loss: 5.8684\n",
            "[Batch 7] Current Loss: 6.0561\n",
            "[Batch 8] Current Loss: 5.6637\n",
            "[Batch 9] Current Loss: 5.2500\n",
            "Ep 4 (Step 030700): Train loss 2.457, Val loss 5.571\n",
            "[Batch 0] Current Loss: 2.1230\n",
            "[Batch 1] Current Loss: 2.8965\n",
            "[Batch 2] Current Loss: 2.3233\n",
            "[Batch 3] Current Loss: 2.9717\n",
            "[Batch 4] Current Loss: 2.3521\n",
            "[Batch 5] Current Loss: 2.4396\n",
            "[Batch 6] Current Loss: 1.8875\n",
            "[Batch 7] Current Loss: 2.3939\n",
            "[Batch 8] Current Loss: 2.4767\n",
            "[Batch 9] Current Loss: 2.6308\n",
            "[Batch 0] Current Loss: 4.7954\n",
            "[Batch 1] Current Loss: 5.4726\n",
            "[Batch 2] Current Loss: 4.9692\n",
            "[Batch 3] Current Loss: 5.4483\n",
            "[Batch 4] Current Loss: 5.8872\n",
            "[Batch 5] Current Loss: 5.8027\n",
            "[Batch 6] Current Loss: 5.8725\n",
            "[Batch 7] Current Loss: 5.7787\n",
            "[Batch 8] Current Loss: 5.6804\n",
            "[Batch 9] Current Loss: 5.8852\n",
            "Ep 4 (Step 030720): Train loss 2.450, Val loss 5.559\n",
            "[Batch 0] Current Loss: 2.7948\n",
            "[Batch 1] Current Loss: 2.4908\n",
            "[Batch 2] Current Loss: 1.9329\n",
            "[Batch 3] Current Loss: 2.7774\n",
            "[Batch 4] Current Loss: 3.0253\n",
            "[Batch 5] Current Loss: 3.1544\n",
            "[Batch 6] Current Loss: 2.1594\n",
            "[Batch 7] Current Loss: 2.3738\n",
            "[Batch 8] Current Loss: 2.3048\n",
            "[Batch 9] Current Loss: 2.7606\n",
            "[Batch 0] Current Loss: 6.1196\n",
            "[Batch 1] Current Loss: 5.1037\n",
            "[Batch 2] Current Loss: 5.2064\n",
            "[Batch 3] Current Loss: 5.2032\n",
            "[Batch 4] Current Loss: 4.7448\n",
            "[Batch 5] Current Loss: 5.4214\n",
            "[Batch 6] Current Loss: 6.2865\n",
            "[Batch 7] Current Loss: 5.6833\n",
            "[Batch 8] Current Loss: 5.5542\n",
            "[Batch 9] Current Loss: 5.4699\n",
            "Ep 4 (Step 030740): Train loss 2.577, Val loss 5.479\n",
            "[Batch 0] Current Loss: 3.0282\n",
            "[Batch 1] Current Loss: 1.9713\n",
            "[Batch 2] Current Loss: 2.0933\n",
            "[Batch 3] Current Loss: 2.2276\n",
            "[Batch 4] Current Loss: 3.0584\n",
            "[Batch 5] Current Loss: 2.6271\n",
            "[Batch 6] Current Loss: 2.5238\n",
            "[Batch 7] Current Loss: 2.6234\n",
            "[Batch 8] Current Loss: 2.9313\n",
            "[Batch 9] Current Loss: 2.5720\n",
            "[Batch 0] Current Loss: 5.1068\n",
            "[Batch 1] Current Loss: 5.2247\n",
            "[Batch 2] Current Loss: 5.7178\n",
            "[Batch 3] Current Loss: 4.9771\n",
            "[Batch 4] Current Loss: 5.8395\n",
            "[Batch 5] Current Loss: 5.6210\n",
            "[Batch 6] Current Loss: 5.6018\n",
            "[Batch 7] Current Loss: 4.8662\n",
            "[Batch 8] Current Loss: 5.3778\n",
            "[Batch 9] Current Loss: 5.3012\n",
            "Ep 4 (Step 030760): Train loss 2.566, Val loss 5.363\n",
            "[Batch 0] Current Loss: 2.3876\n",
            "[Batch 1] Current Loss: 2.9560\n",
            "[Batch 2] Current Loss: 2.3864\n",
            "[Batch 3] Current Loss: 2.5600\n",
            "[Batch 4] Current Loss: 2.9801\n",
            "[Batch 5] Current Loss: 2.6956\n",
            "[Batch 6] Current Loss: 2.8335\n",
            "[Batch 7] Current Loss: 2.7284\n",
            "[Batch 8] Current Loss: 2.2147\n",
            "[Batch 9] Current Loss: 2.4950\n",
            "[Batch 0] Current Loss: 5.1750\n",
            "[Batch 1] Current Loss: 5.8098\n",
            "[Batch 2] Current Loss: 5.5988\n",
            "[Batch 3] Current Loss: 4.4304\n",
            "[Batch 4] Current Loss: 5.8155\n",
            "[Batch 5] Current Loss: 5.0818\n",
            "[Batch 6] Current Loss: 5.5351\n",
            "[Batch 7] Current Loss: 5.9123\n",
            "[Batch 8] Current Loss: 6.1046\n",
            "[Batch 9] Current Loss: 5.1476\n",
            "Ep 4 (Step 030780): Train loss 2.624, Val loss 5.461\n",
            "[Batch 0] Current Loss: 2.3377\n",
            "[Batch 1] Current Loss: 2.8510\n",
            "[Batch 2] Current Loss: 2.4407\n",
            "[Batch 3] Current Loss: 2.3362\n",
            "[Batch 4] Current Loss: 2.2172\n",
            "[Batch 5] Current Loss: 2.4416\n",
            "[Batch 6] Current Loss: 3.0063\n",
            "[Batch 7] Current Loss: 2.9589\n",
            "[Batch 8] Current Loss: 2.0245\n",
            "[Batch 9] Current Loss: 2.9836\n",
            "[Batch 0] Current Loss: 4.7191\n",
            "[Batch 1] Current Loss: 5.8688\n",
            "[Batch 2] Current Loss: 5.8715\n",
            "[Batch 3] Current Loss: 5.7109\n",
            "[Batch 4] Current Loss: 6.0258\n",
            "[Batch 5] Current Loss: 6.2292\n",
            "[Batch 6] Current Loss: 5.1534\n",
            "[Batch 7] Current Loss: 6.1374\n",
            "[Batch 8] Current Loss: 5.6019\n",
            "[Batch 9] Current Loss: 5.7310\n",
            "Ep 4 (Step 030800): Train loss 2.560, Val loss 5.705\n",
            "[Batch 0] Current Loss: 2.3979\n",
            "[Batch 1] Current Loss: 3.3202\n",
            "[Batch 2] Current Loss: 2.8071\n",
            "[Batch 3] Current Loss: 2.8193\n",
            "[Batch 4] Current Loss: 2.8767\n",
            "[Batch 5] Current Loss: 2.5336\n",
            "[Batch 6] Current Loss: 2.2004\n",
            "[Batch 7] Current Loss: 2.1950\n",
            "[Batch 8] Current Loss: 2.2437\n",
            "[Batch 9] Current Loss: 2.5076\n",
            "[Batch 0] Current Loss: 5.8985\n",
            "[Batch 1] Current Loss: 5.0385\n",
            "[Batch 2] Current Loss: 4.9330\n",
            "[Batch 3] Current Loss: 5.6194\n",
            "[Batch 4] Current Loss: 5.5553\n",
            "[Batch 5] Current Loss: 6.0691\n",
            "[Batch 6] Current Loss: 5.6260\n",
            "[Batch 7] Current Loss: 5.5314\n",
            "[Batch 8] Current Loss: 4.5569\n",
            "[Batch 9] Current Loss: 5.0167\n",
            "Ep 4 (Step 030820): Train loss 2.590, Val loss 5.384\n",
            "[Batch 0] Current Loss: 3.3899\n",
            "[Batch 1] Current Loss: 2.6037\n",
            "[Batch 2] Current Loss: 2.5560\n",
            "[Batch 3] Current Loss: 3.0706\n",
            "[Batch 4] Current Loss: 2.7536\n",
            "[Batch 5] Current Loss: 2.1497\n",
            "[Batch 6] Current Loss: 2.4612\n",
            "[Batch 7] Current Loss: 2.3244\n",
            "[Batch 8] Current Loss: 2.5698\n",
            "[Batch 9] Current Loss: 2.5260\n",
            "[Batch 0] Current Loss: 6.3952\n",
            "[Batch 1] Current Loss: 4.3918\n",
            "[Batch 2] Current Loss: 5.7642\n",
            "[Batch 3] Current Loss: 4.9583\n",
            "[Batch 4] Current Loss: 5.2205\n",
            "[Batch 5] Current Loss: 4.0739\n",
            "[Batch 6] Current Loss: 4.6332\n",
            "[Batch 7] Current Loss: 5.5014\n",
            "[Batch 8] Current Loss: 5.2827\n",
            "[Batch 9] Current Loss: 5.7848\n",
            "Ep 4 (Step 030840): Train loss 2.640, Val loss 5.201\n",
            "[Batch 0] Current Loss: 2.1333\n",
            "[Batch 1] Current Loss: 2.1558\n",
            "[Batch 2] Current Loss: 2.1188\n",
            "[Batch 3] Current Loss: 2.4152\n",
            "[Batch 4] Current Loss: 2.5838\n",
            "[Batch 5] Current Loss: 2.2100\n",
            "[Batch 6] Current Loss: 2.2015\n",
            "[Batch 7] Current Loss: 3.0330\n",
            "[Batch 8] Current Loss: 2.4038\n",
            "[Batch 9] Current Loss: 2.2848\n",
            "[Batch 0] Current Loss: 5.7606\n",
            "[Batch 1] Current Loss: 5.4886\n",
            "[Batch 2] Current Loss: 5.7593\n",
            "[Batch 3] Current Loss: 4.8228\n",
            "[Batch 4] Current Loss: 5.6001\n",
            "[Batch 5] Current Loss: 5.7721\n",
            "[Batch 6] Current Loss: 5.3212\n",
            "[Batch 7] Current Loss: 5.4249\n",
            "[Batch 8] Current Loss: 5.5220\n",
            "[Batch 9] Current Loss: 5.7334\n",
            "Ep 4 (Step 030860): Train loss 2.354, Val loss 5.520\n",
            "[Batch 0] Current Loss: 2.3216\n",
            "[Batch 1] Current Loss: 2.2988\n",
            "[Batch 2] Current Loss: 2.4438\n",
            "[Batch 3] Current Loss: 2.4355\n",
            "[Batch 4] Current Loss: 2.8030\n",
            "[Batch 5] Current Loss: 2.4242\n",
            "[Batch 6] Current Loss: 2.5807\n",
            "[Batch 7] Current Loss: 2.3404\n",
            "[Batch 8] Current Loss: 2.4329\n",
            "[Batch 9] Current Loss: 2.5154\n",
            "[Batch 0] Current Loss: 5.5408\n",
            "[Batch 1] Current Loss: 5.6809\n",
            "[Batch 2] Current Loss: 6.0032\n",
            "[Batch 3] Current Loss: 4.6516\n",
            "[Batch 4] Current Loss: 5.5687\n",
            "[Batch 5] Current Loss: 5.9008\n",
            "[Batch 6] Current Loss: 4.7189\n",
            "[Batch 7] Current Loss: 5.3494\n",
            "[Batch 8] Current Loss: 5.5641\n",
            "[Batch 9] Current Loss: 5.4918\n",
            "Ep 4 (Step 030880): Train loss 2.460, Val loss 5.447\n",
            "[Batch 0] Current Loss: 2.0316\n",
            "[Batch 1] Current Loss: 2.5092\n",
            "[Batch 2] Current Loss: 2.7346\n",
            "[Batch 3] Current Loss: 2.9456\n",
            "[Batch 4] Current Loss: 2.5626\n",
            "[Batch 5] Current Loss: 2.2876\n",
            "[Batch 6] Current Loss: 1.8191\n",
            "[Batch 7] Current Loss: 2.7209\n",
            "[Batch 8] Current Loss: 1.9936\n",
            "[Batch 9] Current Loss: 2.6931\n",
            "[Batch 0] Current Loss: 6.0198\n",
            "[Batch 1] Current Loss: 5.0770\n",
            "[Batch 2] Current Loss: 5.2649\n",
            "[Batch 3] Current Loss: 6.0414\n",
            "[Batch 4] Current Loss: 5.0808\n",
            "[Batch 5] Current Loss: 5.8491\n",
            "[Batch 6] Current Loss: 5.2545\n",
            "[Batch 7] Current Loss: 5.6515\n",
            "[Batch 8] Current Loss: 5.4902\n",
            "[Batch 9] Current Loss: 5.9838\n",
            "Ep 4 (Step 030900): Train loss 2.430, Val loss 5.571\n",
            "[Batch 0] Current Loss: 1.9063\n",
            "[Batch 1] Current Loss: 3.0280\n",
            "[Batch 2] Current Loss: 2.6126\n",
            "[Batch 3] Current Loss: 2.5555\n",
            "[Batch 4] Current Loss: 2.3281\n",
            "[Batch 5] Current Loss: 2.2189\n",
            "[Batch 6] Current Loss: 1.7781\n",
            "[Batch 7] Current Loss: 3.1304\n",
            "[Batch 8] Current Loss: 1.8770\n",
            "[Batch 9] Current Loss: 2.5968\n",
            "[Batch 0] Current Loss: 5.2284\n",
            "[Batch 1] Current Loss: 5.0731\n",
            "[Batch 2] Current Loss: 5.7539\n",
            "[Batch 3] Current Loss: 5.2143\n",
            "[Batch 4] Current Loss: 5.9111\n",
            "[Batch 5] Current Loss: 6.2805\n",
            "[Batch 6] Current Loss: 5.0627\n",
            "[Batch 7] Current Loss: 6.1313\n",
            "[Batch 8] Current Loss: 5.2763\n",
            "[Batch 9] Current Loss: 5.2984\n",
            "Ep 4 (Step 030920): Train loss 2.403, Val loss 5.523\n",
            "[Batch 0] Current Loss: 2.7605\n",
            "[Batch 1] Current Loss: 1.9940\n",
            "[Batch 2] Current Loss: 2.0969\n",
            "[Batch 3] Current Loss: 2.7948\n",
            "[Batch 4] Current Loss: 2.2596\n",
            "[Batch 5] Current Loss: 2.2830\n",
            "[Batch 6] Current Loss: 2.6801\n",
            "[Batch 7] Current Loss: 2.5694\n",
            "[Batch 8] Current Loss: 2.3086\n",
            "[Batch 9] Current Loss: 2.7517\n",
            "[Batch 0] Current Loss: 4.7853\n",
            "[Batch 1] Current Loss: 5.8608\n",
            "[Batch 2] Current Loss: 5.1431\n",
            "[Batch 3] Current Loss: 5.7879\n",
            "[Batch 4] Current Loss: 5.4306\n",
            "[Batch 5] Current Loss: 5.5474\n",
            "[Batch 6] Current Loss: 5.7179\n",
            "[Batch 7] Current Loss: 6.7173\n",
            "[Batch 8] Current Loss: 5.3370\n",
            "[Batch 9] Current Loss: 5.1765\n",
            "Ep 4 (Step 030940): Train loss 2.450, Val loss 5.550\n",
            "[Batch 0] Current Loss: 3.0284\n",
            "[Batch 1] Current Loss: 2.6078\n",
            "[Batch 2] Current Loss: 2.3279\n",
            "[Batch 3] Current Loss: 2.1726\n",
            "[Batch 4] Current Loss: 2.3026\n",
            "[Batch 5] Current Loss: 1.9409\n",
            "[Batch 6] Current Loss: 2.7325\n",
            "[Batch 7] Current Loss: 2.6930\n",
            "[Batch 8] Current Loss: 2.6546\n",
            "[Batch 9] Current Loss: 2.7932\n",
            "[Batch 0] Current Loss: 5.8423\n",
            "[Batch 1] Current Loss: 6.2425\n",
            "[Batch 2] Current Loss: 5.2410\n",
            "[Batch 3] Current Loss: 5.5907\n",
            "[Batch 4] Current Loss: 5.1339\n",
            "[Batch 5] Current Loss: 5.7438\n",
            "[Batch 6] Current Loss: 5.8536\n",
            "[Batch 7] Current Loss: 5.3225\n",
            "[Batch 8] Current Loss: 6.2760\n",
            "[Batch 9] Current Loss: 5.9851\n",
            "Ep 4 (Step 030960): Train loss 2.525, Val loss 5.723\n",
            "[Batch 0] Current Loss: 2.3279\n",
            "[Batch 1] Current Loss: 2.5487\n",
            "[Batch 2] Current Loss: 2.9551\n",
            "[Batch 3] Current Loss: 2.3339\n",
            "[Batch 4] Current Loss: 2.0929\n",
            "[Batch 5] Current Loss: 2.5528\n",
            "[Batch 6] Current Loss: 1.7440\n",
            "[Batch 7] Current Loss: 2.1199\n",
            "[Batch 8] Current Loss: 2.4479\n",
            "[Batch 9] Current Loss: 2.7289\n",
            "[Batch 0] Current Loss: 5.6101\n",
            "[Batch 1] Current Loss: 5.2380\n",
            "[Batch 2] Current Loss: 6.2608\n",
            "[Batch 3] Current Loss: 4.9324\n",
            "[Batch 4] Current Loss: 5.9030\n",
            "[Batch 5] Current Loss: 5.1015\n",
            "[Batch 6] Current Loss: 6.6659\n",
            "[Batch 7] Current Loss: 5.4533\n",
            "[Batch 8] Current Loss: 4.8492\n",
            "[Batch 9] Current Loss: 5.4166\n",
            "Ep 4 (Step 030980): Train loss 2.385, Val loss 5.543\n",
            "[Batch 0] Current Loss: 2.2938\n",
            "[Batch 1] Current Loss: 2.1204\n",
            "[Batch 2] Current Loss: 2.7574\n",
            "[Batch 3] Current Loss: 2.7519\n",
            "[Batch 4] Current Loss: 2.8028\n",
            "[Batch 5] Current Loss: 2.2171\n",
            "[Batch 6] Current Loss: 2.3945\n",
            "[Batch 7] Current Loss: 2.3272\n",
            "[Batch 8] Current Loss: 2.1639\n",
            "[Batch 9] Current Loss: 2.6151\n",
            "[Batch 0] Current Loss: 5.1831\n",
            "[Batch 1] Current Loss: 5.0687\n",
            "[Batch 2] Current Loss: 5.8877\n",
            "[Batch 3] Current Loss: 5.7812\n",
            "[Batch 4] Current Loss: 5.7138\n",
            "[Batch 5] Current Loss: 5.1514\n",
            "[Batch 6] Current Loss: 5.1787\n",
            "[Batch 7] Current Loss: 5.2317\n",
            "[Batch 8] Current Loss: 5.6155\n",
            "[Batch 9] Current Loss: 5.8633\n",
            "Ep 4 (Step 031000): Train loss 2.444, Val loss 5.468\n",
            "[Batch 0] Current Loss: 2.5242\n",
            "[Batch 1] Current Loss: 2.3592\n",
            "[Batch 2] Current Loss: 2.3400\n",
            "[Batch 3] Current Loss: 2.4036\n",
            "[Batch 4] Current Loss: 2.5741\n",
            "[Batch 5] Current Loss: 2.3216\n",
            "[Batch 6] Current Loss: 2.7804\n",
            "[Batch 7] Current Loss: 1.7306\n",
            "[Batch 8] Current Loss: 2.7624\n",
            "[Batch 9] Current Loss: 2.6156\n",
            "[Batch 0] Current Loss: 5.3282\n",
            "[Batch 1] Current Loss: 5.3613\n",
            "[Batch 2] Current Loss: 5.3166\n",
            "[Batch 3] Current Loss: 5.8261\n",
            "[Batch 4] Current Loss: 5.4397\n",
            "[Batch 5] Current Loss: 6.0205\n",
            "[Batch 6] Current Loss: 5.0077\n",
            "[Batch 7] Current Loss: 6.0901\n",
            "[Batch 8] Current Loss: 6.0632\n",
            "[Batch 9] Current Loss: 4.8631\n",
            "Ep 4 (Step 031020): Train loss 2.441, Val loss 5.532\n",
            "[Batch 0] Current Loss: 2.6948\n",
            "[Batch 1] Current Loss: 2.1667\n",
            "[Batch 2] Current Loss: 2.0574\n",
            "[Batch 3] Current Loss: 2.6972\n",
            "[Batch 4] Current Loss: 2.2341\n",
            "[Batch 5] Current Loss: 2.8946\n",
            "[Batch 6] Current Loss: 2.6848\n",
            "[Batch 7] Current Loss: 2.0359\n",
            "[Batch 8] Current Loss: 2.6244\n",
            "[Batch 9] Current Loss: 2.4953\n",
            "[Batch 0] Current Loss: 5.9657\n",
            "[Batch 1] Current Loss: 4.8808\n",
            "[Batch 2] Current Loss: 4.7771\n",
            "[Batch 3] Current Loss: 5.4441\n",
            "[Batch 4] Current Loss: 4.1050\n",
            "[Batch 5] Current Loss: 4.6711\n",
            "[Batch 6] Current Loss: 5.0102\n",
            "[Batch 7] Current Loss: 5.6418\n",
            "[Batch 8] Current Loss: 6.1491\n",
            "[Batch 9] Current Loss: 5.0753\n",
            "Ep 4 (Step 031040): Train loss 2.459, Val loss 5.172\n",
            "[Batch 0] Current Loss: 2.4335\n",
            "[Batch 1] Current Loss: 2.6303\n",
            "[Batch 2] Current Loss: 2.4735\n",
            "[Batch 3] Current Loss: 2.5803\n",
            "[Batch 4] Current Loss: 2.4810\n",
            "[Batch 5] Current Loss: 1.8272\n",
            "[Batch 6] Current Loss: 2.6321\n",
            "[Batch 7] Current Loss: 2.6508\n",
            "[Batch 8] Current Loss: 2.7337\n",
            "[Batch 9] Current Loss: 2.2310\n",
            "[Batch 0] Current Loss: 5.5862\n",
            "[Batch 1] Current Loss: 6.3050\n",
            "[Batch 2] Current Loss: 5.7256\n",
            "[Batch 3] Current Loss: 5.8882\n",
            "[Batch 4] Current Loss: 4.9796\n",
            "[Batch 5] Current Loss: 5.5824\n",
            "[Batch 6] Current Loss: 6.4250\n",
            "[Batch 7] Current Loss: 5.5678\n",
            "[Batch 8] Current Loss: 5.8010\n",
            "[Batch 9] Current Loss: 5.5110\n",
            "Ep 4 (Step 031060): Train loss 2.467, Val loss 5.737\n",
            "[Batch 0] Current Loss: 2.4862\n",
            "[Batch 1] Current Loss: 2.2273\n",
            "[Batch 2] Current Loss: 2.3858\n",
            "[Batch 3] Current Loss: 2.5783\n",
            "[Batch 4] Current Loss: 2.1261\n",
            "[Batch 5] Current Loss: 2.4758\n",
            "[Batch 6] Current Loss: 2.3965\n",
            "[Batch 7] Current Loss: 3.0089\n",
            "[Batch 8] Current Loss: 3.1757\n",
            "[Batch 9] Current Loss: 2.6113\n",
            "[Batch 0] Current Loss: 5.5817\n",
            "[Batch 1] Current Loss: 5.3249\n",
            "[Batch 2] Current Loss: 5.2152\n",
            "[Batch 3] Current Loss: 5.7585\n",
            "[Batch 4] Current Loss: 5.3472\n",
            "[Batch 5] Current Loss: 5.3004\n",
            "[Batch 6] Current Loss: 5.2324\n",
            "[Batch 7] Current Loss: 5.2561\n",
            "[Batch 8] Current Loss: 5.6799\n",
            "[Batch 9] Current Loss: 5.1768\n",
            "Ep 4 (Step 031080): Train loss 2.547, Val loss 5.387\n",
            "[Batch 0] Current Loss: 1.9269\n",
            "[Batch 1] Current Loss: 3.3067\n",
            "[Batch 2] Current Loss: 2.4447\n",
            "[Batch 3] Current Loss: 2.9442\n",
            "[Batch 4] Current Loss: 3.4328\n",
            "[Batch 5] Current Loss: 2.5511\n",
            "[Batch 6] Current Loss: 2.3251\n",
            "[Batch 7] Current Loss: 2.8261\n",
            "[Batch 8] Current Loss: 2.4266\n",
            "[Batch 9] Current Loss: 2.8536\n",
            "[Batch 0] Current Loss: 5.4901\n",
            "[Batch 1] Current Loss: 4.4243\n",
            "[Batch 2] Current Loss: 5.5483\n",
            "[Batch 3] Current Loss: 5.0663\n",
            "[Batch 4] Current Loss: 4.6666\n",
            "[Batch 5] Current Loss: 5.1989\n",
            "[Batch 6] Current Loss: 4.9859\n",
            "[Batch 7] Current Loss: 6.1703\n",
            "[Batch 8] Current Loss: 4.9377\n",
            "[Batch 9] Current Loss: 5.4028\n",
            "Ep 4 (Step 031100): Train loss 2.704, Val loss 5.189\n",
            "[Batch 0] Current Loss: 2.0041\n",
            "[Batch 1] Current Loss: 2.5108\n",
            "[Batch 2] Current Loss: 2.2325\n",
            "[Batch 3] Current Loss: 2.2450\n",
            "[Batch 4] Current Loss: 2.3360\n",
            "[Batch 5] Current Loss: 2.2431\n",
            "[Batch 6] Current Loss: 2.4168\n",
            "[Batch 7] Current Loss: 2.5812\n",
            "[Batch 8] Current Loss: 2.2524\n",
            "[Batch 9] Current Loss: 3.3364\n",
            "[Batch 0] Current Loss: 5.7986\n",
            "[Batch 1] Current Loss: 5.3812\n",
            "[Batch 2] Current Loss: 5.8789\n",
            "[Batch 3] Current Loss: 5.3017\n",
            "[Batch 4] Current Loss: 6.0127\n",
            "[Batch 5] Current Loss: 6.0210\n",
            "[Batch 6] Current Loss: 6.0813\n",
            "[Batch 7] Current Loss: 5.6064\n",
            "[Batch 8] Current Loss: 5.7772\n",
            "[Batch 9] Current Loss: 5.4925\n",
            "Ep 4 (Step 031120): Train loss 2.416, Val loss 5.735\n",
            "[Batch 0] Current Loss: 2.2200\n",
            "[Batch 1] Current Loss: 2.4697\n",
            "[Batch 2] Current Loss: 3.2125\n",
            "[Batch 3] Current Loss: 2.1605\n",
            "[Batch 4] Current Loss: 2.8242\n",
            "[Batch 5] Current Loss: 2.5315\n",
            "[Batch 6] Current Loss: 2.6949\n",
            "[Batch 7] Current Loss: 2.8904\n",
            "[Batch 8] Current Loss: 3.0803\n",
            "[Batch 9] Current Loss: 2.7277\n",
            "[Batch 0] Current Loss: 5.0129\n",
            "[Batch 1] Current Loss: 5.6001\n",
            "[Batch 2] Current Loss: 5.3412\n",
            "[Batch 3] Current Loss: 4.8748\n",
            "[Batch 4] Current Loss: 5.5758\n",
            "[Batch 5] Current Loss: 5.1906\n",
            "[Batch 6] Current Loss: 5.1027\n",
            "[Batch 7] Current Loss: 5.2041\n",
            "[Batch 8] Current Loss: 6.0217\n",
            "[Batch 9] Current Loss: 5.8286\n",
            "Ep 4 (Step 031140): Train loss 2.681, Val loss 5.375\n",
            "[Batch 0] Current Loss: 2.5280\n",
            "[Batch 1] Current Loss: 2.2655\n",
            "[Batch 2] Current Loss: 2.5849\n",
            "[Batch 3] Current Loss: 3.1200\n",
            "[Batch 4] Current Loss: 2.1440\n",
            "[Batch 5] Current Loss: 2.9456\n",
            "[Batch 6] Current Loss: 2.4668\n",
            "[Batch 7] Current Loss: 2.5129\n",
            "[Batch 8] Current Loss: 2.6948\n",
            "[Batch 9] Current Loss: 2.3236\n",
            "[Batch 0] Current Loss: 5.0743\n",
            "[Batch 1] Current Loss: 4.9905\n",
            "[Batch 2] Current Loss: 5.6873\n",
            "[Batch 3] Current Loss: 5.3703\n",
            "[Batch 4] Current Loss: 5.2741\n",
            "[Batch 5] Current Loss: 5.5425\n",
            "[Batch 6] Current Loss: 6.0349\n",
            "[Batch 7] Current Loss: 5.4308\n",
            "[Batch 8] Current Loss: 6.6365\n",
            "[Batch 9] Current Loss: 4.8778\n",
            "Ep 4 (Step 031160): Train loss 2.559, Val loss 5.492\n",
            "[Batch 0] Current Loss: 2.1392\n",
            "[Batch 1] Current Loss: 2.2071\n",
            "[Batch 2] Current Loss: 2.7455\n",
            "[Batch 3] Current Loss: 2.2549\n",
            "[Batch 4] Current Loss: 2.0807\n",
            "[Batch 5] Current Loss: 2.6202\n",
            "[Batch 6] Current Loss: 2.4289\n",
            "[Batch 7] Current Loss: 2.9227\n",
            "[Batch 8] Current Loss: 2.3675\n",
            "[Batch 9] Current Loss: 2.6366\n",
            "[Batch 0] Current Loss: 5.0389\n",
            "[Batch 1] Current Loss: 5.0441\n",
            "[Batch 2] Current Loss: 4.6464\n",
            "[Batch 3] Current Loss: 5.4469\n",
            "[Batch 4] Current Loss: 5.5769\n",
            "[Batch 5] Current Loss: 5.2687\n",
            "[Batch 6] Current Loss: 4.5437\n",
            "[Batch 7] Current Loss: 6.2477\n",
            "[Batch 8] Current Loss: 5.9449\n",
            "[Batch 9] Current Loss: 5.4477\n",
            "Ep 4 (Step 031180): Train loss 2.440, Val loss 5.321\n",
            "[Batch 0] Current Loss: 2.1322\n",
            "[Batch 1] Current Loss: 2.4249\n",
            "[Batch 2] Current Loss: 3.1242\n",
            "[Batch 3] Current Loss: 2.5197\n",
            "[Batch 4] Current Loss: 2.3243\n",
            "[Batch 5] Current Loss: 2.4222\n",
            "[Batch 6] Current Loss: 2.4394\n",
            "[Batch 7] Current Loss: 2.3935\n",
            "[Batch 8] Current Loss: 1.9687\n",
            "[Batch 9] Current Loss: 2.7930\n",
            "[Batch 0] Current Loss: 6.1760\n",
            "[Batch 1] Current Loss: 5.6456\n",
            "[Batch 2] Current Loss: 6.2198\n",
            "[Batch 3] Current Loss: 6.6677\n",
            "[Batch 4] Current Loss: 5.1148\n",
            "[Batch 5] Current Loss: 5.3261\n",
            "[Batch 6] Current Loss: 4.9793\n",
            "[Batch 7] Current Loss: 5.4548\n",
            "[Batch 8] Current Loss: 5.3119\n",
            "[Batch 9] Current Loss: 5.2821\n",
            "Ep 4 (Step 031200): Train loss 2.454, Val loss 5.618\n",
            "[Batch 0] Current Loss: 2.6505\n",
            "[Batch 1] Current Loss: 2.2761\n",
            "[Batch 2] Current Loss: 2.9582\n",
            "[Batch 3] Current Loss: 2.8618\n",
            "[Batch 4] Current Loss: 2.6069\n",
            "[Batch 5] Current Loss: 2.7154\n",
            "[Batch 6] Current Loss: 2.3661\n",
            "[Batch 7] Current Loss: 2.4240\n",
            "[Batch 8] Current Loss: 2.5681\n",
            "[Batch 9] Current Loss: 3.0094\n",
            "[Batch 0] Current Loss: 5.3757\n",
            "[Batch 1] Current Loss: 5.9118\n",
            "[Batch 2] Current Loss: 5.9370\n",
            "[Batch 3] Current Loss: 5.4051\n",
            "[Batch 4] Current Loss: 6.1758\n",
            "[Batch 5] Current Loss: 5.4367\n",
            "[Batch 6] Current Loss: 5.7677\n",
            "[Batch 7] Current Loss: 5.4724\n",
            "[Batch 8] Current Loss: 5.1672\n",
            "[Batch 9] Current Loss: 5.3558\n",
            "Ep 4 (Step 031220): Train loss 2.644, Val loss 5.601\n",
            "[Batch 0] Current Loss: 2.5721\n",
            "[Batch 1] Current Loss: 1.8747\n",
            "[Batch 2] Current Loss: 2.2438\n",
            "[Batch 3] Current Loss: 1.9147\n",
            "[Batch 4] Current Loss: 2.3683\n",
            "[Batch 5] Current Loss: 2.2510\n",
            "[Batch 6] Current Loss: 2.6513\n",
            "[Batch 7] Current Loss: 2.5597\n",
            "[Batch 8] Current Loss: 2.4169\n",
            "[Batch 9] Current Loss: 1.9394\n",
            "[Batch 0] Current Loss: 4.9981\n",
            "[Batch 1] Current Loss: 5.4857\n",
            "[Batch 2] Current Loss: 5.9963\n",
            "[Batch 3] Current Loss: 4.5370\n",
            "[Batch 4] Current Loss: 5.7323\n",
            "[Batch 5] Current Loss: 5.0338\n",
            "[Batch 6] Current Loss: 6.2892\n",
            "[Batch 7] Current Loss: 4.8153\n",
            "[Batch 8] Current Loss: 5.1985\n",
            "[Batch 9] Current Loss: 5.4245\n",
            "Ep 4 (Step 031240): Train loss 2.279, Val loss 5.351\n",
            "[Batch 0] Current Loss: 2.4399\n",
            "[Batch 1] Current Loss: 2.7832\n",
            "[Batch 2] Current Loss: 2.2038\n",
            "[Batch 3] Current Loss: 2.4411\n",
            "[Batch 4] Current Loss: 2.0000\n",
            "[Batch 5] Current Loss: 2.2237\n",
            "[Batch 6] Current Loss: 2.0804\n",
            "[Batch 7] Current Loss: 2.0269\n",
            "[Batch 8] Current Loss: 1.8642\n",
            "[Batch 9] Current Loss: 2.8085\n",
            "[Batch 0] Current Loss: 5.5115\n",
            "[Batch 1] Current Loss: 6.3199\n",
            "[Batch 2] Current Loss: 5.6986\n",
            "[Batch 3] Current Loss: 5.2835\n",
            "[Batch 4] Current Loss: 5.3197\n",
            "[Batch 5] Current Loss: 6.0514\n",
            "[Batch 6] Current Loss: 5.6413\n",
            "[Batch 7] Current Loss: 5.3719\n",
            "[Batch 8] Current Loss: 5.4579\n",
            "[Batch 9] Current Loss: 5.6335\n",
            "Ep 4 (Step 031260): Train loss 2.287, Val loss 5.629\n",
            "[Batch 0] Current Loss: 2.4681\n",
            "[Batch 1] Current Loss: 2.4116\n",
            "[Batch 2] Current Loss: 2.8328\n",
            "[Batch 3] Current Loss: 3.0717\n",
            "[Batch 4] Current Loss: 2.0081\n",
            "[Batch 5] Current Loss: 1.9289\n",
            "[Batch 6] Current Loss: 2.4823\n",
            "[Batch 7] Current Loss: 2.5157\n",
            "[Batch 8] Current Loss: 2.3030\n",
            "[Batch 9] Current Loss: 2.4747\n",
            "[Batch 0] Current Loss: 5.0780\n",
            "[Batch 1] Current Loss: 5.4170\n",
            "[Batch 2] Current Loss: 5.3246\n",
            "[Batch 3] Current Loss: 7.0730\n",
            "[Batch 4] Current Loss: 5.3582\n",
            "[Batch 5] Current Loss: 4.7170\n",
            "[Batch 6] Current Loss: 5.5079\n",
            "[Batch 7] Current Loss: 5.7955\n",
            "[Batch 8] Current Loss: 4.1063\n",
            "[Batch 9] Current Loss: 5.5650\n",
            "Ep 4 (Step 031280): Train loss 2.450, Val loss 5.394\n",
            "[Batch 0] Current Loss: 2.4107\n",
            "[Batch 1] Current Loss: 2.2891\n",
            "[Batch 2] Current Loss: 2.8408\n",
            "[Batch 3] Current Loss: 2.9134\n",
            "[Batch 4] Current Loss: 2.6965\n",
            "[Batch 5] Current Loss: 2.1455\n",
            "[Batch 6] Current Loss: 2.7413\n",
            "[Batch 7] Current Loss: 3.0210\n",
            "[Batch 8] Current Loss: 2.3510\n",
            "[Batch 9] Current Loss: 1.7386\n",
            "[Batch 0] Current Loss: 5.6594\n",
            "[Batch 1] Current Loss: 5.4335\n",
            "[Batch 2] Current Loss: 5.5002\n",
            "[Batch 3] Current Loss: 4.6821\n",
            "[Batch 4] Current Loss: 5.6189\n",
            "[Batch 5] Current Loss: 4.7233\n",
            "[Batch 6] Current Loss: 5.9142\n",
            "[Batch 7] Current Loss: 5.5817\n",
            "[Batch 8] Current Loss: 4.8162\n",
            "[Batch 9] Current Loss: 4.9756\n",
            "Ep 4 (Step 031300): Train loss 2.515, Val loss 5.291\n",
            "[Batch 0] Current Loss: 2.2704\n",
            "[Batch 1] Current Loss: 2.0767\n",
            "[Batch 2] Current Loss: 3.0138\n",
            "[Batch 3] Current Loss: 2.4599\n",
            "[Batch 4] Current Loss: 3.4646\n",
            "[Batch 5] Current Loss: 2.2777\n",
            "[Batch 6] Current Loss: 2.9105\n",
            "[Batch 7] Current Loss: 2.8462\n",
            "[Batch 8] Current Loss: 2.2144\n",
            "[Batch 9] Current Loss: 2.5403\n",
            "[Batch 0] Current Loss: 5.0616\n",
            "[Batch 1] Current Loss: 5.0428\n",
            "[Batch 2] Current Loss: 5.7803\n",
            "[Batch 3] Current Loss: 5.4506\n",
            "[Batch 4] Current Loss: 5.0036\n",
            "[Batch 5] Current Loss: 5.6472\n",
            "[Batch 6] Current Loss: 5.7719\n",
            "[Batch 7] Current Loss: 5.0700\n",
            "[Batch 8] Current Loss: 5.1208\n",
            "[Batch 9] Current Loss: 5.5812\n",
            "Ep 4 (Step 031320): Train loss 2.607, Val loss 5.353\n",
            "[Batch 0] Current Loss: 3.6033\n",
            "[Batch 1] Current Loss: 2.1436\n",
            "[Batch 2] Current Loss: 2.6497\n",
            "[Batch 3] Current Loss: 2.5878\n",
            "[Batch 4] Current Loss: 3.0800\n",
            "[Batch 5] Current Loss: 1.6883\n",
            "[Batch 6] Current Loss: 2.7950\n",
            "[Batch 7] Current Loss: 1.8836\n",
            "[Batch 8] Current Loss: 2.4971\n",
            "[Batch 9] Current Loss: 2.2998\n",
            "[Batch 0] Current Loss: 6.0590\n",
            "[Batch 1] Current Loss: 5.7342\n",
            "[Batch 2] Current Loss: 5.2619\n",
            "[Batch 3] Current Loss: 5.0513\n",
            "[Batch 4] Current Loss: 6.7121\n",
            "[Batch 5] Current Loss: 5.7084\n",
            "[Batch 6] Current Loss: 6.2270\n",
            "[Batch 7] Current Loss: 5.3098\n",
            "[Batch 8] Current Loss: 4.9860\n",
            "[Batch 9] Current Loss: 5.5740\n",
            "Ep 4 (Step 031340): Train loss 2.523, Val loss 5.662\n",
            "[Batch 0] Current Loss: 2.1066\n",
            "[Batch 1] Current Loss: 2.3332\n",
            "[Batch 2] Current Loss: 2.5281\n",
            "[Batch 3] Current Loss: 2.8987\n",
            "[Batch 4] Current Loss: 2.7010\n",
            "[Batch 5] Current Loss: 2.4912\n",
            "[Batch 6] Current Loss: 2.8520\n",
            "[Batch 7] Current Loss: 3.0612\n",
            "[Batch 8] Current Loss: 2.7643\n",
            "[Batch 9] Current Loss: 2.7610\n",
            "[Batch 0] Current Loss: 6.2115\n",
            "[Batch 1] Current Loss: 5.0056\n",
            "[Batch 2] Current Loss: 5.1104\n",
            "[Batch 3] Current Loss: 5.2044\n",
            "[Batch 4] Current Loss: 5.7567\n",
            "[Batch 5] Current Loss: 5.6905\n",
            "[Batch 6] Current Loss: 5.2818\n",
            "[Batch 7] Current Loss: 5.0128\n",
            "[Batch 8] Current Loss: 5.7086\n",
            "[Batch 9] Current Loss: 5.1848\n",
            "Ep 4 (Step 031360): Train loss 2.650, Val loss 5.417\n",
            "[Batch 0] Current Loss: 3.1987\n",
            "[Batch 1] Current Loss: 2.3796\n",
            "[Batch 2] Current Loss: 2.6931\n",
            "[Batch 3] Current Loss: 2.3833\n",
            "[Batch 4] Current Loss: 2.9754\n",
            "[Batch 5] Current Loss: 2.0472\n",
            "[Batch 6] Current Loss: 2.8642\n",
            "[Batch 7] Current Loss: 2.3352\n",
            "[Batch 8] Current Loss: 2.5015\n",
            "[Batch 9] Current Loss: 2.2187\n",
            "[Batch 0] Current Loss: 5.4712\n",
            "[Batch 1] Current Loss: 5.4206\n",
            "[Batch 2] Current Loss: 4.8052\n",
            "[Batch 3] Current Loss: 5.5348\n",
            "[Batch 4] Current Loss: 5.5772\n",
            "[Batch 5] Current Loss: 6.0054\n",
            "[Batch 6] Current Loss: 6.1423\n",
            "[Batch 7] Current Loss: 5.5798\n",
            "[Batch 8] Current Loss: 5.2135\n",
            "[Batch 9] Current Loss: 5.3837\n",
            "Ep 4 (Step 031380): Train loss 2.560, Val loss 5.513\n",
            "[Batch 0] Current Loss: 2.0669\n",
            "[Batch 1] Current Loss: 2.6492\n",
            "[Batch 2] Current Loss: 2.0075\n",
            "[Batch 3] Current Loss: 2.1987\n",
            "[Batch 4] Current Loss: 2.8868\n",
            "[Batch 5] Current Loss: 2.4455\n",
            "[Batch 6] Current Loss: 3.1497\n",
            "[Batch 7] Current Loss: 2.3850\n",
            "[Batch 8] Current Loss: 2.2426\n",
            "[Batch 9] Current Loss: 2.5318\n",
            "[Batch 0] Current Loss: 4.5630\n",
            "[Batch 1] Current Loss: 5.5948\n",
            "[Batch 2] Current Loss: 5.9037\n",
            "[Batch 3] Current Loss: 5.6257\n",
            "[Batch 4] Current Loss: 6.2066\n",
            "[Batch 5] Current Loss: 4.9118\n",
            "[Batch 6] Current Loss: 5.2927\n",
            "[Batch 7] Current Loss: 5.6202\n",
            "[Batch 8] Current Loss: 5.6722\n",
            "[Batch 9] Current Loss: 5.2351\n",
            "Ep 4 (Step 031400): Train loss 2.456, Val loss 5.463\n",
            "[Batch 0] Current Loss: 2.6205\n",
            "[Batch 1] Current Loss: 2.5696\n",
            "[Batch 2] Current Loss: 2.6738\n",
            "[Batch 3] Current Loss: 1.9385\n",
            "[Batch 4] Current Loss: 2.2639\n",
            "[Batch 5] Current Loss: 2.1698\n",
            "[Batch 6] Current Loss: 2.2647\n",
            "[Batch 7] Current Loss: 2.3005\n",
            "[Batch 8] Current Loss: 2.3655\n",
            "[Batch 9] Current Loss: 3.0829\n",
            "[Batch 0] Current Loss: 5.4710\n",
            "[Batch 1] Current Loss: 5.0470\n",
            "[Batch 2] Current Loss: 6.2989\n",
            "[Batch 3] Current Loss: 4.6701\n",
            "[Batch 4] Current Loss: 5.7133\n",
            "[Batch 5] Current Loss: 5.6967\n",
            "[Batch 6] Current Loss: 5.2894\n",
            "[Batch 7] Current Loss: 5.8277\n",
            "[Batch 8] Current Loss: 6.3863\n",
            "[Batch 9] Current Loss: 5.5859\n",
            "Ep 4 (Step 031420): Train loss 2.425, Val loss 5.599\n",
            "[Batch 0] Current Loss: 3.3683\n",
            "[Batch 1] Current Loss: 2.6251\n",
            "[Batch 2] Current Loss: 2.6165\n",
            "[Batch 3] Current Loss: 2.1273\n",
            "[Batch 4] Current Loss: 2.0941\n",
            "[Batch 5] Current Loss: 2.1814\n",
            "[Batch 6] Current Loss: 2.8097\n",
            "[Batch 7] Current Loss: 2.3550\n",
            "[Batch 8] Current Loss: 2.7388\n",
            "[Batch 9] Current Loss: 2.0217\n",
            "[Batch 0] Current Loss: 5.2546\n",
            "[Batch 1] Current Loss: 5.0041\n",
            "[Batch 2] Current Loss: 5.0107\n",
            "[Batch 3] Current Loss: 5.3549\n",
            "[Batch 4] Current Loss: 5.8045\n",
            "[Batch 5] Current Loss: 4.8171\n",
            "[Batch 6] Current Loss: 5.7264\n",
            "[Batch 7] Current Loss: 5.7786\n",
            "[Batch 8] Current Loss: 6.2638\n",
            "[Batch 9] Current Loss: 5.3181\n",
            "Ep 4 (Step 031440): Train loss 2.494, Val loss 5.433\n",
            "[Batch 0] Current Loss: 2.9039\n",
            "[Batch 1] Current Loss: 2.6107\n",
            "[Batch 2] Current Loss: 2.3051\n",
            "[Batch 3] Current Loss: 1.7661\n",
            "[Batch 4] Current Loss: 3.0609\n",
            "[Batch 5] Current Loss: 2.8475\n",
            "[Batch 6] Current Loss: 2.7758\n",
            "[Batch 7] Current Loss: 2.3798\n",
            "[Batch 8] Current Loss: 2.8410\n",
            "[Batch 9] Current Loss: 2.1907\n",
            "[Batch 0] Current Loss: 6.1638\n",
            "[Batch 1] Current Loss: 4.9217\n",
            "[Batch 2] Current Loss: 5.5233\n",
            "[Batch 3] Current Loss: 5.4632\n",
            "[Batch 4] Current Loss: 5.3022\n",
            "[Batch 5] Current Loss: 5.9167\n",
            "[Batch 6] Current Loss: 5.8225\n",
            "[Batch 7] Current Loss: 5.5227\n",
            "[Batch 8] Current Loss: 5.5595\n",
            "[Batch 9] Current Loss: 5.6639\n",
            "Ep 4 (Step 031460): Train loss 2.568, Val loss 5.586\n",
            "[Batch 0] Current Loss: 2.9627\n",
            "[Batch 1] Current Loss: 2.3441\n",
            "[Batch 2] Current Loss: 1.8892\n",
            "[Batch 3] Current Loss: 2.5374\n",
            "[Batch 4] Current Loss: 2.6209\n",
            "[Batch 5] Current Loss: 2.5438\n",
            "[Batch 6] Current Loss: 2.0584\n",
            "[Batch 7] Current Loss: 2.8615\n",
            "[Batch 8] Current Loss: 1.8900\n",
            "[Batch 9] Current Loss: 2.3439\n",
            "[Batch 0] Current Loss: 4.6801\n",
            "[Batch 1] Current Loss: 5.3129\n",
            "[Batch 2] Current Loss: 5.5661\n",
            "[Batch 3] Current Loss: 5.3732\n",
            "[Batch 4] Current Loss: 5.4574\n",
            "[Batch 5] Current Loss: 5.3778\n",
            "[Batch 6] Current Loss: 5.3753\n",
            "[Batch 7] Current Loss: 5.1060\n",
            "[Batch 8] Current Loss: 4.9728\n",
            "[Batch 9] Current Loss: 5.3148\n",
            "Ep 4 (Step 031480): Train loss 2.405, Val loss 5.254\n",
            "[Batch 0] Current Loss: 2.2553\n",
            "[Batch 1] Current Loss: 2.2998\n",
            "[Batch 2] Current Loss: 2.4562\n",
            "[Batch 3] Current Loss: 2.3522\n",
            "[Batch 4] Current Loss: 2.4847\n",
            "[Batch 5] Current Loss: 2.9360\n",
            "[Batch 6] Current Loss: 2.0990\n",
            "[Batch 7] Current Loss: 2.7842\n",
            "[Batch 8] Current Loss: 2.3139\n",
            "[Batch 9] Current Loss: 1.6308\n",
            "[Batch 0] Current Loss: 5.9723\n",
            "[Batch 1] Current Loss: 5.5787\n",
            "[Batch 2] Current Loss: 4.7398\n",
            "[Batch 3] Current Loss: 5.7649\n",
            "[Batch 4] Current Loss: 5.3117\n",
            "[Batch 5] Current Loss: 6.1615\n",
            "[Batch 6] Current Loss: 5.9677\n",
            "[Batch 7] Current Loss: 5.2618\n",
            "[Batch 8] Current Loss: 5.9453\n",
            "[Batch 9] Current Loss: 4.9938\n",
            "Ep 4 (Step 031500): Train loss 2.361, Val loss 5.570\n",
            "[Batch 0] Current Loss: 2.1742\n",
            "[Batch 1] Current Loss: 2.1356\n",
            "[Batch 2] Current Loss: 2.3253\n",
            "[Batch 3] Current Loss: 3.3901\n",
            "[Batch 4] Current Loss: 2.4398\n",
            "[Batch 5] Current Loss: 1.8430\n",
            "[Batch 6] Current Loss: 2.9921\n",
            "[Batch 7] Current Loss: 2.4064\n",
            "[Batch 8] Current Loss: 2.5478\n",
            "[Batch 9] Current Loss: 2.4602\n",
            "[Batch 0] Current Loss: 6.6821\n",
            "[Batch 1] Current Loss: 6.7836\n",
            "[Batch 2] Current Loss: 5.8042\n",
            "[Batch 3] Current Loss: 5.5602\n",
            "[Batch 4] Current Loss: 6.2461\n",
            "[Batch 5] Current Loss: 5.6388\n",
            "[Batch 6] Current Loss: 5.6909\n",
            "[Batch 7] Current Loss: 4.7827\n",
            "[Batch 8] Current Loss: 5.4800\n",
            "[Batch 9] Current Loss: 5.0820\n",
            "Ep 4 (Step 031520): Train loss 2.471, Val loss 5.775\n",
            "[Batch 0] Current Loss: 2.5510\n",
            "[Batch 1] Current Loss: 2.8118\n",
            "[Batch 2] Current Loss: 2.5097\n",
            "[Batch 3] Current Loss: 2.2018\n",
            "[Batch 4] Current Loss: 2.5818\n",
            "[Batch 5] Current Loss: 2.1720\n",
            "[Batch 6] Current Loss: 2.0867\n",
            "[Batch 7] Current Loss: 2.3415\n",
            "[Batch 8] Current Loss: 1.9526\n",
            "[Batch 9] Current Loss: 2.7499\n",
            "[Batch 0] Current Loss: 6.5440\n",
            "[Batch 1] Current Loss: 5.8126\n",
            "[Batch 2] Current Loss: 5.6897\n",
            "[Batch 3] Current Loss: 6.1735\n",
            "[Batch 4] Current Loss: 6.2689\n",
            "[Batch 5] Current Loss: 5.5392\n",
            "[Batch 6] Current Loss: 5.4428\n",
            "[Batch 7] Current Loss: 5.6371\n",
            "[Batch 8] Current Loss: 5.8643\n",
            "[Batch 9] Current Loss: 6.1774\n",
            "Ep 4 (Step 031540): Train loss 2.396, Val loss 5.915\n",
            "[Batch 0] Current Loss: 2.2150\n",
            "[Batch 1] Current Loss: 2.7256\n",
            "[Batch 2] Current Loss: 2.1083\n",
            "[Batch 3] Current Loss: 2.8638\n",
            "[Batch 4] Current Loss: 2.1160\n",
            "[Batch 5] Current Loss: 3.1750\n",
            "[Batch 6] Current Loss: 2.1479\n",
            "[Batch 7] Current Loss: 3.1836\n",
            "[Batch 8] Current Loss: 2.7642\n",
            "[Batch 9] Current Loss: 2.3179\n",
            "[Batch 0] Current Loss: 5.5876\n",
            "[Batch 1] Current Loss: 5.8371\n",
            "[Batch 2] Current Loss: 5.2485\n",
            "[Batch 3] Current Loss: 5.4181\n",
            "[Batch 4] Current Loss: 5.6782\n",
            "[Batch 5] Current Loss: 5.3877\n",
            "[Batch 6] Current Loss: 5.6476\n",
            "[Batch 7] Current Loss: 5.2391\n",
            "[Batch 8] Current Loss: 5.9811\n",
            "[Batch 9] Current Loss: 5.4022\n",
            "Ep 4 (Step 031560): Train loss 2.562, Val loss 5.543\n",
            "[Batch 0] Current Loss: 2.5187\n",
            "[Batch 1] Current Loss: 2.1824\n",
            "[Batch 2] Current Loss: 2.5171\n",
            "[Batch 3] Current Loss: 3.1161\n",
            "[Batch 4] Current Loss: 2.7287\n",
            "[Batch 5] Current Loss: 2.1705\n",
            "[Batch 6] Current Loss: 2.4576\n",
            "[Batch 7] Current Loss: 2.2290\n",
            "[Batch 8] Current Loss: 2.7643\n",
            "[Batch 9] Current Loss: 2.4226\n",
            "[Batch 0] Current Loss: 5.2638\n",
            "[Batch 1] Current Loss: 5.6000\n",
            "[Batch 2] Current Loss: 5.4591\n",
            "[Batch 3] Current Loss: 5.8399\n",
            "[Batch 4] Current Loss: 5.0291\n",
            "[Batch 5] Current Loss: 5.1080\n",
            "[Batch 6] Current Loss: 5.8149\n",
            "[Batch 7] Current Loss: 5.6928\n",
            "[Batch 8] Current Loss: 5.0258\n",
            "[Batch 9] Current Loss: 5.4270\n",
            "Ep 4 (Step 031580): Train loss 2.511, Val loss 5.426\n",
            "[Batch 0] Current Loss: 2.3041\n",
            "[Batch 1] Current Loss: 2.2785\n",
            "[Batch 2] Current Loss: 2.5828\n",
            "[Batch 3] Current Loss: 2.5496\n",
            "[Batch 4] Current Loss: 2.5195\n",
            "[Batch 5] Current Loss: 1.7715\n",
            "[Batch 6] Current Loss: 2.5933\n",
            "[Batch 7] Current Loss: 2.1735\n",
            "[Batch 8] Current Loss: 1.9600\n",
            "[Batch 9] Current Loss: 2.5749\n",
            "[Batch 0] Current Loss: 5.9204\n",
            "[Batch 1] Current Loss: 5.8356\n",
            "[Batch 2] Current Loss: 5.2363\n",
            "[Batch 3] Current Loss: 5.2213\n",
            "[Batch 4] Current Loss: 5.7745\n",
            "[Batch 5] Current Loss: 5.2130\n",
            "[Batch 6] Current Loss: 4.7058\n",
            "[Batch 7] Current Loss: 5.7318\n",
            "[Batch 8] Current Loss: 5.0240\n",
            "[Batch 9] Current Loss: 5.2413\n",
            "Ep 4 (Step 031600): Train loss 2.331, Val loss 5.390\n",
            "[Batch 0] Current Loss: 2.7899\n",
            "[Batch 1] Current Loss: 1.7628\n",
            "[Batch 2] Current Loss: 1.6991\n",
            "[Batch 3] Current Loss: 2.6236\n",
            "[Batch 4] Current Loss: 2.2797\n",
            "[Batch 5] Current Loss: 1.7440\n",
            "[Batch 6] Current Loss: 3.2016\n",
            "[Batch 7] Current Loss: 2.5432\n",
            "[Batch 8] Current Loss: 2.5017\n",
            "[Batch 9] Current Loss: 2.4114\n",
            "[Batch 0] Current Loss: 5.4421\n",
            "[Batch 1] Current Loss: 6.0814\n",
            "[Batch 2] Current Loss: 6.1284\n",
            "[Batch 3] Current Loss: 5.3682\n",
            "[Batch 4] Current Loss: 4.8408\n",
            "[Batch 5] Current Loss: 5.4605\n",
            "[Batch 6] Current Loss: 5.3637\n",
            "[Batch 7] Current Loss: 4.5298\n",
            "[Batch 8] Current Loss: 5.7460\n",
            "[Batch 9] Current Loss: 5.0397\n",
            "Ep 4 (Step 031620): Train loss 2.356, Val loss 5.400\n",
            "[Batch 0] Current Loss: 3.3547\n",
            "[Batch 1] Current Loss: 2.1976\n",
            "[Batch 2] Current Loss: 2.4876\n",
            "[Batch 3] Current Loss: 2.9296\n",
            "[Batch 4] Current Loss: 2.2325\n",
            "[Batch 5] Current Loss: 1.9275\n",
            "[Batch 6] Current Loss: 2.3441\n",
            "[Batch 7] Current Loss: 1.9175\n",
            "[Batch 8] Current Loss: 1.8521\n",
            "[Batch 9] Current Loss: 2.6808\n",
            "[Batch 0] Current Loss: 5.4492\n",
            "[Batch 1] Current Loss: 5.9539\n",
            "[Batch 2] Current Loss: 6.1678\n",
            "[Batch 3] Current Loss: 5.3466\n",
            "[Batch 4] Current Loss: 6.2926\n",
            "[Batch 5] Current Loss: 5.3066\n",
            "[Batch 6] Current Loss: 4.4084\n",
            "[Batch 7] Current Loss: 6.0817\n",
            "[Batch 8] Current Loss: 5.8086\n",
            "[Batch 9] Current Loss: 5.4712\n",
            "Ep 4 (Step 031640): Train loss 2.392, Val loss 5.629\n",
            "[Batch 0] Current Loss: 2.4876\n",
            "[Batch 1] Current Loss: 1.7799\n",
            "[Batch 2] Current Loss: 2.7536\n",
            "[Batch 3] Current Loss: 2.2021\n",
            "[Batch 4] Current Loss: 2.4379\n",
            "[Batch 5] Current Loss: 2.4261\n",
            "[Batch 6] Current Loss: 2.4746\n",
            "[Batch 7] Current Loss: 1.5854\n",
            "[Batch 8] Current Loss: 1.7139\n",
            "[Batch 9] Current Loss: 2.7979\n",
            "[Batch 0] Current Loss: 5.2749\n",
            "[Batch 1] Current Loss: 5.8708\n",
            "[Batch 2] Current Loss: 5.4407\n",
            "[Batch 3] Current Loss: 4.9509\n",
            "[Batch 4] Current Loss: 6.0018\n",
            "[Batch 5] Current Loss: 5.7780\n",
            "[Batch 6] Current Loss: 5.6177\n",
            "[Batch 7] Current Loss: 4.5201\n",
            "[Batch 8] Current Loss: 5.4160\n",
            "[Batch 9] Current Loss: 5.7701\n",
            "Ep 4 (Step 031660): Train loss 2.266, Val loss 5.464\n",
            "[Batch 0] Current Loss: 1.8393\n",
            "[Batch 1] Current Loss: 3.1369\n",
            "[Batch 2] Current Loss: 2.3447\n",
            "[Batch 3] Current Loss: 2.4240\n",
            "[Batch 4] Current Loss: 2.6338\n",
            "[Batch 5] Current Loss: 2.4817\n",
            "[Batch 6] Current Loss: 2.1244\n",
            "[Batch 7] Current Loss: 1.9989\n",
            "[Batch 8] Current Loss: 2.6152\n",
            "[Batch 9] Current Loss: 2.7348\n",
            "[Batch 0] Current Loss: 4.7911\n",
            "[Batch 1] Current Loss: 5.1935\n",
            "[Batch 2] Current Loss: 5.5861\n",
            "[Batch 3] Current Loss: 6.4468\n",
            "[Batch 4] Current Loss: 5.9804\n",
            "[Batch 5] Current Loss: 4.6870\n",
            "[Batch 6] Current Loss: 5.3441\n",
            "[Batch 7] Current Loss: 6.0822\n",
            "[Batch 8] Current Loss: 5.9047\n",
            "[Batch 9] Current Loss: 5.5780\n",
            "Ep 4 (Step 031680): Train loss 2.433, Val loss 5.559\n",
            "[Batch 0] Current Loss: 2.7107\n",
            "[Batch 1] Current Loss: 2.8759\n",
            "[Batch 2] Current Loss: 2.1669\n",
            "[Batch 3] Current Loss: 2.6948\n",
            "[Batch 4] Current Loss: 2.0272\n",
            "[Batch 5] Current Loss: 2.7662\n",
            "[Batch 6] Current Loss: 2.5373\n",
            "[Batch 7] Current Loss: 2.3695\n",
            "[Batch 8] Current Loss: 2.1022\n",
            "[Batch 9] Current Loss: 1.9889\n",
            "[Batch 0] Current Loss: 4.7949\n",
            "[Batch 1] Current Loss: 5.1348\n",
            "[Batch 2] Current Loss: 5.8583\n",
            "[Batch 3] Current Loss: 5.5185\n",
            "[Batch 4] Current Loss: 5.2444\n",
            "[Batch 5] Current Loss: 5.4870\n",
            "[Batch 6] Current Loss: 5.1968\n",
            "[Batch 7] Current Loss: 6.2679\n",
            "[Batch 8] Current Loss: 6.2847\n",
            "[Batch 9] Current Loss: 4.8622\n",
            "Ep 4 (Step 031700): Train loss 2.424, Val loss 5.465\n",
            "[Batch 0] Current Loss: 2.2523\n",
            "[Batch 1] Current Loss: 2.0363\n",
            "[Batch 2] Current Loss: 2.5795\n",
            "[Batch 3] Current Loss: 2.6773\n",
            "[Batch 4] Current Loss: 2.4454\n",
            "[Batch 5] Current Loss: 2.2418\n",
            "[Batch 6] Current Loss: 1.8528\n",
            "[Batch 7] Current Loss: 2.4263\n",
            "[Batch 8] Current Loss: 2.8268\n",
            "[Batch 9] Current Loss: 2.4396\n",
            "[Batch 0] Current Loss: 4.8614\n",
            "[Batch 1] Current Loss: 5.8541\n",
            "[Batch 2] Current Loss: 5.2951\n",
            "[Batch 3] Current Loss: 5.7769\n",
            "[Batch 4] Current Loss: 6.5549\n",
            "[Batch 5] Current Loss: 5.3407\n",
            "[Batch 6] Current Loss: 5.8513\n",
            "[Batch 7] Current Loss: 4.7965\n",
            "[Batch 8] Current Loss: 5.2077\n",
            "[Batch 9] Current Loss: 5.1206\n",
            "Ep 4 (Step 031720): Train loss 2.378, Val loss 5.466\n",
            "[Batch 0] Current Loss: 2.5395\n",
            "[Batch 1] Current Loss: 2.7190\n",
            "[Batch 2] Current Loss: 2.7993\n",
            "[Batch 3] Current Loss: 2.0110\n",
            "[Batch 4] Current Loss: 2.5977\n",
            "[Batch 5] Current Loss: 2.2917\n",
            "[Batch 6] Current Loss: 2.4274\n",
            "[Batch 7] Current Loss: 2.6145\n",
            "[Batch 8] Current Loss: 2.1184\n",
            "[Batch 9] Current Loss: 2.4354\n",
            "[Batch 0] Current Loss: 5.4178\n",
            "[Batch 1] Current Loss: 5.2833\n",
            "[Batch 2] Current Loss: 5.5890\n",
            "[Batch 3] Current Loss: 5.0753\n",
            "[Batch 4] Current Loss: 5.6579\n",
            "[Batch 5] Current Loss: 4.6749\n",
            "[Batch 6] Current Loss: 5.6405\n",
            "[Batch 7] Current Loss: 5.0311\n",
            "[Batch 8] Current Loss: 5.3477\n",
            "[Batch 9] Current Loss: 4.7468\n",
            "Ep 4 (Step 031740): Train loss 2.455, Val loss 5.246\n",
            "[Batch 0] Current Loss: 2.6375\n",
            "[Batch 1] Current Loss: 3.1794\n",
            "[Batch 2] Current Loss: 1.9532\n",
            "[Batch 3] Current Loss: 2.0621\n",
            "[Batch 4] Current Loss: 2.3203\n",
            "[Batch 5] Current Loss: 2.0312\n",
            "[Batch 6] Current Loss: 2.0884\n",
            "[Batch 7] Current Loss: 2.3372\n",
            "[Batch 8] Current Loss: 2.7283\n",
            "[Batch 9] Current Loss: 2.1787\n",
            "[Batch 0] Current Loss: 4.9576\n",
            "[Batch 1] Current Loss: 5.1492\n",
            "[Batch 2] Current Loss: 5.5289\n",
            "[Batch 3] Current Loss: 4.9727\n",
            "[Batch 4] Current Loss: 5.7153\n",
            "[Batch 5] Current Loss: 5.2155\n",
            "[Batch 6] Current Loss: 5.0651\n",
            "[Batch 7] Current Loss: 4.8981\n",
            "[Batch 8] Current Loss: 6.0719\n",
            "[Batch 9] Current Loss: 5.1689\n",
            "Ep 4 (Step 031760): Train loss 2.352, Val loss 5.274\n",
            "[Batch 0] Current Loss: 2.2251\n",
            "[Batch 1] Current Loss: 2.7461\n",
            "[Batch 2] Current Loss: 2.3180\n",
            "[Batch 3] Current Loss: 2.5381\n",
            "[Batch 4] Current Loss: 3.1322\n",
            "[Batch 5] Current Loss: 3.1812\n",
            "[Batch 6] Current Loss: 2.2396\n",
            "[Batch 7] Current Loss: 2.4970\n",
            "[Batch 8] Current Loss: 2.6856\n",
            "[Batch 9] Current Loss: 2.5836\n",
            "[Batch 0] Current Loss: 5.7992\n",
            "[Batch 1] Current Loss: 4.9799\n",
            "[Batch 2] Current Loss: 5.9134\n",
            "[Batch 3] Current Loss: 5.5474\n",
            "[Batch 4] Current Loss: 5.6814\n",
            "[Batch 5] Current Loss: 5.1619\n",
            "[Batch 6] Current Loss: 5.3195\n",
            "[Batch 7] Current Loss: 5.0041\n",
            "[Batch 8] Current Loss: 6.1600\n",
            "[Batch 9] Current Loss: 5.2915\n",
            "Ep 4 (Step 031780): Train loss 2.615, Val loss 5.486\n",
            "[Batch 0] Current Loss: 2.5592\n",
            "[Batch 1] Current Loss: 2.4699\n",
            "[Batch 2] Current Loss: 2.7375\n",
            "[Batch 3] Current Loss: 2.5151\n",
            "[Batch 4] Current Loss: 2.2698\n",
            "[Batch 5] Current Loss: 2.3087\n",
            "[Batch 6] Current Loss: 2.8503\n",
            "[Batch 7] Current Loss: 2.6273\n",
            "[Batch 8] Current Loss: 2.2697\n",
            "[Batch 9] Current Loss: 2.4793\n",
            "[Batch 0] Current Loss: 4.5723\n",
            "[Batch 1] Current Loss: 5.0070\n",
            "[Batch 2] Current Loss: 6.1112\n",
            "[Batch 3] Current Loss: 5.5869\n",
            "[Batch 4] Current Loss: 5.4929\n",
            "[Batch 5] Current Loss: 4.6790\n",
            "[Batch 6] Current Loss: 4.6289\n",
            "[Batch 7] Current Loss: 5.2283\n",
            "[Batch 8] Current Loss: 6.1616\n",
            "[Batch 9] Current Loss: 5.9042\n",
            "Ep 4 (Step 031800): Train loss 2.509, Val loss 5.337\n",
            "[Batch 0] Current Loss: 2.3758\n",
            "[Batch 1] Current Loss: 2.1505\n",
            "[Batch 2] Current Loss: 2.5023\n",
            "[Batch 3] Current Loss: 2.8639\n",
            "[Batch 4] Current Loss: 2.0175\n",
            "[Batch 5] Current Loss: 2.7316\n",
            "[Batch 6] Current Loss: 2.2497\n",
            "[Batch 7] Current Loss: 2.9198\n",
            "[Batch 8] Current Loss: 2.3956\n",
            "[Batch 9] Current Loss: 2.0420\n",
            "[Batch 0] Current Loss: 4.8196\n",
            "[Batch 1] Current Loss: 4.9162\n",
            "[Batch 2] Current Loss: 5.9249\n",
            "[Batch 3] Current Loss: 5.6920\n",
            "[Batch 4] Current Loss: 6.1756\n",
            "[Batch 5] Current Loss: 5.8155\n",
            "[Batch 6] Current Loss: 5.4916\n",
            "[Batch 7] Current Loss: 5.9199\n",
            "[Batch 8] Current Loss: 5.1326\n",
            "[Batch 9] Current Loss: 4.6271\n",
            "Ep 4 (Step 031820): Train loss 2.425, Val loss 5.451\n",
            "[Batch 0] Current Loss: 1.9131\n",
            "[Batch 1] Current Loss: 2.5677\n",
            "[Batch 2] Current Loss: 2.5902\n",
            "[Batch 3] Current Loss: 2.7489\n",
            "[Batch 4] Current Loss: 2.0510\n",
            "[Batch 5] Current Loss: 2.2774\n",
            "[Batch 6] Current Loss: 2.4920\n",
            "[Batch 7] Current Loss: 2.2342\n",
            "[Batch 8] Current Loss: 3.0363\n",
            "[Batch 9] Current Loss: 2.5685\n",
            "[Batch 0] Current Loss: 5.5952\n",
            "[Batch 1] Current Loss: 5.8308\n",
            "[Batch 2] Current Loss: 5.1893\n",
            "[Batch 3] Current Loss: 5.5374\n",
            "[Batch 4] Current Loss: 4.9582\n",
            "[Batch 5] Current Loss: 5.3681\n",
            "[Batch 6] Current Loss: 5.1710\n",
            "[Batch 7] Current Loss: 5.5516\n",
            "[Batch 8] Current Loss: 6.0176\n",
            "[Batch 9] Current Loss: 5.5036\n",
            "Ep 4 (Step 031840): Train loss 2.448, Val loss 5.472\n",
            "[Batch 0] Current Loss: 2.1130\n",
            "[Batch 1] Current Loss: 2.8146\n",
            "[Batch 2] Current Loss: 2.3534\n",
            "[Batch 3] Current Loss: 2.5227\n",
            "[Batch 4] Current Loss: 2.6201\n",
            "[Batch 5] Current Loss: 1.9824\n",
            "[Batch 6] Current Loss: 2.7612\n",
            "[Batch 7] Current Loss: 3.0780\n",
            "[Batch 8] Current Loss: 2.2930\n",
            "[Batch 9] Current Loss: 1.9351\n",
            "[Batch 0] Current Loss: 5.6724\n",
            "[Batch 1] Current Loss: 5.2621\n",
            "[Batch 2] Current Loss: 5.9049\n",
            "[Batch 3] Current Loss: 6.1551\n",
            "[Batch 4] Current Loss: 5.8197\n",
            "[Batch 5] Current Loss: 4.9261\n",
            "[Batch 6] Current Loss: 5.3621\n",
            "[Batch 7] Current Loss: 4.8268\n",
            "[Batch 8] Current Loss: 5.6466\n",
            "[Batch 9] Current Loss: 5.3223\n",
            "Ep 4 (Step 031860): Train loss 2.447, Val loss 5.490\n",
            "[Batch 0] Current Loss: 2.6460\n",
            "[Batch 1] Current Loss: 2.2966\n",
            "[Batch 2] Current Loss: 2.1625\n",
            "[Batch 3] Current Loss: 2.2501\n",
            "[Batch 4] Current Loss: 2.0345\n",
            "[Batch 5] Current Loss: 2.6032\n",
            "[Batch 6] Current Loss: 2.6726\n",
            "[Batch 7] Current Loss: 2.3222\n",
            "[Batch 8] Current Loss: 2.1641\n",
            "[Batch 9] Current Loss: 2.4613\n",
            "[Batch 0] Current Loss: 5.3801\n",
            "[Batch 1] Current Loss: 5.6372\n",
            "[Batch 2] Current Loss: 4.5798\n",
            "[Batch 3] Current Loss: 5.5202\n",
            "[Batch 4] Current Loss: 4.8510\n",
            "[Batch 5] Current Loss: 4.3953\n",
            "[Batch 6] Current Loss: 5.7863\n",
            "[Batch 7] Current Loss: 5.7201\n",
            "[Batch 8] Current Loss: 5.2102\n",
            "[Batch 9] Current Loss: 5.3269\n",
            "Ep 4 (Step 031880): Train loss 2.361, Val loss 5.241\n",
            "[Batch 0] Current Loss: 2.5176\n",
            "[Batch 1] Current Loss: 3.3097\n",
            "[Batch 2] Current Loss: 2.9103\n",
            "[Batch 3] Current Loss: 1.9798\n",
            "[Batch 4] Current Loss: 2.7875\n",
            "[Batch 5] Current Loss: 2.1649\n",
            "[Batch 6] Current Loss: 2.7371\n",
            "[Batch 7] Current Loss: 2.5231\n",
            "[Batch 8] Current Loss: 2.3345\n",
            "[Batch 9] Current Loss: 2.9806\n",
            "[Batch 0] Current Loss: 5.4748\n",
            "[Batch 1] Current Loss: 5.6298\n",
            "[Batch 2] Current Loss: 5.8344\n",
            "[Batch 3] Current Loss: 5.4760\n",
            "[Batch 4] Current Loss: 5.7139\n",
            "[Batch 5] Current Loss: 5.2071\n",
            "[Batch 6] Current Loss: 4.7892\n",
            "[Batch 7] Current Loss: 5.2390\n",
            "[Batch 8] Current Loss: 5.6560\n",
            "[Batch 9] Current Loss: 5.8484\n",
            "Ep 4 (Step 031900): Train loss 2.625, Val loss 5.487\n",
            "[Batch 0] Current Loss: 2.2911\n",
            "[Batch 1] Current Loss: 2.8513\n",
            "[Batch 2] Current Loss: 2.1933\n",
            "[Batch 3] Current Loss: 2.5923\n",
            "[Batch 4] Current Loss: 2.1101\n",
            "[Batch 5] Current Loss: 2.6990\n",
            "[Batch 6] Current Loss: 3.0526\n",
            "[Batch 7] Current Loss: 2.1404\n",
            "[Batch 8] Current Loss: 2.5508\n",
            "[Batch 9] Current Loss: 2.6264\n",
            "[Batch 0] Current Loss: 5.8201\n",
            "[Batch 1] Current Loss: 5.5953\n",
            "[Batch 2] Current Loss: 5.5484\n",
            "[Batch 3] Current Loss: 5.2703\n",
            "[Batch 4] Current Loss: 6.3363\n",
            "[Batch 5] Current Loss: 4.2263\n",
            "[Batch 6] Current Loss: 5.7139\n",
            "[Batch 7] Current Loss: 5.3714\n",
            "[Batch 8] Current Loss: 5.6556\n",
            "[Batch 9] Current Loss: 5.8749\n",
            "Ep 4 (Step 031920): Train loss 2.511, Val loss 5.541\n",
            "[Batch 0] Current Loss: 2.2663\n",
            "[Batch 1] Current Loss: 2.5952\n",
            "[Batch 2] Current Loss: 2.0219\n",
            "[Batch 3] Current Loss: 2.3882\n",
            "[Batch 4] Current Loss: 2.2305\n",
            "[Batch 5] Current Loss: 2.4959\n",
            "[Batch 6] Current Loss: 2.3571\n",
            "[Batch 7] Current Loss: 2.8120\n",
            "[Batch 8] Current Loss: 1.8274\n",
            "[Batch 9] Current Loss: 2.0044\n",
            "[Batch 0] Current Loss: 5.1966\n",
            "[Batch 1] Current Loss: 4.9934\n",
            "[Batch 2] Current Loss: 5.0562\n",
            "[Batch 3] Current Loss: 4.8627\n",
            "[Batch 4] Current Loss: 5.5868\n",
            "[Batch 5] Current Loss: 6.0641\n",
            "[Batch 6] Current Loss: 5.3417\n",
            "[Batch 7] Current Loss: 6.0607\n",
            "[Batch 8] Current Loss: 4.5363\n",
            "[Batch 9] Current Loss: 4.8128\n",
            "Ep 4 (Step 031940): Train loss 2.300, Val loss 5.251\n",
            "[Batch 0] Current Loss: 3.0083\n",
            "[Batch 1] Current Loss: 2.6117\n",
            "[Batch 2] Current Loss: 2.2371\n",
            "[Batch 3] Current Loss: 2.1074\n",
            "[Batch 4] Current Loss: 2.1616\n",
            "[Batch 5] Current Loss: 2.1919\n",
            "[Batch 6] Current Loss: 2.7813\n",
            "[Batch 7] Current Loss: 2.7744\n",
            "[Batch 8] Current Loss: 2.9307\n",
            "[Batch 9] Current Loss: 2.3236\n",
            "[Batch 0] Current Loss: 5.7814\n",
            "[Batch 1] Current Loss: 5.3461\n",
            "[Batch 2] Current Loss: 4.8622\n",
            "[Batch 3] Current Loss: 5.2848\n",
            "[Batch 4] Current Loss: 5.7181\n",
            "[Batch 5] Current Loss: 5.8328\n",
            "[Batch 6] Current Loss: 6.3792\n",
            "[Batch 7] Current Loss: 5.1801\n",
            "[Batch 8] Current Loss: 4.7975\n",
            "[Batch 9] Current Loss: 4.6833\n",
            "Ep 4 (Step 031960): Train loss 2.513, Val loss 5.387\n",
            "[Batch 0] Current Loss: 2.6532\n",
            "[Batch 1] Current Loss: 1.9674\n",
            "[Batch 2] Current Loss: 2.4649\n",
            "[Batch 3] Current Loss: 2.4819\n",
            "[Batch 4] Current Loss: 2.3714\n",
            "[Batch 5] Current Loss: 3.0128\n",
            "[Batch 6] Current Loss: 2.6702\n",
            "[Batch 7] Current Loss: 2.1003\n",
            "[Batch 8] Current Loss: 2.4234\n",
            "[Batch 9] Current Loss: 2.5577\n",
            "[Batch 0] Current Loss: 5.5221\n",
            "[Batch 1] Current Loss: 5.7847\n",
            "[Batch 2] Current Loss: 5.9864\n",
            "[Batch 3] Current Loss: 5.2519\n",
            "[Batch 4] Current Loss: 5.9974\n",
            "[Batch 5] Current Loss: 4.8181\n",
            "[Batch 6] Current Loss: 4.7100\n",
            "[Batch 7] Current Loss: 5.0759\n",
            "[Batch 8] Current Loss: 5.2967\n",
            "[Batch 9] Current Loss: 5.5026\n",
            "Ep 4 (Step 031980): Train loss 2.470, Val loss 5.395\n",
            "[Batch 0] Current Loss: 2.6195\n",
            "[Batch 1] Current Loss: 2.5504\n",
            "[Batch 2] Current Loss: 3.0799\n",
            "[Batch 3] Current Loss: 2.0412\n",
            "[Batch 4] Current Loss: 2.3120\n",
            "[Batch 5] Current Loss: 1.9372\n",
            "[Batch 6] Current Loss: 2.4401\n",
            "[Batch 7] Current Loss: 2.9465\n",
            "[Batch 8] Current Loss: 2.3330\n",
            "[Batch 9] Current Loss: 2.5579\n",
            "[Batch 0] Current Loss: 5.0441\n",
            "[Batch 1] Current Loss: 5.9693\n",
            "[Batch 2] Current Loss: 5.5157\n",
            "[Batch 3] Current Loss: 5.3766\n",
            "[Batch 4] Current Loss: 5.1144\n",
            "[Batch 5] Current Loss: 5.7766\n",
            "[Batch 6] Current Loss: 6.2407\n",
            "[Batch 7] Current Loss: 5.6576\n",
            "[Batch 8] Current Loss: 5.1609\n",
            "[Batch 9] Current Loss: 4.3781\n",
            "Ep 4 (Step 032000): Train loss 2.482, Val loss 5.423\n",
            "[Batch 0] Current Loss: 2.5802\n",
            "[Batch 1] Current Loss: 2.1051\n",
            "[Batch 2] Current Loss: 1.8044\n",
            "[Batch 3] Current Loss: 2.7414\n",
            "[Batch 4] Current Loss: 2.0098\n",
            "[Batch 5] Current Loss: 2.2361\n",
            "[Batch 6] Current Loss: 2.4242\n",
            "[Batch 7] Current Loss: 2.4246\n",
            "[Batch 8] Current Loss: 2.6639\n",
            "[Batch 9] Current Loss: 1.9511\n",
            "[Batch 0] Current Loss: 6.1067\n",
            "[Batch 1] Current Loss: 5.4661\n",
            "[Batch 2] Current Loss: 5.2039\n",
            "[Batch 3] Current Loss: 5.8229\n",
            "[Batch 4] Current Loss: 5.5007\n",
            "[Batch 5] Current Loss: 5.2889\n",
            "[Batch 6] Current Loss: 5.7502\n",
            "[Batch 7] Current Loss: 5.2139\n",
            "[Batch 8] Current Loss: 5.5536\n",
            "[Batch 9] Current Loss: 5.4891\n",
            "Ep 4 (Step 032020): Train loss 2.294, Val loss 5.540\n",
            "[Batch 0] Current Loss: 1.8643\n",
            "[Batch 1] Current Loss: 2.5109\n",
            "[Batch 2] Current Loss: 2.4673\n",
            "[Batch 3] Current Loss: 1.8412\n",
            "[Batch 4] Current Loss: 2.3082\n",
            "[Batch 5] Current Loss: 2.3536\n",
            "[Batch 6] Current Loss: 2.5162\n",
            "[Batch 7] Current Loss: 1.8872\n",
            "[Batch 8] Current Loss: 3.3788\n",
            "[Batch 9] Current Loss: 2.4948\n",
            "[Batch 0] Current Loss: 6.0141\n",
            "[Batch 1] Current Loss: 5.7154\n",
            "[Batch 2] Current Loss: 4.6246\n",
            "[Batch 3] Current Loss: 5.2561\n",
            "[Batch 4] Current Loss: 5.8031\n",
            "[Batch 5] Current Loss: 6.0587\n",
            "[Batch 6] Current Loss: 4.6659\n",
            "[Batch 7] Current Loss: 5.1298\n",
            "[Batch 8] Current Loss: 4.4781\n",
            "[Batch 9] Current Loss: 5.5940\n",
            "Ep 4 (Step 032040): Train loss 2.362, Val loss 5.334\n",
            "[Batch 0] Current Loss: 1.8651\n",
            "[Batch 1] Current Loss: 2.1914\n",
            "[Batch 2] Current Loss: 2.0453\n",
            "[Batch 3] Current Loss: 2.6755\n",
            "[Batch 4] Current Loss: 2.8055\n",
            "[Batch 5] Current Loss: 2.2711\n",
            "[Batch 6] Current Loss: 2.8318\n",
            "[Batch 7] Current Loss: 2.5192\n",
            "[Batch 8] Current Loss: 2.5031\n",
            "[Batch 9] Current Loss: 2.5914\n",
            "[Batch 0] Current Loss: 5.8652\n",
            "[Batch 1] Current Loss: 5.6360\n",
            "[Batch 2] Current Loss: 5.3406\n",
            "[Batch 3] Current Loss: 5.0762\n",
            "[Batch 4] Current Loss: 6.4022\n",
            "[Batch 5] Current Loss: 6.1923\n",
            "[Batch 6] Current Loss: 5.4211\n",
            "[Batch 7] Current Loss: 6.3272\n",
            "[Batch 8] Current Loss: 6.0820\n",
            "[Batch 9] Current Loss: 5.6599\n",
            "Ep 4 (Step 032060): Train loss 2.430, Val loss 5.800\n",
            "[Batch 0] Current Loss: 2.0371\n",
            "[Batch 1] Current Loss: 2.1797\n",
            "[Batch 2] Current Loss: 2.3625\n",
            "[Batch 3] Current Loss: 2.6077\n",
            "[Batch 4] Current Loss: 3.3094\n",
            "[Batch 5] Current Loss: 2.3477\n",
            "[Batch 6] Current Loss: 3.0902\n",
            "[Batch 7] Current Loss: 2.7164\n",
            "[Batch 8] Current Loss: 1.7656\n",
            "[Batch 9] Current Loss: 3.0960\n",
            "[Batch 0] Current Loss: 5.8868\n",
            "[Batch 1] Current Loss: 5.8971\n",
            "[Batch 2] Current Loss: 4.8499\n",
            "[Batch 3] Current Loss: 4.6496\n",
            "[Batch 4] Current Loss: 4.5675\n",
            "[Batch 5] Current Loss: 5.5225\n",
            "[Batch 6] Current Loss: 4.7826\n",
            "[Batch 7] Current Loss: 5.1785\n",
            "[Batch 8] Current Loss: 6.1838\n",
            "[Batch 9] Current Loss: 5.3975\n",
            "Ep 4 (Step 032080): Train loss 2.551, Val loss 5.292\n",
            "[Batch 0] Current Loss: 2.7864\n",
            "[Batch 1] Current Loss: 2.7061\n",
            "[Batch 2] Current Loss: 2.4719\n",
            "[Batch 3] Current Loss: 2.7961\n",
            "[Batch 4] Current Loss: 2.2615\n",
            "[Batch 5] Current Loss: 2.6120\n",
            "[Batch 6] Current Loss: 2.5607\n",
            "[Batch 7] Current Loss: 2.5002\n",
            "[Batch 8] Current Loss: 2.4553\n",
            "[Batch 9] Current Loss: 2.7504\n",
            "[Batch 0] Current Loss: 4.6652\n",
            "[Batch 1] Current Loss: 5.0034\n",
            "[Batch 2] Current Loss: 5.1764\n",
            "[Batch 3] Current Loss: 5.6131\n",
            "[Batch 4] Current Loss: 5.3414\n",
            "[Batch 5] Current Loss: 6.2737\n",
            "[Batch 6] Current Loss: 5.5972\n",
            "[Batch 7] Current Loss: 5.7545\n",
            "[Batch 8] Current Loss: 5.7975\n",
            "[Batch 9] Current Loss: 4.6757\n",
            "Ep 4 (Step 032100): Train loss 2.590, Val loss 5.390\n",
            "[Batch 0] Current Loss: 2.3844\n",
            "[Batch 1] Current Loss: 2.7514\n",
            "[Batch 2] Current Loss: 2.2651\n",
            "[Batch 3] Current Loss: 2.4089\n",
            "[Batch 4] Current Loss: 1.9919\n",
            "[Batch 5] Current Loss: 2.6636\n",
            "[Batch 6] Current Loss: 2.2657\n",
            "[Batch 7] Current Loss: 2.7649\n",
            "[Batch 8] Current Loss: 2.3064\n",
            "[Batch 9] Current Loss: 3.0619\n",
            "[Batch 0] Current Loss: 4.9926\n",
            "[Batch 1] Current Loss: 4.9770\n",
            "[Batch 2] Current Loss: 5.3311\n",
            "[Batch 3] Current Loss: 6.1786\n",
            "[Batch 4] Current Loss: 6.0825\n",
            "[Batch 5] Current Loss: 4.9528\n",
            "[Batch 6] Current Loss: 5.0640\n",
            "[Batch 7] Current Loss: 5.5622\n",
            "[Batch 8] Current Loss: 5.2261\n",
            "[Batch 9] Current Loss: 5.4292\n",
            "Ep 4 (Step 032120): Train loss 2.486, Val loss 5.380\n",
            "[Batch 0] Current Loss: 2.8838\n",
            "[Batch 1] Current Loss: 1.9172\n",
            "[Batch 2] Current Loss: 2.3646\n",
            "[Batch 3] Current Loss: 2.3277\n",
            "[Batch 4] Current Loss: 2.3965\n",
            "[Batch 5] Current Loss: 1.7890\n",
            "[Batch 6] Current Loss: 2.4311\n",
            "[Batch 7] Current Loss: 2.5852\n",
            "[Batch 8] Current Loss: 1.9330\n",
            "[Batch 9] Current Loss: 2.2569\n",
            "[Batch 0] Current Loss: 4.9038\n",
            "[Batch 1] Current Loss: 4.9076\n",
            "[Batch 2] Current Loss: 5.8724\n",
            "[Batch 3] Current Loss: 5.2554\n",
            "[Batch 4] Current Loss: 5.5332\n",
            "[Batch 5] Current Loss: 5.7948\n",
            "[Batch 6] Current Loss: 5.9649\n",
            "[Batch 7] Current Loss: 5.4304\n",
            "[Batch 8] Current Loss: 5.1552\n",
            "[Batch 9] Current Loss: 5.3413\n",
            "Ep 4 (Step 032140): Train loss 2.289, Val loss 5.416\n",
            "[Batch 0] Current Loss: 2.8641\n",
            "[Batch 1] Current Loss: 2.3145\n",
            "[Batch 2] Current Loss: 2.3051\n",
            "[Batch 3] Current Loss: 2.0673\n",
            "[Batch 4] Current Loss: 2.5775\n",
            "[Batch 5] Current Loss: 2.6584\n",
            "[Batch 6] Current Loss: 2.2480\n",
            "[Batch 7] Current Loss: 2.4318\n",
            "[Batch 8] Current Loss: 2.8472\n",
            "[Batch 9] Current Loss: 2.8740\n",
            "[Batch 0] Current Loss: 5.9517\n",
            "[Batch 1] Current Loss: 5.8914\n",
            "[Batch 2] Current Loss: 4.9838\n",
            "[Batch 3] Current Loss: 4.9606\n",
            "[Batch 4] Current Loss: 5.4182\n",
            "[Batch 5] Current Loss: 5.1235\n",
            "[Batch 6] Current Loss: 6.1269\n",
            "[Batch 7] Current Loss: 6.0733\n",
            "[Batch 8] Current Loss: 5.6097\n",
            "[Batch 9] Current Loss: 5.1860\n",
            "Ep 4 (Step 032160): Train loss 2.519, Val loss 5.533\n",
            "[Batch 0] Current Loss: 2.4531\n",
            "[Batch 1] Current Loss: 2.3748\n",
            "[Batch 2] Current Loss: 2.1341\n",
            "[Batch 3] Current Loss: 2.4053\n",
            "[Batch 4] Current Loss: 2.4701\n",
            "[Batch 5] Current Loss: 2.1870\n",
            "[Batch 6] Current Loss: 2.1941\n",
            "[Batch 7] Current Loss: 2.1392\n",
            "[Batch 8] Current Loss: 2.5382\n",
            "[Batch 9] Current Loss: 2.3329\n",
            "[Batch 0] Current Loss: 5.2324\n",
            "[Batch 1] Current Loss: 5.1803\n",
            "[Batch 2] Current Loss: 5.2089\n",
            "[Batch 3] Current Loss: 4.8323\n",
            "[Batch 4] Current Loss: 5.6756\n",
            "[Batch 5] Current Loss: 5.2467\n",
            "[Batch 6] Current Loss: 5.6373\n",
            "[Batch 7] Current Loss: 5.3585\n",
            "[Batch 8] Current Loss: 5.5071\n",
            "[Batch 9] Current Loss: 4.7557\n",
            "Ep 4 (Step 032180): Train loss 2.323, Val loss 5.263\n",
            "[Batch 0] Current Loss: 2.5348\n",
            "[Batch 1] Current Loss: 2.6196\n",
            "[Batch 2] Current Loss: 2.4154\n",
            "[Batch 3] Current Loss: 2.8839\n",
            "[Batch 4] Current Loss: 2.0454\n",
            "[Batch 5] Current Loss: 2.5744\n",
            "[Batch 6] Current Loss: 2.5451\n",
            "[Batch 7] Current Loss: 2.5887\n",
            "[Batch 8] Current Loss: 2.3138\n",
            "[Batch 9] Current Loss: 2.0541\n",
            "[Batch 0] Current Loss: 5.6783\n",
            "[Batch 1] Current Loss: 4.9525\n",
            "[Batch 2] Current Loss: 5.0951\n",
            "[Batch 3] Current Loss: 5.0425\n",
            "[Batch 4] Current Loss: 5.5552\n",
            "[Batch 5] Current Loss: 5.6438\n",
            "[Batch 6] Current Loss: 4.5648\n",
            "[Batch 7] Current Loss: 5.6000\n",
            "[Batch 8] Current Loss: 5.8101\n",
            "[Batch 9] Current Loss: 5.3640\n",
            "Ep 4 (Step 032200): Train loss 2.458, Val loss 5.331\n",
            "[Batch 0] Current Loss: 2.4451\n",
            "[Batch 1] Current Loss: 2.2359\n",
            "[Batch 2] Current Loss: 2.4674\n",
            "[Batch 3] Current Loss: 2.6999\n",
            "[Batch 4] Current Loss: 2.6365\n",
            "[Batch 5] Current Loss: 2.5305\n",
            "[Batch 6] Current Loss: 2.0841\n",
            "[Batch 7] Current Loss: 2.5946\n",
            "[Batch 8] Current Loss: 2.1298\n",
            "[Batch 9] Current Loss: 2.3389\n",
            "[Batch 0] Current Loss: 5.6261\n",
            "[Batch 1] Current Loss: 5.1702\n",
            "[Batch 2] Current Loss: 4.9654\n",
            "[Batch 3] Current Loss: 5.9221\n",
            "[Batch 4] Current Loss: 6.0766\n",
            "[Batch 5] Current Loss: 4.6986\n",
            "[Batch 6] Current Loss: 4.8770\n",
            "[Batch 7] Current Loss: 4.2350\n",
            "[Batch 8] Current Loss: 5.7007\n",
            "[Batch 9] Current Loss: 6.0844\n",
            "Ep 4 (Step 032220): Train loss 2.416, Val loss 5.336\n",
            "[Batch 0] Current Loss: 2.1037\n",
            "[Batch 1] Current Loss: 2.4379\n",
            "[Batch 2] Current Loss: 2.6739\n",
            "[Batch 3] Current Loss: 2.4351\n",
            "[Batch 4] Current Loss: 2.3630\n",
            "[Batch 5] Current Loss: 2.3530\n",
            "[Batch 6] Current Loss: 2.6271\n",
            "[Batch 7] Current Loss: 2.1056\n",
            "[Batch 8] Current Loss: 2.1243\n",
            "[Batch 9] Current Loss: 2.4361\n",
            "[Batch 0] Current Loss: 4.8125\n",
            "[Batch 1] Current Loss: 5.1911\n",
            "[Batch 2] Current Loss: 5.0930\n",
            "[Batch 3] Current Loss: 5.8855\n",
            "[Batch 4] Current Loss: 5.4213\n",
            "[Batch 5] Current Loss: 4.9364\n",
            "[Batch 6] Current Loss: 5.5865\n",
            "[Batch 7] Current Loss: 5.6893\n",
            "[Batch 8] Current Loss: 5.5252\n",
            "[Batch 9] Current Loss: 5.3024\n",
            "Ep 4 (Step 032240): Train loss 2.366, Val loss 5.344\n",
            "[Batch 0] Current Loss: 2.1766\n",
            "[Batch 1] Current Loss: 1.9642\n",
            "[Batch 2] Current Loss: 2.7394\n",
            "[Batch 3] Current Loss: 2.3324\n",
            "[Batch 4] Current Loss: 2.1501\n",
            "[Batch 5] Current Loss: 3.0495\n",
            "[Batch 6] Current Loss: 2.2917\n",
            "[Batch 7] Current Loss: 2.8614\n",
            "[Batch 8] Current Loss: 2.0235\n",
            "[Batch 9] Current Loss: 1.9026\n",
            "[Batch 0] Current Loss: 5.1534\n",
            "[Batch 1] Current Loss: 5.8532\n",
            "[Batch 2] Current Loss: 5.9549\n",
            "[Batch 3] Current Loss: 5.3209\n",
            "[Batch 4] Current Loss: 4.5369\n",
            "[Batch 5] Current Loss: 5.6608\n",
            "[Batch 6] Current Loss: 5.6378\n",
            "[Batch 7] Current Loss: 5.2091\n",
            "[Batch 8] Current Loss: 4.7860\n",
            "[Batch 9] Current Loss: 5.2815\n",
            "Ep 4 (Step 032260): Train loss 2.349, Val loss 5.339\n",
            "[Batch 0] Current Loss: 2.4303\n",
            "[Batch 1] Current Loss: 2.8662\n",
            "[Batch 2] Current Loss: 2.1564\n",
            "[Batch 3] Current Loss: 2.2052\n",
            "[Batch 4] Current Loss: 2.7997\n",
            "[Batch 5] Current Loss: 2.7938\n",
            "[Batch 6] Current Loss: 2.6588\n",
            "[Batch 7] Current Loss: 2.3432\n",
            "[Batch 8] Current Loss: 1.8157\n",
            "[Batch 9] Current Loss: 2.6014\n",
            "[Batch 0] Current Loss: 5.1877\n",
            "[Batch 1] Current Loss: 5.7430\n",
            "[Batch 2] Current Loss: 5.0711\n",
            "[Batch 3] Current Loss: 5.5987\n",
            "[Batch 4] Current Loss: 5.8535\n",
            "[Batch 5] Current Loss: 5.4952\n",
            "[Batch 6] Current Loss: 5.9121\n",
            "[Batch 7] Current Loss: 5.2632\n",
            "[Batch 8] Current Loss: 5.6570\n",
            "[Batch 9] Current Loss: 5.1977\n",
            "Ep 4 (Step 032280): Train loss 2.467, Val loss 5.498\n",
            "[Batch 0] Current Loss: 2.2956\n",
            "[Batch 1] Current Loss: 2.3275\n",
            "[Batch 2] Current Loss: 2.4917\n",
            "[Batch 3] Current Loss: 2.3953\n",
            "[Batch 4] Current Loss: 2.6266\n",
            "[Batch 5] Current Loss: 2.0010\n",
            "[Batch 6] Current Loss: 2.2922\n",
            "[Batch 7] Current Loss: 2.3084\n",
            "[Batch 8] Current Loss: 2.2234\n",
            "[Batch 9] Current Loss: 2.5213\n",
            "[Batch 0] Current Loss: 5.5211\n",
            "[Batch 1] Current Loss: 5.6755\n",
            "[Batch 2] Current Loss: 5.1712\n",
            "[Batch 3] Current Loss: 5.5856\n",
            "[Batch 4] Current Loss: 5.4820\n",
            "[Batch 5] Current Loss: 5.2547\n",
            "[Batch 6] Current Loss: 5.1984\n",
            "[Batch 7] Current Loss: 5.9081\n",
            "[Batch 8] Current Loss: 4.9451\n",
            "[Batch 9] Current Loss: 5.9366\n",
            "Ep 4 (Step 032300): Train loss 2.348, Val loss 5.468\n",
            "[Batch 0] Current Loss: 2.2676\n",
            "[Batch 1] Current Loss: 2.8803\n",
            "[Batch 2] Current Loss: 2.4573\n",
            "[Batch 3] Current Loss: 2.2262\n",
            "[Batch 4] Current Loss: 1.9911\n",
            "[Batch 5] Current Loss: 2.5414\n",
            "[Batch 6] Current Loss: 1.8975\n",
            "[Batch 7] Current Loss: 2.0181\n",
            "[Batch 8] Current Loss: 2.9265\n",
            "[Batch 9] Current Loss: 2.7811\n",
            "[Batch 0] Current Loss: 5.2125\n",
            "[Batch 1] Current Loss: 5.8044\n",
            "[Batch 2] Current Loss: 5.3950\n",
            "[Batch 3] Current Loss: 5.1512\n",
            "[Batch 4] Current Loss: 4.5597\n",
            "[Batch 5] Current Loss: 5.9392\n",
            "[Batch 6] Current Loss: 5.0497\n",
            "[Batch 7] Current Loss: 4.7305\n",
            "[Batch 8] Current Loss: 5.0276\n",
            "[Batch 9] Current Loss: 5.5135\n",
            "Ep 4 (Step 032320): Train loss 2.399, Val loss 5.238\n",
            "[Batch 0] Current Loss: 2.6715\n",
            "[Batch 1] Current Loss: 2.6125\n",
            "[Batch 2] Current Loss: 1.6558\n",
            "[Batch 3] Current Loss: 1.8403\n",
            "[Batch 4] Current Loss: 2.4224\n",
            "[Batch 5] Current Loss: 1.8871\n",
            "[Batch 6] Current Loss: 2.0669\n",
            "[Batch 7] Current Loss: 2.4233\n",
            "[Batch 8] Current Loss: 3.1521\n",
            "[Batch 9] Current Loss: 2.6666\n",
            "[Batch 0] Current Loss: 6.1031\n",
            "[Batch 1] Current Loss: 5.5829\n",
            "[Batch 2] Current Loss: 5.4605\n",
            "[Batch 3] Current Loss: 5.7217\n",
            "[Batch 4] Current Loss: 5.3513\n",
            "[Batch 5] Current Loss: 5.2469\n",
            "[Batch 6] Current Loss: 5.5061\n",
            "[Batch 7] Current Loss: 6.0192\n",
            "[Batch 8] Current Loss: 5.1230\n",
            "[Batch 9] Current Loss: 5.2867\n",
            "Ep 4 (Step 032340): Train loss 2.340, Val loss 5.540\n",
            "[Batch 0] Current Loss: 2.0557\n",
            "[Batch 1] Current Loss: 2.3619\n",
            "[Batch 2] Current Loss: 2.1861\n",
            "[Batch 3] Current Loss: 2.8731\n",
            "[Batch 4] Current Loss: 2.8415\n",
            "[Batch 5] Current Loss: 2.3302\n",
            "[Batch 6] Current Loss: 2.0644\n",
            "[Batch 7] Current Loss: 1.7211\n",
            "[Batch 8] Current Loss: 2.4004\n",
            "[Batch 9] Current Loss: 2.4653\n",
            "[Batch 0] Current Loss: 5.0285\n",
            "[Batch 1] Current Loss: 5.8077\n",
            "[Batch 2] Current Loss: 5.7878\n",
            "[Batch 3] Current Loss: 4.9884\n",
            "[Batch 4] Current Loss: 5.6591\n",
            "[Batch 5] Current Loss: 5.5528\n",
            "[Batch 6] Current Loss: 5.6727\n",
            "[Batch 7] Current Loss: 5.0948\n",
            "[Batch 8] Current Loss: 5.3567\n",
            "[Batch 9] Current Loss: 4.9437\n",
            "Ep 4 (Step 032360): Train loss 2.330, Val loss 5.389\n",
            "[Batch 0] Current Loss: 2.4490\n",
            "[Batch 1] Current Loss: 2.3860\n",
            "[Batch 2] Current Loss: 2.1725\n",
            "[Batch 3] Current Loss: 2.5447\n",
            "[Batch 4] Current Loss: 2.6713\n",
            "[Batch 5] Current Loss: 2.4006\n",
            "[Batch 6] Current Loss: 2.2002\n",
            "[Batch 7] Current Loss: 2.4921\n",
            "[Batch 8] Current Loss: 2.4257\n",
            "[Batch 9] Current Loss: 2.4620\n",
            "[Batch 0] Current Loss: 5.5041\n",
            "[Batch 1] Current Loss: 5.6285\n",
            "[Batch 2] Current Loss: 5.0809\n",
            "[Batch 3] Current Loss: 5.2830\n",
            "[Batch 4] Current Loss: 5.5536\n",
            "[Batch 5] Current Loss: 5.5829\n",
            "[Batch 6] Current Loss: 5.9356\n",
            "[Batch 7] Current Loss: 4.6362\n",
            "[Batch 8] Current Loss: 5.7247\n",
            "[Batch 9] Current Loss: 4.8262\n",
            "Ep 4 (Step 032380): Train loss 2.420, Val loss 5.376\n",
            "[Batch 0] Current Loss: 2.5328\n",
            "[Batch 1] Current Loss: 2.6263\n",
            "[Batch 2] Current Loss: 2.1334\n",
            "[Batch 3] Current Loss: 2.2009\n",
            "[Batch 4] Current Loss: 2.6215\n",
            "[Batch 5] Current Loss: 2.8339\n",
            "[Batch 6] Current Loss: 2.9440\n",
            "[Batch 7] Current Loss: 2.8003\n",
            "[Batch 8] Current Loss: 2.3406\n",
            "[Batch 9] Current Loss: 2.3107\n",
            "[Batch 0] Current Loss: 5.8557\n",
            "[Batch 1] Current Loss: 5.6217\n",
            "[Batch 2] Current Loss: 5.1816\n",
            "[Batch 3] Current Loss: 5.4328\n",
            "[Batch 4] Current Loss: 5.3588\n",
            "[Batch 5] Current Loss: 5.1430\n",
            "[Batch 6] Current Loss: 4.5676\n",
            "[Batch 7] Current Loss: 5.6302\n",
            "[Batch 8] Current Loss: 5.4379\n",
            "[Batch 9] Current Loss: 5.9848\n",
            "Ep 4 (Step 032400): Train loss 2.534, Val loss 5.421\n",
            "[Batch 0] Current Loss: 2.0683\n",
            "[Batch 1] Current Loss: 2.5492\n",
            "[Batch 2] Current Loss: 2.4952\n",
            "[Batch 3] Current Loss: 2.3626\n",
            "[Batch 4] Current Loss: 2.1115\n",
            "[Batch 5] Current Loss: 2.3027\n",
            "[Batch 6] Current Loss: 2.0935\n",
            "[Batch 7] Current Loss: 1.7199\n",
            "[Batch 8] Current Loss: 2.3399\n",
            "[Batch 9] Current Loss: 2.5806\n",
            "[Batch 0] Current Loss: 5.3361\n",
            "[Batch 1] Current Loss: 4.8117\n",
            "[Batch 2] Current Loss: 5.9211\n",
            "[Batch 3] Current Loss: 5.2438\n",
            "[Batch 4] Current Loss: 4.6573\n",
            "[Batch 5] Current Loss: 5.2960\n",
            "[Batch 6] Current Loss: 4.9212\n",
            "[Batch 7] Current Loss: 6.3691\n",
            "[Batch 8] Current Loss: 5.5039\n",
            "[Batch 9] Current Loss: 5.9335\n",
            "Ep 4 (Step 032420): Train loss 2.262, Val loss 5.399\n",
            "[Batch 0] Current Loss: 2.2354\n",
            "[Batch 1] Current Loss: 2.8280\n",
            "[Batch 2] Current Loss: 2.3811\n",
            "[Batch 3] Current Loss: 3.3979\n",
            "[Batch 4] Current Loss: 1.9338\n",
            "[Batch 5] Current Loss: 2.4662\n",
            "[Batch 6] Current Loss: 2.5349\n",
            "[Batch 7] Current Loss: 2.5169\n",
            "[Batch 8] Current Loss: 2.2903\n",
            "[Batch 9] Current Loss: 2.4610\n",
            "[Batch 0] Current Loss: 5.7728\n",
            "[Batch 1] Current Loss: 4.8241\n",
            "[Batch 2] Current Loss: 5.8456\n",
            "[Batch 3] Current Loss: 4.6048\n",
            "[Batch 4] Current Loss: 5.3134\n",
            "[Batch 5] Current Loss: 5.9638\n",
            "[Batch 6] Current Loss: 5.6951\n",
            "[Batch 7] Current Loss: 5.0048\n",
            "[Batch 8] Current Loss: 4.4567\n",
            "[Batch 9] Current Loss: 4.8064\n",
            "Ep 4 (Step 032440): Train loss 2.505, Val loss 5.229\n",
            "[Batch 0] Current Loss: 2.1255\n",
            "[Batch 1] Current Loss: 2.2269\n",
            "[Batch 2] Current Loss: 2.8016\n",
            "[Batch 3] Current Loss: 3.0149\n",
            "[Batch 4] Current Loss: 1.8904\n",
            "[Batch 5] Current Loss: 2.6307\n",
            "[Batch 6] Current Loss: 2.5298\n",
            "[Batch 7] Current Loss: 2.5019\n",
            "[Batch 8] Current Loss: 2.3543\n",
            "[Batch 9] Current Loss: 2.1830\n",
            "[Batch 0] Current Loss: 5.1851\n",
            "[Batch 1] Current Loss: 5.5558\n",
            "[Batch 2] Current Loss: 5.4650\n",
            "[Batch 3] Current Loss: 5.8928\n",
            "[Batch 4] Current Loss: 5.4665\n",
            "[Batch 5] Current Loss: 5.3675\n",
            "[Batch 6] Current Loss: 5.4264\n",
            "[Batch 7] Current Loss: 5.8537\n",
            "[Batch 8] Current Loss: 5.8700\n",
            "[Batch 9] Current Loss: 5.6922\n",
            "Ep 4 (Step 032460): Train loss 2.426, Val loss 5.578\n",
            "[Batch 0] Current Loss: 2.3431\n",
            "[Batch 1] Current Loss: 2.7058\n",
            "[Batch 2] Current Loss: 2.7995\n",
            "[Batch 3] Current Loss: 2.2491\n",
            "[Batch 4] Current Loss: 1.7477\n",
            "[Batch 5] Current Loss: 2.6023\n",
            "[Batch 6] Current Loss: 2.4012\n",
            "[Batch 7] Current Loss: 2.1734\n",
            "[Batch 8] Current Loss: 2.0430\n",
            "[Batch 9] Current Loss: 2.0653\n",
            "[Batch 0] Current Loss: 6.5423\n",
            "[Batch 1] Current Loss: 5.7393\n",
            "[Batch 2] Current Loss: 5.0239\n",
            "[Batch 3] Current Loss: 6.3546\n",
            "[Batch 4] Current Loss: 6.0442\n",
            "[Batch 5] Current Loss: 5.4004\n",
            "[Batch 6] Current Loss: 5.3290\n",
            "[Batch 7] Current Loss: 5.4696\n",
            "[Batch 8] Current Loss: 5.5330\n",
            "[Batch 9] Current Loss: 5.2255\n",
            "Ep 4 (Step 032480): Train loss 2.313, Val loss 5.666\n",
            "[Batch 0] Current Loss: 1.8800\n",
            "[Batch 1] Current Loss: 2.1723\n",
            "[Batch 2] Current Loss: 2.7652\n",
            "[Batch 3] Current Loss: 2.4986\n",
            "[Batch 4] Current Loss: 2.1379\n",
            "[Batch 5] Current Loss: 3.0018\n",
            "[Batch 6] Current Loss: 2.8812\n",
            "[Batch 7] Current Loss: 2.3303\n",
            "[Batch 8] Current Loss: 3.1556\n",
            "[Batch 9] Current Loss: 2.3030\n",
            "[Batch 0] Current Loss: 6.1399\n",
            "[Batch 1] Current Loss: 5.7196\n",
            "[Batch 2] Current Loss: 5.2488\n",
            "[Batch 3] Current Loss: 5.5149\n",
            "[Batch 4] Current Loss: 6.0965\n",
            "[Batch 5] Current Loss: 4.6159\n",
            "[Batch 6] Current Loss: 5.4837\n",
            "[Batch 7] Current Loss: 5.3059\n",
            "[Batch 8] Current Loss: 6.0291\n",
            "[Batch 9] Current Loss: 5.4009\n",
            "Ep 4 (Step 032500): Train loss 2.513, Val loss 5.556\n",
            "[Batch 0] Current Loss: 2.6398\n",
            "[Batch 1] Current Loss: 1.9259\n",
            "[Batch 2] Current Loss: 2.2629\n",
            "[Batch 3] Current Loss: 2.9236\n",
            "[Batch 4] Current Loss: 2.2641\n",
            "[Batch 5] Current Loss: 2.5075\n",
            "[Batch 6] Current Loss: 2.5661\n",
            "[Batch 7] Current Loss: 2.3529\n",
            "[Batch 8] Current Loss: 2.3342\n",
            "[Batch 9] Current Loss: 2.3537\n",
            "[Batch 0] Current Loss: 5.4221\n",
            "[Batch 1] Current Loss: 5.5477\n",
            "[Batch 2] Current Loss: 5.6577\n",
            "[Batch 3] Current Loss: 6.4268\n",
            "[Batch 4] Current Loss: 4.6485\n",
            "[Batch 5] Current Loss: 5.7776\n",
            "[Batch 6] Current Loss: 5.1910\n",
            "[Batch 7] Current Loss: 5.0640\n",
            "[Batch 8] Current Loss: 5.5187\n",
            "[Batch 9] Current Loss: 5.4542\n",
            "Ep 4 (Step 032520): Train loss 2.413, Val loss 5.471\n",
            "[Batch 0] Current Loss: 1.9054\n",
            "[Batch 1] Current Loss: 2.0906\n",
            "[Batch 2] Current Loss: 2.4138\n",
            "[Batch 3] Current Loss: 1.9840\n",
            "[Batch 4] Current Loss: 2.6552\n",
            "[Batch 5] Current Loss: 1.9736\n",
            "[Batch 6] Current Loss: 2.2826\n",
            "[Batch 7] Current Loss: 2.6377\n",
            "[Batch 8] Current Loss: 1.9295\n",
            "[Batch 9] Current Loss: 2.4895\n",
            "[Batch 0] Current Loss: 5.3583\n",
            "[Batch 1] Current Loss: 6.2306\n",
            "[Batch 2] Current Loss: 5.6860\n",
            "[Batch 3] Current Loss: 5.3904\n",
            "[Batch 4] Current Loss: 5.2958\n",
            "[Batch 5] Current Loss: 5.9900\n",
            "[Batch 6] Current Loss: 5.1722\n",
            "[Batch 7] Current Loss: 6.4995\n",
            "[Batch 8] Current Loss: 5.3196\n",
            "[Batch 9] Current Loss: 5.5449\n",
            "Ep 4 (Step 032540): Train loss 2.236, Val loss 5.649\n",
            "[Batch 0] Current Loss: 2.9698\n",
            "[Batch 1] Current Loss: 2.4880\n",
            "[Batch 2] Current Loss: 2.0014\n",
            "[Batch 3] Current Loss: 2.6786\n",
            "[Batch 4] Current Loss: 1.6039\n",
            "[Batch 5] Current Loss: 2.7085\n",
            "[Batch 6] Current Loss: 2.3258\n",
            "[Batch 7] Current Loss: 2.1665\n",
            "[Batch 8] Current Loss: 2.1885\n",
            "[Batch 9] Current Loss: 2.4406\n",
            "[Batch 0] Current Loss: 5.2447\n",
            "[Batch 1] Current Loss: 5.2003\n",
            "[Batch 2] Current Loss: 4.6487\n",
            "[Batch 3] Current Loss: 5.6937\n",
            "[Batch 4] Current Loss: 5.7855\n",
            "[Batch 5] Current Loss: 6.0975\n",
            "[Batch 6] Current Loss: 4.9097\n",
            "[Batch 7] Current Loss: 5.2394\n",
            "[Batch 8] Current Loss: 5.7514\n",
            "[Batch 9] Current Loss: 4.5253\n",
            "Ep 4 (Step 032560): Train loss 2.357, Val loss 5.310\n",
            "[Batch 0] Current Loss: 2.8958\n",
            "[Batch 1] Current Loss: 2.3437\n",
            "[Batch 2] Current Loss: 2.3114\n",
            "[Batch 3] Current Loss: 1.7095\n",
            "[Batch 4] Current Loss: 3.0289\n",
            "[Batch 5] Current Loss: 2.4068\n",
            "[Batch 6] Current Loss: 2.4669\n",
            "[Batch 7] Current Loss: 2.6885\n",
            "[Batch 8] Current Loss: 2.4015\n",
            "[Batch 9] Current Loss: 2.0026\n",
            "[Batch 0] Current Loss: 5.9232\n",
            "[Batch 1] Current Loss: 5.8863\n",
            "[Batch 2] Current Loss: 5.2226\n",
            "[Batch 3] Current Loss: 5.3359\n",
            "[Batch 4] Current Loss: 5.7672\n",
            "[Batch 5] Current Loss: 4.6804\n",
            "[Batch 6] Current Loss: 6.0025\n",
            "[Batch 7] Current Loss: 5.3503\n",
            "[Batch 8] Current Loss: 5.1293\n",
            "[Batch 9] Current Loss: 5.8956\n",
            "Ep 4 (Step 032580): Train loss 2.426, Val loss 5.519\n",
            "[Batch 0] Current Loss: 2.0000\n",
            "[Batch 1] Current Loss: 2.7937\n",
            "[Batch 2] Current Loss: 2.3922\n",
            "[Batch 3] Current Loss: 2.3105\n",
            "[Batch 4] Current Loss: 2.1034\n",
            "[Batch 5] Current Loss: 2.4058\n",
            "[Batch 6] Current Loss: 2.8480\n",
            "[Batch 7] Current Loss: 2.4166\n",
            "[Batch 8] Current Loss: 1.7309\n",
            "[Batch 9] Current Loss: 2.6337\n",
            "[Batch 0] Current Loss: 5.3203\n",
            "[Batch 1] Current Loss: 5.2229\n",
            "[Batch 2] Current Loss: 5.3971\n",
            "[Batch 3] Current Loss: 5.2314\n",
            "[Batch 4] Current Loss: 5.9062\n",
            "[Batch 5] Current Loss: 5.1535\n",
            "[Batch 6] Current Loss: 4.6774\n",
            "[Batch 7] Current Loss: 5.6349\n",
            "[Batch 8] Current Loss: 4.9440\n",
            "[Batch 9] Current Loss: 5.6941\n",
            "Ep 4 (Step 032600): Train loss 2.363, Val loss 5.318\n",
            "[Batch 0] Current Loss: 2.3912\n",
            "[Batch 1] Current Loss: 2.5733\n",
            "[Batch 2] Current Loss: 2.0970\n",
            "[Batch 3] Current Loss: 2.4538\n",
            "[Batch 4] Current Loss: 2.7569\n",
            "[Batch 5] Current Loss: 2.2797\n",
            "[Batch 6] Current Loss: 2.6281\n",
            "[Batch 7] Current Loss: 2.9897\n",
            "[Batch 8] Current Loss: 2.9194\n",
            "[Batch 9] Current Loss: 2.8505\n",
            "[Batch 0] Current Loss: 5.1666\n",
            "[Batch 1] Current Loss: 5.6198\n",
            "[Batch 2] Current Loss: 4.7741\n",
            "[Batch 3] Current Loss: 4.9754\n",
            "[Batch 4] Current Loss: 5.2913\n",
            "[Batch 5] Current Loss: 5.0564\n",
            "[Batch 6] Current Loss: 5.4995\n",
            "[Batch 7] Current Loss: 5.7116\n",
            "[Batch 8] Current Loss: 4.8081\n",
            "[Batch 9] Current Loss: 5.2862\n",
            "Ep 4 (Step 032620): Train loss 2.594, Val loss 5.219\n",
            "[Batch 0] Current Loss: 2.3455\n",
            "[Batch 1] Current Loss: 1.9877\n",
            "[Batch 2] Current Loss: 2.6838\n",
            "[Batch 3] Current Loss: 2.5501\n",
            "[Batch 4] Current Loss: 2.2406\n",
            "[Batch 5] Current Loss: 1.4926\n",
            "[Batch 6] Current Loss: 2.5015\n",
            "[Batch 7] Current Loss: 2.7068\n",
            "[Batch 8] Current Loss: 2.0754\n",
            "[Batch 9] Current Loss: 2.7868\n",
            "[Batch 0] Current Loss: 4.8245\n",
            "[Batch 1] Current Loss: 5.0748\n",
            "[Batch 2] Current Loss: 5.2831\n",
            "[Batch 3] Current Loss: 6.2277\n",
            "[Batch 4] Current Loss: 4.6609\n",
            "[Batch 5] Current Loss: 4.9219\n",
            "[Batch 6] Current Loss: 6.0764\n",
            "[Batch 7] Current Loss: 4.7780\n",
            "[Batch 8] Current Loss: 5.7856\n",
            "[Batch 9] Current Loss: 4.6694\n",
            "Ep 4 (Step 032640): Train loss 2.337, Val loss 5.230\n",
            "[Batch 0] Current Loss: 2.2171\n",
            "[Batch 1] Current Loss: 2.2260\n",
            "[Batch 2] Current Loss: 2.0792\n",
            "[Batch 3] Current Loss: 2.5728\n",
            "[Batch 4] Current Loss: 2.6144\n",
            "[Batch 5] Current Loss: 2.6833\n",
            "[Batch 6] Current Loss: 1.7988\n",
            "[Batch 7] Current Loss: 2.0056\n",
            "[Batch 8] Current Loss: 2.7074\n",
            "[Batch 9] Current Loss: 2.4036\n",
            "[Batch 0] Current Loss: 5.2897\n",
            "[Batch 1] Current Loss: 5.9495\n",
            "[Batch 2] Current Loss: 5.1374\n",
            "[Batch 3] Current Loss: 5.0734\n",
            "[Batch 4] Current Loss: 5.7384\n",
            "[Batch 5] Current Loss: 5.1256\n",
            "[Batch 6] Current Loss: 6.1976\n",
            "[Batch 7] Current Loss: 4.5925\n",
            "[Batch 8] Current Loss: 6.1266\n",
            "[Batch 9] Current Loss: 5.5618\n",
            "Ep 4 (Step 032660): Train loss 2.331, Val loss 5.479\n",
            "[Batch 0] Current Loss: 2.3055\n",
            "[Batch 1] Current Loss: 2.6009\n",
            "[Batch 2] Current Loss: 2.5789\n",
            "[Batch 3] Current Loss: 2.3664\n",
            "[Batch 4] Current Loss: 2.8050\n",
            "[Batch 5] Current Loss: 2.3643\n",
            "[Batch 6] Current Loss: 2.0531\n",
            "[Batch 7] Current Loss: 2.0107\n",
            "[Batch 8] Current Loss: 2.3208\n",
            "[Batch 9] Current Loss: 2.0962\n",
            "[Batch 0] Current Loss: 5.5540\n",
            "[Batch 1] Current Loss: 6.0589\n",
            "[Batch 2] Current Loss: 4.9245\n",
            "[Batch 3] Current Loss: 5.5464\n",
            "[Batch 4] Current Loss: 5.6904\n",
            "[Batch 5] Current Loss: 4.8702\n",
            "[Batch 6] Current Loss: 5.3755\n",
            "[Batch 7] Current Loss: 5.9296\n",
            "[Batch 8] Current Loss: 5.7813\n",
            "[Batch 9] Current Loss: 4.9791\n",
            "Ep 4 (Step 032680): Train loss 2.350, Val loss 5.471\n",
            "[Batch 0] Current Loss: 2.5638\n",
            "[Batch 1] Current Loss: 2.4591\n",
            "[Batch 2] Current Loss: 2.4430\n",
            "[Batch 3] Current Loss: 2.4263\n",
            "[Batch 4] Current Loss: 2.1592\n",
            "[Batch 5] Current Loss: 2.6009\n",
            "[Batch 6] Current Loss: 2.0326\n",
            "[Batch 7] Current Loss: 3.1327\n",
            "[Batch 8] Current Loss: 2.4517\n",
            "[Batch 9] Current Loss: 2.6002\n",
            "[Batch 0] Current Loss: 5.4104\n",
            "[Batch 1] Current Loss: 5.3622\n",
            "[Batch 2] Current Loss: 5.3225\n",
            "[Batch 3] Current Loss: 5.2478\n",
            "[Batch 4] Current Loss: 5.7468\n",
            "[Batch 5] Current Loss: 5.9025\n",
            "[Batch 6] Current Loss: 4.7192\n",
            "[Batch 7] Current Loss: 5.5360\n",
            "[Batch 8] Current Loss: 5.6992\n",
            "[Batch 9] Current Loss: 4.5544\n",
            "Ep 4 (Step 032700): Train loss 2.487, Val loss 5.350\n",
            "[Batch 0] Current Loss: 2.7167\n",
            "[Batch 1] Current Loss: 2.9025\n",
            "[Batch 2] Current Loss: 2.8453\n",
            "[Batch 3] Current Loss: 2.7658\n",
            "[Batch 4] Current Loss: 1.9884\n",
            "[Batch 5] Current Loss: 2.4591\n",
            "[Batch 6] Current Loss: 2.3168\n",
            "[Batch 7] Current Loss: 2.9465\n",
            "[Batch 8] Current Loss: 2.8438\n",
            "[Batch 9] Current Loss: 2.4830\n",
            "[Batch 0] Current Loss: 6.2170\n",
            "[Batch 1] Current Loss: 6.3889\n",
            "[Batch 2] Current Loss: 5.7311\n",
            "[Batch 3] Current Loss: 5.9050\n",
            "[Batch 4] Current Loss: 4.9399\n",
            "[Batch 5] Current Loss: 5.5610\n",
            "[Batch 6] Current Loss: 5.1529\n",
            "[Batch 7] Current Loss: 5.0840\n",
            "[Batch 8] Current Loss: 5.5499\n",
            "[Batch 9] Current Loss: 6.1274\n",
            "Ep 4 (Step 032720): Train loss 2.627, Val loss 5.666\n",
            "[Batch 0] Current Loss: 2.5662\n",
            "[Batch 1] Current Loss: 2.5779\n",
            "[Batch 2] Current Loss: 2.1269\n",
            "[Batch 3] Current Loss: 2.5214\n",
            "[Batch 4] Current Loss: 2.0762\n",
            "[Batch 5] Current Loss: 2.2687\n",
            "[Batch 6] Current Loss: 2.2467\n",
            "[Batch 7] Current Loss: 2.4987\n",
            "[Batch 8] Current Loss: 2.4279\n",
            "[Batch 9] Current Loss: 1.8980\n",
            "[Batch 0] Current Loss: 5.5544\n",
            "[Batch 1] Current Loss: 4.9053\n",
            "[Batch 2] Current Loss: 5.6928\n",
            "[Batch 3] Current Loss: 5.8111\n",
            "[Batch 4] Current Loss: 5.4856\n",
            "[Batch 5] Current Loss: 5.5075\n",
            "[Batch 6] Current Loss: 5.1872\n",
            "[Batch 7] Current Loss: 5.6061\n",
            "[Batch 8] Current Loss: 5.7375\n",
            "[Batch 9] Current Loss: 5.6496\n",
            "Ep 4 (Step 032740): Train loss 2.321, Val loss 5.514\n",
            "[Batch 0] Current Loss: 2.2493\n",
            "[Batch 1] Current Loss: 2.5224\n",
            "[Batch 2] Current Loss: 2.6579\n",
            "[Batch 3] Current Loss: 2.4877\n",
            "[Batch 4] Current Loss: 2.5730\n",
            "[Batch 5] Current Loss: 2.2164\n",
            "[Batch 6] Current Loss: 2.0714\n",
            "[Batch 7] Current Loss: 1.8512\n",
            "[Batch 8] Current Loss: 2.7944\n",
            "[Batch 9] Current Loss: 2.7484\n",
            "[Batch 0] Current Loss: 5.6207\n",
            "[Batch 1] Current Loss: 5.2826\n",
            "[Batch 2] Current Loss: 5.5421\n",
            "[Batch 3] Current Loss: 5.1560\n",
            "[Batch 4] Current Loss: 5.7685\n",
            "[Batch 5] Current Loss: 4.2540\n",
            "[Batch 6] Current Loss: 5.1885\n",
            "[Batch 7] Current Loss: 5.3686\n",
            "[Batch 8] Current Loss: 4.6147\n",
            "[Batch 9] Current Loss: 5.5505\n",
            "Ep 4 (Step 032760): Train loss 2.417, Val loss 5.235\n",
            "[Batch 0] Current Loss: 2.2394\n",
            "[Batch 1] Current Loss: 2.5246\n",
            "[Batch 2] Current Loss: 2.5326\n",
            "[Batch 3] Current Loss: 2.6648\n",
            "[Batch 4] Current Loss: 2.4352\n",
            "[Batch 5] Current Loss: 2.3013\n",
            "[Batch 6] Current Loss: 2.3846\n",
            "[Batch 7] Current Loss: 2.4620\n",
            "[Batch 8] Current Loss: 1.7168\n",
            "[Batch 9] Current Loss: 2.6165\n",
            "[Batch 0] Current Loss: 5.3500\n",
            "[Batch 1] Current Loss: 5.3540\n",
            "[Batch 2] Current Loss: 5.4909\n",
            "[Batch 3] Current Loss: 5.1357\n",
            "[Batch 4] Current Loss: 5.7143\n",
            "[Batch 5] Current Loss: 5.6259\n",
            "[Batch 6] Current Loss: 5.0080\n",
            "[Batch 7] Current Loss: 5.3306\n",
            "[Batch 8] Current Loss: 5.6571\n",
            "[Batch 9] Current Loss: 5.3486\n",
            "Ep 4 (Step 032780): Train loss 2.388, Val loss 5.402\n",
            "[Batch 0] Current Loss: 2.3888\n",
            "[Batch 1] Current Loss: 1.9071\n",
            "[Batch 2] Current Loss: 2.6895\n",
            "[Batch 3] Current Loss: 2.6038\n",
            "[Batch 4] Current Loss: 1.9016\n",
            "[Batch 5] Current Loss: 2.1290\n",
            "[Batch 6] Current Loss: 2.3662\n",
            "[Batch 7] Current Loss: 2.2414\n",
            "[Batch 8] Current Loss: 2.1301\n",
            "[Batch 9] Current Loss: 2.2109\n",
            "[Batch 0] Current Loss: 5.3601\n",
            "[Batch 1] Current Loss: 5.4358\n",
            "[Batch 2] Current Loss: 5.3753\n",
            "[Batch 3] Current Loss: 5.4448\n",
            "[Batch 4] Current Loss: 4.6529\n",
            "[Batch 5] Current Loss: 5.4112\n",
            "[Batch 6] Current Loss: 6.0409\n",
            "[Batch 7] Current Loss: 4.8210\n",
            "[Batch 8] Current Loss: 5.7476\n",
            "[Batch 9] Current Loss: 4.9113\n",
            "Ep 4 (Step 032800): Train loss 2.257, Val loss 5.320\n",
            "[Batch 0] Current Loss: 2.3069\n",
            "[Batch 1] Current Loss: 2.0853\n",
            "[Batch 2] Current Loss: 2.8205\n",
            "[Batch 3] Current Loss: 1.8677\n",
            "[Batch 4] Current Loss: 2.6826\n",
            "[Batch 5] Current Loss: 2.1897\n",
            "[Batch 6] Current Loss: 2.7953\n",
            "[Batch 7] Current Loss: 2.5329\n",
            "[Batch 8] Current Loss: 2.7941\n",
            "[Batch 9] Current Loss: 2.3597\n",
            "[Batch 0] Current Loss: 5.6068\n",
            "[Batch 1] Current Loss: 5.0556\n",
            "[Batch 2] Current Loss: 6.4879\n",
            "[Batch 3] Current Loss: 5.2989\n",
            "[Batch 4] Current Loss: 5.9100\n",
            "[Batch 5] Current Loss: 4.9608\n",
            "[Batch 6] Current Loss: 5.4560\n",
            "[Batch 7] Current Loss: 5.6220\n",
            "[Batch 8] Current Loss: 4.9751\n",
            "[Batch 9] Current Loss: 5.3676\n",
            "Ep 4 (Step 032820): Train loss 2.443, Val loss 5.474\n",
            "[Batch 0] Current Loss: 2.4422\n",
            "[Batch 1] Current Loss: 2.9588\n",
            "[Batch 2] Current Loss: 2.7909\n",
            "[Batch 3] Current Loss: 2.8423\n",
            "[Batch 4] Current Loss: 2.5229\n",
            "[Batch 5] Current Loss: 2.2150\n",
            "[Batch 6] Current Loss: 2.5777\n",
            "[Batch 7] Current Loss: 2.0961\n",
            "[Batch 8] Current Loss: 2.4997\n",
            "[Batch 9] Current Loss: 1.8762\n",
            "[Batch 0] Current Loss: 5.9423\n",
            "[Batch 1] Current Loss: 5.5079\n",
            "[Batch 2] Current Loss: 6.3246\n",
            "[Batch 3] Current Loss: 5.6855\n",
            "[Batch 4] Current Loss: 5.2153\n",
            "[Batch 5] Current Loss: 5.6897\n",
            "[Batch 6] Current Loss: 4.9374\n",
            "[Batch 7] Current Loss: 4.9901\n",
            "[Batch 8] Current Loss: 5.4715\n",
            "[Batch 9] Current Loss: 4.9482\n",
            "Ep 4 (Step 032840): Train loss 2.482, Val loss 5.471\n",
            "[Batch 0] Current Loss: 2.1613\n",
            "[Batch 1] Current Loss: 2.4821\n",
            "[Batch 2] Current Loss: 1.9210\n",
            "[Batch 3] Current Loss: 2.3704\n",
            "[Batch 4] Current Loss: 2.8944\n",
            "[Batch 5] Current Loss: 2.5883\n",
            "[Batch 6] Current Loss: 2.0012\n",
            "[Batch 7] Current Loss: 1.9902\n",
            "[Batch 8] Current Loss: 2.4276\n",
            "[Batch 9] Current Loss: 2.0526\n",
            "[Batch 0] Current Loss: 6.0275\n",
            "[Batch 1] Current Loss: 5.5245\n",
            "[Batch 2] Current Loss: 5.1545\n",
            "[Batch 3] Current Loss: 5.7923\n",
            "[Batch 4] Current Loss: 5.7670\n",
            "[Batch 5] Current Loss: 5.1077\n",
            "[Batch 6] Current Loss: 5.4217\n",
            "[Batch 7] Current Loss: 5.5367\n",
            "[Batch 8] Current Loss: 4.9789\n",
            "[Batch 9] Current Loss: 5.2224\n",
            "Ep 4 (Step 032860): Train loss 2.289, Val loss 5.453\n",
            "[Batch 0] Current Loss: 1.6972\n",
            "[Batch 1] Current Loss: 2.4793\n",
            "[Batch 2] Current Loss: 2.1123\n",
            "[Batch 3] Current Loss: 2.3855\n",
            "[Batch 4] Current Loss: 2.5682\n",
            "[Batch 5] Current Loss: 2.3892\n",
            "[Batch 6] Current Loss: 1.8255\n",
            "[Batch 7] Current Loss: 2.4169\n",
            "[Batch 8] Current Loss: 1.9388\n",
            "[Batch 9] Current Loss: 2.4333\n",
            "[Batch 0] Current Loss: 6.0084\n",
            "[Batch 1] Current Loss: 5.9195\n",
            "[Batch 2] Current Loss: 5.3946\n",
            "[Batch 3] Current Loss: 5.7079\n",
            "[Batch 4] Current Loss: 5.4425\n",
            "[Batch 5] Current Loss: 4.9360\n",
            "[Batch 6] Current Loss: 5.7705\n",
            "[Batch 7] Current Loss: 5.4768\n",
            "[Batch 8] Current Loss: 5.4990\n",
            "[Batch 9] Current Loss: 5.7528\n",
            "Ep 4 (Step 032880): Train loss 2.225, Val loss 5.591\n",
            "[Batch 0] Current Loss: 2.1232\n",
            "[Batch 1] Current Loss: 2.2498\n",
            "[Batch 2] Current Loss: 2.4486\n",
            "[Batch 3] Current Loss: 2.5135\n",
            "[Batch 4] Current Loss: 2.9490\n",
            "[Batch 5] Current Loss: 2.2365\n",
            "[Batch 6] Current Loss: 2.2809\n",
            "[Batch 7] Current Loss: 2.2718\n",
            "[Batch 8] Current Loss: 2.2883\n",
            "[Batch 9] Current Loss: 2.4382\n",
            "[Batch 0] Current Loss: 5.3379\n",
            "[Batch 1] Current Loss: 5.6558\n",
            "[Batch 2] Current Loss: 5.2431\n",
            "[Batch 3] Current Loss: 4.9002\n",
            "[Batch 4] Current Loss: 5.4174\n",
            "[Batch 5] Current Loss: 5.7509\n",
            "[Batch 6] Current Loss: 5.3394\n",
            "[Batch 7] Current Loss: 5.5226\n",
            "[Batch 8] Current Loss: 5.2103\n",
            "[Batch 9] Current Loss: 6.0990\n",
            "Ep 4 (Step 032900): Train loss 2.380, Val loss 5.448\n",
            "[Batch 0] Current Loss: 2.4101\n",
            "[Batch 1] Current Loss: 2.6749\n",
            "[Batch 2] Current Loss: 2.4896\n",
            "[Batch 3] Current Loss: 2.6631\n",
            "[Batch 4] Current Loss: 2.6027\n",
            "[Batch 5] Current Loss: 2.5845\n",
            "[Batch 6] Current Loss: 2.6569\n",
            "[Batch 7] Current Loss: 2.6416\n",
            "[Batch 8] Current Loss: 1.9184\n",
            "[Batch 9] Current Loss: 2.6510\n",
            "[Batch 0] Current Loss: 6.1035\n",
            "[Batch 1] Current Loss: 5.7911\n",
            "[Batch 2] Current Loss: 4.1644\n",
            "[Batch 3] Current Loss: 5.5501\n",
            "[Batch 4] Current Loss: 5.6138\n",
            "[Batch 5] Current Loss: 6.0350\n",
            "[Batch 6] Current Loss: 6.4402\n",
            "[Batch 7] Current Loss: 5.8796\n",
            "[Batch 8] Current Loss: 5.6997\n",
            "[Batch 9] Current Loss: 6.0833\n",
            "Ep 4 (Step 032920): Train loss 2.529, Val loss 5.736\n",
            "[Batch 0] Current Loss: 2.2717\n",
            "[Batch 1] Current Loss: 2.5912\n",
            "[Batch 2] Current Loss: 1.8347\n",
            "[Batch 3] Current Loss: 2.4543\n",
            "[Batch 4] Current Loss: 2.8518\n",
            "[Batch 5] Current Loss: 2.6709\n",
            "[Batch 6] Current Loss: 2.6495\n",
            "[Batch 7] Current Loss: 2.2417\n",
            "[Batch 8] Current Loss: 2.1946\n",
            "[Batch 9] Current Loss: 1.6345\n",
            "[Batch 0] Current Loss: 5.8860\n",
            "[Batch 1] Current Loss: 5.0724\n",
            "[Batch 2] Current Loss: 5.5260\n",
            "[Batch 3] Current Loss: 5.5994\n",
            "[Batch 4] Current Loss: 5.2627\n",
            "[Batch 5] Current Loss: 5.3244\n",
            "[Batch 6] Current Loss: 4.9157\n",
            "[Batch 7] Current Loss: 5.1843\n",
            "[Batch 8] Current Loss: 5.2765\n",
            "[Batch 9] Current Loss: 6.2943\n",
            "Ep 4 (Step 032940): Train loss 2.339, Val loss 5.434\n",
            "[Batch 0] Current Loss: 2.2617\n",
            "[Batch 1] Current Loss: 2.6223\n",
            "[Batch 2] Current Loss: 2.9674\n",
            "[Batch 3] Current Loss: 2.2322\n",
            "[Batch 4] Current Loss: 2.7703\n",
            "[Batch 5] Current Loss: 2.9105\n",
            "[Batch 6] Current Loss: 2.0582\n",
            "[Batch 7] Current Loss: 2.1127\n",
            "[Batch 8] Current Loss: 2.4160\n",
            "[Batch 9] Current Loss: 2.3484\n",
            "[Batch 0] Current Loss: 5.4944\n",
            "[Batch 1] Current Loss: 4.7999\n",
            "[Batch 2] Current Loss: 6.2086\n",
            "[Batch 3] Current Loss: 5.6583\n",
            "[Batch 4] Current Loss: 5.7869\n",
            "[Batch 5] Current Loss: 5.0822\n",
            "[Batch 6] Current Loss: 4.9838\n",
            "[Batch 7] Current Loss: 5.3964\n",
            "[Batch 8] Current Loss: 5.7708\n",
            "[Batch 9] Current Loss: 5.5514\n",
            "Ep 4 (Step 032960): Train loss 2.470, Val loss 5.473\n",
            "[Batch 0] Current Loss: 2.4967\n",
            "[Batch 1] Current Loss: 2.3312\n",
            "[Batch 2] Current Loss: 2.6594\n",
            "[Batch 3] Current Loss: 3.2856\n",
            "[Batch 4] Current Loss: 2.5844\n",
            "[Batch 5] Current Loss: 1.9520\n",
            "[Batch 6] Current Loss: 1.7394\n",
            "[Batch 7] Current Loss: 2.2808\n",
            "[Batch 8] Current Loss: 2.4864\n",
            "[Batch 9] Current Loss: 2.3459\n",
            "[Batch 0] Current Loss: 5.4566\n",
            "[Batch 1] Current Loss: 4.8432\n",
            "[Batch 2] Current Loss: 6.2215\n",
            "[Batch 3] Current Loss: 5.1331\n",
            "[Batch 4] Current Loss: 4.6993\n",
            "[Batch 5] Current Loss: 4.9459\n",
            "[Batch 6] Current Loss: 5.7760\n",
            "[Batch 7] Current Loss: 5.1993\n",
            "[Batch 8] Current Loss: 5.7025\n",
            "[Batch 9] Current Loss: 6.1677\n",
            "Ep 4 (Step 032980): Train loss 2.416, Val loss 5.415\n",
            "[Batch 0] Current Loss: 2.3968\n",
            "[Batch 1] Current Loss: 2.1504\n",
            "[Batch 2] Current Loss: 2.7887\n",
            "[Batch 3] Current Loss: 2.4752\n",
            "[Batch 4] Current Loss: 2.5555\n",
            "[Batch 5] Current Loss: 2.3781\n",
            "[Batch 6] Current Loss: 2.8023\n",
            "[Batch 7] Current Loss: 1.9550\n",
            "[Batch 8] Current Loss: 1.8998\n",
            "[Batch 9] Current Loss: 2.3178\n",
            "[Batch 0] Current Loss: 5.8686\n",
            "[Batch 1] Current Loss: 5.0487\n",
            "[Batch 2] Current Loss: 5.2798\n",
            "[Batch 3] Current Loss: 5.9465\n",
            "[Batch 4] Current Loss: 5.1011\n",
            "[Batch 5] Current Loss: 6.0508\n",
            "[Batch 6] Current Loss: 4.4391\n",
            "[Batch 7] Current Loss: 5.1676\n",
            "[Batch 8] Current Loss: 5.2798\n",
            "[Batch 9] Current Loss: 6.4317\n",
            "Ep 4 (Step 033000): Train loss 2.372, Val loss 5.461\n",
            "[Batch 0] Current Loss: 2.2764\n",
            "[Batch 1] Current Loss: 2.6737\n",
            "[Batch 2] Current Loss: 2.3355\n",
            "[Batch 3] Current Loss: 2.7112\n",
            "[Batch 4] Current Loss: 2.6397\n",
            "[Batch 5] Current Loss: 2.6497\n",
            "[Batch 6] Current Loss: 2.6152\n",
            "[Batch 7] Current Loss: 2.2870\n",
            "[Batch 8] Current Loss: 2.2399\n",
            "[Batch 9] Current Loss: 2.3499\n",
            "[Batch 0] Current Loss: 5.8120\n",
            "[Batch 1] Current Loss: 6.2303\n",
            "[Batch 2] Current Loss: 5.3014\n",
            "[Batch 3] Current Loss: 5.1022\n",
            "[Batch 4] Current Loss: 4.6203\n",
            "[Batch 5] Current Loss: 5.5590\n",
            "[Batch 6] Current Loss: 5.7869\n",
            "[Batch 7] Current Loss: 5.6750\n",
            "[Batch 8] Current Loss: 5.7730\n",
            "[Batch 9] Current Loss: 5.2957\n",
            "Ep 4 (Step 033020): Train loss 2.478, Val loss 5.516\n",
            "[Batch 0] Current Loss: 2.4049\n",
            "[Batch 1] Current Loss: 3.1831\n",
            "[Batch 2] Current Loss: 1.6701\n",
            "[Batch 3] Current Loss: 1.9880\n",
            "[Batch 4] Current Loss: 2.7747\n",
            "[Batch 5] Current Loss: 2.9214\n",
            "[Batch 6] Current Loss: 2.3810\n",
            "[Batch 7] Current Loss: 2.6038\n",
            "[Batch 8] Current Loss: 2.0546\n",
            "[Batch 9] Current Loss: 2.0616\n",
            "[Batch 0] Current Loss: 6.3155\n",
            "[Batch 1] Current Loss: 5.6364\n",
            "[Batch 2] Current Loss: 6.0382\n",
            "[Batch 3] Current Loss: 5.2577\n",
            "[Batch 4] Current Loss: 4.8783\n",
            "[Batch 5] Current Loss: 5.1377\n",
            "[Batch 6] Current Loss: 5.8760\n",
            "[Batch 7] Current Loss: 5.7369\n",
            "[Batch 8] Current Loss: 4.9908\n",
            "[Batch 9] Current Loss: 4.8891\n",
            "Ep 4 (Step 033040): Train loss 2.404, Val loss 5.476\n",
            "[Batch 0] Current Loss: 2.3928\n",
            "[Batch 1] Current Loss: 2.5423\n",
            "[Batch 2] Current Loss: 3.2018\n",
            "[Batch 3] Current Loss: 3.0591\n",
            "[Batch 4] Current Loss: 2.6465\n",
            "[Batch 5] Current Loss: 2.1856\n",
            "[Batch 6] Current Loss: 2.5072\n",
            "[Batch 7] Current Loss: 2.0441\n",
            "[Batch 8] Current Loss: 2.2895\n",
            "[Batch 9] Current Loss: 2.3149\n",
            "[Batch 0] Current Loss: 5.0756\n",
            "[Batch 1] Current Loss: 5.5883\n",
            "[Batch 2] Current Loss: 5.8717\n",
            "[Batch 3] Current Loss: 4.8552\n",
            "[Batch 4] Current Loss: 5.1967\n",
            "[Batch 5] Current Loss: 5.6135\n",
            "[Batch 6] Current Loss: 5.8722\n",
            "[Batch 7] Current Loss: 6.0652\n",
            "[Batch 8] Current Loss: 5.8771\n",
            "[Batch 9] Current Loss: 6.6024\n",
            "Ep 4 (Step 033060): Train loss 2.518, Val loss 5.662\n",
            "[Batch 0] Current Loss: 2.0457\n",
            "[Batch 1] Current Loss: 2.2292\n",
            "[Batch 2] Current Loss: 2.1357\n",
            "[Batch 3] Current Loss: 2.5111\n",
            "[Batch 4] Current Loss: 2.1699\n",
            "[Batch 5] Current Loss: 2.3950\n",
            "[Batch 6] Current Loss: 2.6791\n",
            "[Batch 7] Current Loss: 2.1511\n",
            "[Batch 8] Current Loss: 2.3163\n",
            "[Batch 9] Current Loss: 2.9707\n",
            "[Batch 0] Current Loss: 5.2001\n",
            "[Batch 1] Current Loss: 5.7834\n",
            "[Batch 2] Current Loss: 5.9692\n",
            "[Batch 3] Current Loss: 5.9040\n",
            "[Batch 4] Current Loss: 6.2835\n",
            "[Batch 5] Current Loss: 5.3256\n",
            "[Batch 6] Current Loss: 6.2463\n",
            "[Batch 7] Current Loss: 5.2929\n",
            "[Batch 8] Current Loss: 6.0184\n",
            "[Batch 9] Current Loss: 5.2263\n",
            "Ep 4 (Step 033080): Train loss 2.360, Val loss 5.725\n",
            "[Batch 0] Current Loss: 2.1694\n",
            "[Batch 1] Current Loss: 2.9237\n",
            "[Batch 2] Current Loss: 2.5225\n",
            "[Batch 3] Current Loss: 2.5031\n",
            "[Batch 4] Current Loss: 2.2520\n",
            "[Batch 5] Current Loss: 2.4475\n",
            "[Batch 6] Current Loss: 2.5463\n",
            "[Batch 7] Current Loss: 2.3444\n",
            "[Batch 8] Current Loss: 2.4948\n",
            "[Batch 9] Current Loss: 2.6737\n",
            "[Batch 0] Current Loss: 5.6590\n",
            "[Batch 1] Current Loss: 6.3462\n",
            "[Batch 2] Current Loss: 5.6589\n",
            "[Batch 3] Current Loss: 5.7577\n",
            "[Batch 4] Current Loss: 5.8306\n",
            "[Batch 5] Current Loss: 5.5317\n",
            "[Batch 6] Current Loss: 4.9743\n",
            "[Batch 7] Current Loss: 5.3392\n",
            "[Batch 8] Current Loss: 5.9233\n",
            "[Batch 9] Current Loss: 5.9125\n",
            "Ep 4 (Step 033100): Train loss 2.488, Val loss 5.693\n",
            "[Batch 0] Current Loss: 2.2885\n",
            "[Batch 1] Current Loss: 2.4456\n",
            "[Batch 2] Current Loss: 2.3970\n",
            "[Batch 3] Current Loss: 2.9431\n",
            "[Batch 4] Current Loss: 2.7677\n",
            "[Batch 5] Current Loss: 2.4015\n",
            "[Batch 6] Current Loss: 2.4637\n",
            "[Batch 7] Current Loss: 2.2997\n",
            "[Batch 8] Current Loss: 1.7833\n",
            "[Batch 9] Current Loss: 2.2428\n",
            "[Batch 0] Current Loss: 5.2896\n",
            "[Batch 1] Current Loss: 5.8582\n",
            "[Batch 2] Current Loss: 5.7065\n",
            "[Batch 3] Current Loss: 5.4103\n",
            "[Batch 4] Current Loss: 4.9461\n",
            "[Batch 5] Current Loss: 5.5964\n",
            "[Batch 6] Current Loss: 5.5213\n",
            "[Batch 7] Current Loss: 5.5571\n",
            "[Batch 8] Current Loss: 5.4826\n",
            "[Batch 9] Current Loss: 5.4067\n",
            "Ep 4 (Step 033120): Train loss 2.403, Val loss 5.477\n",
            "[Batch 0] Current Loss: 1.6330\n",
            "[Batch 1] Current Loss: 2.2426\n",
            "[Batch 2] Current Loss: 2.4848\n",
            "[Batch 3] Current Loss: 1.6716\n",
            "[Batch 4] Current Loss: 2.0542\n",
            "[Batch 5] Current Loss: 2.9020\n",
            "[Batch 6] Current Loss: 2.6734\n",
            "[Batch 7] Current Loss: 2.6348\n",
            "[Batch 8] Current Loss: 2.0551\n",
            "[Batch 9] Current Loss: 2.4013\n",
            "[Batch 0] Current Loss: 5.9613\n",
            "[Batch 1] Current Loss: 6.0480\n",
            "[Batch 2] Current Loss: 5.3860\n",
            "[Batch 3] Current Loss: 5.7100\n",
            "[Batch 4] Current Loss: 4.0192\n",
            "[Batch 5] Current Loss: 6.2338\n",
            "[Batch 6] Current Loss: 4.9722\n",
            "[Batch 7] Current Loss: 5.0802\n",
            "[Batch 8] Current Loss: 5.5168\n",
            "[Batch 9] Current Loss: 5.8065\n",
            "Ep 4 (Step 033140): Train loss 2.275, Val loss 5.473\n",
            "[Batch 0] Current Loss: 2.5599\n",
            "[Batch 1] Current Loss: 2.3972\n",
            "[Batch 2] Current Loss: 2.5881\n",
            "[Batch 3] Current Loss: 2.7661\n",
            "[Batch 4] Current Loss: 2.8282\n",
            "[Batch 5] Current Loss: 2.5652\n",
            "[Batch 6] Current Loss: 2.0350\n",
            "[Batch 7] Current Loss: 2.7533\n",
            "[Batch 8] Current Loss: 2.2385\n",
            "[Batch 9] Current Loss: 2.2105\n",
            "[Batch 0] Current Loss: 5.1044\n",
            "[Batch 1] Current Loss: 4.9287\n",
            "[Batch 2] Current Loss: 5.7146\n",
            "[Batch 3] Current Loss: 6.0912\n",
            "[Batch 4] Current Loss: 5.2923\n",
            "[Batch 5] Current Loss: 5.8155\n",
            "[Batch 6] Current Loss: 5.4763\n",
            "[Batch 7] Current Loss: 5.0127\n",
            "[Batch 8] Current Loss: 5.7281\n",
            "[Batch 9] Current Loss: 5.5470\n",
            "Ep 4 (Step 033160): Train loss 2.494, Val loss 5.471\n",
            "[Batch 0] Current Loss: 2.2122\n",
            "[Batch 1] Current Loss: 1.8798\n",
            "[Batch 2] Current Loss: 2.4096\n",
            "[Batch 3] Current Loss: 2.2695\n",
            "[Batch 4] Current Loss: 3.1521\n",
            "[Batch 5] Current Loss: 2.7569\n",
            "[Batch 6] Current Loss: 2.1461\n",
            "[Batch 7] Current Loss: 2.2112\n",
            "[Batch 8] Current Loss: 1.8553\n",
            "[Batch 9] Current Loss: 2.3266\n",
            "[Batch 0] Current Loss: 6.4847\n",
            "[Batch 1] Current Loss: 6.0325\n",
            "[Batch 2] Current Loss: 5.1064\n",
            "[Batch 3] Current Loss: 5.4011\n",
            "[Batch 4] Current Loss: 4.8927\n",
            "[Batch 5] Current Loss: 4.9184\n",
            "[Batch 6] Current Loss: 4.7039\n",
            "[Batch 7] Current Loss: 5.9650\n",
            "[Batch 8] Current Loss: 5.8354\n",
            "[Batch 9] Current Loss: 5.6059\n",
            "Ep 4 (Step 033180): Train loss 2.322, Val loss 5.495\n",
            "[Batch 0] Current Loss: 2.0551\n",
            "[Batch 1] Current Loss: 2.6282\n",
            "[Batch 2] Current Loss: 2.8099\n",
            "[Batch 3] Current Loss: 2.1829\n",
            "[Batch 4] Current Loss: 2.3729\n",
            "[Batch 5] Current Loss: 2.2086\n",
            "[Batch 6] Current Loss: 2.3518\n",
            "[Batch 7] Current Loss: 2.3914\n",
            "[Batch 8] Current Loss: 1.8675\n",
            "[Batch 9] Current Loss: 2.3993\n",
            "[Batch 0] Current Loss: 5.5841\n",
            "[Batch 1] Current Loss: 5.2769\n",
            "[Batch 2] Current Loss: 5.1146\n",
            "[Batch 3] Current Loss: 5.0311\n",
            "[Batch 4] Current Loss: 6.0137\n",
            "[Batch 5] Current Loss: 4.8343\n",
            "[Batch 6] Current Loss: 6.2000\n",
            "[Batch 7] Current Loss: 5.0453\n",
            "[Batch 8] Current Loss: 4.8205\n",
            "[Batch 9] Current Loss: 5.9026\n",
            "Ep 4 (Step 033200): Train loss 2.327, Val loss 5.382\n",
            "[Batch 0] Current Loss: 2.3253\n",
            "[Batch 1] Current Loss: 2.6122\n",
            "[Batch 2] Current Loss: 2.2687\n",
            "[Batch 3] Current Loss: 2.7570\n",
            "[Batch 4] Current Loss: 2.1674\n",
            "[Batch 5] Current Loss: 2.3677\n",
            "[Batch 6] Current Loss: 1.6236\n",
            "[Batch 7] Current Loss: 1.9399\n",
            "[Batch 8] Current Loss: 2.4493\n",
            "[Batch 9] Current Loss: 2.2944\n",
            "[Batch 0] Current Loss: 5.1540\n",
            "[Batch 1] Current Loss: 5.0019\n",
            "[Batch 2] Current Loss: 5.2859\n",
            "[Batch 3] Current Loss: 5.7670\n",
            "[Batch 4] Current Loss: 4.5390\n",
            "[Batch 5] Current Loss: 6.0944\n",
            "[Batch 6] Current Loss: 5.9891\n",
            "[Batch 7] Current Loss: 5.2685\n",
            "[Batch 8] Current Loss: 4.7786\n",
            "[Batch 9] Current Loss: 5.4844\n",
            "Ep 4 (Step 033220): Train loss 2.281, Val loss 5.336\n",
            "[Batch 0] Current Loss: 1.7906\n",
            "[Batch 1] Current Loss: 2.3140\n",
            "[Batch 2] Current Loss: 2.1811\n",
            "[Batch 3] Current Loss: 2.3170\n",
            "[Batch 4] Current Loss: 1.7581\n",
            "[Batch 5] Current Loss: 2.9772\n",
            "[Batch 6] Current Loss: 2.3615\n",
            "[Batch 7] Current Loss: 2.5182\n",
            "[Batch 8] Current Loss: 2.6140\n",
            "[Batch 9] Current Loss: 1.9689\n",
            "[Batch 0] Current Loss: 5.2291\n",
            "[Batch 1] Current Loss: 4.8622\n",
            "[Batch 2] Current Loss: 5.3851\n",
            "[Batch 3] Current Loss: 5.3645\n",
            "[Batch 4] Current Loss: 5.2114\n",
            "[Batch 5] Current Loss: 5.7622\n",
            "[Batch 6] Current Loss: 5.5254\n",
            "[Batch 7] Current Loss: 5.4104\n",
            "[Batch 8] Current Loss: 6.4367\n",
            "[Batch 9] Current Loss: 5.1950\n",
            "Ep 4 (Step 033240): Train loss 2.280, Val loss 5.438\n",
            "[Batch 0] Current Loss: 1.9983\n",
            "[Batch 1] Current Loss: 2.0946\n",
            "[Batch 2] Current Loss: 1.9085\n",
            "[Batch 3] Current Loss: 2.5948\n",
            "[Batch 4] Current Loss: 1.8686\n",
            "[Batch 5] Current Loss: 1.8464\n",
            "[Batch 6] Current Loss: 2.9285\n",
            "[Batch 7] Current Loss: 2.1664\n",
            "[Batch 8] Current Loss: 2.5005\n",
            "[Batch 9] Current Loss: 2.6403\n",
            "[Batch 0] Current Loss: 5.7585\n",
            "[Batch 1] Current Loss: 5.8762\n",
            "[Batch 2] Current Loss: 5.0253\n",
            "[Batch 3] Current Loss: 4.7498\n",
            "[Batch 4] Current Loss: 5.9216\n",
            "[Batch 5] Current Loss: 5.4975\n",
            "[Batch 6] Current Loss: 4.9528\n",
            "[Batch 7] Current Loss: 5.4894\n",
            "[Batch 8] Current Loss: 4.8173\n",
            "[Batch 9] Current Loss: 6.2711\n",
            "Ep 4 (Step 033260): Train loss 2.255, Val loss 5.436\n",
            "[Batch 0] Current Loss: 2.2936\n",
            "[Batch 1] Current Loss: 3.1002\n",
            "[Batch 2] Current Loss: 2.3541\n",
            "[Batch 3] Current Loss: 2.1792\n",
            "[Batch 4] Current Loss: 2.0158\n",
            "[Batch 5] Current Loss: 2.5827\n",
            "[Batch 6] Current Loss: 2.4518\n",
            "[Batch 7] Current Loss: 2.3021\n",
            "[Batch 8] Current Loss: 2.0652\n",
            "[Batch 9] Current Loss: 1.7884\n",
            "[Batch 0] Current Loss: 5.6232\n",
            "[Batch 1] Current Loss: 5.4482\n",
            "[Batch 2] Current Loss: 5.8334\n",
            "[Batch 3] Current Loss: 4.8233\n",
            "[Batch 4] Current Loss: 5.1057\n",
            "[Batch 5] Current Loss: 4.8236\n",
            "[Batch 6] Current Loss: 4.3382\n",
            "[Batch 7] Current Loss: 5.7680\n",
            "[Batch 8] Current Loss: 5.7992\n",
            "[Batch 9] Current Loss: 4.5534\n",
            "Ep 4 (Step 033280): Train loss 2.313, Val loss 5.212\n",
            "[Batch 0] Current Loss: 2.7937\n",
            "[Batch 1] Current Loss: 2.1527\n",
            "[Batch 2] Current Loss: 2.2135\n",
            "[Batch 3] Current Loss: 2.5398\n",
            "[Batch 4] Current Loss: 1.7026\n",
            "[Batch 5] Current Loss: 2.8990\n",
            "[Batch 6] Current Loss: 2.8872\n",
            "[Batch 7] Current Loss: 1.9085\n",
            "[Batch 8] Current Loss: 1.9730\n",
            "[Batch 9] Current Loss: 2.3404\n",
            "[Batch 0] Current Loss: 5.8627\n",
            "[Batch 1] Current Loss: 6.1223\n",
            "[Batch 2] Current Loss: 5.3877\n",
            "[Batch 3] Current Loss: 5.6997\n",
            "[Batch 4] Current Loss: 5.2048\n",
            "[Batch 5] Current Loss: 5.4851\n",
            "[Batch 6] Current Loss: 5.5922\n",
            "[Batch 7] Current Loss: 4.8354\n",
            "[Batch 8] Current Loss: 5.7941\n",
            "[Batch 9] Current Loss: 5.8763\n",
            "Ep 4 (Step 033300): Train loss 2.341, Val loss 5.586\n",
            "[Batch 0] Current Loss: 2.2185\n",
            "[Batch 1] Current Loss: 1.7554\n",
            "[Batch 2] Current Loss: 2.3152\n",
            "[Batch 3] Current Loss: 2.1068\n",
            "[Batch 4] Current Loss: 1.7333\n",
            "[Batch 5] Current Loss: 2.7843\n",
            "[Batch 6] Current Loss: 2.4913\n",
            "[Batch 7] Current Loss: 2.0929\n",
            "[Batch 8] Current Loss: 1.9527\n",
            "[Batch 9] Current Loss: 2.6256\n",
            "[Batch 0] Current Loss: 4.7921\n",
            "[Batch 1] Current Loss: 5.2030\n",
            "[Batch 2] Current Loss: 5.2893\n",
            "[Batch 3] Current Loss: 5.8755\n",
            "[Batch 4] Current Loss: 4.9617\n",
            "[Batch 5] Current Loss: 4.6307\n",
            "[Batch 6] Current Loss: 5.3972\n",
            "[Batch 7] Current Loss: 5.8566\n",
            "[Batch 8] Current Loss: 5.5812\n",
            "[Batch 9] Current Loss: 5.1680\n",
            "Ep 4 (Step 033320): Train loss 2.208, Val loss 5.276\n",
            "[Batch 0] Current Loss: 1.6037\n",
            "[Batch 1] Current Loss: 2.8259\n",
            "[Batch 2] Current Loss: 2.7010\n",
            "[Batch 3] Current Loss: 2.0160\n",
            "[Batch 4] Current Loss: 1.8321\n",
            "[Batch 5] Current Loss: 2.5229\n",
            "[Batch 6] Current Loss: 2.8734\n",
            "[Batch 7] Current Loss: 1.9027\n",
            "[Batch 8] Current Loss: 2.3142\n",
            "[Batch 9] Current Loss: 2.7882\n",
            "[Batch 0] Current Loss: 5.4943\n",
            "[Batch 1] Current Loss: 4.6083\n",
            "[Batch 2] Current Loss: 4.8391\n",
            "[Batch 3] Current Loss: 5.7065\n",
            "[Batch 4] Current Loss: 5.2029\n",
            "[Batch 5] Current Loss: 5.3554\n",
            "[Batch 6] Current Loss: 6.1511\n",
            "[Batch 7] Current Loss: 5.7102\n",
            "[Batch 8] Current Loss: 5.8705\n",
            "[Batch 9] Current Loss: 5.3571\n",
            "Ep 4 (Step 033340): Train loss 2.338, Val loss 5.430\n",
            "[Batch 0] Current Loss: 2.3633\n",
            "[Batch 1] Current Loss: 2.2736\n",
            "[Batch 2] Current Loss: 1.9578\n",
            "[Batch 3] Current Loss: 2.3195\n",
            "[Batch 4] Current Loss: 2.4124\n",
            "[Batch 5] Current Loss: 2.6125\n",
            "[Batch 6] Current Loss: 2.9544\n",
            "[Batch 7] Current Loss: 2.0818\n",
            "[Batch 8] Current Loss: 2.0757\n",
            "[Batch 9] Current Loss: 2.2734\n",
            "[Batch 0] Current Loss: 5.7724\n",
            "[Batch 1] Current Loss: 5.3868\n",
            "[Batch 2] Current Loss: 4.5745\n",
            "[Batch 3] Current Loss: 4.8300\n",
            "[Batch 4] Current Loss: 5.5905\n",
            "[Batch 5] Current Loss: 6.0525\n",
            "[Batch 6] Current Loss: 5.3958\n",
            "[Batch 7] Current Loss: 5.9079\n",
            "[Batch 8] Current Loss: 5.6629\n",
            "[Batch 9] Current Loss: 6.0759\n",
            "Ep 4 (Step 033360): Train loss 2.332, Val loss 5.525\n",
            "[Batch 0] Current Loss: 2.3126\n",
            "[Batch 1] Current Loss: 2.1141\n",
            "[Batch 2] Current Loss: 2.3364\n",
            "[Batch 3] Current Loss: 1.9892\n",
            "[Batch 4] Current Loss: 3.1039\n",
            "[Batch 5] Current Loss: 2.1934\n",
            "[Batch 6] Current Loss: 2.9271\n",
            "[Batch 7] Current Loss: 1.8926\n",
            "[Batch 8] Current Loss: 2.6195\n",
            "[Batch 9] Current Loss: 2.8248\n",
            "[Batch 0] Current Loss: 5.8010\n",
            "[Batch 1] Current Loss: 6.7488\n",
            "[Batch 2] Current Loss: 5.1193\n",
            "[Batch 3] Current Loss: 5.1721\n",
            "[Batch 4] Current Loss: 5.0366\n",
            "[Batch 5] Current Loss: 6.3334\n",
            "[Batch 6] Current Loss: 5.9548\n",
            "[Batch 7] Current Loss: 5.4768\n",
            "[Batch 8] Current Loss: 5.5885\n",
            "[Batch 9] Current Loss: 5.6024\n",
            "Ep 4 (Step 033380): Train loss 2.431, Val loss 5.683\n",
            "[Batch 0] Current Loss: 2.7496\n",
            "[Batch 1] Current Loss: 2.3572\n",
            "[Batch 2] Current Loss: 2.4277\n",
            "[Batch 3] Current Loss: 2.4025\n",
            "[Batch 4] Current Loss: 2.3946\n",
            "[Batch 5] Current Loss: 2.6462\n",
            "[Batch 6] Current Loss: 2.2918\n",
            "[Batch 7] Current Loss: 2.6251\n",
            "[Batch 8] Current Loss: 2.5604\n",
            "[Batch 9] Current Loss: 2.4568\n",
            "[Batch 0] Current Loss: 5.4574\n",
            "[Batch 1] Current Loss: 4.9966\n",
            "[Batch 2] Current Loss: 5.4568\n",
            "[Batch 3] Current Loss: 5.2137\n",
            "[Batch 4] Current Loss: 4.9118\n",
            "[Batch 5] Current Loss: 5.3832\n",
            "[Batch 6] Current Loss: 5.8036\n",
            "[Batch 7] Current Loss: 5.2599\n",
            "[Batch 8] Current Loss: 5.0350\n",
            "[Batch 9] Current Loss: 5.2136\n",
            "Ep 4 (Step 033400): Train loss 2.491, Val loss 5.273\n",
            "[Batch 0] Current Loss: 2.5991\n",
            "[Batch 1] Current Loss: 2.5121\n",
            "[Batch 2] Current Loss: 2.5199\n",
            "[Batch 3] Current Loss: 2.2675\n",
            "[Batch 4] Current Loss: 2.6132\n",
            "[Batch 5] Current Loss: 2.3581\n",
            "[Batch 6] Current Loss: 2.1343\n",
            "[Batch 7] Current Loss: 2.1186\n",
            "[Batch 8] Current Loss: 2.3253\n",
            "[Batch 9] Current Loss: 1.9144\n",
            "[Batch 0] Current Loss: 6.3553\n",
            "[Batch 1] Current Loss: 4.8602\n",
            "[Batch 2] Current Loss: 5.1254\n",
            "[Batch 3] Current Loss: 4.8789\n",
            "[Batch 4] Current Loss: 5.7173\n",
            "[Batch 5] Current Loss: 6.0645\n",
            "[Batch 6] Current Loss: 4.9500\n",
            "[Batch 7] Current Loss: 4.6714\n",
            "[Batch 8] Current Loss: 6.3685\n",
            "[Batch 9] Current Loss: 4.7561\n",
            "Ep 4 (Step 033420): Train loss 2.336, Val loss 5.375\n",
            "[Batch 0] Current Loss: 2.1907\n",
            "[Batch 1] Current Loss: 2.4285\n",
            "[Batch 2] Current Loss: 2.9348\n",
            "[Batch 3] Current Loss: 1.7278\n",
            "[Batch 4] Current Loss: 2.3880\n",
            "[Batch 5] Current Loss: 2.6610\n",
            "[Batch 6] Current Loss: 2.4760\n",
            "[Batch 7] Current Loss: 1.8600\n",
            "[Batch 8] Current Loss: 2.5120\n",
            "[Batch 9] Current Loss: 2.4390\n",
            "[Batch 0] Current Loss: 5.1034\n",
            "[Batch 1] Current Loss: 4.7161\n",
            "[Batch 2] Current Loss: 5.5507\n",
            "[Batch 3] Current Loss: 5.9701\n",
            "[Batch 4] Current Loss: 6.1288\n",
            "[Batch 5] Current Loss: 5.7067\n",
            "[Batch 6] Current Loss: 5.5590\n",
            "[Batch 7] Current Loss: 4.9753\n",
            "[Batch 8] Current Loss: 5.6847\n",
            "[Batch 9] Current Loss: 5.6602\n",
            "Ep 4 (Step 033440): Train loss 2.362, Val loss 5.506\n",
            "[Batch 0] Current Loss: 2.1741\n",
            "[Batch 1] Current Loss: 1.9381\n",
            "[Batch 2] Current Loss: 2.5872\n",
            "[Batch 3] Current Loss: 2.5807\n",
            "[Batch 4] Current Loss: 2.6625\n",
            "[Batch 5] Current Loss: 2.2988\n",
            "[Batch 6] Current Loss: 2.5833\n",
            "[Batch 7] Current Loss: 2.0936\n",
            "[Batch 8] Current Loss: 2.5519\n",
            "[Batch 9] Current Loss: 1.9923\n",
            "[Batch 0] Current Loss: 4.8783\n",
            "[Batch 1] Current Loss: 5.7816\n",
            "[Batch 2] Current Loss: 5.5999\n",
            "[Batch 3] Current Loss: 5.7289\n",
            "[Batch 4] Current Loss: 5.5153\n",
            "[Batch 5] Current Loss: 5.0836\n",
            "[Batch 6] Current Loss: 5.5835\n",
            "[Batch 7] Current Loss: 5.5369\n",
            "[Batch 8] Current Loss: 5.8827\n",
            "[Batch 9] Current Loss: 4.8358\n",
            "Ep 4 (Step 033460): Train loss 2.346, Val loss 5.443\n",
            "[Batch 0] Current Loss: 2.1896\n",
            "[Batch 1] Current Loss: 2.7608\n",
            "[Batch 2] Current Loss: 2.3050\n",
            "[Batch 3] Current Loss: 2.6345\n",
            "[Batch 4] Current Loss: 1.9997\n",
            "[Batch 5] Current Loss: 2.8737\n",
            "[Batch 6] Current Loss: 3.0126\n",
            "[Batch 7] Current Loss: 2.9720\n",
            "[Batch 8] Current Loss: 2.8416\n",
            "[Batch 9] Current Loss: 2.2504\n",
            "[Batch 0] Current Loss: 5.2007\n",
            "[Batch 1] Current Loss: 4.7176\n",
            "[Batch 2] Current Loss: 6.2235\n",
            "[Batch 3] Current Loss: 5.6908\n",
            "[Batch 4] Current Loss: 5.6672\n",
            "[Batch 5] Current Loss: 5.1892\n",
            "[Batch 6] Current Loss: 6.2206\n",
            "[Batch 7] Current Loss: 4.9386\n",
            "[Batch 8] Current Loss: 5.6403\n",
            "[Batch 9] Current Loss: 5.9434\n",
            "Ep 4 (Step 033480): Train loss 2.584, Val loss 5.543\n",
            "[Batch 0] Current Loss: 2.1856\n",
            "[Batch 1] Current Loss: 2.1266\n",
            "[Batch 2] Current Loss: 2.4372\n",
            "[Batch 3] Current Loss: 2.7483\n",
            "[Batch 4] Current Loss: 3.1158\n",
            "[Batch 5] Current Loss: 2.3553\n",
            "[Batch 6] Current Loss: 2.4596\n",
            "[Batch 7] Current Loss: 2.8544\n",
            "[Batch 8] Current Loss: 2.8964\n",
            "[Batch 9] Current Loss: 2.2646\n",
            "[Batch 0] Current Loss: 4.4282\n",
            "[Batch 1] Current Loss: 6.2522\n",
            "[Batch 2] Current Loss: 4.8858\n",
            "[Batch 3] Current Loss: 4.1274\n",
            "[Batch 4] Current Loss: 5.7462\n",
            "[Batch 5] Current Loss: 4.7909\n",
            "[Batch 6] Current Loss: 5.0686\n",
            "[Batch 7] Current Loss: 6.1967\n",
            "[Batch 8] Current Loss: 6.0807\n",
            "[Batch 9] Current Loss: 5.6616\n",
            "Ep 4 (Step 033500): Train loss 2.544, Val loss 5.324\n",
            "[Batch 0] Current Loss: 2.5487\n",
            "[Batch 1] Current Loss: 1.5495\n",
            "[Batch 2] Current Loss: 2.4741\n",
            "[Batch 3] Current Loss: 2.2690\n",
            "[Batch 4] Current Loss: 2.1813\n",
            "[Batch 5] Current Loss: 1.7735\n",
            "[Batch 6] Current Loss: 2.4978\n",
            "[Batch 7] Current Loss: 2.5958\n",
            "[Batch 8] Current Loss: 2.5414\n",
            "[Batch 9] Current Loss: 2.7204\n",
            "[Batch 0] Current Loss: 5.3344\n",
            "[Batch 1] Current Loss: 4.5649\n",
            "[Batch 2] Current Loss: 5.4172\n",
            "[Batch 3] Current Loss: 5.6973\n",
            "[Batch 4] Current Loss: 4.8902\n",
            "[Batch 5] Current Loss: 5.3215\n",
            "[Batch 6] Current Loss: 5.4653\n",
            "[Batch 7] Current Loss: 5.1776\n",
            "[Batch 8] Current Loss: 5.3254\n",
            "[Batch 9] Current Loss: 6.1516\n",
            "Ep 4 (Step 033520): Train loss 2.315, Val loss 5.335\n",
            "[Batch 0] Current Loss: 2.4595\n",
            "[Batch 1] Current Loss: 2.5667\n",
            "[Batch 2] Current Loss: 2.3924\n",
            "[Batch 3] Current Loss: 2.1098\n",
            "[Batch 4] Current Loss: 2.8247\n",
            "[Batch 5] Current Loss: 1.7032\n",
            "[Batch 6] Current Loss: 2.4571\n",
            "[Batch 7] Current Loss: 2.2778\n",
            "[Batch 8] Current Loss: 1.7988\n",
            "[Batch 9] Current Loss: 2.4740\n",
            "[Batch 0] Current Loss: 4.8831\n",
            "[Batch 1] Current Loss: 5.0936\n",
            "[Batch 2] Current Loss: 5.7711\n",
            "[Batch 3] Current Loss: 5.8199\n",
            "[Batch 4] Current Loss: 5.2003\n",
            "[Batch 5] Current Loss: 5.6389\n",
            "[Batch 6] Current Loss: 5.9382\n",
            "[Batch 7] Current Loss: 5.6760\n",
            "[Batch 8] Current Loss: 5.2034\n",
            "[Batch 9] Current Loss: 5.7201\n",
            "Ep 4 (Step 033540): Train loss 2.306, Val loss 5.494\n",
            "[Batch 0] Current Loss: 1.9091\n",
            "[Batch 1] Current Loss: 2.4020\n",
            "[Batch 2] Current Loss: 2.6596\n",
            "[Batch 3] Current Loss: 2.5373\n",
            "[Batch 4] Current Loss: 2.4949\n",
            "[Batch 5] Current Loss: 1.9939\n",
            "[Batch 6] Current Loss: 2.0899\n",
            "[Batch 7] Current Loss: 2.0986\n",
            "[Batch 8] Current Loss: 2.7102\n",
            "[Batch 9] Current Loss: 2.8199\n",
            "[Batch 0] Current Loss: 5.5154\n",
            "[Batch 1] Current Loss: 5.3477\n",
            "[Batch 2] Current Loss: 5.2310\n",
            "[Batch 3] Current Loss: 6.0115\n",
            "[Batch 4] Current Loss: 5.8319\n",
            "[Batch 5] Current Loss: 5.9774\n",
            "[Batch 6] Current Loss: 6.6499\n",
            "[Batch 7] Current Loss: 6.1130\n",
            "[Batch 8] Current Loss: 5.5618\n",
            "[Batch 9] Current Loss: 5.2163\n",
            "Ep 4 (Step 033560): Train loss 2.372, Val loss 5.746\n",
            "[Batch 0] Current Loss: 2.7152\n",
            "[Batch 1] Current Loss: 2.0846\n",
            "[Batch 2] Current Loss: 2.8619\n",
            "[Batch 3] Current Loss: 1.8849\n",
            "[Batch 4] Current Loss: 2.3589\n",
            "[Batch 5] Current Loss: 2.8361\n",
            "[Batch 6] Current Loss: 2.5787\n",
            "[Batch 7] Current Loss: 2.7183\n",
            "[Batch 8] Current Loss: 2.3994\n",
            "[Batch 9] Current Loss: 2.7591\n",
            "[Batch 0] Current Loss: 5.1876\n",
            "[Batch 1] Current Loss: 4.9966\n",
            "[Batch 2] Current Loss: 5.2541\n",
            "[Batch 3] Current Loss: 4.8584\n",
            "[Batch 4] Current Loss: 5.2746\n",
            "[Batch 5] Current Loss: 6.2280\n",
            "[Batch 6] Current Loss: 6.1549\n",
            "[Batch 7] Current Loss: 5.9981\n",
            "[Batch 8] Current Loss: 5.2759\n",
            "[Batch 9] Current Loss: 5.2438\n",
            "Ep 4 (Step 033580): Train loss 2.520, Val loss 5.447\n",
            "[Batch 0] Current Loss: 2.3841\n",
            "[Batch 1] Current Loss: 2.4985\n",
            "[Batch 2] Current Loss: 2.4474\n",
            "[Batch 3] Current Loss: 2.5947\n",
            "[Batch 4] Current Loss: 2.1659\n",
            "[Batch 5] Current Loss: 2.0617\n",
            "[Batch 6] Current Loss: 2.1350\n",
            "[Batch 7] Current Loss: 2.3187\n",
            "[Batch 8] Current Loss: 1.8216\n",
            "[Batch 9] Current Loss: 2.7494\n",
            "[Batch 0] Current Loss: 5.4226\n",
            "[Batch 1] Current Loss: 6.0260\n",
            "[Batch 2] Current Loss: 5.1569\n",
            "[Batch 3] Current Loss: 5.2766\n",
            "[Batch 4] Current Loss: 5.9680\n",
            "[Batch 5] Current Loss: 4.7957\n",
            "[Batch 6] Current Loss: 5.5111\n",
            "[Batch 7] Current Loss: 5.9261\n",
            "[Batch 8] Current Loss: 5.3172\n",
            "[Batch 9] Current Loss: 5.4396\n",
            "Ep 4 (Step 033600): Train loss 2.318, Val loss 5.484\n",
            "[Batch 0] Current Loss: 2.7651\n",
            "[Batch 1] Current Loss: 2.2353\n",
            "[Batch 2] Current Loss: 2.4932\n",
            "[Batch 3] Current Loss: 2.3375\n",
            "[Batch 4] Current Loss: 2.0858\n",
            "[Batch 5] Current Loss: 2.0365\n",
            "[Batch 6] Current Loss: 2.3736\n",
            "[Batch 7] Current Loss: 2.6691\n",
            "[Batch 8] Current Loss: 2.6147\n",
            "[Batch 9] Current Loss: 2.2341\n",
            "[Batch 0] Current Loss: 5.7406\n",
            "[Batch 1] Current Loss: 5.8655\n",
            "[Batch 2] Current Loss: 4.5570\n",
            "[Batch 3] Current Loss: 5.2533\n",
            "[Batch 4] Current Loss: 5.4030\n",
            "[Batch 5] Current Loss: 5.8793\n",
            "[Batch 6] Current Loss: 5.5714\n",
            "[Batch 7] Current Loss: 5.1217\n",
            "[Batch 8] Current Loss: 5.3698\n",
            "[Batch 9] Current Loss: 5.4559\n",
            "Ep 4 (Step 033620): Train loss 2.384, Val loss 5.422\n",
            "[Batch 0] Current Loss: 2.0538\n",
            "[Batch 1] Current Loss: 2.8885\n",
            "[Batch 2] Current Loss: 2.6485\n",
            "[Batch 3] Current Loss: 2.0105\n",
            "[Batch 4] Current Loss: 2.5485\n",
            "[Batch 5] Current Loss: 2.7268\n",
            "[Batch 6] Current Loss: 2.3770\n",
            "[Batch 7] Current Loss: 2.3219\n",
            "[Batch 8] Current Loss: 2.6109\n",
            "[Batch 9] Current Loss: 2.6849\n",
            "[Batch 0] Current Loss: 4.4349\n",
            "[Batch 1] Current Loss: 4.7634\n",
            "[Batch 2] Current Loss: 5.6572\n",
            "[Batch 3] Current Loss: 6.4268\n",
            "[Batch 4] Current Loss: 5.5972\n",
            "[Batch 5] Current Loss: 5.6166\n",
            "[Batch 6] Current Loss: 5.2264\n",
            "[Batch 7] Current Loss: 5.4000\n",
            "[Batch 8] Current Loss: 4.7861\n",
            "[Batch 9] Current Loss: 4.7915\n",
            "Ep 4 (Step 033640): Train loss 2.487, Val loss 5.270\n",
            "[Batch 0] Current Loss: 2.3013\n",
            "[Batch 1] Current Loss: 2.3411\n",
            "[Batch 2] Current Loss: 2.3277\n",
            "[Batch 3] Current Loss: 2.1233\n",
            "[Batch 4] Current Loss: 2.6495\n",
            "[Batch 5] Current Loss: 2.2991\n",
            "[Batch 6] Current Loss: 2.6163\n",
            "[Batch 7] Current Loss: 2.1832\n",
            "[Batch 8] Current Loss: 1.7260\n",
            "[Batch 9] Current Loss: 2.6681\n",
            "[Batch 0] Current Loss: 5.3794\n",
            "[Batch 1] Current Loss: 4.9052\n",
            "[Batch 2] Current Loss: 5.8977\n",
            "[Batch 3] Current Loss: 5.0228\n",
            "[Batch 4] Current Loss: 5.6908\n",
            "[Batch 5] Current Loss: 5.6252\n",
            "[Batch 6] Current Loss: 5.7662\n",
            "[Batch 7] Current Loss: 5.6713\n",
            "[Batch 8] Current Loss: 4.8175\n",
            "[Batch 9] Current Loss: 4.5093\n",
            "Ep 4 (Step 033660): Train loss 2.324, Val loss 5.329\n",
            "[Batch 0] Current Loss: 2.3369\n",
            "[Batch 1] Current Loss: 2.1686\n",
            "[Batch 2] Current Loss: 2.2816\n",
            "[Batch 3] Current Loss: 2.7397\n",
            "[Batch 4] Current Loss: 2.1417\n",
            "[Batch 5] Current Loss: 2.4324\n",
            "[Batch 6] Current Loss: 2.0991\n",
            "[Batch 7] Current Loss: 2.1750\n",
            "[Batch 8] Current Loss: 2.3308\n",
            "[Batch 9] Current Loss: 2.3722\n",
            "[Batch 0] Current Loss: 5.3398\n",
            "[Batch 1] Current Loss: 5.4793\n",
            "[Batch 2] Current Loss: 5.5262\n",
            "[Batch 3] Current Loss: 5.1828\n",
            "[Batch 4] Current Loss: 5.5139\n",
            "[Batch 5] Current Loss: 5.9456\n",
            "[Batch 6] Current Loss: 4.5537\n",
            "[Batch 7] Current Loss: 5.0903\n",
            "[Batch 8] Current Loss: 5.4286\n",
            "[Batch 9] Current Loss: 6.2895\n",
            "Ep 4 (Step 033680): Train loss 2.308, Val loss 5.435\n",
            "[Batch 0] Current Loss: 2.5600\n",
            "[Batch 1] Current Loss: 2.3190\n",
            "[Batch 2] Current Loss: 2.6286\n",
            "[Batch 3] Current Loss: 2.8861\n",
            "[Batch 4] Current Loss: 1.5523\n",
            "[Batch 5] Current Loss: 1.7128\n",
            "[Batch 6] Current Loss: 2.5997\n",
            "[Batch 7] Current Loss: 2.7918\n",
            "[Batch 8] Current Loss: 2.1064\n",
            "[Batch 9] Current Loss: 1.7695\n",
            "[Batch 0] Current Loss: 6.2350\n",
            "[Batch 1] Current Loss: 4.9105\n",
            "[Batch 2] Current Loss: 5.7922\n",
            "[Batch 3] Current Loss: 4.9530\n",
            "[Batch 4] Current Loss: 5.2955\n",
            "[Batch 5] Current Loss: 5.0059\n",
            "[Batch 6] Current Loss: 6.0047\n",
            "[Batch 7] Current Loss: 5.7222\n",
            "[Batch 8] Current Loss: 5.5043\n",
            "[Batch 9] Current Loss: 5.2186\n",
            "Ep 4 (Step 033700): Train loss 2.293, Val loss 5.464\n",
            "[Batch 0] Current Loss: 2.4161\n",
            "[Batch 1] Current Loss: 2.6163\n",
            "[Batch 2] Current Loss: 2.0166\n",
            "[Batch 3] Current Loss: 2.6186\n",
            "[Batch 4] Current Loss: 2.3935\n",
            "[Batch 5] Current Loss: 2.2411\n",
            "[Batch 6] Current Loss: 1.9450\n",
            "[Batch 7] Current Loss: 2.3643\n",
            "[Batch 8] Current Loss: 2.4678\n",
            "[Batch 9] Current Loss: 2.5275\n",
            "[Batch 0] Current Loss: 5.8152\n",
            "[Batch 1] Current Loss: 5.6240\n",
            "[Batch 2] Current Loss: 5.2940\n",
            "[Batch 3] Current Loss: 4.5381\n",
            "[Batch 4] Current Loss: 5.6894\n",
            "[Batch 5] Current Loss: 6.0979\n",
            "[Batch 6] Current Loss: 5.4704\n",
            "[Batch 7] Current Loss: 5.6547\n",
            "[Batch 8] Current Loss: 5.6232\n",
            "[Batch 9] Current Loss: 5.1508\n",
            "Ep 4 (Step 033720): Train loss 2.361, Val loss 5.496\n",
            "[Batch 0] Current Loss: 2.2549\n",
            "[Batch 1] Current Loss: 3.0219\n",
            "[Batch 2] Current Loss: 2.1114\n",
            "[Batch 3] Current Loss: 1.6611\n",
            "[Batch 4] Current Loss: 2.5623\n",
            "[Batch 5] Current Loss: 2.6207\n",
            "[Batch 6] Current Loss: 2.0452\n",
            "[Batch 7] Current Loss: 1.6124\n",
            "[Batch 8] Current Loss: 2.6005\n",
            "[Batch 9] Current Loss: 1.8214\n",
            "[Batch 0] Current Loss: 5.2651\n",
            "[Batch 1] Current Loss: 4.5458\n",
            "[Batch 2] Current Loss: 5.4410\n",
            "[Batch 3] Current Loss: 5.4257\n",
            "[Batch 4] Current Loss: 5.6086\n",
            "[Batch 5] Current Loss: 5.5376\n",
            "[Batch 6] Current Loss: 5.5834\n",
            "[Batch 7] Current Loss: 4.7138\n",
            "[Batch 8] Current Loss: 4.6693\n",
            "[Batch 9] Current Loss: 5.5150\n",
            "Ep 4 (Step 033740): Train loss 2.231, Val loss 5.231\n",
            "[Batch 0] Current Loss: 2.4405\n",
            "[Batch 1] Current Loss: 1.8307\n",
            "[Batch 2] Current Loss: 2.0722\n",
            "[Batch 3] Current Loss: 2.5268\n",
            "[Batch 4] Current Loss: 2.4846\n",
            "[Batch 5] Current Loss: 2.7275\n",
            "[Batch 6] Current Loss: 2.5673\n",
            "[Batch 7] Current Loss: 2.7830\n",
            "[Batch 8] Current Loss: 1.8171\n",
            "[Batch 9] Current Loss: 1.8076\n",
            "[Batch 0] Current Loss: 5.4455\n",
            "[Batch 1] Current Loss: 5.6116\n",
            "[Batch 2] Current Loss: 6.7451\n",
            "[Batch 3] Current Loss: 6.0845\n",
            "[Batch 4] Current Loss: 5.4182\n",
            "[Batch 5] Current Loss: 6.1072\n",
            "[Batch 6] Current Loss: 5.6201\n",
            "[Batch 7] Current Loss: 5.2625\n",
            "[Batch 8] Current Loss: 4.2681\n",
            "[Batch 9] Current Loss: 5.6427\n",
            "Ep 4 (Step 033760): Train loss 2.306, Val loss 5.621\n",
            "[Batch 0] Current Loss: 2.6297\n",
            "[Batch 1] Current Loss: 1.9151\n",
            "[Batch 2] Current Loss: 1.7987\n",
            "[Batch 3] Current Loss: 2.7703\n",
            "[Batch 4] Current Loss: 2.1561\n",
            "[Batch 5] Current Loss: 2.1014\n",
            "[Batch 6] Current Loss: 2.0124\n",
            "[Batch 7] Current Loss: 2.3397\n",
            "[Batch 8] Current Loss: 2.0710\n",
            "[Batch 9] Current Loss: 2.1367\n",
            "[Batch 0] Current Loss: 4.8133\n",
            "[Batch 1] Current Loss: 4.8629\n",
            "[Batch 2] Current Loss: 5.3879\n",
            "[Batch 3] Current Loss: 5.2396\n",
            "[Batch 4] Current Loss: 6.5105\n",
            "[Batch 5] Current Loss: 5.9376\n",
            "[Batch 6] Current Loss: 5.5628\n",
            "[Batch 7] Current Loss: 5.4148\n",
            "[Batch 8] Current Loss: 5.2653\n",
            "[Batch 9] Current Loss: 5.6068\n",
            "Ep 4 (Step 033780): Train loss 2.193, Val loss 5.460\n",
            "[Batch 0] Current Loss: 2.5929\n",
            "[Batch 1] Current Loss: 2.6207\n",
            "[Batch 2] Current Loss: 1.9365\n",
            "[Batch 3] Current Loss: 1.9699\n",
            "[Batch 4] Current Loss: 2.3308\n",
            "[Batch 5] Current Loss: 2.8691\n",
            "[Batch 6] Current Loss: 2.3692\n",
            "[Batch 7] Current Loss: 2.9854\n",
            "[Batch 8] Current Loss: 2.7607\n",
            "[Batch 9] Current Loss: 2.0791\n",
            "[Batch 0] Current Loss: 5.6548\n",
            "[Batch 1] Current Loss: 5.1442\n",
            "[Batch 2] Current Loss: 5.6812\n",
            "[Batch 3] Current Loss: 6.3093\n",
            "[Batch 4] Current Loss: 4.7702\n",
            "[Batch 5] Current Loss: 5.2579\n",
            "[Batch 6] Current Loss: 5.0332\n",
            "[Batch 7] Current Loss: 5.5865\n",
            "[Batch 8] Current Loss: 4.6512\n",
            "[Batch 9] Current Loss: 4.8576\n",
            "Ep 4 (Step 033800): Train loss 2.451, Val loss 5.295\n",
            "[Batch 0] Current Loss: 2.5354\n",
            "[Batch 1] Current Loss: 1.9999\n",
            "[Batch 2] Current Loss: 2.3496\n",
            "[Batch 3] Current Loss: 2.7707\n",
            "[Batch 4] Current Loss: 2.7395\n",
            "[Batch 5] Current Loss: 2.3641\n",
            "[Batch 6] Current Loss: 2.3412\n",
            "[Batch 7] Current Loss: 2.3595\n",
            "[Batch 8] Current Loss: 2.0918\n",
            "[Batch 9] Current Loss: 2.8769\n",
            "[Batch 0] Current Loss: 5.0481\n",
            "[Batch 1] Current Loss: 4.9766\n",
            "[Batch 2] Current Loss: 5.2550\n",
            "[Batch 3] Current Loss: 4.7064\n",
            "[Batch 4] Current Loss: 5.4375\n",
            "[Batch 5] Current Loss: 5.7476\n",
            "[Batch 6] Current Loss: 6.0519\n",
            "[Batch 7] Current Loss: 5.6282\n",
            "[Batch 8] Current Loss: 5.2152\n",
            "[Batch 9] Current Loss: 4.6751\n",
            "Ep 4 (Step 033820): Train loss 2.443, Val loss 5.274\n",
            "Every effort moves you can do to make a train.  Theresa Country  The train station is about  long, but it's not a good idea. The train station is a train station. The train station is about  long and  wide. The\n",
            "[Batch 0] Current Loss: 1.9446\n",
            "[Batch 1] Current Loss: 2.3401\n",
            "[Batch 2] Current Loss: 2.3472\n",
            "[Batch 3] Current Loss: 1.9050\n",
            "[Batch 4] Current Loss: 2.3714\n",
            "[Batch 5] Current Loss: 2.4821\n",
            "[Batch 6] Current Loss: 2.7285\n",
            "[Batch 7] Current Loss: 2.8182\n",
            "[Batch 8] Current Loss: 2.1243\n",
            "[Batch 9] Current Loss: 2.2374\n",
            "[Batch 0] Current Loss: 6.2260\n",
            "[Batch 1] Current Loss: 5.1533\n",
            "[Batch 2] Current Loss: 5.5652\n",
            "[Batch 3] Current Loss: 6.2968\n",
            "[Batch 4] Current Loss: 5.5598\n",
            "[Batch 5] Current Loss: 6.1039\n",
            "[Batch 6] Current Loss: 5.4764\n",
            "[Batch 7] Current Loss: 5.2913\n",
            "[Batch 8] Current Loss: 5.3517\n",
            "[Batch 9] Current Loss: 5.2842\n",
            "Ep 5 (Step 033840): Train loss 2.330, Val loss 5.631\n",
            "[Batch 0] Current Loss: 2.2678\n",
            "[Batch 1] Current Loss: 2.1750\n",
            "[Batch 2] Current Loss: 1.8375\n",
            "[Batch 3] Current Loss: 2.4176\n",
            "[Batch 4] Current Loss: 2.6314\n",
            "[Batch 5] Current Loss: 2.9307\n",
            "[Batch 6] Current Loss: 2.0480\n",
            "[Batch 7] Current Loss: 2.3251\n",
            "[Batch 8] Current Loss: 2.3595\n",
            "[Batch 9] Current Loss: 2.3721\n",
            "[Batch 0] Current Loss: 5.3641\n",
            "[Batch 1] Current Loss: 4.6225\n",
            "[Batch 2] Current Loss: 5.6376\n",
            "[Batch 3] Current Loss: 4.9434\n",
            "[Batch 4] Current Loss: 4.9410\n",
            "[Batch 5] Current Loss: 5.5401\n",
            "[Batch 6] Current Loss: 5.9446\n",
            "[Batch 7] Current Loss: 4.3059\n",
            "[Batch 8] Current Loss: 4.9619\n",
            "[Batch 9] Current Loss: 6.1989\n",
            "Ep 5 (Step 033860): Train loss 2.336, Val loss 5.246\n",
            "[Batch 0] Current Loss: 2.4692\n",
            "[Batch 1] Current Loss: 2.1931\n",
            "[Batch 2] Current Loss: 2.1984\n",
            "[Batch 3] Current Loss: 2.6788\n",
            "[Batch 4] Current Loss: 2.1690\n",
            "[Batch 5] Current Loss: 2.4426\n",
            "[Batch 6] Current Loss: 2.6803\n",
            "[Batch 7] Current Loss: 2.4399\n",
            "[Batch 8] Current Loss: 2.2644\n",
            "[Batch 9] Current Loss: 2.1684\n",
            "[Batch 0] Current Loss: 5.1642\n",
            "[Batch 1] Current Loss: 6.0620\n",
            "[Batch 2] Current Loss: 5.6051\n",
            "[Batch 3] Current Loss: 5.9529\n",
            "[Batch 4] Current Loss: 6.2630\n",
            "[Batch 5] Current Loss: 5.5968\n",
            "[Batch 6] Current Loss: 5.9207\n",
            "[Batch 7] Current Loss: 5.5413\n",
            "[Batch 8] Current Loss: 5.1341\n",
            "[Batch 9] Current Loss: 5.7101\n",
            "Ep 5 (Step 033880): Train loss 2.370, Val loss 5.695\n",
            "[Batch 0] Current Loss: 2.7374\n",
            "[Batch 1] Current Loss: 2.3512\n",
            "[Batch 2] Current Loss: 2.3962\n",
            "[Batch 3] Current Loss: 2.1501\n",
            "[Batch 4] Current Loss: 1.9841\n",
            "[Batch 5] Current Loss: 2.1492\n",
            "[Batch 6] Current Loss: 3.0072\n",
            "[Batch 7] Current Loss: 2.2276\n",
            "[Batch 8] Current Loss: 2.5908\n",
            "[Batch 9] Current Loss: 2.2803\n",
            "[Batch 0] Current Loss: 5.5724\n",
            "[Batch 1] Current Loss: 5.8400\n",
            "[Batch 2] Current Loss: 6.0136\n",
            "[Batch 3] Current Loss: 5.0438\n",
            "[Batch 4] Current Loss: 5.7880\n",
            "[Batch 5] Current Loss: 4.9901\n",
            "[Batch 6] Current Loss: 5.3844\n",
            "[Batch 7] Current Loss: 6.5384\n",
            "[Batch 8] Current Loss: 5.2527\n",
            "[Batch 9] Current Loss: 5.4719\n",
            "Ep 5 (Step 033900): Train loss 2.387, Val loss 5.590\n",
            "[Batch 0] Current Loss: 2.4126\n",
            "[Batch 1] Current Loss: 2.1236\n",
            "[Batch 2] Current Loss: 1.9384\n",
            "[Batch 3] Current Loss: 2.2632\n",
            "[Batch 4] Current Loss: 2.2978\n",
            "[Batch 5] Current Loss: 2.3403\n",
            "[Batch 6] Current Loss: 2.6217\n",
            "[Batch 7] Current Loss: 2.3949\n",
            "[Batch 8] Current Loss: 2.1213\n",
            "[Batch 9] Current Loss: 1.5433\n",
            "[Batch 0] Current Loss: 5.1833\n",
            "[Batch 1] Current Loss: 4.4747\n",
            "[Batch 2] Current Loss: 5.5533\n",
            "[Batch 3] Current Loss: 5.3782\n",
            "[Batch 4] Current Loss: 5.6151\n",
            "[Batch 5] Current Loss: 4.9007\n",
            "[Batch 6] Current Loss: 5.1582\n",
            "[Batch 7] Current Loss: 5.5904\n",
            "[Batch 8] Current Loss: 4.8370\n",
            "[Batch 9] Current Loss: 5.1199\n",
            "Ep 5 (Step 033920): Train loss 2.206, Val loss 5.181\n",
            "[Batch 0] Current Loss: 2.5830\n",
            "[Batch 1] Current Loss: 2.3570\n",
            "[Batch 2] Current Loss: 1.8222\n",
            "[Batch 3] Current Loss: 2.2909\n",
            "[Batch 4] Current Loss: 2.2352\n",
            "[Batch 5] Current Loss: 2.1721\n",
            "[Batch 6] Current Loss: 2.0243\n",
            "[Batch 7] Current Loss: 2.5761\n",
            "[Batch 8] Current Loss: 2.1747\n",
            "[Batch 9] Current Loss: 2.4430\n",
            "[Batch 0] Current Loss: 6.0295\n",
            "[Batch 1] Current Loss: 5.6645\n",
            "[Batch 2] Current Loss: 5.3764\n",
            "[Batch 3] Current Loss: 5.5775\n",
            "[Batch 4] Current Loss: 5.4077\n",
            "[Batch 5] Current Loss: 5.7212\n",
            "[Batch 6] Current Loss: 5.4877\n",
            "[Batch 7] Current Loss: 5.4501\n",
            "[Batch 8] Current Loss: 6.0806\n",
            "[Batch 9] Current Loss: 4.5455\n",
            "Ep 5 (Step 033940): Train loss 2.268, Val loss 5.534\n",
            "[Batch 0] Current Loss: 1.7371\n",
            "[Batch 1] Current Loss: 3.0770\n",
            "[Batch 2] Current Loss: 2.6101\n",
            "[Batch 3] Current Loss: 2.5345\n",
            "[Batch 4] Current Loss: 2.7358\n",
            "[Batch 5] Current Loss: 1.7116\n",
            "[Batch 6] Current Loss: 2.3890\n",
            "[Batch 7] Current Loss: 2.4562\n",
            "[Batch 8] Current Loss: 2.1677\n",
            "[Batch 9] Current Loss: 2.6087\n",
            "[Batch 0] Current Loss: 6.4060\n",
            "[Batch 1] Current Loss: 5.2406\n",
            "[Batch 2] Current Loss: 5.8354\n",
            "[Batch 3] Current Loss: 6.0934\n",
            "[Batch 4] Current Loss: 5.3354\n",
            "[Batch 5] Current Loss: 6.3077\n",
            "[Batch 6] Current Loss: 5.4209\n",
            "[Batch 7] Current Loss: 5.6390\n",
            "[Batch 8] Current Loss: 5.2841\n",
            "[Batch 9] Current Loss: 6.3762\n",
            "Ep 5 (Step 033960): Train loss 2.403, Val loss 5.794\n",
            "[Batch 0] Current Loss: 2.6765\n",
            "[Batch 1] Current Loss: 1.8256\n",
            "[Batch 2] Current Loss: 1.8943\n",
            "[Batch 3] Current Loss: 2.1694\n",
            "[Batch 4] Current Loss: 2.7318\n",
            "[Batch 5] Current Loss: 1.8244\n",
            "[Batch 6] Current Loss: 2.5752\n",
            "[Batch 7] Current Loss: 2.7583\n",
            "[Batch 8] Current Loss: 2.1592\n",
            "[Batch 9] Current Loss: 2.7640\n",
            "[Batch 0] Current Loss: 5.4688\n",
            "[Batch 1] Current Loss: 5.2002\n",
            "[Batch 2] Current Loss: 5.2537\n",
            "[Batch 3] Current Loss: 5.8768\n",
            "[Batch 4] Current Loss: 6.0912\n",
            "[Batch 5] Current Loss: 5.4837\n",
            "[Batch 6] Current Loss: 5.9345\n",
            "[Batch 7] Current Loss: 5.6462\n",
            "[Batch 8] Current Loss: 5.6572\n",
            "[Batch 9] Current Loss: 5.5021\n",
            "Ep 5 (Step 033980): Train loss 2.338, Val loss 5.611\n",
            "[Batch 0] Current Loss: 2.2967\n",
            "[Batch 1] Current Loss: 2.2075\n",
            "[Batch 2] Current Loss: 2.0478\n",
            "[Batch 3] Current Loss: 2.4085\n",
            "[Batch 4] Current Loss: 1.8802\n",
            "[Batch 5] Current Loss: 2.0878\n",
            "[Batch 6] Current Loss: 2.1262\n",
            "[Batch 7] Current Loss: 2.0471\n",
            "[Batch 8] Current Loss: 1.8863\n",
            "[Batch 9] Current Loss: 2.5064\n",
            "[Batch 0] Current Loss: 5.4993\n",
            "[Batch 1] Current Loss: 4.3802\n",
            "[Batch 2] Current Loss: 5.4224\n",
            "[Batch 3] Current Loss: 5.7994\n",
            "[Batch 4] Current Loss: 6.7417\n",
            "[Batch 5] Current Loss: 4.7598\n",
            "[Batch 6] Current Loss: 5.5776\n",
            "[Batch 7] Current Loss: 5.7935\n",
            "[Batch 8] Current Loss: 5.8051\n",
            "[Batch 9] Current Loss: 6.2683\n",
            "Ep 5 (Step 034000): Train loss 2.149, Val loss 5.605\n",
            "[Batch 0] Current Loss: 2.8700\n",
            "[Batch 1] Current Loss: 2.3403\n",
            "[Batch 2] Current Loss: 2.9279\n",
            "[Batch 3] Current Loss: 2.1951\n",
            "[Batch 4] Current Loss: 2.0348\n",
            "[Batch 5] Current Loss: 1.7693\n",
            "[Batch 6] Current Loss: 2.6111\n",
            "[Batch 7] Current Loss: 2.2393\n",
            "[Batch 8] Current Loss: 2.0260\n",
            "[Batch 9] Current Loss: 2.4894\n",
            "[Batch 0] Current Loss: 5.6873\n",
            "[Batch 1] Current Loss: 5.3160\n",
            "[Batch 2] Current Loss: 5.5345\n",
            "[Batch 3] Current Loss: 4.8943\n",
            "[Batch 4] Current Loss: 5.4077\n",
            "[Batch 5] Current Loss: 4.7919\n",
            "[Batch 6] Current Loss: 5.7094\n",
            "[Batch 7] Current Loss: 6.2380\n",
            "[Batch 8] Current Loss: 5.9732\n",
            "[Batch 9] Current Loss: 5.1655\n",
            "Ep 5 (Step 034020): Train loss 2.350, Val loss 5.472\n",
            "[Batch 0] Current Loss: 2.6161\n",
            "[Batch 1] Current Loss: 2.1655\n",
            "[Batch 2] Current Loss: 2.0266\n",
            "[Batch 3] Current Loss: 2.1032\n",
            "[Batch 4] Current Loss: 2.5994\n",
            "[Batch 5] Current Loss: 2.1959\n",
            "[Batch 6] Current Loss: 1.8004\n",
            "[Batch 7] Current Loss: 2.3039\n",
            "[Batch 8] Current Loss: 2.4488\n",
            "[Batch 9] Current Loss: 2.0190\n",
            "[Batch 0] Current Loss: 5.0182\n",
            "[Batch 1] Current Loss: 5.2908\n",
            "[Batch 2] Current Loss: 5.7260\n",
            "[Batch 3] Current Loss: 6.3718\n",
            "[Batch 4] Current Loss: 5.9245\n",
            "[Batch 5] Current Loss: 5.2927\n",
            "[Batch 6] Current Loss: 5.2386\n",
            "[Batch 7] Current Loss: 5.3394\n",
            "[Batch 8] Current Loss: 4.9051\n",
            "[Batch 9] Current Loss: 5.6269\n",
            "Ep 5 (Step 034040): Train loss 2.228, Val loss 5.473\n",
            "[Batch 0] Current Loss: 2.2013\n",
            "[Batch 1] Current Loss: 2.2921\n",
            "[Batch 2] Current Loss: 1.9065\n",
            "[Batch 3] Current Loss: 2.4709\n",
            "[Batch 4] Current Loss: 2.2940\n",
            "[Batch 5] Current Loss: 3.0209\n",
            "[Batch 6] Current Loss: 2.3660\n",
            "[Batch 7] Current Loss: 2.5000\n",
            "[Batch 8] Current Loss: 2.1737\n",
            "[Batch 9] Current Loss: 1.3509\n",
            "[Batch 0] Current Loss: 4.6081\n",
            "[Batch 1] Current Loss: 5.1332\n",
            "[Batch 2] Current Loss: 6.7173\n",
            "[Batch 3] Current Loss: 5.6143\n",
            "[Batch 4] Current Loss: 5.4895\n",
            "[Batch 5] Current Loss: 6.7980\n",
            "[Batch 6] Current Loss: 6.2741\n",
            "[Batch 7] Current Loss: 5.9409\n",
            "[Batch 8] Current Loss: 5.0523\n",
            "[Batch 9] Current Loss: 5.9943\n",
            "Ep 5 (Step 034060): Train loss 2.258, Val loss 5.762\n",
            "[Batch 0] Current Loss: 2.4266\n",
            "[Batch 1] Current Loss: 2.4067\n",
            "[Batch 2] Current Loss: 1.6237\n",
            "[Batch 3] Current Loss: 2.1461\n",
            "[Batch 4] Current Loss: 2.7802\n",
            "[Batch 5] Current Loss: 2.4511\n",
            "[Batch 6] Current Loss: 2.1945\n",
            "[Batch 7] Current Loss: 2.5701\n",
            "[Batch 8] Current Loss: 2.4272\n",
            "[Batch 9] Current Loss: 2.2354\n",
            "[Batch 0] Current Loss: 5.1085\n",
            "[Batch 1] Current Loss: 5.5759\n",
            "[Batch 2] Current Loss: 5.2590\n",
            "[Batch 3] Current Loss: 5.1140\n",
            "[Batch 4] Current Loss: 5.4441\n",
            "[Batch 5] Current Loss: 5.8607\n",
            "[Batch 6] Current Loss: 6.0032\n",
            "[Batch 7] Current Loss: 5.9629\n",
            "[Batch 8] Current Loss: 4.9600\n",
            "[Batch 9] Current Loss: 5.4414\n",
            "Ep 5 (Step 034080): Train loss 2.326, Val loss 5.473\n",
            "[Batch 0] Current Loss: 2.5723\n",
            "[Batch 1] Current Loss: 2.2948\n",
            "[Batch 2] Current Loss: 2.0749\n",
            "[Batch 3] Current Loss: 2.7965\n",
            "[Batch 4] Current Loss: 1.0166\n",
            "[Batch 5] Current Loss: 2.6456\n",
            "[Batch 6] Current Loss: 2.4536\n",
            "[Batch 7] Current Loss: 2.1574\n",
            "[Batch 8] Current Loss: 2.4654\n",
            "[Batch 9] Current Loss: 1.9777\n",
            "[Batch 0] Current Loss: 5.8089\n",
            "[Batch 1] Current Loss: 5.4817\n",
            "[Batch 2] Current Loss: 5.2443\n",
            "[Batch 3] Current Loss: 6.1499\n",
            "[Batch 4] Current Loss: 5.9449\n",
            "[Batch 5] Current Loss: 4.9220\n",
            "[Batch 6] Current Loss: 6.1244\n",
            "[Batch 7] Current Loss: 5.9005\n",
            "[Batch 8] Current Loss: 6.1736\n",
            "[Batch 9] Current Loss: 5.1781\n",
            "Ep 5 (Step 034100): Train loss 2.245, Val loss 5.693\n",
            "[Batch 0] Current Loss: 2.6145\n",
            "[Batch 1] Current Loss: 2.3409\n",
            "[Batch 2] Current Loss: 1.4808\n",
            "[Batch 3] Current Loss: 2.0521\n",
            "[Batch 4] Current Loss: 2.4650\n",
            "[Batch 5] Current Loss: 2.6271\n",
            "[Batch 6] Current Loss: 2.4896\n",
            "[Batch 7] Current Loss: 2.2715\n",
            "[Batch 8] Current Loss: 1.8183\n",
            "[Batch 9] Current Loss: 1.9381\n",
            "[Batch 0] Current Loss: 4.9249\n",
            "[Batch 1] Current Loss: 5.5190\n",
            "[Batch 2] Current Loss: 4.7674\n",
            "[Batch 3] Current Loss: 5.5637\n",
            "[Batch 4] Current Loss: 4.9783\n",
            "[Batch 5] Current Loss: 5.8270\n",
            "[Batch 6] Current Loss: 5.3513\n",
            "[Batch 7] Current Loss: 6.0856\n",
            "[Batch 8] Current Loss: 5.0494\n",
            "[Batch 9] Current Loss: 5.7031\n",
            "Ep 5 (Step 034120): Train loss 2.210, Val loss 5.377\n",
            "[Batch 0] Current Loss: 1.8502\n",
            "[Batch 1] Current Loss: 2.2086\n",
            "[Batch 2] Current Loss: 2.7242\n",
            "[Batch 3] Current Loss: 2.5663\n",
            "[Batch 4] Current Loss: 2.0035\n",
            "[Batch 5] Current Loss: 2.1643\n",
            "[Batch 6] Current Loss: 2.6813\n",
            "[Batch 7] Current Loss: 2.9003\n",
            "[Batch 8] Current Loss: 1.2799\n",
            "[Batch 9] Current Loss: 2.7567\n",
            "[Batch 0] Current Loss: 5.5395\n",
            "[Batch 1] Current Loss: 5.7652\n",
            "[Batch 2] Current Loss: 5.3566\n",
            "[Batch 3] Current Loss: 6.5419\n",
            "[Batch 4] Current Loss: 5.0950\n",
            "[Batch 5] Current Loss: 5.7617\n",
            "[Batch 6] Current Loss: 5.7306\n",
            "[Batch 7] Current Loss: 6.1719\n",
            "[Batch 8] Current Loss: 4.9968\n",
            "[Batch 9] Current Loss: 5.6602\n",
            "Ep 5 (Step 034140): Train loss 2.314, Val loss 5.662\n",
            "[Batch 0] Current Loss: 2.3986\n",
            "[Batch 1] Current Loss: 2.3512\n",
            "[Batch 2] Current Loss: 1.8278\n",
            "[Batch 3] Current Loss: 1.8262\n",
            "[Batch 4] Current Loss: 2.2524\n",
            "[Batch 5] Current Loss: 1.9714\n",
            "[Batch 6] Current Loss: 1.9875\n",
            "[Batch 7] Current Loss: 2.3808\n",
            "[Batch 8] Current Loss: 2.3897\n",
            "[Batch 9] Current Loss: 1.8525\n",
            "[Batch 0] Current Loss: 5.8865\n",
            "[Batch 1] Current Loss: 6.1384\n",
            "[Batch 2] Current Loss: 5.2752\n",
            "[Batch 3] Current Loss: 5.8238\n",
            "[Batch 4] Current Loss: 5.4329\n",
            "[Batch 5] Current Loss: 5.4432\n",
            "[Batch 6] Current Loss: 5.1143\n",
            "[Batch 7] Current Loss: 5.8566\n",
            "[Batch 8] Current Loss: 6.0841\n",
            "[Batch 9] Current Loss: 5.7524\n",
            "Ep 5 (Step 034160): Train loss 2.124, Val loss 5.681\n",
            "[Batch 0] Current Loss: 2.1747\n",
            "[Batch 1] Current Loss: 2.0066\n",
            "[Batch 2] Current Loss: 2.3052\n",
            "[Batch 3] Current Loss: 2.8125\n",
            "[Batch 4] Current Loss: 2.7863\n",
            "[Batch 5] Current Loss: 2.1261\n",
            "[Batch 6] Current Loss: 2.4995\n",
            "[Batch 7] Current Loss: 2.6647\n",
            "[Batch 8] Current Loss: 2.4581\n",
            "[Batch 9] Current Loss: 2.8414\n",
            "[Batch 0] Current Loss: 4.8899\n",
            "[Batch 1] Current Loss: 5.6041\n",
            "[Batch 2] Current Loss: 5.4780\n",
            "[Batch 3] Current Loss: 5.3652\n",
            "[Batch 4] Current Loss: 5.0182\n",
            "[Batch 5] Current Loss: 6.1034\n",
            "[Batch 6] Current Loss: 5.5568\n",
            "[Batch 7] Current Loss: 6.0661\n",
            "[Batch 8] Current Loss: 6.1239\n",
            "[Batch 9] Current Loss: 5.5344\n",
            "Ep 5 (Step 034180): Train loss 2.467, Val loss 5.574\n",
            "[Batch 0] Current Loss: 2.2234\n",
            "[Batch 1] Current Loss: 1.8451\n",
            "[Batch 2] Current Loss: 2.2232\n",
            "[Batch 3] Current Loss: 2.0693\n",
            "[Batch 4] Current Loss: 2.1988\n",
            "[Batch 5] Current Loss: 2.4047\n",
            "[Batch 6] Current Loss: 2.5149\n",
            "[Batch 7] Current Loss: 1.6851\n",
            "[Batch 8] Current Loss: 2.1320\n",
            "[Batch 9] Current Loss: 2.3878\n",
            "[Batch 0] Current Loss: 5.8170\n",
            "[Batch 1] Current Loss: 6.4008\n",
            "[Batch 2] Current Loss: 5.6061\n",
            "[Batch 3] Current Loss: 5.9757\n",
            "[Batch 4] Current Loss: 4.3579\n",
            "[Batch 5] Current Loss: 6.3130\n",
            "[Batch 6] Current Loss: 5.8243\n",
            "[Batch 7] Current Loss: 5.5627\n",
            "[Batch 8] Current Loss: 6.1616\n",
            "[Batch 9] Current Loss: 6.5929\n",
            "Ep 5 (Step 034200): Train loss 2.168, Val loss 5.861\n",
            "[Batch 0] Current Loss: 2.0972\n",
            "[Batch 1] Current Loss: 2.5197\n",
            "[Batch 2] Current Loss: 2.2087\n",
            "[Batch 3] Current Loss: 1.7397\n",
            "[Batch 4] Current Loss: 3.0451\n",
            "[Batch 5] Current Loss: 2.5929\n",
            "[Batch 6] Current Loss: 2.3704\n",
            "[Batch 7] Current Loss: 2.1336\n",
            "[Batch 8] Current Loss: 2.4727\n",
            "[Batch 9] Current Loss: 1.9691\n",
            "[Batch 0] Current Loss: 5.5291\n",
            "[Batch 1] Current Loss: 6.3985\n",
            "[Batch 2] Current Loss: 6.1575\n",
            "[Batch 3] Current Loss: 5.8469\n",
            "[Batch 4] Current Loss: 6.2789\n",
            "[Batch 5] Current Loss: 5.1919\n",
            "[Batch 6] Current Loss: 5.6955\n",
            "[Batch 7] Current Loss: 4.8276\n",
            "[Batch 8] Current Loss: 5.3559\n",
            "[Batch 9] Current Loss: 5.8499\n",
            "Ep 5 (Step 034220): Train loss 2.315, Val loss 5.713\n",
            "[Batch 0] Current Loss: 1.6490\n",
            "[Batch 1] Current Loss: 2.5678\n",
            "[Batch 2] Current Loss: 2.3276\n",
            "[Batch 3] Current Loss: 2.0766\n",
            "[Batch 4] Current Loss: 1.8812\n",
            "[Batch 5] Current Loss: 2.0722\n",
            "[Batch 6] Current Loss: 2.1497\n",
            "[Batch 7] Current Loss: 2.5184\n",
            "[Batch 8] Current Loss: 3.1675\n",
            "[Batch 9] Current Loss: 1.7494\n",
            "[Batch 0] Current Loss: 5.4244\n",
            "[Batch 1] Current Loss: 6.1705\n",
            "[Batch 2] Current Loss: 5.7954\n",
            "[Batch 3] Current Loss: 6.5550\n",
            "[Batch 4] Current Loss: 4.8871\n",
            "[Batch 5] Current Loss: 5.5776\n",
            "[Batch 6] Current Loss: 5.7680\n",
            "[Batch 7] Current Loss: 5.9069\n",
            "[Batch 8] Current Loss: 5.3203\n",
            "[Batch 9] Current Loss: 5.5461\n",
            "Ep 5 (Step 034240): Train loss 2.216, Val loss 5.695\n",
            "[Batch 0] Current Loss: 1.7159\n",
            "[Batch 1] Current Loss: 1.7841\n",
            "[Batch 2] Current Loss: 2.1908\n",
            "[Batch 3] Current Loss: 2.0517\n",
            "[Batch 4] Current Loss: 2.3202\n",
            "[Batch 5] Current Loss: 2.2007\n",
            "[Batch 6] Current Loss: 3.0571\n",
            "[Batch 7] Current Loss: 2.3293\n",
            "[Batch 8] Current Loss: 2.5766\n",
            "[Batch 9] Current Loss: 2.2463\n",
            "[Batch 0] Current Loss: 4.8967\n",
            "[Batch 1] Current Loss: 5.5993\n",
            "[Batch 2] Current Loss: 6.3129\n",
            "[Batch 3] Current Loss: 5.8488\n",
            "[Batch 4] Current Loss: 5.4229\n",
            "[Batch 5] Current Loss: 5.8744\n",
            "[Batch 6] Current Loss: 5.7625\n",
            "[Batch 7] Current Loss: 5.9668\n",
            "[Batch 8] Current Loss: 6.0603\n",
            "[Batch 9] Current Loss: 6.0668\n",
            "Ep 5 (Step 034260): Train loss 2.247, Val loss 5.781\n",
            "[Batch 0] Current Loss: 2.0247\n",
            "[Batch 1] Current Loss: 1.7635\n",
            "[Batch 2] Current Loss: 2.2080\n",
            "[Batch 3] Current Loss: 2.3605\n",
            "[Batch 4] Current Loss: 1.4677\n",
            "[Batch 5] Current Loss: 2.1430\n",
            "[Batch 6] Current Loss: 2.4217\n",
            "[Batch 7] Current Loss: 1.9021\n",
            "[Batch 8] Current Loss: 2.5523\n",
            "[Batch 9] Current Loss: 2.5348\n",
            "[Batch 0] Current Loss: 5.6676\n",
            "[Batch 1] Current Loss: 5.6810\n",
            "[Batch 2] Current Loss: 5.7321\n",
            "[Batch 3] Current Loss: 5.0831\n",
            "[Batch 4] Current Loss: 5.5909\n",
            "[Batch 5] Current Loss: 5.6158\n",
            "[Batch 6] Current Loss: 5.6106\n",
            "[Batch 7] Current Loss: 5.7412\n",
            "[Batch 8] Current Loss: 5.8577\n",
            "[Batch 9] Current Loss: 6.2879\n",
            "Ep 5 (Step 034280): Train loss 2.138, Val loss 5.687\n",
            "[Batch 0] Current Loss: 1.9270\n",
            "[Batch 1] Current Loss: 2.5397\n",
            "[Batch 2] Current Loss: 2.1483\n",
            "[Batch 3] Current Loss: 2.2611\n",
            "[Batch 4] Current Loss: 2.5445\n",
            "[Batch 5] Current Loss: 2.0607\n",
            "[Batch 6] Current Loss: 2.3583\n",
            "[Batch 7] Current Loss: 2.1405\n",
            "[Batch 8] Current Loss: 2.6677\n",
            "[Batch 9] Current Loss: 1.6096\n",
            "[Batch 0] Current Loss: 5.4240\n",
            "[Batch 1] Current Loss: 5.6230\n",
            "[Batch 2] Current Loss: 5.8171\n",
            "[Batch 3] Current Loss: 5.0250\n",
            "[Batch 4] Current Loss: 4.9104\n",
            "[Batch 5] Current Loss: 5.1105\n",
            "[Batch 6] Current Loss: 6.0158\n",
            "[Batch 7] Current Loss: 5.8697\n",
            "[Batch 8] Current Loss: 4.7029\n",
            "[Batch 9] Current Loss: 4.6876\n",
            "Ep 5 (Step 034300): Train loss 2.226, Val loss 5.319\n",
            "[Batch 0] Current Loss: 2.8445\n",
            "[Batch 1] Current Loss: 2.3553\n",
            "[Batch 2] Current Loss: 1.9240\n",
            "[Batch 3] Current Loss: 2.6643\n",
            "[Batch 4] Current Loss: 2.7213\n",
            "[Batch 5] Current Loss: 1.9209\n",
            "[Batch 6] Current Loss: 2.5841\n",
            "[Batch 7] Current Loss: 2.2053\n",
            "[Batch 8] Current Loss: 2.1951\n",
            "[Batch 9] Current Loss: 2.1775\n",
            "[Batch 0] Current Loss: 5.6348\n",
            "[Batch 1] Current Loss: 6.3019\n",
            "[Batch 2] Current Loss: 5.1301\n",
            "[Batch 3] Current Loss: 6.0426\n",
            "[Batch 4] Current Loss: 5.8329\n",
            "[Batch 5] Current Loss: 5.0618\n",
            "[Batch 6] Current Loss: 4.6633\n",
            "[Batch 7] Current Loss: 5.5389\n",
            "[Batch 8] Current Loss: 5.4072\n",
            "[Batch 9] Current Loss: 5.5041\n",
            "Ep 5 (Step 034320): Train loss 2.359, Val loss 5.512\n",
            "[Batch 0] Current Loss: 2.5884\n",
            "[Batch 1] Current Loss: 2.3145\n",
            "[Batch 2] Current Loss: 2.4800\n",
            "[Batch 3] Current Loss: 2.4347\n",
            "[Batch 4] Current Loss: 1.9989\n",
            "[Batch 5] Current Loss: 2.5409\n",
            "[Batch 6] Current Loss: 2.5302\n",
            "[Batch 7] Current Loss: 2.3773\n",
            "[Batch 8] Current Loss: 2.8457\n",
            "[Batch 9] Current Loss: 2.5902\n",
            "[Batch 0] Current Loss: 5.9122\n",
            "[Batch 1] Current Loss: 5.6803\n",
            "[Batch 2] Current Loss: 5.4844\n",
            "[Batch 3] Current Loss: 5.2150\n",
            "[Batch 4] Current Loss: 6.1163\n",
            "[Batch 5] Current Loss: 5.4051\n",
            "[Batch 6] Current Loss: 4.9706\n",
            "[Batch 7] Current Loss: 6.0815\n",
            "[Batch 8] Current Loss: 5.4694\n",
            "[Batch 9] Current Loss: 6.0959\n",
            "Ep 5 (Step 034340): Train loss 2.470, Val loss 5.643\n",
            "[Batch 0] Current Loss: 2.3527\n",
            "[Batch 1] Current Loss: 2.6754\n",
            "[Batch 2] Current Loss: 2.3708\n",
            "[Batch 3] Current Loss: 1.6504\n",
            "[Batch 4] Current Loss: 2.1415\n",
            "[Batch 5] Current Loss: 2.2605\n",
            "[Batch 6] Current Loss: 2.7610\n",
            "[Batch 7] Current Loss: 2.2985\n",
            "[Batch 8] Current Loss: 2.6776\n",
            "[Batch 9] Current Loss: 2.3766\n",
            "[Batch 0] Current Loss: 5.9960\n",
            "[Batch 1] Current Loss: 5.0533\n",
            "[Batch 2] Current Loss: 5.2389\n",
            "[Batch 3] Current Loss: 6.2007\n",
            "[Batch 4] Current Loss: 5.9596\n",
            "[Batch 5] Current Loss: 5.4143\n",
            "[Batch 6] Current Loss: 5.5055\n",
            "[Batch 7] Current Loss: 6.3803\n",
            "[Batch 8] Current Loss: 5.2919\n",
            "[Batch 9] Current Loss: 5.7546\n",
            "Ep 5 (Step 034360): Train loss 2.357, Val loss 5.679\n",
            "[Batch 0] Current Loss: 2.4479\n",
            "[Batch 1] Current Loss: 2.0658\n",
            "[Batch 2] Current Loss: 2.2508\n",
            "[Batch 3] Current Loss: 2.5217\n",
            "[Batch 4] Current Loss: 2.1560\n",
            "[Batch 5] Current Loss: 2.6658\n",
            "[Batch 6] Current Loss: 1.9857\n",
            "[Batch 7] Current Loss: 2.1939\n",
            "[Batch 8] Current Loss: 2.7432\n",
            "[Batch 9] Current Loss: 2.6727\n",
            "[Batch 0] Current Loss: 5.6098\n",
            "[Batch 1] Current Loss: 5.9472\n",
            "[Batch 2] Current Loss: 6.3632\n",
            "[Batch 3] Current Loss: 5.7098\n",
            "[Batch 4] Current Loss: 6.1060\n",
            "[Batch 5] Current Loss: 6.2605\n",
            "[Batch 6] Current Loss: 5.7653\n",
            "[Batch 7] Current Loss: 5.2460\n",
            "[Batch 8] Current Loss: 5.8827\n",
            "[Batch 9] Current Loss: 6.5455\n",
            "Ep 5 (Step 034380): Train loss 2.370, Val loss 5.944\n",
            "[Batch 0] Current Loss: 2.7605\n",
            "[Batch 1] Current Loss: 1.9214\n",
            "[Batch 2] Current Loss: 2.5498\n",
            "[Batch 3] Current Loss: 2.2066\n",
            "[Batch 4] Current Loss: 1.8853\n",
            "[Batch 5] Current Loss: 2.6436\n",
            "[Batch 6] Current Loss: 2.7100\n",
            "[Batch 7] Current Loss: 2.3355\n",
            "[Batch 8] Current Loss: 1.9178\n",
            "[Batch 9] Current Loss: 2.6633\n",
            "[Batch 0] Current Loss: 5.0485\n",
            "[Batch 1] Current Loss: 5.1508\n",
            "[Batch 2] Current Loss: 5.5791\n",
            "[Batch 3] Current Loss: 6.2573\n",
            "[Batch 4] Current Loss: 5.5973\n",
            "[Batch 5] Current Loss: 4.9516\n",
            "[Batch 6] Current Loss: 5.7663\n",
            "[Batch 7] Current Loss: 5.7708\n",
            "[Batch 8] Current Loss: 6.7792\n",
            "[Batch 9] Current Loss: 5.4396\n",
            "Ep 5 (Step 034400): Train loss 2.359, Val loss 5.634\n",
            "[Batch 0] Current Loss: 2.6756\n",
            "[Batch 1] Current Loss: 2.2371\n",
            "[Batch 2] Current Loss: 2.3358\n",
            "[Batch 3] Current Loss: 2.4417\n",
            "[Batch 4] Current Loss: 1.5572\n",
            "[Batch 5] Current Loss: 1.7345\n",
            "[Batch 6] Current Loss: 1.8274\n",
            "[Batch 7] Current Loss: 2.5772\n",
            "[Batch 8] Current Loss: 1.4097\n",
            "[Batch 9] Current Loss: 1.9907\n",
            "[Batch 0] Current Loss: 5.2369\n",
            "[Batch 1] Current Loss: 5.5861\n",
            "[Batch 2] Current Loss: 6.0254\n",
            "[Batch 3] Current Loss: 6.0046\n",
            "[Batch 4] Current Loss: 5.6613\n",
            "[Batch 5] Current Loss: 5.1452\n",
            "[Batch 6] Current Loss: 5.2417\n",
            "[Batch 7] Current Loss: 6.2423\n",
            "[Batch 8] Current Loss: 5.2601\n",
            "[Batch 9] Current Loss: 5.8328\n",
            "Ep 5 (Step 034420): Train loss 2.079, Val loss 5.624\n",
            "[Batch 0] Current Loss: 2.2220\n",
            "[Batch 1] Current Loss: 2.7715\n",
            "[Batch 2] Current Loss: 1.7409\n",
            "[Batch 3] Current Loss: 2.4446\n",
            "[Batch 4] Current Loss: 2.1754\n",
            "[Batch 5] Current Loss: 2.4661\n",
            "[Batch 6] Current Loss: 1.7822\n",
            "[Batch 7] Current Loss: 2.1178\n",
            "[Batch 8] Current Loss: 2.2721\n",
            "[Batch 9] Current Loss: 2.1321\n",
            "[Batch 0] Current Loss: 5.7692\n",
            "[Batch 1] Current Loss: 5.1009\n",
            "[Batch 2] Current Loss: 5.4150\n",
            "[Batch 3] Current Loss: 5.7606\n",
            "[Batch 4] Current Loss: 5.2202\n",
            "[Batch 5] Current Loss: 4.4871\n",
            "[Batch 6] Current Loss: 5.6246\n",
            "[Batch 7] Current Loss: 6.4439\n",
            "[Batch 8] Current Loss: 6.3408\n",
            "[Batch 9] Current Loss: 5.3336\n",
            "Ep 5 (Step 034440): Train loss 2.212, Val loss 5.550\n",
            "[Batch 0] Current Loss: 2.4316\n",
            "[Batch 1] Current Loss: 2.0239\n",
            "[Batch 2] Current Loss: 1.9869\n",
            "[Batch 3] Current Loss: 2.0645\n",
            "[Batch 4] Current Loss: 1.7288\n",
            "[Batch 5] Current Loss: 2.5776\n",
            "[Batch 6] Current Loss: 2.1454\n",
            "[Batch 7] Current Loss: 3.0424\n",
            "[Batch 8] Current Loss: 2.6696\n",
            "[Batch 9] Current Loss: 2.7157\n",
            "[Batch 0] Current Loss: 4.1535\n",
            "[Batch 1] Current Loss: 6.2548\n",
            "[Batch 2] Current Loss: 5.1250\n",
            "[Batch 3] Current Loss: 5.4247\n",
            "[Batch 4] Current Loss: 5.9947\n",
            "[Batch 5] Current Loss: 5.5894\n",
            "[Batch 6] Current Loss: 4.6957\n",
            "[Batch 7] Current Loss: 5.0700\n",
            "[Batch 8] Current Loss: 5.2311\n",
            "[Batch 9] Current Loss: 5.2236\n",
            "Ep 5 (Step 034460): Train loss 2.339, Val loss 5.276\n",
            "[Batch 0] Current Loss: 2.4973\n",
            "[Batch 1] Current Loss: 2.2705\n",
            "[Batch 2] Current Loss: 2.8817\n",
            "[Batch 3] Current Loss: 1.9762\n",
            "[Batch 4] Current Loss: 1.6914\n",
            "[Batch 5] Current Loss: 2.8262\n",
            "[Batch 6] Current Loss: 1.9629\n",
            "[Batch 7] Current Loss: 1.9330\n",
            "[Batch 8] Current Loss: 2.5372\n",
            "[Batch 9] Current Loss: 2.2930\n",
            "[Batch 0] Current Loss: 5.7158\n",
            "[Batch 1] Current Loss: 5.5028\n",
            "[Batch 2] Current Loss: 6.1451\n",
            "[Batch 3] Current Loss: 5.7108\n",
            "[Batch 4] Current Loss: 5.3744\n",
            "[Batch 5] Current Loss: 5.7502\n",
            "[Batch 6] Current Loss: 5.3822\n",
            "[Batch 7] Current Loss: 5.6633\n",
            "[Batch 8] Current Loss: 4.7615\n",
            "[Batch 9] Current Loss: 5.8145\n",
            "Ep 5 (Step 034480): Train loss 2.287, Val loss 5.582\n",
            "[Batch 0] Current Loss: 2.3676\n",
            "[Batch 1] Current Loss: 1.5530\n",
            "[Batch 2] Current Loss: 2.2169\n",
            "[Batch 3] Current Loss: 2.1543\n",
            "[Batch 4] Current Loss: 1.8880\n",
            "[Batch 5] Current Loss: 2.4837\n",
            "[Batch 6] Current Loss: 3.2002\n",
            "[Batch 7] Current Loss: 1.7126\n",
            "[Batch 8] Current Loss: 2.3931\n",
            "[Batch 9] Current Loss: 2.2302\n",
            "[Batch 0] Current Loss: 5.1373\n",
            "[Batch 1] Current Loss: 5.5328\n",
            "[Batch 2] Current Loss: 5.6581\n",
            "[Batch 3] Current Loss: 5.9278\n",
            "[Batch 4] Current Loss: 6.1174\n",
            "[Batch 5] Current Loss: 6.4138\n",
            "[Batch 6] Current Loss: 6.0635\n",
            "[Batch 7] Current Loss: 5.8505\n",
            "[Batch 8] Current Loss: 5.3034\n",
            "[Batch 9] Current Loss: 6.0727\n",
            "Ep 5 (Step 034500): Train loss 2.220, Val loss 5.808\n",
            "[Batch 0] Current Loss: 2.1545\n",
            "[Batch 1] Current Loss: 1.9765\n",
            "[Batch 2] Current Loss: 2.5136\n",
            "[Batch 3] Current Loss: 2.4350\n",
            "[Batch 4] Current Loss: 2.1132\n",
            "[Batch 5] Current Loss: 2.2392\n",
            "[Batch 6] Current Loss: 2.1541\n",
            "[Batch 7] Current Loss: 2.1796\n",
            "[Batch 8] Current Loss: 2.0183\n",
            "[Batch 9] Current Loss: 2.1716\n",
            "[Batch 0] Current Loss: 4.8725\n",
            "[Batch 1] Current Loss: 6.1313\n",
            "[Batch 2] Current Loss: 4.9539\n",
            "[Batch 3] Current Loss: 5.8507\n",
            "[Batch 4] Current Loss: 6.2960\n",
            "[Batch 5] Current Loss: 5.8495\n",
            "[Batch 6] Current Loss: 5.8408\n",
            "[Batch 7] Current Loss: 5.5497\n",
            "[Batch 8] Current Loss: 5.5954\n",
            "[Batch 9] Current Loss: 6.1764\n",
            "Ep 5 (Step 034520): Train loss 2.196, Val loss 5.712\n",
            "[Batch 0] Current Loss: 2.5911\n",
            "[Batch 1] Current Loss: 1.9338\n",
            "[Batch 2] Current Loss: 2.1146\n",
            "[Batch 3] Current Loss: 2.3939\n",
            "[Batch 4] Current Loss: 2.2001\n",
            "[Batch 5] Current Loss: 2.1975\n",
            "[Batch 6] Current Loss: 2.0258\n",
            "[Batch 7] Current Loss: 1.9293\n",
            "[Batch 8] Current Loss: 2.3869\n",
            "[Batch 9] Current Loss: 2.1585\n",
            "[Batch 0] Current Loss: 5.9617\n",
            "[Batch 1] Current Loss: 5.4038\n",
            "[Batch 2] Current Loss: 5.7785\n",
            "[Batch 3] Current Loss: 6.2265\n",
            "[Batch 4] Current Loss: 5.9138\n",
            "[Batch 5] Current Loss: 6.2249\n",
            "[Batch 6] Current Loss: 5.3872\n",
            "[Batch 7] Current Loss: 5.3504\n",
            "[Batch 8] Current Loss: 5.5702\n",
            "[Batch 9] Current Loss: 5.4898\n",
            "Ep 5 (Step 034540): Train loss 2.193, Val loss 5.731\n",
            "[Batch 0] Current Loss: 1.8423\n",
            "[Batch 1] Current Loss: 1.6325\n",
            "[Batch 2] Current Loss: 2.8036\n",
            "[Batch 3] Current Loss: 1.8645\n",
            "[Batch 4] Current Loss: 2.0900\n",
            "[Batch 5] Current Loss: 2.3339\n",
            "[Batch 6] Current Loss: 2.2560\n",
            "[Batch 7] Current Loss: 1.9120\n",
            "[Batch 8] Current Loss: 2.1705\n",
            "[Batch 9] Current Loss: 1.8966\n",
            "[Batch 0] Current Loss: 5.0993\n",
            "[Batch 1] Current Loss: 6.2806\n",
            "[Batch 2] Current Loss: 5.7217\n",
            "[Batch 3] Current Loss: 5.9110\n",
            "[Batch 4] Current Loss: 5.0104\n",
            "[Batch 5] Current Loss: 5.6587\n",
            "[Batch 6] Current Loss: 5.6539\n",
            "[Batch 7] Current Loss: 6.5154\n",
            "[Batch 8] Current Loss: 4.8588\n",
            "[Batch 9] Current Loss: 6.2874\n",
            "Ep 5 (Step 034560): Train loss 2.080, Val loss 5.700\n",
            "[Batch 0] Current Loss: 1.7718\n",
            "[Batch 1] Current Loss: 2.8204\n",
            "[Batch 2] Current Loss: 3.0226\n",
            "[Batch 3] Current Loss: 2.5017\n",
            "[Batch 4] Current Loss: 2.1520\n",
            "[Batch 5] Current Loss: 2.8995\n",
            "[Batch 6] Current Loss: 2.0790\n",
            "[Batch 7] Current Loss: 2.3553\n",
            "[Batch 8] Current Loss: 1.7538\n",
            "[Batch 9] Current Loss: 2.3397\n",
            "[Batch 0] Current Loss: 5.6510\n",
            "[Batch 1] Current Loss: 5.4481\n",
            "[Batch 2] Current Loss: 6.1504\n",
            "[Batch 3] Current Loss: 7.0258\n",
            "[Batch 4] Current Loss: 5.2821\n",
            "[Batch 5] Current Loss: 5.7772\n",
            "[Batch 6] Current Loss: 6.5675\n",
            "[Batch 7] Current Loss: 6.1283\n",
            "[Batch 8] Current Loss: 6.0028\n",
            "[Batch 9] Current Loss: 5.8194\n",
            "Ep 5 (Step 034580): Train loss 2.370, Val loss 5.985\n",
            "[Batch 0] Current Loss: 2.7368\n",
            "[Batch 1] Current Loss: 1.1944\n",
            "[Batch 2] Current Loss: 2.6790\n",
            "[Batch 3] Current Loss: 1.5425\n",
            "[Batch 4] Current Loss: 1.9748\n",
            "[Batch 5] Current Loss: 2.5518\n",
            "[Batch 6] Current Loss: 2.0592\n",
            "[Batch 7] Current Loss: 2.0537\n",
            "[Batch 8] Current Loss: 1.9090\n",
            "[Batch 9] Current Loss: 1.5481\n",
            "[Batch 0] Current Loss: 5.4775\n",
            "[Batch 1] Current Loss: 5.8619\n",
            "[Batch 2] Current Loss: 6.2299\n",
            "[Batch 3] Current Loss: 5.5889\n",
            "[Batch 4] Current Loss: 5.2800\n",
            "[Batch 5] Current Loss: 5.4836\n",
            "[Batch 6] Current Loss: 5.4708\n",
            "[Batch 7] Current Loss: 5.5097\n",
            "[Batch 8] Current Loss: 6.2569\n",
            "[Batch 9] Current Loss: 6.1866\n",
            "Ep 5 (Step 034600): Train loss 2.025, Val loss 5.735\n",
            "[Batch 0] Current Loss: 2.0723\n",
            "[Batch 1] Current Loss: 2.1230\n",
            "[Batch 2] Current Loss: 2.6035\n",
            "[Batch 3] Current Loss: 2.4079\n",
            "[Batch 4] Current Loss: 2.7636\n",
            "[Batch 5] Current Loss: 2.0698\n",
            "[Batch 6] Current Loss: 2.4559\n",
            "[Batch 7] Current Loss: 2.1197\n",
            "[Batch 8] Current Loss: 2.5181\n",
            "[Batch 9] Current Loss: 2.1268\n",
            "[Batch 0] Current Loss: 5.8631\n",
            "[Batch 1] Current Loss: 5.5245\n",
            "[Batch 2] Current Loss: 6.2337\n",
            "[Batch 3] Current Loss: 5.6445\n",
            "[Batch 4] Current Loss: 6.2128\n",
            "[Batch 5] Current Loss: 6.3501\n",
            "[Batch 6] Current Loss: 5.7122\n",
            "[Batch 7] Current Loss: 5.9712\n",
            "[Batch 8] Current Loss: 5.1770\n",
            "[Batch 9] Current Loss: 6.1102\n",
            "Ep 5 (Step 034620): Train loss 2.326, Val loss 5.880\n",
            "[Batch 0] Current Loss: 2.8252\n",
            "[Batch 1] Current Loss: 2.0531\n",
            "[Batch 2] Current Loss: 2.3323\n",
            "[Batch 3] Current Loss: 1.8799\n",
            "[Batch 4] Current Loss: 2.5133\n",
            "[Batch 5] Current Loss: 1.4590\n",
            "[Batch 6] Current Loss: 2.2560\n",
            "[Batch 7] Current Loss: 2.3736\n",
            "[Batch 8] Current Loss: 2.1699\n",
            "[Batch 9] Current Loss: 2.2106\n",
            "[Batch 0] Current Loss: 6.2217\n",
            "[Batch 1] Current Loss: 5.8421\n",
            "[Batch 2] Current Loss: 5.4923\n",
            "[Batch 3] Current Loss: 5.7330\n",
            "[Batch 4] Current Loss: 5.7607\n",
            "[Batch 5] Current Loss: 4.9680\n",
            "[Batch 6] Current Loss: 5.1869\n",
            "[Batch 7] Current Loss: 6.1393\n",
            "[Batch 8] Current Loss: 5.5786\n",
            "[Batch 9] Current Loss: 5.8936\n",
            "Ep 5 (Step 034640): Train loss 2.207, Val loss 5.682\n",
            "[Batch 0] Current Loss: 2.3032\n",
            "[Batch 1] Current Loss: 2.9022\n",
            "[Batch 2] Current Loss: 2.7945\n",
            "[Batch 3] Current Loss: 1.8918\n",
            "[Batch 4] Current Loss: 1.8043\n",
            "[Batch 5] Current Loss: 1.9195\n",
            "[Batch 6] Current Loss: 2.1697\n",
            "[Batch 7] Current Loss: 2.0166\n",
            "[Batch 8] Current Loss: 2.1900\n",
            "[Batch 9] Current Loss: 2.4103\n",
            "[Batch 0] Current Loss: 5.6813\n",
            "[Batch 1] Current Loss: 5.2717\n",
            "[Batch 2] Current Loss: 5.7170\n",
            "[Batch 3] Current Loss: 6.1873\n",
            "[Batch 4] Current Loss: 5.8901\n",
            "[Batch 5] Current Loss: 6.3435\n",
            "[Batch 6] Current Loss: 6.1896\n",
            "[Batch 7] Current Loss: 5.7455\n",
            "[Batch 8] Current Loss: 5.9119\n",
            "[Batch 9] Current Loss: 5.8792\n",
            "Ep 5 (Step 034660): Train loss 2.240, Val loss 5.882\n",
            "[Batch 0] Current Loss: 2.4143\n",
            "[Batch 1] Current Loss: 3.2151\n",
            "[Batch 2] Current Loss: 2.4119\n",
            "[Batch 3] Current Loss: 2.2754\n",
            "[Batch 4] Current Loss: 2.4697\n",
            "[Batch 5] Current Loss: 2.1079\n",
            "[Batch 6] Current Loss: 2.1158\n",
            "[Batch 7] Current Loss: 2.7065\n",
            "[Batch 8] Current Loss: 2.4600\n",
            "[Batch 9] Current Loss: 1.9295\n",
            "[Batch 0] Current Loss: 6.3446\n",
            "[Batch 1] Current Loss: 6.6039\n",
            "[Batch 2] Current Loss: 5.5571\n",
            "[Batch 3] Current Loss: 6.0890\n",
            "[Batch 4] Current Loss: 5.7455\n",
            "[Batch 5] Current Loss: 5.3227\n",
            "[Batch 6] Current Loss: 6.2932\n",
            "[Batch 7] Current Loss: 6.5815\n",
            "[Batch 8] Current Loss: 5.8136\n",
            "[Batch 9] Current Loss: 5.9266\n",
            "Ep 5 (Step 034680): Train loss 2.411, Val loss 6.028\n",
            "[Batch 0] Current Loss: 2.5340\n",
            "[Batch 1] Current Loss: 2.4158\n",
            "[Batch 2] Current Loss: 2.2046\n",
            "[Batch 3] Current Loss: 2.0425\n",
            "[Batch 4] Current Loss: 2.6975\n",
            "[Batch 5] Current Loss: 1.9676\n",
            "[Batch 6] Current Loss: 2.1144\n",
            "[Batch 7] Current Loss: 2.2815\n",
            "[Batch 8] Current Loss: 2.1861\n",
            "[Batch 9] Current Loss: 1.7200\n",
            "[Batch 0] Current Loss: 6.0236\n",
            "[Batch 1] Current Loss: 6.1062\n",
            "[Batch 2] Current Loss: 6.0352\n",
            "[Batch 3] Current Loss: 5.7267\n",
            "[Batch 4] Current Loss: 5.1793\n",
            "[Batch 5] Current Loss: 5.0097\n",
            "[Batch 6] Current Loss: 5.6503\n",
            "[Batch 7] Current Loss: 5.3954\n",
            "[Batch 8] Current Loss: 5.2074\n",
            "[Batch 9] Current Loss: 5.7828\n",
            "Ep 5 (Step 034700): Train loss 2.216, Val loss 5.612\n",
            "[Batch 0] Current Loss: 2.5227\n",
            "[Batch 1] Current Loss: 2.8030\n",
            "[Batch 2] Current Loss: 2.2140\n",
            "[Batch 3] Current Loss: 2.7156\n",
            "[Batch 4] Current Loss: 2.5878\n",
            "[Batch 5] Current Loss: 1.8698\n",
            "[Batch 6] Current Loss: 2.3644\n",
            "[Batch 7] Current Loss: 2.1852\n",
            "[Batch 8] Current Loss: 1.9956\n",
            "[Batch 9] Current Loss: 2.2774\n",
            "[Batch 0] Current Loss: 5.4514\n",
            "[Batch 1] Current Loss: 4.9013\n",
            "[Batch 2] Current Loss: 5.7239\n",
            "[Batch 3] Current Loss: 5.9066\n",
            "[Batch 4] Current Loss: 6.6463\n",
            "[Batch 5] Current Loss: 5.8036\n",
            "[Batch 6] Current Loss: 5.4449\n",
            "[Batch 7] Current Loss: 5.4940\n",
            "[Batch 8] Current Loss: 5.5077\n",
            "[Batch 9] Current Loss: 5.7817\n",
            "Ep 5 (Step 034720): Train loss 2.354, Val loss 5.666\n",
            "[Batch 0] Current Loss: 2.6044\n",
            "[Batch 1] Current Loss: 2.5888\n",
            "[Batch 2] Current Loss: 2.3418\n",
            "[Batch 3] Current Loss: 2.2018\n",
            "[Batch 4] Current Loss: 2.6566\n",
            "[Batch 5] Current Loss: 2.7563\n",
            "[Batch 6] Current Loss: 2.5086\n",
            "[Batch 7] Current Loss: 1.9890\n",
            "[Batch 8] Current Loss: 2.5158\n",
            "[Batch 9] Current Loss: 1.3978\n",
            "[Batch 0] Current Loss: 5.3875\n",
            "[Batch 1] Current Loss: 5.3443\n",
            "[Batch 2] Current Loss: 6.7841\n",
            "[Batch 3] Current Loss: 4.3815\n",
            "[Batch 4] Current Loss: 5.7734\n",
            "[Batch 5] Current Loss: 5.8552\n",
            "[Batch 6] Current Loss: 5.8729\n",
            "[Batch 7] Current Loss: 5.6873\n",
            "[Batch 8] Current Loss: 5.0456\n",
            "[Batch 9] Current Loss: 6.2925\n",
            "Ep 5 (Step 034740): Train loss 2.356, Val loss 5.642\n",
            "[Batch 0] Current Loss: 3.1657\n",
            "[Batch 1] Current Loss: 2.4158\n",
            "[Batch 2] Current Loss: 2.1923\n",
            "[Batch 3] Current Loss: 1.8904\n",
            "[Batch 4] Current Loss: 2.7304\n",
            "[Batch 5] Current Loss: 2.0292\n",
            "[Batch 6] Current Loss: 2.3436\n",
            "[Batch 7] Current Loss: 2.3512\n",
            "[Batch 8] Current Loss: 2.9298\n",
            "[Batch 9] Current Loss: 2.4246\n",
            "[Batch 0] Current Loss: 4.6907\n",
            "[Batch 1] Current Loss: 4.8665\n",
            "[Batch 2] Current Loss: 5.8376\n",
            "[Batch 3] Current Loss: 5.7894\n",
            "[Batch 4] Current Loss: 5.5270\n",
            "[Batch 5] Current Loss: 6.4932\n",
            "[Batch 6] Current Loss: 6.0209\n",
            "[Batch 7] Current Loss: 4.7509\n",
            "[Batch 8] Current Loss: 4.9792\n",
            "[Batch 9] Current Loss: 5.4766\n",
            "Ep 5 (Step 034760): Train loss 2.447, Val loss 5.443\n",
            "[Batch 0] Current Loss: 2.9567\n",
            "[Batch 1] Current Loss: 2.5631\n",
            "[Batch 2] Current Loss: 2.7600\n",
            "[Batch 3] Current Loss: 2.6417\n",
            "[Batch 4] Current Loss: 2.0928\n",
            "[Batch 5] Current Loss: 2.0346\n",
            "[Batch 6] Current Loss: 1.7031\n",
            "[Batch 7] Current Loss: 2.7783\n",
            "[Batch 8] Current Loss: 2.0441\n",
            "[Batch 9] Current Loss: 2.4051\n",
            "[Batch 0] Current Loss: 5.1286\n",
            "[Batch 1] Current Loss: 5.9047\n",
            "[Batch 2] Current Loss: 6.0421\n",
            "[Batch 3] Current Loss: 5.9903\n",
            "[Batch 4] Current Loss: 5.2648\n",
            "[Batch 5] Current Loss: 6.0950\n",
            "[Batch 6] Current Loss: 5.3823\n",
            "[Batch 7] Current Loss: 6.0502\n",
            "[Batch 8] Current Loss: 5.0726\n",
            "[Batch 9] Current Loss: 5.2912\n",
            "Ep 5 (Step 034780): Train loss 2.398, Val loss 5.622\n",
            "[Batch 0] Current Loss: 2.5891\n",
            "[Batch 1] Current Loss: 2.6838\n",
            "[Batch 2] Current Loss: 2.0077\n",
            "[Batch 3] Current Loss: 2.8418\n",
            "[Batch 4] Current Loss: 2.6319\n",
            "[Batch 5] Current Loss: 2.8156\n",
            "[Batch 6] Current Loss: 2.9787\n",
            "[Batch 7] Current Loss: 2.0330\n",
            "[Batch 8] Current Loss: 2.7838\n",
            "[Batch 9] Current Loss: 1.8542\n",
            "[Batch 0] Current Loss: 5.3615\n",
            "[Batch 1] Current Loss: 5.5994\n",
            "[Batch 2] Current Loss: 5.9285\n",
            "[Batch 3] Current Loss: 6.0353\n",
            "[Batch 4] Current Loss: 5.6373\n",
            "[Batch 5] Current Loss: 6.7788\n",
            "[Batch 6] Current Loss: 5.7078\n",
            "[Batch 7] Current Loss: 4.6364\n",
            "[Batch 8] Current Loss: 5.1732\n",
            "[Batch 9] Current Loss: 5.8268\n",
            "Ep 5 (Step 034800): Train loss 2.522, Val loss 5.668\n",
            "[Batch 0] Current Loss: 2.4015\n",
            "[Batch 1] Current Loss: 1.8640\n",
            "[Batch 2] Current Loss: 2.4590\n",
            "[Batch 3] Current Loss: 1.9941\n",
            "[Batch 4] Current Loss: 2.0857\n",
            "[Batch 5] Current Loss: 2.4851\n",
            "[Batch 6] Current Loss: 2.3842\n",
            "[Batch 7] Current Loss: 2.0932\n",
            "[Batch 8] Current Loss: 2.2176\n",
            "[Batch 9] Current Loss: 2.5660\n",
            "[Batch 0] Current Loss: 5.2574\n",
            "[Batch 1] Current Loss: 5.7307\n",
            "[Batch 2] Current Loss: 6.0135\n",
            "[Batch 3] Current Loss: 6.5201\n",
            "[Batch 4] Current Loss: 5.4039\n",
            "[Batch 5] Current Loss: 6.1402\n",
            "[Batch 6] Current Loss: 5.4105\n",
            "[Batch 7] Current Loss: 5.3396\n",
            "[Batch 8] Current Loss: 6.0893\n",
            "[Batch 9] Current Loss: 4.7057\n",
            "Ep 5 (Step 034820): Train loss 2.255, Val loss 5.661\n",
            "[Batch 0] Current Loss: 2.0900\n",
            "[Batch 1] Current Loss: 2.0631\n",
            "[Batch 2] Current Loss: 2.4184\n",
            "[Batch 3] Current Loss: 1.5651\n",
            "[Batch 4] Current Loss: 2.0576\n",
            "[Batch 5] Current Loss: 2.3599\n",
            "[Batch 6] Current Loss: 1.9987\n",
            "[Batch 7] Current Loss: 2.5049\n",
            "[Batch 8] Current Loss: 2.2406\n",
            "[Batch 9] Current Loss: 2.5432\n",
            "[Batch 0] Current Loss: 6.7502\n",
            "[Batch 1] Current Loss: 5.4009\n",
            "[Batch 2] Current Loss: 5.5790\n",
            "[Batch 3] Current Loss: 6.3303\n",
            "[Batch 4] Current Loss: 6.1058\n",
            "[Batch 5] Current Loss: 5.5938\n",
            "[Batch 6] Current Loss: 6.1973\n",
            "[Batch 7] Current Loss: 5.9778\n",
            "[Batch 8] Current Loss: 5.8788\n",
            "[Batch 9] Current Loss: 5.3016\n",
            "Ep 5 (Step 034840): Train loss 2.184, Val loss 5.912\n",
            "[Batch 0] Current Loss: 2.0595\n",
            "[Batch 1] Current Loss: 1.9112\n",
            "[Batch 2] Current Loss: 1.9939\n",
            "[Batch 3] Current Loss: 2.4893\n",
            "[Batch 4] Current Loss: 2.3810\n",
            "[Batch 5] Current Loss: 2.6861\n",
            "[Batch 6] Current Loss: 2.0471\n",
            "[Batch 7] Current Loss: 2.0422\n",
            "[Batch 8] Current Loss: 2.2261\n",
            "[Batch 9] Current Loss: 2.4506\n",
            "[Batch 0] Current Loss: 6.1211\n",
            "[Batch 1] Current Loss: 5.4108\n",
            "[Batch 2] Current Loss: 6.2347\n",
            "[Batch 3] Current Loss: 6.2016\n",
            "[Batch 4] Current Loss: 5.9112\n",
            "[Batch 5] Current Loss: 5.8405\n",
            "[Batch 6] Current Loss: 5.7165\n",
            "[Batch 7] Current Loss: 5.4826\n",
            "[Batch 8] Current Loss: 5.2698\n",
            "[Batch 9] Current Loss: 5.6512\n",
            "Ep 5 (Step 034860): Train loss 2.229, Val loss 5.784\n",
            "[Batch 0] Current Loss: 2.3156\n",
            "[Batch 1] Current Loss: 2.9787\n",
            "[Batch 2] Current Loss: 2.1046\n",
            "[Batch 3] Current Loss: 2.1776\n",
            "[Batch 4] Current Loss: 2.3276\n",
            "[Batch 5] Current Loss: 2.4135\n",
            "[Batch 6] Current Loss: 2.2958\n",
            "[Batch 7] Current Loss: 2.4632\n",
            "[Batch 8] Current Loss: 1.4332\n",
            "[Batch 9] Current Loss: 2.1876\n",
            "[Batch 0] Current Loss: 6.1179\n",
            "[Batch 1] Current Loss: 6.2969\n",
            "[Batch 2] Current Loss: 5.8204\n",
            "[Batch 3] Current Loss: 4.7309\n",
            "[Batch 4] Current Loss: 4.0215\n",
            "[Batch 5] Current Loss: 5.5746\n",
            "[Batch 6] Current Loss: 6.1104\n",
            "[Batch 7] Current Loss: 5.6537\n",
            "[Batch 8] Current Loss: 5.8660\n",
            "[Batch 9] Current Loss: 6.3634\n",
            "Ep 5 (Step 034880): Train loss 2.270, Val loss 5.656\n",
            "[Batch 0] Current Loss: 2.2830\n",
            "[Batch 1] Current Loss: 2.0313\n",
            "[Batch 2] Current Loss: 2.4158\n",
            "[Batch 3] Current Loss: 2.3087\n",
            "[Batch 4] Current Loss: 2.5259\n",
            "[Batch 5] Current Loss: 2.7584\n",
            "[Batch 6] Current Loss: 2.2247\n",
            "[Batch 7] Current Loss: 2.0610\n",
            "[Batch 8] Current Loss: 2.4693\n",
            "[Batch 9] Current Loss: 1.8290\n",
            "[Batch 0] Current Loss: 5.7453\n",
            "[Batch 1] Current Loss: 5.6611\n",
            "[Batch 2] Current Loss: 5.5022\n",
            "[Batch 3] Current Loss: 6.1181\n",
            "[Batch 4] Current Loss: 5.0308\n",
            "[Batch 5] Current Loss: 4.9985\n",
            "[Batch 6] Current Loss: 5.4770\n",
            "[Batch 7] Current Loss: 5.0504\n",
            "[Batch 8] Current Loss: 5.8975\n",
            "[Batch 9] Current Loss: 6.2160\n",
            "Ep 5 (Step 034900): Train loss 2.291, Val loss 5.570\n",
            "[Batch 0] Current Loss: 2.0624\n",
            "[Batch 1] Current Loss: 2.9549\n",
            "[Batch 2] Current Loss: 2.4994\n",
            "[Batch 3] Current Loss: 2.8612\n",
            "[Batch 4] Current Loss: 2.0762\n",
            "[Batch 5] Current Loss: 1.8866\n",
            "[Batch 6] Current Loss: 2.1034\n",
            "[Batch 7] Current Loss: 2.3294\n",
            "[Batch 8] Current Loss: 2.0406\n",
            "[Batch 9] Current Loss: 1.7497\n",
            "[Batch 0] Current Loss: 5.7406\n",
            "[Batch 1] Current Loss: 4.5595\n",
            "[Batch 2] Current Loss: 6.1653\n",
            "[Batch 3] Current Loss: 5.5952\n",
            "[Batch 4] Current Loss: 5.8290\n",
            "[Batch 5] Current Loss: 6.4666\n",
            "[Batch 6] Current Loss: 5.6918\n",
            "[Batch 7] Current Loss: 6.2494\n",
            "[Batch 8] Current Loss: 5.3326\n",
            "[Batch 9] Current Loss: 4.8547\n",
            "Ep 5 (Step 034920): Train loss 2.256, Val loss 5.648\n",
            "[Batch 0] Current Loss: 2.4792\n",
            "[Batch 1] Current Loss: 2.4497\n",
            "[Batch 2] Current Loss: 2.2636\n",
            "[Batch 3] Current Loss: 1.8074\n",
            "[Batch 4] Current Loss: 1.6264\n",
            "[Batch 5] Current Loss: 2.1597\n",
            "[Batch 6] Current Loss: 2.8862\n",
            "[Batch 7] Current Loss: 2.3628\n",
            "[Batch 8] Current Loss: 2.7118\n",
            "[Batch 9] Current Loss: 1.7221\n",
            "[Batch 0] Current Loss: 4.9622\n",
            "[Batch 1] Current Loss: 6.1714\n",
            "[Batch 2] Current Loss: 5.5319\n",
            "[Batch 3] Current Loss: 5.7554\n",
            "[Batch 4] Current Loss: 5.8853\n",
            "[Batch 5] Current Loss: 6.5588\n",
            "[Batch 6] Current Loss: 6.0123\n",
            "[Batch 7] Current Loss: 6.2182\n",
            "[Batch 8] Current Loss: 4.7466\n",
            "[Batch 9] Current Loss: 5.0062\n",
            "Ep 5 (Step 034940): Train loss 2.247, Val loss 5.685\n",
            "[Batch 0] Current Loss: 2.4517\n",
            "[Batch 1] Current Loss: 2.4470\n",
            "[Batch 2] Current Loss: 1.8845\n",
            "[Batch 3] Current Loss: 2.5291\n",
            "[Batch 4] Current Loss: 2.1123\n",
            "[Batch 5] Current Loss: 1.8342\n",
            "[Batch 6] Current Loss: 2.2728\n",
            "[Batch 7] Current Loss: 1.9333\n",
            "[Batch 8] Current Loss: 1.7004\n",
            "[Batch 9] Current Loss: 1.4593\n",
            "[Batch 0] Current Loss: 5.6612\n",
            "[Batch 1] Current Loss: 5.8155\n",
            "[Batch 2] Current Loss: 5.4476\n",
            "[Batch 3] Current Loss: 5.8696\n",
            "[Batch 4] Current Loss: 4.8114\n",
            "[Batch 5] Current Loss: 6.0464\n",
            "[Batch 6] Current Loss: 5.5558\n",
            "[Batch 7] Current Loss: 5.1842\n",
            "[Batch 8] Current Loss: 4.6562\n",
            "[Batch 9] Current Loss: 5.4951\n",
            "Ep 5 (Step 034960): Train loss 2.062, Val loss 5.454\n",
            "[Batch 0] Current Loss: 1.9574\n",
            "[Batch 1] Current Loss: 2.5049\n",
            "[Batch 2] Current Loss: 1.8137\n",
            "[Batch 3] Current Loss: 2.7443\n",
            "[Batch 4] Current Loss: 2.1560\n",
            "[Batch 5] Current Loss: 2.1964\n",
            "[Batch 6] Current Loss: 3.1743\n",
            "[Batch 7] Current Loss: 2.0427\n",
            "[Batch 8] Current Loss: 2.4817\n",
            "[Batch 9] Current Loss: 2.1385\n",
            "[Batch 0] Current Loss: 6.2025\n",
            "[Batch 1] Current Loss: 5.9814\n",
            "[Batch 2] Current Loss: 5.6430\n",
            "[Batch 3] Current Loss: 6.2318\n",
            "[Batch 4] Current Loss: 4.5656\n",
            "[Batch 5] Current Loss: 5.8193\n",
            "[Batch 6] Current Loss: 5.6370\n",
            "[Batch 7] Current Loss: 5.6874\n",
            "[Batch 8] Current Loss: 6.1017\n",
            "[Batch 9] Current Loss: 5.8680\n",
            "Ep 5 (Step 034980): Train loss 2.321, Val loss 5.774\n",
            "[Batch 0] Current Loss: 2.7107\n",
            "[Batch 1] Current Loss: 1.9425\n",
            "[Batch 2] Current Loss: 2.0337\n",
            "[Batch 3] Current Loss: 2.4585\n",
            "[Batch 4] Current Loss: 2.4492\n",
            "[Batch 5] Current Loss: 2.6041\n",
            "[Batch 6] Current Loss: 2.0513\n",
            "[Batch 7] Current Loss: 2.5882\n",
            "[Batch 8] Current Loss: 2.3120\n",
            "[Batch 9] Current Loss: 2.0738\n",
            "[Batch 0] Current Loss: 5.8336\n",
            "[Batch 1] Current Loss: 4.2176\n",
            "[Batch 2] Current Loss: 5.2492\n",
            "[Batch 3] Current Loss: 4.3872\n",
            "[Batch 4] Current Loss: 6.0078\n",
            "[Batch 5] Current Loss: 6.6769\n",
            "[Batch 6] Current Loss: 4.9826\n",
            "[Batch 7] Current Loss: 5.7489\n",
            "[Batch 8] Current Loss: 5.6902\n",
            "[Batch 9] Current Loss: 5.6451\n",
            "Ep 5 (Step 035000): Train loss 2.322, Val loss 5.444\n",
            "[Batch 0] Current Loss: 2.0803\n",
            "[Batch 1] Current Loss: 2.3200\n",
            "[Batch 2] Current Loss: 1.9479\n",
            "[Batch 3] Current Loss: 2.1221\n",
            "[Batch 4] Current Loss: 2.1920\n",
            "[Batch 5] Current Loss: 2.1128\n",
            "[Batch 6] Current Loss: 2.2222\n",
            "[Batch 7] Current Loss: 2.8114\n",
            "[Batch 8] Current Loss: 2.2697\n",
            "[Batch 9] Current Loss: 1.9513\n",
            "[Batch 0] Current Loss: 6.0510\n",
            "[Batch 1] Current Loss: 5.1116\n",
            "[Batch 2] Current Loss: 5.6743\n",
            "[Batch 3] Current Loss: 5.8218\n",
            "[Batch 4] Current Loss: 5.1553\n",
            "[Batch 5] Current Loss: 6.7284\n",
            "[Batch 6] Current Loss: 5.3401\n",
            "[Batch 7] Current Loss: 5.9873\n",
            "[Batch 8] Current Loss: 6.5630\n",
            "[Batch 9] Current Loss: 5.7637\n",
            "Ep 5 (Step 035020): Train loss 2.203, Val loss 5.820\n",
            "[Batch 0] Current Loss: 2.1378\n",
            "[Batch 1] Current Loss: 1.9446\n",
            "[Batch 2] Current Loss: 2.2182\n",
            "[Batch 3] Current Loss: 2.3834\n",
            "[Batch 4] Current Loss: 1.9144\n",
            "[Batch 5] Current Loss: 1.4375\n",
            "[Batch 6] Current Loss: 2.6562\n",
            "[Batch 7] Current Loss: 2.3513\n",
            "[Batch 8] Current Loss: 2.3805\n",
            "[Batch 9] Current Loss: 2.2920\n",
            "[Batch 0] Current Loss: 5.6411\n",
            "[Batch 1] Current Loss: 6.0013\n",
            "[Batch 2] Current Loss: 6.3801\n",
            "[Batch 3] Current Loss: 6.4405\n",
            "[Batch 4] Current Loss: 4.7739\n",
            "[Batch 5] Current Loss: 5.1219\n",
            "[Batch 6] Current Loss: 5.9638\n",
            "[Batch 7] Current Loss: 6.0854\n",
            "[Batch 8] Current Loss: 5.6587\n",
            "[Batch 9] Current Loss: 4.8236\n",
            "Ep 5 (Step 035040): Train loss 2.172, Val loss 5.689\n",
            "[Batch 0] Current Loss: 2.3155\n",
            "[Batch 1] Current Loss: 2.6679\n",
            "[Batch 2] Current Loss: 1.8908\n",
            "[Batch 3] Current Loss: 1.5391\n",
            "[Batch 4] Current Loss: 2.4685\n",
            "[Batch 5] Current Loss: 2.6732\n",
            "[Batch 6] Current Loss: 2.7685\n",
            "[Batch 7] Current Loss: 2.3579\n",
            "[Batch 8] Current Loss: 2.2296\n",
            "[Batch 9] Current Loss: 2.1245\n",
            "[Batch 0] Current Loss: 5.3700\n",
            "[Batch 1] Current Loss: 5.2686\n",
            "[Batch 2] Current Loss: 6.4333\n",
            "[Batch 3] Current Loss: 6.5043\n",
            "[Batch 4] Current Loss: 5.7413\n",
            "[Batch 5] Current Loss: 5.2989\n",
            "[Batch 6] Current Loss: 4.9688\n",
            "[Batch 7] Current Loss: 5.8822\n",
            "[Batch 8] Current Loss: 5.0775\n",
            "[Batch 9] Current Loss: 6.0281\n",
            "Ep 5 (Step 035060): Train loss 2.304, Val loss 5.657\n",
            "[Batch 0] Current Loss: 1.4266\n",
            "[Batch 1] Current Loss: 2.5406\n",
            "[Batch 2] Current Loss: 1.8984\n",
            "[Batch 3] Current Loss: 2.2870\n",
            "[Batch 4] Current Loss: 2.5661\n",
            "[Batch 5] Current Loss: 1.8636\n",
            "[Batch 6] Current Loss: 2.4816\n",
            "[Batch 7] Current Loss: 1.9482\n",
            "[Batch 8] Current Loss: 2.3348\n",
            "[Batch 9] Current Loss: 2.5076\n",
            "[Batch 0] Current Loss: 6.0771\n",
            "[Batch 1] Current Loss: 6.0354\n",
            "[Batch 2] Current Loss: 5.5356\n",
            "[Batch 3] Current Loss: 5.5569\n",
            "[Batch 4] Current Loss: 6.1652\n",
            "[Batch 5] Current Loss: 5.4374\n",
            "[Batch 6] Current Loss: 5.5420\n",
            "[Batch 7] Current Loss: 5.6314\n",
            "[Batch 8] Current Loss: 6.0916\n",
            "[Batch 9] Current Loss: 5.3218\n",
            "Ep 5 (Step 035080): Train loss 2.185, Val loss 5.739\n",
            "[Batch 0] Current Loss: 2.3769\n",
            "[Batch 1] Current Loss: 2.0359\n",
            "[Batch 2] Current Loss: 1.4553\n",
            "[Batch 3] Current Loss: 1.8501\n",
            "[Batch 4] Current Loss: 2.5423\n",
            "[Batch 5] Current Loss: 2.2156\n",
            "[Batch 6] Current Loss: 2.0457\n",
            "[Batch 7] Current Loss: 1.7676\n",
            "[Batch 8] Current Loss: 2.3934\n",
            "[Batch 9] Current Loss: 2.3964\n",
            "[Batch 0] Current Loss: 6.5668\n",
            "[Batch 1] Current Loss: 6.0896\n",
            "[Batch 2] Current Loss: 5.8190\n",
            "[Batch 3] Current Loss: 5.5459\n",
            "[Batch 4] Current Loss: 5.7806\n",
            "[Batch 5] Current Loss: 5.6357\n",
            "[Batch 6] Current Loss: 5.4562\n",
            "[Batch 7] Current Loss: 5.6771\n",
            "[Batch 8] Current Loss: 5.0442\n",
            "[Batch 9] Current Loss: 5.5363\n",
            "Ep 5 (Step 035100): Train loss 2.108, Val loss 5.715\n",
            "[Batch 0] Current Loss: 2.6664\n",
            "[Batch 1] Current Loss: 2.6020\n",
            "[Batch 2] Current Loss: 2.0589\n",
            "[Batch 3] Current Loss: 2.3320\n",
            "[Batch 4] Current Loss: 2.2907\n",
            "[Batch 5] Current Loss: 1.8512\n",
            "[Batch 6] Current Loss: 2.2475\n",
            "[Batch 7] Current Loss: 2.0942\n",
            "[Batch 8] Current Loss: 2.2349\n",
            "[Batch 9] Current Loss: 1.1791\n",
            "[Batch 0] Current Loss: 6.0958\n",
            "[Batch 1] Current Loss: 5.8371\n",
            "[Batch 2] Current Loss: 5.8152\n",
            "[Batch 3] Current Loss: 6.3391\n",
            "[Batch 4] Current Loss: 4.6741\n",
            "[Batch 5] Current Loss: 6.2417\n",
            "[Batch 6] Current Loss: 6.1806\n",
            "[Batch 7] Current Loss: 5.7582\n",
            "[Batch 8] Current Loss: 5.2195\n",
            "[Batch 9] Current Loss: 5.4391\n",
            "Ep 5 (Step 035120): Train loss 2.156, Val loss 5.760\n",
            "[Batch 0] Current Loss: 2.0394\n",
            "[Batch 1] Current Loss: 2.0103\n",
            "[Batch 2] Current Loss: 2.3466\n",
            "[Batch 3] Current Loss: 2.3836\n",
            "[Batch 4] Current Loss: 2.0304\n",
            "[Batch 5] Current Loss: 2.3916\n",
            "[Batch 6] Current Loss: 2.2929\n",
            "[Batch 7] Current Loss: 2.2105\n",
            "[Batch 8] Current Loss: 2.3884\n",
            "[Batch 9] Current Loss: 2.1587\n",
            "[Batch 0] Current Loss: 5.1746\n",
            "[Batch 1] Current Loss: 5.5791\n",
            "[Batch 2] Current Loss: 4.4927\n",
            "[Batch 3] Current Loss: 6.1976\n",
            "[Batch 4] Current Loss: 5.4287\n",
            "[Batch 5] Current Loss: 5.9473\n",
            "[Batch 6] Current Loss: 6.0338\n",
            "[Batch 7] Current Loss: 6.0543\n",
            "[Batch 8] Current Loss: 6.2964\n",
            "[Batch 9] Current Loss: 5.1962\n",
            "Ep 5 (Step 035140): Train loss 2.225, Val loss 5.640\n",
            "[Batch 0] Current Loss: 2.0340\n",
            "[Batch 1] Current Loss: 1.9637\n",
            "[Batch 2] Current Loss: 2.1771\n",
            "[Batch 3] Current Loss: 1.9188\n",
            "[Batch 4] Current Loss: 1.6544\n",
            "[Batch 5] Current Loss: 2.5567\n",
            "[Batch 6] Current Loss: 1.6671\n",
            "[Batch 7] Current Loss: 2.6743\n",
            "[Batch 8] Current Loss: 2.4726\n",
            "[Batch 9] Current Loss: 2.5248\n",
            "[Batch 0] Current Loss: 5.8127\n",
            "[Batch 1] Current Loss: 5.9147\n",
            "[Batch 2] Current Loss: 5.8038\n",
            "[Batch 3] Current Loss: 4.7859\n",
            "[Batch 4] Current Loss: 5.1150\n",
            "[Batch 5] Current Loss: 5.6134\n",
            "[Batch 6] Current Loss: 5.3090\n",
            "[Batch 7] Current Loss: 6.0553\n",
            "[Batch 8] Current Loss: 5.8265\n",
            "[Batch 9] Current Loss: 5.9450\n",
            "Ep 5 (Step 035160): Train loss 2.164, Val loss 5.618\n",
            "[Batch 0] Current Loss: 1.9128\n",
            "[Batch 1] Current Loss: 2.2940\n",
            "[Batch 2] Current Loss: 1.9701\n",
            "[Batch 3] Current Loss: 2.8723\n",
            "[Batch 4] Current Loss: 2.6486\n",
            "[Batch 5] Current Loss: 2.1210\n",
            "[Batch 6] Current Loss: 2.8072\n",
            "[Batch 7] Current Loss: 2.4767\n",
            "[Batch 8] Current Loss: 2.0588\n",
            "[Batch 9] Current Loss: 2.0424\n",
            "[Batch 0] Current Loss: 5.1141\n",
            "[Batch 1] Current Loss: 4.5865\n",
            "[Batch 2] Current Loss: 5.7661\n",
            "[Batch 3] Current Loss: 5.9398\n",
            "[Batch 4] Current Loss: 6.3692\n",
            "[Batch 5] Current Loss: 6.1165\n",
            "[Batch 6] Current Loss: 5.4557\n",
            "[Batch 7] Current Loss: 5.7285\n",
            "[Batch 8] Current Loss: 5.5292\n",
            "[Batch 9] Current Loss: 5.5651\n",
            "Ep 5 (Step 035180): Train loss 2.320, Val loss 5.617\n",
            "[Batch 0] Current Loss: 2.8805\n",
            "[Batch 1] Current Loss: 2.5217\n",
            "[Batch 2] Current Loss: 2.2228\n",
            "[Batch 3] Current Loss: 2.8213\n",
            "[Batch 4] Current Loss: 2.4975\n",
            "[Batch 5] Current Loss: 1.9697\n",
            "[Batch 6] Current Loss: 2.7401\n",
            "[Batch 7] Current Loss: 2.7436\n",
            "[Batch 8] Current Loss: 2.0354\n",
            "[Batch 9] Current Loss: 2.8463\n",
            "[Batch 0] Current Loss: 5.1999\n",
            "[Batch 1] Current Loss: 5.7128\n",
            "[Batch 2] Current Loss: 6.5408\n",
            "[Batch 3] Current Loss: 6.0128\n",
            "[Batch 4] Current Loss: 5.8588\n",
            "[Batch 5] Current Loss: 5.8100\n",
            "[Batch 6] Current Loss: 5.7968\n",
            "[Batch 7] Current Loss: 5.4691\n",
            "[Batch 8] Current Loss: 5.0695\n",
            "[Batch 9] Current Loss: 6.1641\n",
            "Ep 5 (Step 035200): Train loss 2.528, Val loss 5.763\n",
            "[Batch 0] Current Loss: 1.8094\n",
            "[Batch 1] Current Loss: 1.9332\n",
            "[Batch 2] Current Loss: 2.0665\n",
            "[Batch 3] Current Loss: 2.3689\n",
            "[Batch 4] Current Loss: 1.5116\n",
            "[Batch 5] Current Loss: 2.6142\n",
            "[Batch 6] Current Loss: 2.3591\n",
            "[Batch 7] Current Loss: 2.8526\n",
            "[Batch 8] Current Loss: 2.6608\n",
            "[Batch 9] Current Loss: 1.8288\n",
            "[Batch 0] Current Loss: 5.1720\n",
            "[Batch 1] Current Loss: 5.4011\n",
            "[Batch 2] Current Loss: 5.6040\n",
            "[Batch 3] Current Loss: 6.2413\n",
            "[Batch 4] Current Loss: 5.3929\n",
            "[Batch 5] Current Loss: 5.0634\n",
            "[Batch 6] Current Loss: 5.9227\n",
            "[Batch 7] Current Loss: 5.0626\n",
            "[Batch 8] Current Loss: 5.4364\n",
            "[Batch 9] Current Loss: 4.9905\n",
            "Ep 5 (Step 035220): Train loss 2.201, Val loss 5.429\n",
            "[Batch 0] Current Loss: 2.2887\n",
            "[Batch 1] Current Loss: 2.1690\n",
            "[Batch 2] Current Loss: 1.7682\n",
            "[Batch 3] Current Loss: 2.7702\n",
            "[Batch 4] Current Loss: 2.6153\n",
            "[Batch 5] Current Loss: 2.3763\n",
            "[Batch 6] Current Loss: 2.1552\n",
            "[Batch 7] Current Loss: 1.9207\n",
            "[Batch 8] Current Loss: 2.4557\n",
            "[Batch 9] Current Loss: 2.1798\n",
            "[Batch 0] Current Loss: 6.7088\n",
            "[Batch 1] Current Loss: 5.7371\n",
            "[Batch 2] Current Loss: 5.2225\n",
            "[Batch 3] Current Loss: 4.9908\n",
            "[Batch 4] Current Loss: 5.5220\n",
            "[Batch 5] Current Loss: 6.2071\n",
            "[Batch 6] Current Loss: 5.7527\n",
            "[Batch 7] Current Loss: 5.2227\n",
            "[Batch 8] Current Loss: 5.0134\n",
            "[Batch 9] Current Loss: 6.0706\n",
            "Ep 5 (Step 035240): Train loss 2.270, Val loss 5.645\n",
            "[Batch 0] Current Loss: 2.2853\n",
            "[Batch 1] Current Loss: 2.3077\n",
            "[Batch 2] Current Loss: 2.7967\n",
            "[Batch 3] Current Loss: 2.3743\n",
            "[Batch 4] Current Loss: 2.4782\n",
            "[Batch 5] Current Loss: 2.3483\n",
            "[Batch 6] Current Loss: 2.3425\n",
            "[Batch 7] Current Loss: 1.9887\n",
            "[Batch 8] Current Loss: 1.9762\n",
            "[Batch 9] Current Loss: 2.2308\n",
            "[Batch 0] Current Loss: 5.1855\n",
            "[Batch 1] Current Loss: 5.8048\n",
            "[Batch 2] Current Loss: 5.8785\n",
            "[Batch 3] Current Loss: 5.7882\n",
            "[Batch 4] Current Loss: 5.8427\n",
            "[Batch 5] Current Loss: 6.2192\n",
            "[Batch 6] Current Loss: 5.8818\n",
            "[Batch 7] Current Loss: 6.0796\n",
            "[Batch 8] Current Loss: 6.0009\n",
            "[Batch 9] Current Loss: 4.9836\n",
            "Ep 5 (Step 035260): Train loss 2.313, Val loss 5.766\n",
            "[Batch 0] Current Loss: 2.5370\n",
            "[Batch 1] Current Loss: 2.1557\n",
            "[Batch 2] Current Loss: 2.3660\n",
            "[Batch 3] Current Loss: 2.7500\n",
            "[Batch 4] Current Loss: 2.5618\n",
            "[Batch 5] Current Loss: 1.9430\n",
            "[Batch 6] Current Loss: 2.0250\n",
            "[Batch 7] Current Loss: 2.4749\n",
            "[Batch 8] Current Loss: 2.6454\n",
            "[Batch 9] Current Loss: 2.7746\n",
            "[Batch 0] Current Loss: 5.5384\n",
            "[Batch 1] Current Loss: 5.9313\n",
            "[Batch 2] Current Loss: 5.7512\n",
            "[Batch 3] Current Loss: 5.7898\n",
            "[Batch 4] Current Loss: 5.6931\n",
            "[Batch 5] Current Loss: 6.3815\n",
            "[Batch 6] Current Loss: 5.1988\n",
            "[Batch 7] Current Loss: 5.4968\n",
            "[Batch 8] Current Loss: 5.7951\n",
            "[Batch 9] Current Loss: 6.2617\n",
            "Ep 5 (Step 035280): Train loss 2.423, Val loss 5.784\n",
            "[Batch 0] Current Loss: 2.3347\n",
            "[Batch 1] Current Loss: 2.8584\n",
            "[Batch 2] Current Loss: 2.5112\n",
            "[Batch 3] Current Loss: 2.3457\n",
            "[Batch 4] Current Loss: 1.9866\n",
            "[Batch 5] Current Loss: 2.3631\n",
            "[Batch 6] Current Loss: 2.5729\n",
            "[Batch 7] Current Loss: 2.1191\n",
            "[Batch 8] Current Loss: 2.0611\n",
            "[Batch 9] Current Loss: 1.9841\n",
            "[Batch 0] Current Loss: 6.1373\n",
            "[Batch 1] Current Loss: 6.0814\n",
            "[Batch 2] Current Loss: 5.8097\n",
            "[Batch 3] Current Loss: 4.8935\n",
            "[Batch 4] Current Loss: 5.5528\n",
            "[Batch 5] Current Loss: 6.1038\n",
            "[Batch 6] Current Loss: 6.0389\n",
            "[Batch 7] Current Loss: 5.5243\n",
            "[Batch 8] Current Loss: 6.0244\n",
            "[Batch 9] Current Loss: 5.5851\n",
            "Ep 5 (Step 035300): Train loss 2.314, Val loss 5.775\n",
            "[Batch 0] Current Loss: 2.2923\n",
            "[Batch 1] Current Loss: 2.0292\n",
            "[Batch 2] Current Loss: 3.1085\n",
            "[Batch 3] Current Loss: 2.4214\n",
            "[Batch 4] Current Loss: 2.1768\n",
            "[Batch 5] Current Loss: 1.9365\n",
            "[Batch 6] Current Loss: 2.2714\n",
            "[Batch 7] Current Loss: 2.4197\n",
            "[Batch 8] Current Loss: 2.0701\n",
            "[Batch 9] Current Loss: 2.0530\n",
            "[Batch 0] Current Loss: 5.7445\n",
            "[Batch 1] Current Loss: 5.9695\n",
            "[Batch 2] Current Loss: 6.2229\n",
            "[Batch 3] Current Loss: 5.7033\n",
            "[Batch 4] Current Loss: 6.2441\n",
            "[Batch 5] Current Loss: 6.6417\n",
            "[Batch 6] Current Loss: 5.7461\n",
            "[Batch 7] Current Loss: 5.0987\n",
            "[Batch 8] Current Loss: 5.3709\n",
            "[Batch 9] Current Loss: 5.0642\n",
            "Ep 5 (Step 035320): Train loss 2.278, Val loss 5.781\n",
            "[Batch 0] Current Loss: 2.2019\n",
            "[Batch 1] Current Loss: 2.1902\n",
            "[Batch 2] Current Loss: 1.8607\n",
            "[Batch 3] Current Loss: 2.5893\n",
            "[Batch 4] Current Loss: 2.1074\n",
            "[Batch 5] Current Loss: 2.6400\n",
            "[Batch 6] Current Loss: 2.5969\n",
            "[Batch 7] Current Loss: 1.5642\n",
            "[Batch 8] Current Loss: 2.3734\n",
            "[Batch 9] Current Loss: 2.8920\n",
            "[Batch 0] Current Loss: 6.4064\n",
            "[Batch 1] Current Loss: 5.9610\n",
            "[Batch 2] Current Loss: 5.5343\n",
            "[Batch 3] Current Loss: 5.9684\n",
            "[Batch 4] Current Loss: 5.6525\n",
            "[Batch 5] Current Loss: 6.4858\n",
            "[Batch 6] Current Loss: 5.3036\n",
            "[Batch 7] Current Loss: 6.0225\n",
            "[Batch 8] Current Loss: 5.3259\n",
            "[Batch 9] Current Loss: 6.0650\n",
            "Ep 5 (Step 035340): Train loss 2.302, Val loss 5.873\n",
            "[Batch 0] Current Loss: 2.5971\n",
            "[Batch 1] Current Loss: 2.2693\n",
            "[Batch 2] Current Loss: 2.5854\n",
            "[Batch 3] Current Loss: 2.2376\n",
            "[Batch 4] Current Loss: 2.7701\n",
            "[Batch 5] Current Loss: 2.2636\n",
            "[Batch 6] Current Loss: 2.0317\n",
            "[Batch 7] Current Loss: 2.0807\n",
            "[Batch 8] Current Loss: 2.6456\n",
            "[Batch 9] Current Loss: 2.5115\n",
            "[Batch 0] Current Loss: 4.9492\n",
            "[Batch 1] Current Loss: 5.1595\n",
            "[Batch 2] Current Loss: 6.2251\n",
            "[Batch 3] Current Loss: 5.4994\n",
            "[Batch 4] Current Loss: 4.9081\n",
            "[Batch 5] Current Loss: 4.8033\n",
            "[Batch 6] Current Loss: 5.5793\n",
            "[Batch 7] Current Loss: 5.5978\n",
            "[Batch 8] Current Loss: 5.9287\n",
            "[Batch 9] Current Loss: 5.4999\n",
            "Ep 5 (Step 035360): Train loss 2.399, Val loss 5.415\n",
            "[Batch 0] Current Loss: 2.5889\n",
            "[Batch 1] Current Loss: 2.5935\n",
            "[Batch 2] Current Loss: 2.5477\n",
            "[Batch 3] Current Loss: 2.2776\n",
            "[Batch 4] Current Loss: 2.5147\n",
            "[Batch 5] Current Loss: 2.2022\n",
            "[Batch 6] Current Loss: 2.2772\n",
            "[Batch 7] Current Loss: 2.4434\n",
            "[Batch 8] Current Loss: 1.9320\n",
            "[Batch 9] Current Loss: 2.3128\n",
            "[Batch 0] Current Loss: 5.6775\n",
            "[Batch 1] Current Loss: 6.2376\n",
            "[Batch 2] Current Loss: 5.3219\n",
            "[Batch 3] Current Loss: 5.3234\n",
            "[Batch 4] Current Loss: 5.7833\n",
            "[Batch 5] Current Loss: 5.7382\n",
            "[Batch 6] Current Loss: 5.7169\n",
            "[Batch 7] Current Loss: 5.3381\n",
            "[Batch 8] Current Loss: 5.0310\n",
            "[Batch 9] Current Loss: 6.5905\n",
            "Ep 5 (Step 035380): Train loss 2.369, Val loss 5.676\n",
            "[Batch 0] Current Loss: 1.9269\n",
            "[Batch 1] Current Loss: 2.1332\n",
            "[Batch 2] Current Loss: 2.8326\n",
            "[Batch 3] Current Loss: 1.9023\n",
            "[Batch 4] Current Loss: 1.8871\n",
            "[Batch 5] Current Loss: 1.1444\n",
            "[Batch 6] Current Loss: 2.4783\n",
            "[Batch 7] Current Loss: 2.0164\n",
            "[Batch 8] Current Loss: 2.2089\n",
            "[Batch 9] Current Loss: 1.8262\n",
            "[Batch 0] Current Loss: 5.3649\n",
            "[Batch 1] Current Loss: 5.6388\n",
            "[Batch 2] Current Loss: 5.8216\n",
            "[Batch 3] Current Loss: 5.1923\n",
            "[Batch 4] Current Loss: 5.4719\n",
            "[Batch 5] Current Loss: 5.6857\n",
            "[Batch 6] Current Loss: 4.8765\n",
            "[Batch 7] Current Loss: 5.7167\n",
            "[Batch 8] Current Loss: 5.5729\n",
            "[Batch 9] Current Loss: 6.2395\n",
            "Ep 5 (Step 035400): Train loss 2.036, Val loss 5.558\n",
            "[Batch 0] Current Loss: 2.6056\n",
            "[Batch 1] Current Loss: 2.6264\n",
            "[Batch 2] Current Loss: 2.8247\n",
            "[Batch 3] Current Loss: 2.5795\n",
            "[Batch 4] Current Loss: 2.6354\n",
            "[Batch 5] Current Loss: 1.7465\n",
            "[Batch 6] Current Loss: 2.6682\n",
            "[Batch 7] Current Loss: 2.3486\n",
            "[Batch 8] Current Loss: 2.1149\n",
            "[Batch 9] Current Loss: 2.1639\n",
            "[Batch 0] Current Loss: 4.5804\n",
            "[Batch 1] Current Loss: 5.0918\n",
            "[Batch 2] Current Loss: 6.0657\n",
            "[Batch 3] Current Loss: 6.2450\n",
            "[Batch 4] Current Loss: 6.3013\n",
            "[Batch 5] Current Loss: 5.8574\n",
            "[Batch 6] Current Loss: 5.1849\n",
            "[Batch 7] Current Loss: 5.5043\n",
            "[Batch 8] Current Loss: 5.4532\n",
            "[Batch 9] Current Loss: 5.2386\n",
            "Ep 5 (Step 035420): Train loss 2.431, Val loss 5.552\n",
            "[Batch 0] Current Loss: 2.2991\n",
            "[Batch 1] Current Loss: 2.1594\n",
            "[Batch 2] Current Loss: 1.8586\n",
            "[Batch 3] Current Loss: 1.7939\n",
            "[Batch 4] Current Loss: 1.7701\n",
            "[Batch 5] Current Loss: 1.7331\n",
            "[Batch 6] Current Loss: 2.9174\n",
            "[Batch 7] Current Loss: 2.4487\n",
            "[Batch 8] Current Loss: 2.4151\n",
            "[Batch 9] Current Loss: 2.3629\n",
            "[Batch 0] Current Loss: 5.7076\n",
            "[Batch 1] Current Loss: 6.1671\n",
            "[Batch 2] Current Loss: 5.8545\n",
            "[Batch 3] Current Loss: 4.4108\n",
            "[Batch 4] Current Loss: 6.1700\n",
            "[Batch 5] Current Loss: 4.8856\n",
            "[Batch 6] Current Loss: 5.6370\n",
            "[Batch 7] Current Loss: 6.0499\n",
            "[Batch 8] Current Loss: 6.1861\n",
            "[Batch 9] Current Loss: 5.5096\n",
            "Ep 5 (Step 035440): Train loss 2.176, Val loss 5.658\n",
            "[Batch 0] Current Loss: 2.4326\n",
            "[Batch 1] Current Loss: 2.1128\n",
            "[Batch 2] Current Loss: 2.0027\n",
            "[Batch 3] Current Loss: 1.6623\n",
            "[Batch 4] Current Loss: 2.5042\n",
            "[Batch 5] Current Loss: 2.0875\n",
            "[Batch 6] Current Loss: 2.6491\n",
            "[Batch 7] Current Loss: 2.2871\n",
            "[Batch 8] Current Loss: 2.1855\n",
            "[Batch 9] Current Loss: 2.7813\n",
            "[Batch 0] Current Loss: 5.8437\n",
            "[Batch 1] Current Loss: 6.1656\n",
            "[Batch 2] Current Loss: 5.5185\n",
            "[Batch 3] Current Loss: 4.4873\n",
            "[Batch 4] Current Loss: 5.7504\n",
            "[Batch 5] Current Loss: 5.0666\n",
            "[Batch 6] Current Loss: 5.7199\n",
            "[Batch 7] Current Loss: 6.3013\n",
            "[Batch 8] Current Loss: 5.2344\n",
            "[Batch 9] Current Loss: 6.0096\n",
            "Ep 5 (Step 035460): Train loss 2.271, Val loss 5.610\n",
            "[Batch 0] Current Loss: 1.7685\n",
            "[Batch 1] Current Loss: 2.3427\n",
            "[Batch 2] Current Loss: 1.8725\n",
            "[Batch 3] Current Loss: 2.4482\n",
            "[Batch 4] Current Loss: 1.5042\n",
            "[Batch 5] Current Loss: 2.1884\n",
            "[Batch 6] Current Loss: 2.4242\n",
            "[Batch 7] Current Loss: 2.4295\n",
            "[Batch 8] Current Loss: 1.7654\n",
            "[Batch 9] Current Loss: 1.8843\n",
            "[Batch 0] Current Loss: 5.0954\n",
            "[Batch 1] Current Loss: 6.2879\n",
            "[Batch 2] Current Loss: 5.8166\n",
            "[Batch 3] Current Loss: 5.8001\n",
            "[Batch 4] Current Loss: 4.8811\n",
            "[Batch 5] Current Loss: 5.6515\n",
            "[Batch 6] Current Loss: 5.1936\n",
            "[Batch 7] Current Loss: 5.6296\n",
            "[Batch 8] Current Loss: 5.7045\n",
            "[Batch 9] Current Loss: 5.8036\n",
            "Ep 5 (Step 035480): Train loss 2.063, Val loss 5.586\n",
            "[Batch 0] Current Loss: 2.1606\n",
            "[Batch 1] Current Loss: 1.9665\n",
            "[Batch 2] Current Loss: 2.2843\n",
            "[Batch 3] Current Loss: 2.1527\n",
            "[Batch 4] Current Loss: 2.7502\n",
            "[Batch 5] Current Loss: 2.4204\n",
            "[Batch 6] Current Loss: 2.2538\n",
            "[Batch 7] Current Loss: 2.9162\n",
            "[Batch 8] Current Loss: 2.6829\n",
            "[Batch 9] Current Loss: 2.4611\n",
            "[Batch 0] Current Loss: 5.0213\n",
            "[Batch 1] Current Loss: 5.5771\n",
            "[Batch 2] Current Loss: 4.8318\n",
            "[Batch 3] Current Loss: 5.6671\n",
            "[Batch 4] Current Loss: 5.7533\n",
            "[Batch 5] Current Loss: 5.8619\n",
            "[Batch 6] Current Loss: 5.6373\n",
            "[Batch 7] Current Loss: 5.0257\n",
            "[Batch 8] Current Loss: 5.5343\n",
            "[Batch 9] Current Loss: 5.5366\n",
            "Ep 5 (Step 035500): Train loss 2.405, Val loss 5.445\n",
            "[Batch 0] Current Loss: 1.9303\n",
            "[Batch 1] Current Loss: 2.2263\n",
            "[Batch 2] Current Loss: 2.3102\n",
            "[Batch 3] Current Loss: 1.7534\n",
            "[Batch 4] Current Loss: 2.0885\n",
            "[Batch 5] Current Loss: 1.9704\n",
            "[Batch 6] Current Loss: 2.1888\n",
            "[Batch 7] Current Loss: 2.2504\n",
            "[Batch 8] Current Loss: 2.6482\n",
            "[Batch 9] Current Loss: 2.3358\n",
            "[Batch 0] Current Loss: 5.1409\n",
            "[Batch 1] Current Loss: 5.7071\n",
            "[Batch 2] Current Loss: 5.8454\n",
            "[Batch 3] Current Loss: 5.4138\n",
            "[Batch 4] Current Loss: 6.0808\n",
            "[Batch 5] Current Loss: 5.8114\n",
            "[Batch 6] Current Loss: 4.9653\n",
            "[Batch 7] Current Loss: 5.9757\n",
            "[Batch 8] Current Loss: 5.6621\n",
            "[Batch 9] Current Loss: 6.0337\n",
            "Ep 5 (Step 035520): Train loss 2.170, Val loss 5.664\n",
            "[Batch 0] Current Loss: 2.5293\n",
            "[Batch 1] Current Loss: 2.3296\n",
            "[Batch 2] Current Loss: 2.9060\n",
            "[Batch 3] Current Loss: 2.4261\n",
            "[Batch 4] Current Loss: 1.7924\n",
            "[Batch 5] Current Loss: 2.0808\n",
            "[Batch 6] Current Loss: 2.1422\n",
            "[Batch 7] Current Loss: 1.5374\n",
            "[Batch 8] Current Loss: 2.4997\n",
            "[Batch 9] Current Loss: 1.7333\n",
            "[Batch 0] Current Loss: 5.2927\n",
            "[Batch 1] Current Loss: 5.5983\n",
            "[Batch 2] Current Loss: 6.0499\n",
            "[Batch 3] Current Loss: 4.7844\n",
            "[Batch 4] Current Loss: 5.9895\n",
            "[Batch 5] Current Loss: 6.3481\n",
            "[Batch 6] Current Loss: 4.8804\n",
            "[Batch 7] Current Loss: 6.6170\n",
            "[Batch 8] Current Loss: 6.6543\n",
            "[Batch 9] Current Loss: 5.5918\n",
            "Ep 5 (Step 035540): Train loss 2.198, Val loss 5.781\n",
            "[Batch 0] Current Loss: 2.7447\n",
            "[Batch 1] Current Loss: 1.9289\n",
            "[Batch 2] Current Loss: 3.3528\n",
            "[Batch 3] Current Loss: 2.3864\n",
            "[Batch 4] Current Loss: 1.4319\n",
            "[Batch 5] Current Loss: 2.1872\n",
            "[Batch 6] Current Loss: 2.7502\n",
            "[Batch 7] Current Loss: 2.2938\n",
            "[Batch 8] Current Loss: 2.6875\n",
            "[Batch 9] Current Loss: 2.1783\n",
            "[Batch 0] Current Loss: 5.4676\n",
            "[Batch 1] Current Loss: 5.4773\n",
            "[Batch 2] Current Loss: 5.3684\n",
            "[Batch 3] Current Loss: 5.4580\n",
            "[Batch 4] Current Loss: 6.1420\n",
            "[Batch 5] Current Loss: 5.1632\n",
            "[Batch 6] Current Loss: 5.7066\n",
            "[Batch 7] Current Loss: 5.2287\n",
            "[Batch 8] Current Loss: 5.9594\n",
            "[Batch 9] Current Loss: 5.1610\n",
            "Ep 5 (Step 035560): Train loss 2.394, Val loss 5.513\n",
            "[Batch 0] Current Loss: 2.1716\n",
            "[Batch 1] Current Loss: 1.9997\n",
            "[Batch 2] Current Loss: 2.1838\n",
            "[Batch 3] Current Loss: 2.9352\n",
            "[Batch 4] Current Loss: 1.8893\n",
            "[Batch 5] Current Loss: 2.2890\n",
            "[Batch 6] Current Loss: 1.9880\n",
            "[Batch 7] Current Loss: 2.4345\n",
            "[Batch 8] Current Loss: 1.5186\n",
            "[Batch 9] Current Loss: 2.1362\n",
            "[Batch 0] Current Loss: 5.8043\n",
            "[Batch 1] Current Loss: 5.2845\n",
            "[Batch 2] Current Loss: 5.8203\n",
            "[Batch 3] Current Loss: 5.8101\n",
            "[Batch 4] Current Loss: 6.0845\n",
            "[Batch 5] Current Loss: 5.7994\n",
            "[Batch 6] Current Loss: 5.5589\n",
            "[Batch 7] Current Loss: 5.7960\n",
            "[Batch 8] Current Loss: 5.9057\n",
            "[Batch 9] Current Loss: 6.4909\n",
            "Ep 5 (Step 035580): Train loss 2.155, Val loss 5.835\n",
            "[Batch 0] Current Loss: 1.5808\n",
            "[Batch 1] Current Loss: 2.4145\n",
            "[Batch 2] Current Loss: 1.8566\n",
            "[Batch 3] Current Loss: 1.6803\n",
            "[Batch 4] Current Loss: 2.1481\n",
            "[Batch 5] Current Loss: 2.0684\n",
            "[Batch 6] Current Loss: 2.4441\n",
            "[Batch 7] Current Loss: 1.9262\n",
            "[Batch 8] Current Loss: 1.4020\n",
            "[Batch 9] Current Loss: 1.8691\n",
            "[Batch 0] Current Loss: 6.0053\n",
            "[Batch 1] Current Loss: 5.0257\n",
            "[Batch 2] Current Loss: 6.1797\n",
            "[Batch 3] Current Loss: 5.6407\n",
            "[Batch 4] Current Loss: 6.2288\n",
            "[Batch 5] Current Loss: 5.3557\n",
            "[Batch 6] Current Loss: 5.4648\n",
            "[Batch 7] Current Loss: 6.1383\n",
            "[Batch 8] Current Loss: 6.0795\n",
            "[Batch 9] Current Loss: 5.4529\n",
            "Ep 5 (Step 035600): Train loss 1.939, Val loss 5.757\n",
            "[Batch 0] Current Loss: 2.4820\n",
            "[Batch 1] Current Loss: 2.1228\n",
            "[Batch 2] Current Loss: 1.8800\n",
            "[Batch 3] Current Loss: 2.1249\n",
            "[Batch 4] Current Loss: 2.5678\n",
            "[Batch 5] Current Loss: 2.3032\n",
            "[Batch 6] Current Loss: 2.4000\n",
            "[Batch 7] Current Loss: 2.0461\n",
            "[Batch 8] Current Loss: 2.3899\n",
            "[Batch 9] Current Loss: 1.1651\n",
            "[Batch 0] Current Loss: 5.7624\n",
            "[Batch 1] Current Loss: 6.1043\n",
            "[Batch 2] Current Loss: 5.7076\n",
            "[Batch 3] Current Loss: 6.6468\n",
            "[Batch 4] Current Loss: 5.9398\n",
            "[Batch 5] Current Loss: 5.2871\n",
            "[Batch 6] Current Loss: 5.5150\n",
            "[Batch 7] Current Loss: 7.2203\n",
            "[Batch 8] Current Loss: 5.8213\n",
            "[Batch 9] Current Loss: 5.9453\n",
            "Ep 5 (Step 035620): Train loss 2.148, Val loss 5.995\n",
            "[Batch 0] Current Loss: 2.5937\n",
            "[Batch 1] Current Loss: 2.5062\n",
            "[Batch 2] Current Loss: 2.0517\n",
            "[Batch 3] Current Loss: 2.6411\n",
            "[Batch 4] Current Loss: 1.7773\n",
            "[Batch 5] Current Loss: 1.8234\n",
            "[Batch 6] Current Loss: 2.3913\n",
            "[Batch 7] Current Loss: 2.5278\n",
            "[Batch 8] Current Loss: 2.3708\n",
            "[Batch 9] Current Loss: 1.3931\n",
            "[Batch 0] Current Loss: 6.4199\n",
            "[Batch 1] Current Loss: 6.7604\n",
            "[Batch 2] Current Loss: 5.3831\n",
            "[Batch 3] Current Loss: 6.1885\n",
            "[Batch 4] Current Loss: 6.9545\n",
            "[Batch 5] Current Loss: 6.7821\n",
            "[Batch 6] Current Loss: 6.2857\n",
            "[Batch 7] Current Loss: 5.6795\n",
            "[Batch 8] Current Loss: 5.7737\n",
            "[Batch 9] Current Loss: 5.6276\n",
            "Ep 5 (Step 035640): Train loss 2.208, Val loss 6.185\n",
            "[Batch 0] Current Loss: 2.3354\n",
            "[Batch 1] Current Loss: 2.5002\n",
            "[Batch 2] Current Loss: 1.5910\n",
            "[Batch 3] Current Loss: 2.8233\n",
            "[Batch 4] Current Loss: 2.2384\n",
            "[Batch 5] Current Loss: 2.1517\n",
            "[Batch 6] Current Loss: 2.7875\n",
            "[Batch 7] Current Loss: 2.6643\n",
            "[Batch 8] Current Loss: 2.0640\n",
            "[Batch 9] Current Loss: 2.3019\n",
            "[Batch 0] Current Loss: 6.2167\n",
            "[Batch 1] Current Loss: 4.6722\n",
            "[Batch 2] Current Loss: 5.7821\n",
            "[Batch 3] Current Loss: 6.0009\n",
            "[Batch 4] Current Loss: 5.7526\n",
            "[Batch 5] Current Loss: 5.6060\n",
            "[Batch 6] Current Loss: 5.7439\n",
            "[Batch 7] Current Loss: 5.3744\n",
            "[Batch 8] Current Loss: 5.7500\n",
            "[Batch 9] Current Loss: 5.7477\n",
            "Ep 5 (Step 035660): Train loss 2.346, Val loss 5.665\n",
            "[Batch 0] Current Loss: 2.1937\n",
            "[Batch 1] Current Loss: 2.5266\n",
            "[Batch 2] Current Loss: 1.8042\n",
            "[Batch 3] Current Loss: 2.7861\n",
            "[Batch 4] Current Loss: 2.4256\n",
            "[Batch 5] Current Loss: 1.6490\n",
            "[Batch 6] Current Loss: 2.4836\n",
            "[Batch 7] Current Loss: 2.1241\n",
            "[Batch 8] Current Loss: 2.7831\n",
            "[Batch 9] Current Loss: 2.0842\n",
            "[Batch 0] Current Loss: 5.1416\n",
            "[Batch 1] Current Loss: 5.6656\n",
            "[Batch 2] Current Loss: 5.5764\n",
            "[Batch 3] Current Loss: 5.9373\n",
            "[Batch 4] Current Loss: 6.1965\n",
            "[Batch 5] Current Loss: 5.3286\n",
            "[Batch 6] Current Loss: 5.9585\n",
            "[Batch 7] Current Loss: 4.8774\n",
            "[Batch 8] Current Loss: 5.0438\n",
            "[Batch 9] Current Loss: 5.3509\n",
            "Ep 5 (Step 035680): Train loss 2.286, Val loss 5.508\n",
            "[Batch 0] Current Loss: 1.9782\n",
            "[Batch 1] Current Loss: 2.3105\n",
            "[Batch 2] Current Loss: 2.3516\n",
            "[Batch 3] Current Loss: 2.2110\n",
            "[Batch 4] Current Loss: 2.0801\n",
            "[Batch 5] Current Loss: 1.8530\n",
            "[Batch 6] Current Loss: 2.0301\n",
            "[Batch 7] Current Loss: 2.2070\n",
            "[Batch 8] Current Loss: 2.3650\n",
            "[Batch 9] Current Loss: 2.4493\n",
            "[Batch 0] Current Loss: 5.1608\n",
            "[Batch 1] Current Loss: 5.9012\n",
            "[Batch 2] Current Loss: 6.1163\n",
            "[Batch 3] Current Loss: 5.6456\n",
            "[Batch 4] Current Loss: 5.4646\n",
            "[Batch 5] Current Loss: 5.5900\n",
            "[Batch 6] Current Loss: 5.7228\n",
            "[Batch 7] Current Loss: 5.4721\n",
            "[Batch 8] Current Loss: 5.9193\n",
            "[Batch 9] Current Loss: 6.1662\n",
            "Ep 5 (Step 035700): Train loss 2.184, Val loss 5.716\n",
            "[Batch 0] Current Loss: 2.1180\n",
            "[Batch 1] Current Loss: 2.0063\n",
            "[Batch 2] Current Loss: 2.8209\n",
            "[Batch 3] Current Loss: 2.2774\n",
            "[Batch 4] Current Loss: 2.2931\n",
            "[Batch 5] Current Loss: 2.4244\n",
            "[Batch 6] Current Loss: 2.0373\n",
            "[Batch 7] Current Loss: 1.9654\n",
            "[Batch 8] Current Loss: 2.2845\n",
            "[Batch 9] Current Loss: 1.8571\n",
            "[Batch 0] Current Loss: 6.3959\n",
            "[Batch 1] Current Loss: 6.0629\n",
            "[Batch 2] Current Loss: 5.1886\n",
            "[Batch 3] Current Loss: 5.5629\n",
            "[Batch 4] Current Loss: 5.3096\n",
            "[Batch 5] Current Loss: 5.8417\n",
            "[Batch 6] Current Loss: 5.6694\n",
            "[Batch 7] Current Loss: 5.8503\n",
            "[Batch 8] Current Loss: 5.6924\n",
            "[Batch 9] Current Loss: 5.2121\n",
            "Ep 5 (Step 035720): Train loss 2.208, Val loss 5.679\n",
            "[Batch 0] Current Loss: 1.6160\n",
            "[Batch 1] Current Loss: 1.8916\n",
            "[Batch 2] Current Loss: 2.4584\n",
            "[Batch 3] Current Loss: 2.6775\n",
            "[Batch 4] Current Loss: 2.0249\n",
            "[Batch 5] Current Loss: 2.7512\n",
            "[Batch 6] Current Loss: 2.4356\n",
            "[Batch 7] Current Loss: 2.7115\n",
            "[Batch 8] Current Loss: 2.4240\n",
            "[Batch 9] Current Loss: 2.0687\n",
            "[Batch 0] Current Loss: 5.6960\n",
            "[Batch 1] Current Loss: 6.4117\n",
            "[Batch 2] Current Loss: 6.3517\n",
            "[Batch 3] Current Loss: 5.8934\n",
            "[Batch 4] Current Loss: 5.8761\n",
            "[Batch 5] Current Loss: 5.4438\n",
            "[Batch 6] Current Loss: 6.3561\n",
            "[Batch 7] Current Loss: 4.6093\n",
            "[Batch 8] Current Loss: 6.6040\n",
            "[Batch 9] Current Loss: 4.9212\n",
            "Ep 5 (Step 035740): Train loss 2.306, Val loss 5.816\n",
            "[Batch 0] Current Loss: 2.6899\n",
            "[Batch 1] Current Loss: 2.6009\n",
            "[Batch 2] Current Loss: 2.4420\n",
            "[Batch 3] Current Loss: 2.3747\n",
            "[Batch 4] Current Loss: 2.7988\n",
            "[Batch 5] Current Loss: 2.1815\n",
            "[Batch 6] Current Loss: 2.3224\n",
            "[Batch 7] Current Loss: 2.9592\n",
            "[Batch 8] Current Loss: 2.5956\n",
            "[Batch 9] Current Loss: 2.0117\n",
            "[Batch 0] Current Loss: 5.6368\n",
            "[Batch 1] Current Loss: 5.8507\n",
            "[Batch 2] Current Loss: 6.4423\n",
            "[Batch 3] Current Loss: 5.5822\n",
            "[Batch 4] Current Loss: 6.0889\n",
            "[Batch 5] Current Loss: 4.9933\n",
            "[Batch 6] Current Loss: 5.5063\n",
            "[Batch 7] Current Loss: 4.8431\n",
            "[Batch 8] Current Loss: 5.0700\n",
            "[Batch 9] Current Loss: 5.8322\n",
            "Ep 5 (Step 035760): Train loss 2.498, Val loss 5.585\n",
            "[Batch 0] Current Loss: 2.1268\n",
            "[Batch 1] Current Loss: 2.2842\n",
            "[Batch 2] Current Loss: 1.5016\n",
            "[Batch 3] Current Loss: 1.7759\n",
            "[Batch 4] Current Loss: 2.9637\n",
            "[Batch 5] Current Loss: 1.9662\n",
            "[Batch 6] Current Loss: 3.0610\n",
            "[Batch 7] Current Loss: 2.5701\n",
            "[Batch 8] Current Loss: 1.7106\n",
            "[Batch 9] Current Loss: 3.3008\n",
            "[Batch 0] Current Loss: 5.8303\n",
            "[Batch 1] Current Loss: 6.2494\n",
            "[Batch 2] Current Loss: 5.4126\n",
            "[Batch 3] Current Loss: 6.2862\n",
            "[Batch 4] Current Loss: 5.2309\n",
            "[Batch 5] Current Loss: 4.9423\n",
            "[Batch 6] Current Loss: 6.0434\n",
            "[Batch 7] Current Loss: 5.5043\n",
            "[Batch 8] Current Loss: 6.5087\n",
            "[Batch 9] Current Loss: 5.9034\n",
            "Ep 5 (Step 035780): Train loss 2.326, Val loss 5.791\n",
            "[Batch 0] Current Loss: 2.1534\n",
            "[Batch 1] Current Loss: 2.6571\n",
            "[Batch 2] Current Loss: 2.3727\n",
            "[Batch 3] Current Loss: 2.7207\n",
            "[Batch 4] Current Loss: 2.8815\n",
            "[Batch 5] Current Loss: 2.5440\n",
            "[Batch 6] Current Loss: 2.4451\n",
            "[Batch 7] Current Loss: 2.4938\n",
            "[Batch 8] Current Loss: 2.9142\n",
            "[Batch 9] Current Loss: 2.1450\n",
            "[Batch 0] Current Loss: 6.4875\n",
            "[Batch 1] Current Loss: 6.0006\n",
            "[Batch 2] Current Loss: 5.1525\n",
            "[Batch 3] Current Loss: 5.1574\n",
            "[Batch 4] Current Loss: 4.5794\n",
            "[Batch 5] Current Loss: 5.4299\n",
            "[Batch 6] Current Loss: 5.7406\n",
            "[Batch 7] Current Loss: 6.3978\n",
            "[Batch 8] Current Loss: 6.0332\n",
            "[Batch 9] Current Loss: 6.0542\n",
            "Ep 5 (Step 035800): Train loss 2.533, Val loss 5.703\n",
            "[Batch 0] Current Loss: 2.4651\n",
            "[Batch 1] Current Loss: 2.4143\n",
            "[Batch 2] Current Loss: 2.0712\n",
            "[Batch 3] Current Loss: 2.6618\n",
            "[Batch 4] Current Loss: 2.0537\n",
            "[Batch 5] Current Loss: 2.4762\n",
            "[Batch 6] Current Loss: 1.7999\n",
            "[Batch 7] Current Loss: 2.6859\n",
            "[Batch 8] Current Loss: 2.2663\n",
            "[Batch 9] Current Loss: 2.5542\n",
            "[Batch 0] Current Loss: 6.2701\n",
            "[Batch 1] Current Loss: 6.8101\n",
            "[Batch 2] Current Loss: 6.4300\n",
            "[Batch 3] Current Loss: 5.3123\n",
            "[Batch 4] Current Loss: 5.7826\n",
            "[Batch 5] Current Loss: 5.4889\n",
            "[Batch 6] Current Loss: 5.4035\n",
            "[Batch 7] Current Loss: 6.5881\n",
            "[Batch 8] Current Loss: 6.0445\n",
            "[Batch 9] Current Loss: 4.8872\n",
            "Ep 5 (Step 035820): Train loss 2.345, Val loss 5.902\n",
            "[Batch 0] Current Loss: 2.5181\n",
            "[Batch 1] Current Loss: 2.1500\n",
            "[Batch 2] Current Loss: 2.0681\n",
            "[Batch 3] Current Loss: 2.2376\n",
            "[Batch 4] Current Loss: 2.2850\n",
            "[Batch 5] Current Loss: 1.1922\n",
            "[Batch 6] Current Loss: 1.7460\n",
            "[Batch 7] Current Loss: 2.3793\n",
            "[Batch 8] Current Loss: 1.7592\n",
            "[Batch 9] Current Loss: 1.6270\n",
            "[Batch 0] Current Loss: 6.3237\n",
            "[Batch 1] Current Loss: 5.3614\n",
            "[Batch 2] Current Loss: 6.6278\n",
            "[Batch 3] Current Loss: 6.4814\n",
            "[Batch 4] Current Loss: 4.9968\n",
            "[Batch 5] Current Loss: 5.5518\n",
            "[Batch 6] Current Loss: 5.2395\n",
            "[Batch 7] Current Loss: 5.7889\n",
            "[Batch 8] Current Loss: 6.3739\n",
            "[Batch 9] Current Loss: 5.2419\n",
            "Ep 5 (Step 035840): Train loss 1.996, Val loss 5.799\n",
            "[Batch 0] Current Loss: 1.7500\n",
            "[Batch 1] Current Loss: 2.8600\n",
            "[Batch 2] Current Loss: 2.1621\n",
            "[Batch 3] Current Loss: 2.4336\n",
            "[Batch 4] Current Loss: 2.2780\n",
            "[Batch 5] Current Loss: 2.2436\n",
            "[Batch 6] Current Loss: 2.1502\n",
            "[Batch 7] Current Loss: 1.8632\n",
            "[Batch 8] Current Loss: 2.2666\n",
            "[Batch 9] Current Loss: 1.9079\n",
            "[Batch 0] Current Loss: 5.7634\n",
            "[Batch 1] Current Loss: 5.0782\n",
            "[Batch 2] Current Loss: 5.7025\n",
            "[Batch 3] Current Loss: 5.4449\n",
            "[Batch 4] Current Loss: 5.1838\n",
            "[Batch 5] Current Loss: 6.0316\n",
            "[Batch 6] Current Loss: 5.7873\n",
            "[Batch 7] Current Loss: 5.3310\n",
            "[Batch 8] Current Loss: 5.1028\n",
            "[Batch 9] Current Loss: 5.8824\n",
            "Ep 5 (Step 035860): Train loss 2.192, Val loss 5.531\n",
            "[Batch 0] Current Loss: 2.0408\n",
            "[Batch 1] Current Loss: 2.0599\n",
            "[Batch 2] Current Loss: 2.5282\n",
            "[Batch 3] Current Loss: 2.4280\n",
            "[Batch 4] Current Loss: 2.8926\n",
            "[Batch 5] Current Loss: 2.5220\n",
            "[Batch 6] Current Loss: 2.7617\n",
            "[Batch 7] Current Loss: 2.4396\n",
            "[Batch 8] Current Loss: 1.7358\n",
            "[Batch 9] Current Loss: 3.0225\n",
            "[Batch 0] Current Loss: 6.3744\n",
            "[Batch 1] Current Loss: 5.7670\n",
            "[Batch 2] Current Loss: 6.5442\n",
            "[Batch 3] Current Loss: 6.1403\n",
            "[Batch 4] Current Loss: 5.1773\n",
            "[Batch 5] Current Loss: 6.4895\n",
            "[Batch 6] Current Loss: 5.5854\n",
            "[Batch 7] Current Loss: 6.2023\n",
            "[Batch 8] Current Loss: 5.5249\n",
            "[Batch 9] Current Loss: 5.9283\n",
            "Ep 5 (Step 035880): Train loss 2.443, Val loss 5.973\n",
            "[Batch 0] Current Loss: 2.0448\n",
            "[Batch 1] Current Loss: 2.1407\n",
            "[Batch 2] Current Loss: 2.3093\n",
            "[Batch 3] Current Loss: 2.0060\n",
            "[Batch 4] Current Loss: 1.8100\n",
            "[Batch 5] Current Loss: 2.2493\n",
            "[Batch 6] Current Loss: 1.9862\n",
            "[Batch 7] Current Loss: 2.3289\n",
            "[Batch 8] Current Loss: 2.6415\n",
            "[Batch 9] Current Loss: 2.3112\n",
            "[Batch 0] Current Loss: 6.1283\n",
            "[Batch 1] Current Loss: 6.1315\n",
            "[Batch 2] Current Loss: 5.7802\n",
            "[Batch 3] Current Loss: 6.1341\n",
            "[Batch 4] Current Loss: 6.0905\n",
            "[Batch 5] Current Loss: 5.8153\n",
            "[Batch 6] Current Loss: 5.9357\n",
            "[Batch 7] Current Loss: 5.5508\n",
            "[Batch 8] Current Loss: 6.2141\n",
            "[Batch 9] Current Loss: 6.9815\n",
            "Ep 5 (Step 035900): Train loss 2.183, Val loss 6.076\n",
            "[Batch 0] Current Loss: 2.0906\n",
            "[Batch 1] Current Loss: 1.9580\n",
            "[Batch 2] Current Loss: 1.8433\n",
            "[Batch 3] Current Loss: 2.5442\n",
            "[Batch 4] Current Loss: 2.0619\n",
            "[Batch 5] Current Loss: 2.2449\n",
            "[Batch 6] Current Loss: 2.1245\n",
            "[Batch 7] Current Loss: 2.5399\n",
            "[Batch 8] Current Loss: 1.5744\n",
            "[Batch 9] Current Loss: 1.7696\n",
            "[Batch 0] Current Loss: 4.9887\n",
            "[Batch 1] Current Loss: 5.0459\n",
            "[Batch 2] Current Loss: 5.7366\n",
            "[Batch 3] Current Loss: 5.9882\n",
            "[Batch 4] Current Loss: 5.3018\n",
            "[Batch 5] Current Loss: 5.1505\n",
            "[Batch 6] Current Loss: 6.0200\n",
            "[Batch 7] Current Loss: 7.1525\n",
            "[Batch 8] Current Loss: 5.7184\n",
            "[Batch 9] Current Loss: 5.6364\n",
            "Ep 5 (Step 035920): Train loss 2.075, Val loss 5.674\n",
            "[Batch 0] Current Loss: 2.7597\n",
            "[Batch 1] Current Loss: 1.5209\n",
            "[Batch 2] Current Loss: 2.4545\n",
            "[Batch 3] Current Loss: 1.8784\n",
            "[Batch 4] Current Loss: 2.2643\n",
            "[Batch 5] Current Loss: 1.8670\n",
            "[Batch 6] Current Loss: 2.1859\n",
            "[Batch 7] Current Loss: 2.6616\n",
            "[Batch 8] Current Loss: 1.8877\n",
            "[Batch 9] Current Loss: 2.6189\n",
            "[Batch 0] Current Loss: 5.7045\n",
            "[Batch 1] Current Loss: 5.4232\n",
            "[Batch 2] Current Loss: 5.3905\n",
            "[Batch 3] Current Loss: 5.4847\n",
            "[Batch 4] Current Loss: 4.9358\n",
            "[Batch 5] Current Loss: 5.0624\n",
            "[Batch 6] Current Loss: 4.8918\n",
            "[Batch 7] Current Loss: 5.6874\n",
            "[Batch 8] Current Loss: 5.1660\n",
            "[Batch 9] Current Loss: 6.0737\n",
            "Ep 5 (Step 035940): Train loss 2.210, Val loss 5.382\n",
            "[Batch 0] Current Loss: 2.3266\n",
            "[Batch 1] Current Loss: 2.3669\n",
            "[Batch 2] Current Loss: 3.2335\n",
            "[Batch 3] Current Loss: 1.9158\n",
            "[Batch 4] Current Loss: 2.3170\n",
            "[Batch 5] Current Loss: 1.7397\n",
            "[Batch 6] Current Loss: 1.5324\n",
            "[Batch 7] Current Loss: 2.4528\n",
            "[Batch 8] Current Loss: 1.7495\n",
            "[Batch 9] Current Loss: 2.0874\n",
            "[Batch 0] Current Loss: 6.4365\n",
            "[Batch 1] Current Loss: 6.1147\n",
            "[Batch 2] Current Loss: 6.6239\n",
            "[Batch 3] Current Loss: 5.5903\n",
            "[Batch 4] Current Loss: 4.8367\n",
            "[Batch 5] Current Loss: 6.0842\n",
            "[Batch 6] Current Loss: 5.9857\n",
            "[Batch 7] Current Loss: 4.9203\n",
            "[Batch 8] Current Loss: 6.3885\n",
            "[Batch 9] Current Loss: 5.8521\n",
            "Ep 5 (Step 035960): Train loss 2.172, Val loss 5.883\n",
            "[Batch 0] Current Loss: 2.4619\n",
            "[Batch 1] Current Loss: 2.4348\n",
            "[Batch 2] Current Loss: 2.6619\n",
            "[Batch 3] Current Loss: 2.4041\n",
            "[Batch 4] Current Loss: 2.2446\n",
            "[Batch 5] Current Loss: 2.3782\n",
            "[Batch 6] Current Loss: 1.6468\n",
            "[Batch 7] Current Loss: 2.2006\n",
            "[Batch 8] Current Loss: 2.1517\n",
            "[Batch 9] Current Loss: 2.2808\n",
            "[Batch 0] Current Loss: 4.9551\n",
            "[Batch 1] Current Loss: 7.3062\n",
            "[Batch 2] Current Loss: 5.2289\n",
            "[Batch 3] Current Loss: 4.8365\n",
            "[Batch 4] Current Loss: 5.2801\n",
            "[Batch 5] Current Loss: 5.6142\n",
            "[Batch 6] Current Loss: 6.0902\n",
            "[Batch 7] Current Loss: 5.4076\n",
            "[Batch 8] Current Loss: 6.0327\n",
            "[Batch 9] Current Loss: 6.3565\n",
            "Ep 5 (Step 035980): Train loss 2.287, Val loss 5.711\n",
            "[Batch 0] Current Loss: 2.6795\n",
            "[Batch 1] Current Loss: 2.3663\n",
            "[Batch 2] Current Loss: 1.9966\n",
            "[Batch 3] Current Loss: 1.3468\n",
            "[Batch 4] Current Loss: 2.5192\n",
            "[Batch 5] Current Loss: 2.2426\n",
            "[Batch 6] Current Loss: 2.3322\n",
            "[Batch 7] Current Loss: 2.4146\n",
            "[Batch 8] Current Loss: 2.7626\n",
            "[Batch 9] Current Loss: 3.2233\n",
            "[Batch 0] Current Loss: 5.8912\n",
            "[Batch 1] Current Loss: 5.1651\n",
            "[Batch 2] Current Loss: 5.3307\n",
            "[Batch 3] Current Loss: 6.2835\n",
            "[Batch 4] Current Loss: 6.2134\n",
            "[Batch 5] Current Loss: 5.2124\n",
            "[Batch 6] Current Loss: 6.0745\n",
            "[Batch 7] Current Loss: 5.3294\n",
            "[Batch 8] Current Loss: 5.2564\n",
            "[Batch 9] Current Loss: 5.2448\n",
            "Ep 5 (Step 036000): Train loss 2.388, Val loss 5.600\n",
            "[Batch 0] Current Loss: 1.6748\n",
            "[Batch 1] Current Loss: 2.6297\n",
            "[Batch 2] Current Loss: 2.6912\n",
            "[Batch 3] Current Loss: 2.1146\n",
            "[Batch 4] Current Loss: 2.2251\n",
            "[Batch 5] Current Loss: 2.4169\n",
            "[Batch 6] Current Loss: 1.7088\n",
            "[Batch 7] Current Loss: 2.2842\n",
            "[Batch 8] Current Loss: 2.3293\n",
            "[Batch 9] Current Loss: 2.5088\n",
            "[Batch 0] Current Loss: 4.8382\n",
            "[Batch 1] Current Loss: 4.3193\n",
            "[Batch 2] Current Loss: 5.4493\n",
            "[Batch 3] Current Loss: 5.9658\n",
            "[Batch 4] Current Loss: 5.6576\n",
            "[Batch 5] Current Loss: 6.3716\n",
            "[Batch 6] Current Loss: 6.4735\n",
            "[Batch 7] Current Loss: 6.0495\n",
            "[Batch 8] Current Loss: 5.7837\n",
            "[Batch 9] Current Loss: 4.9872\n",
            "Ep 5 (Step 036020): Train loss 2.258, Val loss 5.590\n",
            "[Batch 0] Current Loss: 2.7137\n",
            "[Batch 1] Current Loss: 2.1559\n",
            "[Batch 2] Current Loss: 2.7310\n",
            "[Batch 3] Current Loss: 2.6111\n",
            "[Batch 4] Current Loss: 3.1348\n",
            "[Batch 5] Current Loss: 1.6412\n",
            "[Batch 6] Current Loss: 1.8400\n",
            "[Batch 7] Current Loss: 2.1845\n",
            "[Batch 8] Current Loss: 2.7058\n",
            "[Batch 9] Current Loss: 2.5302\n",
            "[Batch 0] Current Loss: 5.8800\n",
            "[Batch 1] Current Loss: 5.9775\n",
            "[Batch 2] Current Loss: 5.5593\n",
            "[Batch 3] Current Loss: 6.0269\n",
            "[Batch 4] Current Loss: 5.3660\n",
            "[Batch 5] Current Loss: 6.5140\n",
            "[Batch 6] Current Loss: 5.5538\n",
            "[Batch 7] Current Loss: 5.8291\n",
            "[Batch 8] Current Loss: 4.4183\n",
            "[Batch 9] Current Loss: 5.3157\n",
            "Ep 5 (Step 036040): Train loss 2.425, Val loss 5.644\n",
            "[Batch 0] Current Loss: 1.5749\n",
            "[Batch 1] Current Loss: 2.0922\n",
            "[Batch 2] Current Loss: 2.5792\n",
            "[Batch 3] Current Loss: 2.1609\n",
            "[Batch 4] Current Loss: 2.4716\n",
            "[Batch 5] Current Loss: 2.5470\n",
            "[Batch 6] Current Loss: 1.9850\n",
            "[Batch 7] Current Loss: 2.7054\n",
            "[Batch 8] Current Loss: 2.2442\n",
            "[Batch 9] Current Loss: 2.2960\n",
            "[Batch 0] Current Loss: 5.3666\n",
            "[Batch 1] Current Loss: 6.0057\n",
            "[Batch 2] Current Loss: 5.2856\n",
            "[Batch 3] Current Loss: 6.1094\n",
            "[Batch 4] Current Loss: 5.4387\n",
            "[Batch 5] Current Loss: 6.0447\n",
            "[Batch 6] Current Loss: 5.1510\n",
            "[Batch 7] Current Loss: 5.2929\n",
            "[Batch 8] Current Loss: 5.8564\n",
            "[Batch 9] Current Loss: 4.2479\n",
            "Ep 5 (Step 036060): Train loss 2.266, Val loss 5.480\n",
            "[Batch 0] Current Loss: 1.7729\n",
            "[Batch 1] Current Loss: 2.0812\n",
            "[Batch 2] Current Loss: 2.1201\n",
            "[Batch 3] Current Loss: 1.7680\n",
            "[Batch 4] Current Loss: 2.7306\n",
            "[Batch 5] Current Loss: 2.0355\n",
            "[Batch 6] Current Loss: 2.1386\n",
            "[Batch 7] Current Loss: 1.9570\n",
            "[Batch 8] Current Loss: 1.6621\n",
            "[Batch 9] Current Loss: 2.1355\n",
            "[Batch 0] Current Loss: 5.3326\n",
            "[Batch 1] Current Loss: 5.6389\n",
            "[Batch 2] Current Loss: 5.5993\n",
            "[Batch 3] Current Loss: 5.5444\n",
            "[Batch 4] Current Loss: 5.7804\n",
            "[Batch 5] Current Loss: 5.8664\n",
            "[Batch 6] Current Loss: 5.5357\n",
            "[Batch 7] Current Loss: 6.0037\n",
            "[Batch 8] Current Loss: 5.5693\n",
            "[Batch 9] Current Loss: 5.5214\n",
            "Ep 5 (Step 036080): Train loss 2.040, Val loss 5.639\n",
            "[Batch 0] Current Loss: 2.0353\n",
            "[Batch 1] Current Loss: 1.8570\n",
            "[Batch 2] Current Loss: 2.1817\n",
            "[Batch 3] Current Loss: 1.8250\n",
            "[Batch 4] Current Loss: 2.8560\n",
            "[Batch 5] Current Loss: 1.9883\n",
            "[Batch 6] Current Loss: 2.8619\n",
            "[Batch 7] Current Loss: 2.2516\n",
            "[Batch 8] Current Loss: 2.1316\n",
            "[Batch 9] Current Loss: 1.8003\n",
            "[Batch 0] Current Loss: 5.1659\n",
            "[Batch 1] Current Loss: 5.7021\n",
            "[Batch 2] Current Loss: 4.8703\n",
            "[Batch 3] Current Loss: 6.1517\n",
            "[Batch 4] Current Loss: 5.8237\n",
            "[Batch 5] Current Loss: 5.5936\n",
            "[Batch 6] Current Loss: 6.0591\n",
            "[Batch 7] Current Loss: 5.8138\n",
            "[Batch 8] Current Loss: 6.0870\n",
            "[Batch 9] Current Loss: 5.3927\n",
            "Ep 5 (Step 036100): Train loss 2.179, Val loss 5.666\n",
            "[Batch 0] Current Loss: 1.8414\n",
            "[Batch 1] Current Loss: 1.8496\n",
            "[Batch 2] Current Loss: 2.2416\n",
            "[Batch 3] Current Loss: 2.6096\n",
            "[Batch 4] Current Loss: 1.9139\n",
            "[Batch 5] Current Loss: 2.4113\n",
            "[Batch 6] Current Loss: 2.3478\n",
            "[Batch 7] Current Loss: 2.4850\n",
            "[Batch 8] Current Loss: 1.9765\n",
            "[Batch 9] Current Loss: 2.0319\n",
            "[Batch 0] Current Loss: 6.2344\n",
            "[Batch 1] Current Loss: 4.6565\n",
            "[Batch 2] Current Loss: 5.1586\n",
            "[Batch 3] Current Loss: 5.0329\n",
            "[Batch 4] Current Loss: 5.3228\n",
            "[Batch 5] Current Loss: 6.4401\n",
            "[Batch 6] Current Loss: 5.1264\n",
            "[Batch 7] Current Loss: 4.9661\n",
            "[Batch 8] Current Loss: 5.4987\n",
            "[Batch 9] Current Loss: 4.9245\n",
            "Ep 5 (Step 036120): Train loss 2.171, Val loss 5.336\n",
            "[Batch 0] Current Loss: 2.5107\n",
            "[Batch 1] Current Loss: 2.7178\n",
            "[Batch 2] Current Loss: 2.6416\n",
            "[Batch 3] Current Loss: 2.2756\n",
            "[Batch 4] Current Loss: 2.4842\n",
            "[Batch 5] Current Loss: 1.8418\n",
            "[Batch 6] Current Loss: 2.2061\n",
            "[Batch 7] Current Loss: 3.0069\n",
            "[Batch 8] Current Loss: 3.0278\n",
            "[Batch 9] Current Loss: 2.7287\n",
            "[Batch 0] Current Loss: 5.4413\n",
            "[Batch 1] Current Loss: 5.7667\n",
            "[Batch 2] Current Loss: 5.3127\n",
            "[Batch 3] Current Loss: 4.2592\n",
            "[Batch 4] Current Loss: 5.2557\n",
            "[Batch 5] Current Loss: 6.2148\n",
            "[Batch 6] Current Loss: 5.7520\n",
            "[Batch 7] Current Loss: 5.4491\n",
            "[Batch 8] Current Loss: 5.7306\n",
            "[Batch 9] Current Loss: 5.9365\n",
            "Ep 5 (Step 036140): Train loss 2.544, Val loss 5.512\n",
            "[Batch 0] Current Loss: 2.6941\n",
            "[Batch 1] Current Loss: 2.5230\n",
            "[Batch 2] Current Loss: 2.5318\n",
            "[Batch 3] Current Loss: 2.2403\n",
            "[Batch 4] Current Loss: 2.8543\n",
            "[Batch 5] Current Loss: 2.0124\n",
            "[Batch 6] Current Loss: 2.6590\n",
            "[Batch 7] Current Loss: 2.2211\n",
            "[Batch 8] Current Loss: 2.0393\n",
            "[Batch 9] Current Loss: 2.7168\n",
            "[Batch 0] Current Loss: 6.0139\n",
            "[Batch 1] Current Loss: 4.4967\n",
            "[Batch 2] Current Loss: 5.5917\n",
            "[Batch 3] Current Loss: 5.8937\n",
            "[Batch 4] Current Loss: 5.1302\n",
            "[Batch 5] Current Loss: 5.5848\n",
            "[Batch 6] Current Loss: 5.4803\n",
            "[Batch 7] Current Loss: 6.3381\n",
            "[Batch 8] Current Loss: 5.9016\n",
            "[Batch 9] Current Loss: 5.6295\n",
            "Ep 5 (Step 036160): Train loss 2.449, Val loss 5.606\n",
            "[Batch 0] Current Loss: 2.2634\n",
            "[Batch 1] Current Loss: 2.1025\n",
            "[Batch 2] Current Loss: 2.8414\n",
            "[Batch 3] Current Loss: 2.4699\n",
            "[Batch 4] Current Loss: 1.7207\n",
            "[Batch 5] Current Loss: 2.1605\n",
            "[Batch 6] Current Loss: 1.9132\n",
            "[Batch 7] Current Loss: 2.2450\n",
            "[Batch 8] Current Loss: 2.1353\n",
            "[Batch 9] Current Loss: 2.1164\n",
            "[Batch 0] Current Loss: 5.7868\n",
            "[Batch 1] Current Loss: 4.3021\n",
            "[Batch 2] Current Loss: 4.8165\n",
            "[Batch 3] Current Loss: 6.2140\n",
            "[Batch 4] Current Loss: 5.8024\n",
            "[Batch 5] Current Loss: 5.9313\n",
            "[Batch 6] Current Loss: 5.0510\n",
            "[Batch 7] Current Loss: 5.3677\n",
            "[Batch 8] Current Loss: 6.8765\n",
            "[Batch 9] Current Loss: 4.6209\n",
            "Ep 5 (Step 036180): Train loss 2.197, Val loss 5.477\n",
            "[Batch 0] Current Loss: 2.3916\n",
            "[Batch 1] Current Loss: 1.9978\n",
            "[Batch 2] Current Loss: 2.3353\n",
            "[Batch 3] Current Loss: 2.5326\n",
            "[Batch 4] Current Loss: 2.1157\n",
            "[Batch 5] Current Loss: 1.7021\n",
            "[Batch 6] Current Loss: 2.1260\n",
            "[Batch 7] Current Loss: 2.4344\n",
            "[Batch 8] Current Loss: 2.4249\n",
            "[Batch 9] Current Loss: 2.7071\n",
            "[Batch 0] Current Loss: 5.2709\n",
            "[Batch 1] Current Loss: 5.5559\n",
            "[Batch 2] Current Loss: 6.4691\n",
            "[Batch 3] Current Loss: 5.9428\n",
            "[Batch 4] Current Loss: 5.2290\n",
            "[Batch 5] Current Loss: 5.7275\n",
            "[Batch 6] Current Loss: 6.3822\n",
            "[Batch 7] Current Loss: 5.1081\n",
            "[Batch 8] Current Loss: 5.8691\n",
            "[Batch 9] Current Loss: 5.6411\n",
            "Ep 5 (Step 036200): Train loss 2.277, Val loss 5.720\n",
            "[Batch 0] Current Loss: 1.8897\n",
            "[Batch 1] Current Loss: 1.8808\n",
            "[Batch 2] Current Loss: 2.4383\n",
            "[Batch 3] Current Loss: 1.8630\n",
            "[Batch 4] Current Loss: 2.8530\n",
            "[Batch 5] Current Loss: 2.4078\n",
            "[Batch 6] Current Loss: 1.9914\n",
            "[Batch 7] Current Loss: 2.2660\n",
            "[Batch 8] Current Loss: 2.6467\n",
            "[Batch 9] Current Loss: 2.7382\n",
            "[Batch 0] Current Loss: 4.7595\n",
            "[Batch 1] Current Loss: 6.2010\n",
            "[Batch 2] Current Loss: 5.0346\n",
            "[Batch 3] Current Loss: 6.0082\n",
            "[Batch 4] Current Loss: 6.0584\n",
            "[Batch 5] Current Loss: 6.4285\n",
            "[Batch 6] Current Loss: 5.4175\n",
            "[Batch 7] Current Loss: 5.9469\n",
            "[Batch 8] Current Loss: 5.9449\n",
            "[Batch 9] Current Loss: 6.1991\n",
            "Ep 5 (Step 036220): Train loss 2.297, Val loss 5.800\n",
            "[Batch 0] Current Loss: 2.2794\n",
            "[Batch 1] Current Loss: 2.1886\n",
            "[Batch 2] Current Loss: 2.2203\n",
            "[Batch 3] Current Loss: 2.5143\n",
            "[Batch 4] Current Loss: 2.6260\n",
            "[Batch 5] Current Loss: 2.2394\n",
            "[Batch 6] Current Loss: 1.6648\n",
            "[Batch 7] Current Loss: 2.3512\n",
            "[Batch 8] Current Loss: 1.7857\n",
            "[Batch 9] Current Loss: 1.5130\n",
            "[Batch 0] Current Loss: 6.3145\n",
            "[Batch 1] Current Loss: 6.0040\n",
            "[Batch 2] Current Loss: 5.5995\n",
            "[Batch 3] Current Loss: 5.0232\n",
            "[Batch 4] Current Loss: 5.6655\n",
            "[Batch 5] Current Loss: 5.6929\n",
            "[Batch 6] Current Loss: 5.3246\n",
            "[Batch 7] Current Loss: 5.6530\n",
            "[Batch 8] Current Loss: 5.9605\n",
            "[Batch 9] Current Loss: 5.8295\n",
            "Ep 5 (Step 036240): Train loss 2.138, Val loss 5.707\n",
            "[Batch 0] Current Loss: 2.5258\n",
            "[Batch 1] Current Loss: 2.1283\n",
            "[Batch 2] Current Loss: 2.1576\n",
            "[Batch 3] Current Loss: 2.7524\n",
            "[Batch 4] Current Loss: 2.1083\n",
            "[Batch 5] Current Loss: 1.9507\n",
            "[Batch 6] Current Loss: 1.9604\n",
            "[Batch 7] Current Loss: 2.9406\n",
            "[Batch 8] Current Loss: 2.9362\n",
            "[Batch 9] Current Loss: 2.4998\n",
            "[Batch 0] Current Loss: 5.6789\n",
            "[Batch 1] Current Loss: 5.6451\n",
            "[Batch 2] Current Loss: 6.3427\n",
            "[Batch 3] Current Loss: 4.6191\n",
            "[Batch 4] Current Loss: 5.7813\n",
            "[Batch 5] Current Loss: 6.2147\n",
            "[Batch 6] Current Loss: 5.9293\n",
            "[Batch 7] Current Loss: 5.0799\n",
            "[Batch 8] Current Loss: 5.4394\n",
            "[Batch 9] Current Loss: 5.3252\n",
            "Ep 5 (Step 036260): Train loss 2.396, Val loss 5.606\n",
            "[Batch 0] Current Loss: 2.4221\n",
            "[Batch 1] Current Loss: 2.6860\n",
            "[Batch 2] Current Loss: 1.7362\n",
            "[Batch 3] Current Loss: 2.1066\n",
            "[Batch 4] Current Loss: 2.0243\n",
            "[Batch 5] Current Loss: 2.3362\n",
            "[Batch 6] Current Loss: 1.6392\n",
            "[Batch 7] Current Loss: 2.1814\n",
            "[Batch 8] Current Loss: 2.2843\n",
            "[Batch 9] Current Loss: 2.3899\n",
            "[Batch 0] Current Loss: 6.1726\n",
            "[Batch 1] Current Loss: 5.3709\n",
            "[Batch 2] Current Loss: 6.0532\n",
            "[Batch 3] Current Loss: 5.2559\n",
            "[Batch 4] Current Loss: 6.4266\n",
            "[Batch 5] Current Loss: 5.7566\n",
            "[Batch 6] Current Loss: 5.4866\n",
            "[Batch 7] Current Loss: 6.4828\n",
            "[Batch 8] Current Loss: 5.9127\n",
            "[Batch 9] Current Loss: 5.8493\n",
            "Ep 5 (Step 036280): Train loss 2.181, Val loss 5.877\n",
            "[Batch 0] Current Loss: 2.2727\n",
            "[Batch 1] Current Loss: 2.4782\n",
            "[Batch 2] Current Loss: 2.0442\n",
            "[Batch 3] Current Loss: 2.6561\n",
            "[Batch 4] Current Loss: 1.8834\n",
            "[Batch 5] Current Loss: 1.9981\n",
            "[Batch 6] Current Loss: 2.5194\n",
            "[Batch 7] Current Loss: 1.7858\n",
            "[Batch 8] Current Loss: 2.1068\n",
            "[Batch 9] Current Loss: 1.7140\n",
            "[Batch 0] Current Loss: 5.2142\n",
            "[Batch 1] Current Loss: 5.0736\n",
            "[Batch 2] Current Loss: 5.3359\n",
            "[Batch 3] Current Loss: 6.6380\n",
            "[Batch 4] Current Loss: 5.5954\n",
            "[Batch 5] Current Loss: 6.0389\n",
            "[Batch 6] Current Loss: 5.8682\n",
            "[Batch 7] Current Loss: 5.2265\n",
            "[Batch 8] Current Loss: 5.3584\n",
            "[Batch 9] Current Loss: 6.2175\n",
            "Ep 5 (Step 036300): Train loss 2.146, Val loss 5.657\n",
            "[Batch 0] Current Loss: 2.5543\n",
            "[Batch 1] Current Loss: 2.1183\n",
            "[Batch 2] Current Loss: 2.0461\n",
            "[Batch 3] Current Loss: 2.2848\n",
            "[Batch 4] Current Loss: 2.2595\n",
            "[Batch 5] Current Loss: 2.2815\n",
            "[Batch 6] Current Loss: 1.6741\n",
            "[Batch 7] Current Loss: 2.2366\n",
            "[Batch 8] Current Loss: 2.1054\n",
            "[Batch 9] Current Loss: 2.2618\n",
            "[Batch 0] Current Loss: 5.9574\n",
            "[Batch 1] Current Loss: 6.1745\n",
            "[Batch 2] Current Loss: 5.6689\n",
            "[Batch 3] Current Loss: 6.1433\n",
            "[Batch 4] Current Loss: 5.9580\n",
            "[Batch 5] Current Loss: 5.2442\n",
            "[Batch 6] Current Loss: 5.5680\n",
            "[Batch 7] Current Loss: 5.5381\n",
            "[Batch 8] Current Loss: 5.5447\n",
            "[Batch 9] Current Loss: 6.0592\n",
            "Ep 5 (Step 036320): Train loss 2.182, Val loss 5.786\n",
            "[Batch 0] Current Loss: 2.0913\n",
            "[Batch 1] Current Loss: 2.6859\n",
            "[Batch 2] Current Loss: 2.0621\n",
            "[Batch 3] Current Loss: 2.0906\n",
            "[Batch 4] Current Loss: 2.0094\n",
            "[Batch 5] Current Loss: 2.0614\n",
            "[Batch 6] Current Loss: 1.9653\n",
            "[Batch 7] Current Loss: 2.5835\n",
            "[Batch 8] Current Loss: 2.1596\n",
            "[Batch 9] Current Loss: 2.4188\n",
            "[Batch 0] Current Loss: 6.2748\n",
            "[Batch 1] Current Loss: 5.9360\n",
            "[Batch 2] Current Loss: 6.7573\n",
            "[Batch 3] Current Loss: 4.8530\n",
            "[Batch 4] Current Loss: 5.2008\n",
            "[Batch 5] Current Loss: 5.5228\n",
            "[Batch 6] Current Loss: 6.3028\n",
            "[Batch 7] Current Loss: 5.7657\n",
            "[Batch 8] Current Loss: 5.8890\n",
            "[Batch 9] Current Loss: 5.8942\n",
            "Ep 5 (Step 036340): Train loss 2.213, Val loss 5.840\n",
            "[Batch 0] Current Loss: 2.3037\n",
            "[Batch 1] Current Loss: 1.9064\n",
            "[Batch 2] Current Loss: 1.9594\n",
            "[Batch 3] Current Loss: 2.1276\n",
            "[Batch 4] Current Loss: 2.3993\n",
            "[Batch 5] Current Loss: 2.1350\n",
            "[Batch 6] Current Loss: 2.7713\n",
            "[Batch 7] Current Loss: 2.0140\n",
            "[Batch 8] Current Loss: 2.0298\n",
            "[Batch 9] Current Loss: 2.0330\n",
            "[Batch 0] Current Loss: 5.8842\n",
            "[Batch 1] Current Loss: 5.3125\n",
            "[Batch 2] Current Loss: 5.8601\n",
            "[Batch 3] Current Loss: 6.3430\n",
            "[Batch 4] Current Loss: 5.6334\n",
            "[Batch 5] Current Loss: 5.0185\n",
            "[Batch 6] Current Loss: 5.2914\n",
            "[Batch 7] Current Loss: 5.1174\n",
            "[Batch 8] Current Loss: 5.6809\n",
            "[Batch 9] Current Loss: 5.7521\n",
            "Ep 5 (Step 036360): Train loss 2.168, Val loss 5.589\n",
            "[Batch 0] Current Loss: 1.9160\n",
            "[Batch 1] Current Loss: 2.2196\n",
            "[Batch 2] Current Loss: 2.2809\n",
            "[Batch 3] Current Loss: 2.6235\n",
            "[Batch 4] Current Loss: 1.5824\n",
            "[Batch 5] Current Loss: 2.1199\n",
            "[Batch 6] Current Loss: 2.3836\n",
            "[Batch 7] Current Loss: 2.3068\n",
            "[Batch 8] Current Loss: 2.2589\n",
            "[Batch 9] Current Loss: 2.4419\n",
            "[Batch 0] Current Loss: 6.1307\n",
            "[Batch 1] Current Loss: 5.5082\n",
            "[Batch 2] Current Loss: 6.3394\n",
            "[Batch 3] Current Loss: 5.8591\n",
            "[Batch 4] Current Loss: 5.3308\n",
            "[Batch 5] Current Loss: 5.8460\n",
            "[Batch 6] Current Loss: 5.6508\n",
            "[Batch 7] Current Loss: 5.7788\n",
            "[Batch 8] Current Loss: 5.4190\n",
            "[Batch 9] Current Loss: 6.0745\n",
            "Ep 5 (Step 036380): Train loss 2.213, Val loss 5.794\n",
            "[Batch 0] Current Loss: 2.9137\n",
            "[Batch 1] Current Loss: 2.9070\n",
            "[Batch 2] Current Loss: 1.9621\n",
            "[Batch 3] Current Loss: 1.9806\n",
            "[Batch 4] Current Loss: 2.0468\n",
            "[Batch 5] Current Loss: 1.9064\n",
            "[Batch 6] Current Loss: 2.2338\n",
            "[Batch 7] Current Loss: 2.1196\n",
            "[Batch 8] Current Loss: 2.0092\n",
            "[Batch 9] Current Loss: 2.2677\n",
            "[Batch 0] Current Loss: 5.2432\n",
            "[Batch 1] Current Loss: 5.5644\n",
            "[Batch 2] Current Loss: 5.9562\n",
            "[Batch 3] Current Loss: 5.3929\n",
            "[Batch 4] Current Loss: 5.2169\n",
            "[Batch 5] Current Loss: 4.6045\n",
            "[Batch 6] Current Loss: 4.9138\n",
            "[Batch 7] Current Loss: 5.6029\n",
            "[Batch 8] Current Loss: 6.0093\n",
            "[Batch 9] Current Loss: 6.2925\n",
            "Ep 5 (Step 036400): Train loss 2.235, Val loss 5.480\n",
            "[Batch 0] Current Loss: 2.1285\n",
            "[Batch 1] Current Loss: 1.6587\n",
            "[Batch 2] Current Loss: 2.1510\n",
            "[Batch 3] Current Loss: 1.6718\n",
            "[Batch 4] Current Loss: 2.0161\n",
            "[Batch 5] Current Loss: 2.2983\n",
            "[Batch 6] Current Loss: 2.4763\n",
            "[Batch 7] Current Loss: 2.4930\n",
            "[Batch 8] Current Loss: 2.8971\n",
            "[Batch 9] Current Loss: 2.6460\n",
            "[Batch 0] Current Loss: 5.1065\n",
            "[Batch 1] Current Loss: 6.2209\n",
            "[Batch 2] Current Loss: 6.0660\n",
            "[Batch 3] Current Loss: 5.2267\n",
            "[Batch 4] Current Loss: 6.1022\n",
            "[Batch 5] Current Loss: 5.4643\n",
            "[Batch 6] Current Loss: 5.7515\n",
            "[Batch 7] Current Loss: 6.3042\n",
            "[Batch 8] Current Loss: 5.8925\n",
            "[Batch 9] Current Loss: 6.2855\n",
            "Ep 5 (Step 036420): Train loss 2.244, Val loss 5.842\n",
            "[Batch 0] Current Loss: 2.3662\n",
            "[Batch 1] Current Loss: 2.2267\n",
            "[Batch 2] Current Loss: 2.4660\n",
            "[Batch 3] Current Loss: 2.3557\n",
            "[Batch 4] Current Loss: 3.0297\n",
            "[Batch 5] Current Loss: 2.1959\n",
            "[Batch 6] Current Loss: 1.7601\n",
            "[Batch 7] Current Loss: 2.0560\n",
            "[Batch 8] Current Loss: 2.1578\n",
            "[Batch 9] Current Loss: 1.5094\n",
            "[Batch 0] Current Loss: 5.9508\n",
            "[Batch 1] Current Loss: 6.3709\n",
            "[Batch 2] Current Loss: 5.7217\n",
            "[Batch 3] Current Loss: 5.7387\n",
            "[Batch 4] Current Loss: 5.8385\n",
            "[Batch 5] Current Loss: 5.3140\n",
            "[Batch 6] Current Loss: 5.5064\n",
            "[Batch 7] Current Loss: 5.3501\n",
            "[Batch 8] Current Loss: 5.4185\n",
            "[Batch 9] Current Loss: 4.9934\n",
            "Ep 5 (Step 036440): Train loss 2.212, Val loss 5.620\n",
            "[Batch 0] Current Loss: 1.9863\n",
            "[Batch 1] Current Loss: 2.1533\n",
            "[Batch 2] Current Loss: 2.5011\n",
            "[Batch 3] Current Loss: 1.8397\n",
            "[Batch 4] Current Loss: 3.0222\n",
            "[Batch 5] Current Loss: 2.1079\n",
            "[Batch 6] Current Loss: 1.9676\n",
            "[Batch 7] Current Loss: 2.1966\n",
            "[Batch 8] Current Loss: 1.8714\n",
            "[Batch 9] Current Loss: 1.8081\n",
            "[Batch 0] Current Loss: 5.6123\n",
            "[Batch 1] Current Loss: 5.2324\n",
            "[Batch 2] Current Loss: 5.2725\n",
            "[Batch 3] Current Loss: 5.9881\n",
            "[Batch 4] Current Loss: 4.7357\n",
            "[Batch 5] Current Loss: 6.1146\n",
            "[Batch 6] Current Loss: 5.4166\n",
            "[Batch 7] Current Loss: 5.3173\n",
            "[Batch 8] Current Loss: 5.6355\n",
            "[Batch 9] Current Loss: 6.0195\n",
            "Ep 5 (Step 036460): Train loss 2.145, Val loss 5.534\n",
            "[Batch 0] Current Loss: 2.4267\n",
            "[Batch 1] Current Loss: 2.8013\n",
            "[Batch 2] Current Loss: 2.0213\n",
            "[Batch 3] Current Loss: 2.4343\n",
            "[Batch 4] Current Loss: 2.0680\n",
            "[Batch 5] Current Loss: 2.4474\n",
            "[Batch 6] Current Loss: 2.7706\n",
            "[Batch 7] Current Loss: 2.0953\n",
            "[Batch 8] Current Loss: 2.1132\n",
            "[Batch 9] Current Loss: 2.3478\n",
            "[Batch 0] Current Loss: 5.3074\n",
            "[Batch 1] Current Loss: 5.1077\n",
            "[Batch 2] Current Loss: 5.4814\n",
            "[Batch 3] Current Loss: 5.3642\n",
            "[Batch 4] Current Loss: 5.3915\n",
            "[Batch 5] Current Loss: 5.9954\n",
            "[Batch 6] Current Loss: 6.2947\n",
            "[Batch 7] Current Loss: 6.2465\n",
            "[Batch 8] Current Loss: 6.0583\n",
            "[Batch 9] Current Loss: 5.2024\n",
            "Ep 5 (Step 036480): Train loss 2.353, Val loss 5.645\n",
            "[Batch 0] Current Loss: 2.1965\n",
            "[Batch 1] Current Loss: 2.5095\n",
            "[Batch 2] Current Loss: 1.9666\n",
            "[Batch 3] Current Loss: 2.3368\n",
            "[Batch 4] Current Loss: 2.6026\n",
            "[Batch 5] Current Loss: 2.8256\n",
            "[Batch 6] Current Loss: 2.3245\n",
            "[Batch 7] Current Loss: 2.3328\n",
            "[Batch 8] Current Loss: 2.5051\n",
            "[Batch 9] Current Loss: 1.9204\n",
            "[Batch 0] Current Loss: 5.8490\n",
            "[Batch 1] Current Loss: 5.4258\n",
            "[Batch 2] Current Loss: 6.1675\n",
            "[Batch 3] Current Loss: 5.5679\n",
            "[Batch 4] Current Loss: 5.9355\n",
            "[Batch 5] Current Loss: 5.7709\n",
            "[Batch 6] Current Loss: 5.6433\n",
            "[Batch 7] Current Loss: 5.9997\n",
            "[Batch 8] Current Loss: 5.5387\n",
            "[Batch 9] Current Loss: 5.9619\n",
            "Ep 5 (Step 036500): Train loss 2.352, Val loss 5.786\n",
            "[Batch 0] Current Loss: 1.9962\n",
            "[Batch 1] Current Loss: 2.0702\n",
            "[Batch 2] Current Loss: 1.3283\n",
            "[Batch 3] Current Loss: 2.2292\n",
            "[Batch 4] Current Loss: 1.8962\n",
            "[Batch 5] Current Loss: 1.7443\n",
            "[Batch 6] Current Loss: 1.7132\n",
            "[Batch 7] Current Loss: 2.1378\n",
            "[Batch 8] Current Loss: 2.7292\n",
            "[Batch 9] Current Loss: 2.0049\n",
            "[Batch 0] Current Loss: 5.8085\n",
            "[Batch 1] Current Loss: 5.7371\n",
            "[Batch 2] Current Loss: 4.8374\n",
            "[Batch 3] Current Loss: 5.9725\n",
            "[Batch 4] Current Loss: 6.5714\n",
            "[Batch 5] Current Loss: 5.1398\n",
            "[Batch 6] Current Loss: 5.1404\n",
            "[Batch 7] Current Loss: 5.0974\n",
            "[Batch 8] Current Loss: 5.8620\n",
            "[Batch 9] Current Loss: 5.5094\n",
            "Ep 5 (Step 036520): Train loss 1.985, Val loss 5.568\n",
            "[Batch 0] Current Loss: 2.1621\n",
            "[Batch 1] Current Loss: 2.2012\n",
            "[Batch 2] Current Loss: 2.4432\n",
            "[Batch 3] Current Loss: 2.8268\n",
            "[Batch 4] Current Loss: 2.0076\n",
            "[Batch 5] Current Loss: 2.3180\n",
            "[Batch 6] Current Loss: 2.3011\n",
            "[Batch 7] Current Loss: 2.5967\n",
            "[Batch 8] Current Loss: 3.0299\n",
            "[Batch 9] Current Loss: 2.2676\n",
            "[Batch 0] Current Loss: 5.2447\n",
            "[Batch 1] Current Loss: 5.3971\n",
            "[Batch 2] Current Loss: 6.4473\n",
            "[Batch 3] Current Loss: 6.4814\n",
            "[Batch 4] Current Loss: 6.4610\n",
            "[Batch 5] Current Loss: 5.2137\n",
            "[Batch 6] Current Loss: 5.6907\n",
            "[Batch 7] Current Loss: 5.4404\n",
            "[Batch 8] Current Loss: 5.6063\n",
            "[Batch 9] Current Loss: 5.3399\n",
            "Ep 5 (Step 036540): Train loss 2.415, Val loss 5.732\n",
            "[Batch 0] Current Loss: 2.4403\n",
            "[Batch 1] Current Loss: 1.9451\n",
            "[Batch 2] Current Loss: 2.8087\n",
            "[Batch 3] Current Loss: 2.8293\n",
            "[Batch 4] Current Loss: 2.2120\n",
            "[Batch 5] Current Loss: 2.2130\n",
            "[Batch 6] Current Loss: 2.0212\n",
            "[Batch 7] Current Loss: 2.2796\n",
            "[Batch 8] Current Loss: 2.2711\n",
            "[Batch 9] Current Loss: 2.0044\n",
            "[Batch 0] Current Loss: 6.3374\n",
            "[Batch 1] Current Loss: 5.8879\n",
            "[Batch 2] Current Loss: 5.4626\n",
            "[Batch 3] Current Loss: 5.7876\n",
            "[Batch 4] Current Loss: 5.8054\n",
            "[Batch 5] Current Loss: 5.5136\n",
            "[Batch 6] Current Loss: 5.0702\n",
            "[Batch 7] Current Loss: 5.5336\n",
            "[Batch 8] Current Loss: 6.8441\n",
            "[Batch 9] Current Loss: 5.7034\n",
            "Ep 5 (Step 036560): Train loss 2.302, Val loss 5.795\n",
            "[Batch 0] Current Loss: 2.5442\n",
            "[Batch 1] Current Loss: 2.0864\n",
            "[Batch 2] Current Loss: 2.4816\n",
            "[Batch 3] Current Loss: 3.2454\n",
            "[Batch 4] Current Loss: 1.9877\n",
            "[Batch 5] Current Loss: 1.9117\n",
            "[Batch 6] Current Loss: 2.8245\n",
            "[Batch 7] Current Loss: 2.3359\n",
            "[Batch 8] Current Loss: 2.3330\n",
            "[Batch 9] Current Loss: 2.4129\n",
            "[Batch 0] Current Loss: 5.6192\n",
            "[Batch 1] Current Loss: 5.4181\n",
            "[Batch 2] Current Loss: 5.2039\n",
            "[Batch 3] Current Loss: 6.1495\n",
            "[Batch 4] Current Loss: 5.8287\n",
            "[Batch 5] Current Loss: 5.4195\n",
            "[Batch 6] Current Loss: 5.4680\n",
            "[Batch 7] Current Loss: 6.5300\n",
            "[Batch 8] Current Loss: 5.6130\n",
            "[Batch 9] Current Loss: 5.2665\n",
            "Ep 5 (Step 036580): Train loss 2.416, Val loss 5.652\n",
            "[Batch 0] Current Loss: 2.2124\n",
            "[Batch 1] Current Loss: 2.0798\n",
            "[Batch 2] Current Loss: 1.6985\n",
            "[Batch 3] Current Loss: 2.2675\n",
            "[Batch 4] Current Loss: 2.0402\n",
            "[Batch 5] Current Loss: 2.7044\n",
            "[Batch 6] Current Loss: 2.4847\n",
            "[Batch 7] Current Loss: 2.1308\n",
            "[Batch 8] Current Loss: 2.2512\n",
            "[Batch 9] Current Loss: 2.4616\n",
            "[Batch 0] Current Loss: 5.8131\n",
            "[Batch 1] Current Loss: 5.8027\n",
            "[Batch 2] Current Loss: 6.3941\n",
            "[Batch 3] Current Loss: 5.5504\n",
            "[Batch 4] Current Loss: 6.0561\n",
            "[Batch 5] Current Loss: 5.5848\n",
            "[Batch 6] Current Loss: 5.7449\n",
            "[Batch 7] Current Loss: 6.5127\n",
            "[Batch 8] Current Loss: 5.8432\n",
            "[Batch 9] Current Loss: 6.2677\n",
            "Ep 5 (Step 036600): Train loss 2.233, Val loss 5.957\n",
            "[Batch 0] Current Loss: 2.1060\n",
            "[Batch 1] Current Loss: 2.7631\n",
            "[Batch 2] Current Loss: 2.6299\n",
            "[Batch 3] Current Loss: 2.0956\n",
            "[Batch 4] Current Loss: 2.0080\n",
            "[Batch 5] Current Loss: 1.6769\n",
            "[Batch 6] Current Loss: 3.0002\n",
            "[Batch 7] Current Loss: 2.0095\n",
            "[Batch 8] Current Loss: 3.0887\n",
            "[Batch 9] Current Loss: 2.2373\n",
            "[Batch 0] Current Loss: 6.3255\n",
            "[Batch 1] Current Loss: 5.6180\n",
            "[Batch 2] Current Loss: 5.6909\n",
            "[Batch 3] Current Loss: 5.9171\n",
            "[Batch 4] Current Loss: 5.5495\n",
            "[Batch 5] Current Loss: 5.3155\n",
            "[Batch 6] Current Loss: 5.0633\n",
            "[Batch 7] Current Loss: 4.5856\n",
            "[Batch 8] Current Loss: 5.7886\n",
            "[Batch 9] Current Loss: 5.4333\n",
            "Ep 5 (Step 036620): Train loss 2.362, Val loss 5.529\n",
            "[Batch 0] Current Loss: 1.8652\n",
            "[Batch 1] Current Loss: 2.8539\n",
            "[Batch 2] Current Loss: 2.4662\n",
            "[Batch 3] Current Loss: 2.8285\n",
            "[Batch 4] Current Loss: 2.6364\n",
            "[Batch 5] Current Loss: 2.0049\n",
            "[Batch 6] Current Loss: 1.8864\n",
            "[Batch 7] Current Loss: 2.3302\n",
            "[Batch 8] Current Loss: 2.6881\n",
            "[Batch 9] Current Loss: 1.8707\n",
            "[Batch 0] Current Loss: 5.4790\n",
            "[Batch 1] Current Loss: 5.7537\n",
            "[Batch 2] Current Loss: 5.8473\n",
            "[Batch 3] Current Loss: 5.8505\n",
            "[Batch 4] Current Loss: 6.1518\n",
            "[Batch 5] Current Loss: 6.0849\n",
            "[Batch 6] Current Loss: 6.3668\n",
            "[Batch 7] Current Loss: 4.8768\n",
            "[Batch 8] Current Loss: 5.3964\n",
            "[Batch 9] Current Loss: 5.0641\n",
            "Ep 5 (Step 036640): Train loss 2.343, Val loss 5.687\n",
            "[Batch 0] Current Loss: 2.5552\n",
            "[Batch 1] Current Loss: 2.0177\n",
            "[Batch 2] Current Loss: 2.5210\n",
            "[Batch 3] Current Loss: 2.2372\n",
            "[Batch 4] Current Loss: 2.0006\n",
            "[Batch 5] Current Loss: 2.2051\n",
            "[Batch 6] Current Loss: 2.1698\n",
            "[Batch 7] Current Loss: 2.6018\n",
            "[Batch 8] Current Loss: 2.1637\n",
            "[Batch 9] Current Loss: 2.1820\n",
            "[Batch 0] Current Loss: 5.4813\n",
            "[Batch 1] Current Loss: 4.6799\n",
            "[Batch 2] Current Loss: 5.5513\n",
            "[Batch 3] Current Loss: 5.8685\n",
            "[Batch 4] Current Loss: 5.4972\n",
            "[Batch 5] Current Loss: 5.0193\n",
            "[Batch 6] Current Loss: 4.9731\n",
            "[Batch 7] Current Loss: 6.0357\n",
            "[Batch 8] Current Loss: 5.5182\n",
            "[Batch 9] Current Loss: 5.7635\n",
            "Ep 5 (Step 036660): Train loss 2.265, Val loss 5.439\n",
            "[Batch 0] Current Loss: 2.2217\n",
            "[Batch 1] Current Loss: 1.7371\n",
            "[Batch 2] Current Loss: 2.4571\n",
            "[Batch 3] Current Loss: 2.1701\n",
            "[Batch 4] Current Loss: 2.6305\n",
            "[Batch 5] Current Loss: 1.7488\n",
            "[Batch 6] Current Loss: 2.3823\n",
            "[Batch 7] Current Loss: 2.0192\n",
            "[Batch 8] Current Loss: 2.0104\n",
            "[Batch 9] Current Loss: 2.6774\n",
            "[Batch 0] Current Loss: 5.5391\n",
            "[Batch 1] Current Loss: 6.0226\n",
            "[Batch 2] Current Loss: 6.4200\n",
            "[Batch 3] Current Loss: 5.9778\n",
            "[Batch 4] Current Loss: 5.9263\n",
            "[Batch 5] Current Loss: 5.7981\n",
            "[Batch 6] Current Loss: 4.7232\n",
            "[Batch 7] Current Loss: 5.5707\n",
            "[Batch 8] Current Loss: 5.5637\n",
            "[Batch 9] Current Loss: 4.8556\n",
            "Ep 5 (Step 036680): Train loss 2.205, Val loss 5.640\n",
            "[Batch 0] Current Loss: 1.8089\n",
            "[Batch 1] Current Loss: 1.7754\n",
            "[Batch 2] Current Loss: 2.5315\n",
            "[Batch 3] Current Loss: 2.1558\n",
            "[Batch 4] Current Loss: 2.5887\n",
            "[Batch 5] Current Loss: 1.7149\n",
            "[Batch 6] Current Loss: 2.2772\n",
            "[Batch 7] Current Loss: 2.0755\n",
            "[Batch 8] Current Loss: 1.8706\n",
            "[Batch 9] Current Loss: 1.6538\n",
            "[Batch 0] Current Loss: 5.6069\n",
            "[Batch 1] Current Loss: 6.1211\n",
            "[Batch 2] Current Loss: 5.8840\n",
            "[Batch 3] Current Loss: 5.9379\n",
            "[Batch 4] Current Loss: 5.8778\n",
            "[Batch 5] Current Loss: 5.6650\n",
            "[Batch 6] Current Loss: 6.7363\n",
            "[Batch 7] Current Loss: 6.0549\n",
            "[Batch 8] Current Loss: 5.3309\n",
            "[Batch 9] Current Loss: 5.6679\n",
            "Ep 5 (Step 036700): Train loss 2.045, Val loss 5.888\n",
            "[Batch 0] Current Loss: 2.6118\n",
            "[Batch 1] Current Loss: 1.9433\n",
            "[Batch 2] Current Loss: 2.5182\n",
            "[Batch 3] Current Loss: 2.1072\n",
            "[Batch 4] Current Loss: 2.0393\n",
            "[Batch 5] Current Loss: 1.8759\n",
            "[Batch 6] Current Loss: 2.6198\n",
            "[Batch 7] Current Loss: 2.5600\n",
            "[Batch 8] Current Loss: 2.4382\n",
            "[Batch 9] Current Loss: 2.3819\n",
            "[Batch 0] Current Loss: 5.9624\n",
            "[Batch 1] Current Loss: 5.0999\n",
            "[Batch 2] Current Loss: 5.9825\n",
            "[Batch 3] Current Loss: 5.1986\n",
            "[Batch 4] Current Loss: 5.1583\n",
            "[Batch 5] Current Loss: 5.7236\n",
            "[Batch 6] Current Loss: 5.1907\n",
            "[Batch 7] Current Loss: 5.8393\n",
            "[Batch 8] Current Loss: 5.1865\n",
            "[Batch 9] Current Loss: 6.7909\n",
            "Ep 5 (Step 036720): Train loss 2.310, Val loss 5.613\n",
            "[Batch 0] Current Loss: 1.9505\n",
            "[Batch 1] Current Loss: 2.1586\n",
            "[Batch 2] Current Loss: 2.0912\n",
            "[Batch 3] Current Loss: 2.6929\n",
            "[Batch 4] Current Loss: 1.9356\n",
            "[Batch 5] Current Loss: 2.6008\n",
            "[Batch 6] Current Loss: 2.3389\n",
            "[Batch 7] Current Loss: 1.9053\n",
            "[Batch 8] Current Loss: 2.1960\n",
            "[Batch 9] Current Loss: 2.6842\n",
            "[Batch 0] Current Loss: 5.0271\n",
            "[Batch 1] Current Loss: 5.4293\n",
            "[Batch 2] Current Loss: 5.4877\n",
            "[Batch 3] Current Loss: 5.7627\n",
            "[Batch 4] Current Loss: 5.6827\n",
            "[Batch 5] Current Loss: 5.4236\n",
            "[Batch 6] Current Loss: 4.9843\n",
            "[Batch 7] Current Loss: 5.5631\n",
            "[Batch 8] Current Loss: 6.8638\n",
            "[Batch 9] Current Loss: 6.8844\n",
            "Ep 5 (Step 036740): Train loss 2.255, Val loss 5.711\n",
            "[Batch 0] Current Loss: 1.6968\n",
            "[Batch 1] Current Loss: 1.6069\n",
            "[Batch 2] Current Loss: 2.2502\n",
            "[Batch 3] Current Loss: 1.7673\n",
            "[Batch 4] Current Loss: 2.0672\n",
            "[Batch 5] Current Loss: 2.5739\n",
            "[Batch 6] Current Loss: 1.8696\n",
            "[Batch 7] Current Loss: 1.8748\n",
            "[Batch 8] Current Loss: 2.4674\n",
            "[Batch 9] Current Loss: 2.2602\n",
            "[Batch 0] Current Loss: 5.7291\n",
            "[Batch 1] Current Loss: 6.1033\n",
            "[Batch 2] Current Loss: 5.8231\n",
            "[Batch 3] Current Loss: 5.9147\n",
            "[Batch 4] Current Loss: 5.1148\n",
            "[Batch 5] Current Loss: 5.3257\n",
            "[Batch 6] Current Loss: 6.5802\n",
            "[Batch 7] Current Loss: 5.4340\n",
            "[Batch 8] Current Loss: 5.6789\n",
            "[Batch 9] Current Loss: 6.1920\n",
            "Ep 5 (Step 036760): Train loss 2.043, Val loss 5.790\n",
            "[Batch 0] Current Loss: 1.6243\n",
            "[Batch 1] Current Loss: 2.8785\n",
            "[Batch 2] Current Loss: 2.1258\n",
            "[Batch 3] Current Loss: 1.9958\n",
            "[Batch 4] Current Loss: 2.0887\n",
            "[Batch 5] Current Loss: 2.1103\n",
            "[Batch 6] Current Loss: 2.3817\n",
            "[Batch 7] Current Loss: 1.6349\n",
            "[Batch 8] Current Loss: 1.9745\n",
            "[Batch 9] Current Loss: 2.0668\n",
            "[Batch 0] Current Loss: 5.7287\n",
            "[Batch 1] Current Loss: 6.0561\n",
            "[Batch 2] Current Loss: 6.2923\n",
            "[Batch 3] Current Loss: 5.5022\n",
            "[Batch 4] Current Loss: 5.7163\n",
            "[Batch 5] Current Loss: 5.7812\n",
            "[Batch 6] Current Loss: 4.8848\n",
            "[Batch 7] Current Loss: 5.8630\n",
            "[Batch 8] Current Loss: 6.0966\n",
            "[Batch 9] Current Loss: 6.0339\n",
            "Ep 5 (Step 036780): Train loss 2.088, Val loss 5.796\n",
            "[Batch 0] Current Loss: 3.1040\n",
            "[Batch 1] Current Loss: 2.3315\n",
            "[Batch 2] Current Loss: 2.7688\n",
            "[Batch 3] Current Loss: 1.9059\n",
            "[Batch 4] Current Loss: 2.3905\n",
            "[Batch 5] Current Loss: 1.8011\n",
            "[Batch 6] Current Loss: 2.4072\n",
            "[Batch 7] Current Loss: 2.4804\n",
            "[Batch 8] Current Loss: 2.6619\n",
            "[Batch 9] Current Loss: 1.6582\n",
            "[Batch 0] Current Loss: 6.6230\n",
            "[Batch 1] Current Loss: 5.4892\n",
            "[Batch 2] Current Loss: 4.9713\n",
            "[Batch 3] Current Loss: 5.8160\n",
            "[Batch 4] Current Loss: 5.6052\n",
            "[Batch 5] Current Loss: 5.9019\n",
            "[Batch 6] Current Loss: 5.7488\n",
            "[Batch 7] Current Loss: 5.5411\n",
            "[Batch 8] Current Loss: 4.5600\n",
            "[Batch 9] Current Loss: 5.3956\n",
            "Ep 5 (Step 036800): Train loss 2.351, Val loss 5.565\n",
            "[Batch 0] Current Loss: 2.8592\n",
            "[Batch 1] Current Loss: 2.0366\n",
            "[Batch 2] Current Loss: 1.6873\n",
            "[Batch 3] Current Loss: 1.9195\n",
            "[Batch 4] Current Loss: 2.4797\n",
            "[Batch 5] Current Loss: 1.8475\n",
            "[Batch 6] Current Loss: 2.8457\n",
            "[Batch 7] Current Loss: 1.9768\n",
            "[Batch 8] Current Loss: 1.6300\n",
            "[Batch 9] Current Loss: 2.5547\n",
            "[Batch 0] Current Loss: 5.1811\n",
            "[Batch 1] Current Loss: 5.6255\n",
            "[Batch 2] Current Loss: 5.2105\n",
            "[Batch 3] Current Loss: 5.9557\n",
            "[Batch 4] Current Loss: 5.6602\n",
            "[Batch 5] Current Loss: 5.2739\n",
            "[Batch 6] Current Loss: 5.6724\n",
            "[Batch 7] Current Loss: 6.7638\n",
            "[Batch 8] Current Loss: 4.5300\n",
            "[Batch 9] Current Loss: 5.5035\n",
            "Ep 5 (Step 036820): Train loss 2.184, Val loss 5.538\n",
            "[Batch 0] Current Loss: 2.7857\n",
            "[Batch 1] Current Loss: 1.9857\n",
            "[Batch 2] Current Loss: 1.8074\n",
            "[Batch 3] Current Loss: 1.8430\n",
            "[Batch 4] Current Loss: 2.2668\n",
            "[Batch 5] Current Loss: 2.6827\n",
            "[Batch 6] Current Loss: 2.1930\n",
            "[Batch 7] Current Loss: 2.8579\n",
            "[Batch 8] Current Loss: 3.0693\n",
            "[Batch 9] Current Loss: 2.2766\n",
            "[Batch 0] Current Loss: 5.2080\n",
            "[Batch 1] Current Loss: 6.2895\n",
            "[Batch 2] Current Loss: 6.0569\n",
            "[Batch 3] Current Loss: 4.5643\n",
            "[Batch 4] Current Loss: 5.5662\n",
            "[Batch 5] Current Loss: 5.1861\n",
            "[Batch 6] Current Loss: 6.0763\n",
            "[Batch 7] Current Loss: 5.8561\n",
            "[Batch 8] Current Loss: 5.7911\n",
            "[Batch 9] Current Loss: 6.0682\n",
            "Ep 5 (Step 036840): Train loss 2.377, Val loss 5.666\n",
            "[Batch 0] Current Loss: 2.3258\n",
            "[Batch 1] Current Loss: 2.8206\n",
            "[Batch 2] Current Loss: 2.5390\n",
            "[Batch 3] Current Loss: 3.1192\n",
            "[Batch 4] Current Loss: 2.1398\n",
            "[Batch 5] Current Loss: 2.0775\n",
            "[Batch 6] Current Loss: 2.1005\n",
            "[Batch 7] Current Loss: 3.3476\n",
            "[Batch 8] Current Loss: 2.5788\n",
            "[Batch 9] Current Loss: 2.5022\n",
            "[Batch 0] Current Loss: 4.9598\n",
            "[Batch 1] Current Loss: 5.9877\n",
            "[Batch 2] Current Loss: 5.7770\n",
            "[Batch 3] Current Loss: 5.7077\n",
            "[Batch 4] Current Loss: 4.8198\n",
            "[Batch 5] Current Loss: 4.8944\n",
            "[Batch 6] Current Loss: 5.3000\n",
            "[Batch 7] Current Loss: 5.8113\n",
            "[Batch 8] Current Loss: 6.1783\n",
            "[Batch 9] Current Loss: 6.1266\n",
            "Ep 5 (Step 036860): Train loss 2.555, Val loss 5.556\n",
            "[Batch 0] Current Loss: 2.0706\n",
            "[Batch 1] Current Loss: 2.2631\n",
            "[Batch 2] Current Loss: 2.2430\n",
            "[Batch 3] Current Loss: 2.5907\n",
            "[Batch 4] Current Loss: 1.7758\n",
            "[Batch 5] Current Loss: 2.9061\n",
            "[Batch 6] Current Loss: 2.4234\n",
            "[Batch 7] Current Loss: 2.7027\n",
            "[Batch 8] Current Loss: 2.3160\n",
            "[Batch 9] Current Loss: 2.6856\n",
            "[Batch 0] Current Loss: 5.7216\n",
            "[Batch 1] Current Loss: 5.2129\n",
            "[Batch 2] Current Loss: 4.7727\n",
            "[Batch 3] Current Loss: 4.6984\n",
            "[Batch 4] Current Loss: 5.6619\n",
            "[Batch 5] Current Loss: 4.2915\n",
            "[Batch 6] Current Loss: 4.8047\n",
            "[Batch 7] Current Loss: 5.7038\n",
            "[Batch 8] Current Loss: 5.7742\n",
            "[Batch 9] Current Loss: 5.8574\n",
            "Ep 5 (Step 036880): Train loss 2.398, Val loss 5.250\n",
            "[Batch 0] Current Loss: 2.0502\n",
            "[Batch 1] Current Loss: 2.6697\n",
            "[Batch 2] Current Loss: 2.4125\n",
            "[Batch 3] Current Loss: 1.6051\n",
            "[Batch 4] Current Loss: 2.2623\n",
            "[Batch 5] Current Loss: 2.2570\n",
            "[Batch 6] Current Loss: 1.9800\n",
            "[Batch 7] Current Loss: 1.7011\n",
            "[Batch 8] Current Loss: 2.3207\n",
            "[Batch 9] Current Loss: 2.5106\n",
            "[Batch 0] Current Loss: 5.1296\n",
            "[Batch 1] Current Loss: 6.1998\n",
            "[Batch 2] Current Loss: 5.4520\n",
            "[Batch 3] Current Loss: 5.7032\n",
            "[Batch 4] Current Loss: 6.1763\n",
            "[Batch 5] Current Loss: 6.0573\n",
            "[Batch 6] Current Loss: 5.5638\n",
            "[Batch 7] Current Loss: 5.5487\n",
            "[Batch 8] Current Loss: 5.5962\n",
            "[Batch 9] Current Loss: 4.9468\n",
            "Ep 5 (Step 036900): Train loss 2.177, Val loss 5.637\n",
            "[Batch 0] Current Loss: 2.5737\n",
            "[Batch 1] Current Loss: 1.8831\n",
            "[Batch 2] Current Loss: 2.2182\n",
            "[Batch 3] Current Loss: 2.5470\n",
            "[Batch 4] Current Loss: 1.5623\n",
            "[Batch 5] Current Loss: 2.3060\n",
            "[Batch 6] Current Loss: 2.3480\n",
            "[Batch 7] Current Loss: 2.6965\n",
            "[Batch 8] Current Loss: 1.7978\n",
            "[Batch 9] Current Loss: 2.5256\n",
            "[Batch 0] Current Loss: 5.7277\n",
            "[Batch 1] Current Loss: 5.5863\n",
            "[Batch 2] Current Loss: 4.6265\n",
            "[Batch 3] Current Loss: 5.0168\n",
            "[Batch 4] Current Loss: 5.2505\n",
            "[Batch 5] Current Loss: 5.9450\n",
            "[Batch 6] Current Loss: 5.2640\n",
            "[Batch 7] Current Loss: 5.1378\n",
            "[Batch 8] Current Loss: 5.6526\n",
            "[Batch 9] Current Loss: 4.6055\n",
            "Ep 5 (Step 036920): Train loss 2.246, Val loss 5.281\n",
            "[Batch 0] Current Loss: 2.6551\n",
            "[Batch 1] Current Loss: 2.5951\n",
            "[Batch 2] Current Loss: 2.7458\n",
            "[Batch 3] Current Loss: 2.7239\n",
            "[Batch 4] Current Loss: 2.3707\n",
            "[Batch 5] Current Loss: 1.7811\n",
            "[Batch 6] Current Loss: 1.8457\n",
            "[Batch 7] Current Loss: 1.4932\n",
            "[Batch 8] Current Loss: 1.6963\n",
            "[Batch 9] Current Loss: 2.0829\n",
            "[Batch 0] Current Loss: 5.5127\n",
            "[Batch 1] Current Loss: 5.8624\n",
            "[Batch 2] Current Loss: 5.7709\n",
            "[Batch 3] Current Loss: 5.7019\n",
            "[Batch 4] Current Loss: 5.9707\n",
            "[Batch 5] Current Loss: 6.6708\n",
            "[Batch 6] Current Loss: 6.2933\n",
            "[Batch 7] Current Loss: 6.4498\n",
            "[Batch 8] Current Loss: 5.7947\n",
            "[Batch 9] Current Loss: 6.2025\n",
            "Ep 5 (Step 036940): Train loss 2.199, Val loss 6.023\n",
            "[Batch 0] Current Loss: 2.4856\n",
            "[Batch 1] Current Loss: 1.7120\n",
            "[Batch 2] Current Loss: 2.3374\n",
            "[Batch 3] Current Loss: 2.2997\n",
            "[Batch 4] Current Loss: 2.4515\n",
            "[Batch 5] Current Loss: 2.5495\n",
            "[Batch 6] Current Loss: 1.8777\n",
            "[Batch 7] Current Loss: 2.0652\n",
            "[Batch 8] Current Loss: 1.9471\n",
            "[Batch 9] Current Loss: 2.3849\n",
            "[Batch 0] Current Loss: 5.3605\n",
            "[Batch 1] Current Loss: 5.8219\n",
            "[Batch 2] Current Loss: 5.2532\n",
            "[Batch 3] Current Loss: 5.2876\n",
            "[Batch 4] Current Loss: 4.4998\n",
            "[Batch 5] Current Loss: 5.2721\n",
            "[Batch 6] Current Loss: 5.3504\n",
            "[Batch 7] Current Loss: 5.8592\n",
            "[Batch 8] Current Loss: 5.0356\n",
            "[Batch 9] Current Loss: 4.7471\n",
            "Ep 5 (Step 036960): Train loss 2.211, Val loss 5.249\n",
            "[Batch 0] Current Loss: 1.6840\n",
            "[Batch 1] Current Loss: 2.1102\n",
            "[Batch 2] Current Loss: 2.6389\n",
            "[Batch 3] Current Loss: 2.6205\n",
            "[Batch 4] Current Loss: 2.3605\n",
            "[Batch 5] Current Loss: 1.9502\n",
            "[Batch 6] Current Loss: 2.1342\n",
            "[Batch 7] Current Loss: 2.4823\n",
            "[Batch 8] Current Loss: 2.2450\n",
            "[Batch 9] Current Loss: 1.6156\n",
            "[Batch 0] Current Loss: 6.2444\n",
            "[Batch 1] Current Loss: 5.4536\n",
            "[Batch 2] Current Loss: 5.3473\n",
            "[Batch 3] Current Loss: 5.5448\n",
            "[Batch 4] Current Loss: 4.9984\n",
            "[Batch 5] Current Loss: 5.5894\n",
            "[Batch 6] Current Loss: 5.5325\n",
            "[Batch 7] Current Loss: 4.9025\n",
            "[Batch 8] Current Loss: 6.1256\n",
            "[Batch 9] Current Loss: 5.7650\n",
            "Ep 5 (Step 036980): Train loss 2.184, Val loss 5.550\n",
            "[Batch 0] Current Loss: 2.2568\n",
            "[Batch 1] Current Loss: 1.9104\n",
            "[Batch 2] Current Loss: 2.6345\n",
            "[Batch 3] Current Loss: 1.9145\n",
            "[Batch 4] Current Loss: 2.3796\n",
            "[Batch 5] Current Loss: 2.1349\n",
            "[Batch 6] Current Loss: 2.4050\n",
            "[Batch 7] Current Loss: 2.4836\n",
            "[Batch 8] Current Loss: 2.4199\n",
            "[Batch 9] Current Loss: 2.2001\n",
            "[Batch 0] Current Loss: 6.3144\n",
            "[Batch 1] Current Loss: 5.6699\n",
            "[Batch 2] Current Loss: 5.1306\n",
            "[Batch 3] Current Loss: 6.3950\n",
            "[Batch 4] Current Loss: 5.4083\n",
            "[Batch 5] Current Loss: 4.8956\n",
            "[Batch 6] Current Loss: 5.8431\n",
            "[Batch 7] Current Loss: 5.3083\n",
            "[Batch 8] Current Loss: 5.4246\n",
            "[Batch 9] Current Loss: 5.7400\n",
            "Ep 5 (Step 037000): Train loss 2.274, Val loss 5.613\n",
            "[Batch 0] Current Loss: 2.3811\n",
            "[Batch 1] Current Loss: 2.2603\n",
            "[Batch 2] Current Loss: 3.1295\n",
            "[Batch 3] Current Loss: 2.2038\n",
            "[Batch 4] Current Loss: 1.4402\n",
            "[Batch 5] Current Loss: 2.2203\n",
            "[Batch 6] Current Loss: 1.8735\n",
            "[Batch 7] Current Loss: 2.7193\n",
            "[Batch 8] Current Loss: 2.1567\n",
            "[Batch 9] Current Loss: 3.1729\n",
            "[Batch 0] Current Loss: 6.3765\n",
            "[Batch 1] Current Loss: 5.4782\n",
            "[Batch 2] Current Loss: 5.2720\n",
            "[Batch 3] Current Loss: 6.1793\n",
            "[Batch 4] Current Loss: 5.5501\n",
            "[Batch 5] Current Loss: 5.6834\n",
            "[Batch 6] Current Loss: 5.7016\n",
            "[Batch 7] Current Loss: 5.6426\n",
            "[Batch 8] Current Loss: 6.5510\n",
            "[Batch 9] Current Loss: 5.8455\n",
            "Ep 5 (Step 037020): Train loss 2.356, Val loss 5.828\n",
            "[Batch 0] Current Loss: 2.0913\n",
            "[Batch 1] Current Loss: 2.0245\n",
            "[Batch 2] Current Loss: 1.6564\n",
            "[Batch 3] Current Loss: 1.8980\n",
            "[Batch 4] Current Loss: 2.0900\n",
            "[Batch 5] Current Loss: 2.7457\n",
            "[Batch 6] Current Loss: 1.8071\n",
            "[Batch 7] Current Loss: 2.2301\n",
            "[Batch 8] Current Loss: 1.9622\n",
            "[Batch 9] Current Loss: 1.5408\n",
            "[Batch 0] Current Loss: 6.3609\n",
            "[Batch 1] Current Loss: 5.5220\n",
            "[Batch 2] Current Loss: 6.6841\n",
            "[Batch 3] Current Loss: 5.2118\n",
            "[Batch 4] Current Loss: 4.6610\n",
            "[Batch 5] Current Loss: 5.5440\n",
            "[Batch 6] Current Loss: 6.0071\n",
            "[Batch 7] Current Loss: 5.6402\n",
            "[Batch 8] Current Loss: 5.7214\n",
            "[Batch 9] Current Loss: 6.4272\n",
            "Ep 5 (Step 037040): Train loss 2.005, Val loss 5.778\n",
            "[Batch 0] Current Loss: 2.0921\n",
            "[Batch 1] Current Loss: 2.7263\n",
            "[Batch 2] Current Loss: 2.1096\n",
            "[Batch 3] Current Loss: 2.6257\n",
            "[Batch 4] Current Loss: 2.3081\n",
            "[Batch 5] Current Loss: 1.9597\n",
            "[Batch 6] Current Loss: 1.8404\n",
            "[Batch 7] Current Loss: 2.0805\n",
            "[Batch 8] Current Loss: 2.3844\n",
            "[Batch 9] Current Loss: 2.2398\n",
            "[Batch 0] Current Loss: 5.0001\n",
            "[Batch 1] Current Loss: 5.8281\n",
            "[Batch 2] Current Loss: 6.2315\n",
            "[Batch 3] Current Loss: 6.4945\n",
            "[Batch 4] Current Loss: 6.0420\n",
            "[Batch 5] Current Loss: 6.1351\n",
            "[Batch 6] Current Loss: 5.6101\n",
            "[Batch 7] Current Loss: 5.3467\n",
            "[Batch 8] Current Loss: 6.0543\n",
            "[Batch 9] Current Loss: 6.2859\n",
            "Ep 5 (Step 037060): Train loss 2.237, Val loss 5.903\n",
            "[Batch 0] Current Loss: 2.1440\n",
            "[Batch 1] Current Loss: 2.5995\n",
            "[Batch 2] Current Loss: 2.0835\n",
            "[Batch 3] Current Loss: 2.3911\n",
            "[Batch 4] Current Loss: 2.0104\n",
            "[Batch 5] Current Loss: 2.1733\n",
            "[Batch 6] Current Loss: 2.9211\n",
            "[Batch 7] Current Loss: 2.3082\n",
            "[Batch 8] Current Loss: 2.7587\n",
            "[Batch 9] Current Loss: 2.4544\n",
            "[Batch 0] Current Loss: 6.0224\n",
            "[Batch 1] Current Loss: 6.5515\n",
            "[Batch 2] Current Loss: 5.8981\n",
            "[Batch 3] Current Loss: 5.1634\n",
            "[Batch 4] Current Loss: 5.6443\n",
            "[Batch 5] Current Loss: 5.0724\n",
            "[Batch 6] Current Loss: 5.7035\n",
            "[Batch 7] Current Loss: 6.1946\n",
            "[Batch 8] Current Loss: 5.3506\n",
            "[Batch 9] Current Loss: 5.3969\n",
            "Ep 5 (Step 037080): Train loss 2.384, Val loss 5.700\n",
            "[Batch 0] Current Loss: 2.2391\n",
            "[Batch 1] Current Loss: 2.3646\n",
            "[Batch 2] Current Loss: 3.2441\n",
            "[Batch 3] Current Loss: 2.5683\n",
            "[Batch 4] Current Loss: 1.8779\n",
            "[Batch 5] Current Loss: 2.0242\n",
            "[Batch 6] Current Loss: 1.8234\n",
            "[Batch 7] Current Loss: 2.7054\n",
            "[Batch 8] Current Loss: 2.1179\n",
            "[Batch 9] Current Loss: 2.6579\n",
            "[Batch 0] Current Loss: 6.3401\n",
            "[Batch 1] Current Loss: 5.9273\n",
            "[Batch 2] Current Loss: 5.9635\n",
            "[Batch 3] Current Loss: 5.3731\n",
            "[Batch 4] Current Loss: 4.9601\n",
            "[Batch 5] Current Loss: 4.8436\n",
            "[Batch 6] Current Loss: 6.0447\n",
            "[Batch 7] Current Loss: 5.5496\n",
            "[Batch 8] Current Loss: 5.7112\n",
            "[Batch 9] Current Loss: 5.2592\n",
            "Ep 5 (Step 037100): Train loss 2.362, Val loss 5.597\n",
            "[Batch 0] Current Loss: 2.0148\n",
            "[Batch 1] Current Loss: 2.2005\n",
            "[Batch 2] Current Loss: 2.4708\n",
            "[Batch 3] Current Loss: 2.3101\n",
            "[Batch 4] Current Loss: 2.2277\n",
            "[Batch 5] Current Loss: 2.2707\n",
            "[Batch 6] Current Loss: 2.3435\n",
            "[Batch 7] Current Loss: 1.7205\n",
            "[Batch 8] Current Loss: 2.9090\n",
            "[Batch 9] Current Loss: 2.3914\n",
            "[Batch 0] Current Loss: 6.1462\n",
            "[Batch 1] Current Loss: 5.3099\n",
            "[Batch 2] Current Loss: 5.9701\n",
            "[Batch 3] Current Loss: 5.7743\n",
            "[Batch 4] Current Loss: 5.9471\n",
            "[Batch 5] Current Loss: 5.2721\n",
            "[Batch 6] Current Loss: 5.6092\n",
            "[Batch 7] Current Loss: 4.7665\n",
            "[Batch 8] Current Loss: 5.1104\n",
            "[Batch 9] Current Loss: 5.5780\n",
            "Ep 5 (Step 037120): Train loss 2.286, Val loss 5.548\n",
            "[Batch 0] Current Loss: 1.5003\n",
            "[Batch 1] Current Loss: 2.6625\n",
            "[Batch 2] Current Loss: 2.2068\n",
            "[Batch 3] Current Loss: 3.0493\n",
            "[Batch 4] Current Loss: 2.2610\n",
            "[Batch 5] Current Loss: 2.6485\n",
            "[Batch 6] Current Loss: 1.6451\n",
            "[Batch 7] Current Loss: 1.5242\n",
            "[Batch 8] Current Loss: 1.9453\n",
            "[Batch 9] Current Loss: 2.6589\n",
            "[Batch 0] Current Loss: 5.4215\n",
            "[Batch 1] Current Loss: 5.7620\n",
            "[Batch 2] Current Loss: 5.8177\n",
            "[Batch 3] Current Loss: 6.7392\n",
            "[Batch 4] Current Loss: 6.2640\n",
            "[Batch 5] Current Loss: 5.9645\n",
            "[Batch 6] Current Loss: 5.0111\n",
            "[Batch 7] Current Loss: 5.2934\n",
            "[Batch 8] Current Loss: 5.7951\n",
            "[Batch 9] Current Loss: 4.9260\n",
            "Ep 5 (Step 037140): Train loss 2.210, Val loss 5.699\n",
            "[Batch 0] Current Loss: 2.4126\n",
            "[Batch 1] Current Loss: 1.8398\n",
            "[Batch 2] Current Loss: 3.0838\n",
            "[Batch 3] Current Loss: 2.4400\n",
            "[Batch 4] Current Loss: 2.3380\n",
            "[Batch 5] Current Loss: 2.1446\n",
            "[Batch 6] Current Loss: 2.4174\n",
            "[Batch 7] Current Loss: 2.4501\n",
            "[Batch 8] Current Loss: 1.7919\n",
            "[Batch 9] Current Loss: 2.0967\n",
            "[Batch 0] Current Loss: 5.2923\n",
            "[Batch 1] Current Loss: 5.5684\n",
            "[Batch 2] Current Loss: 5.5620\n",
            "[Batch 3] Current Loss: 5.7536\n",
            "[Batch 4] Current Loss: 5.7123\n",
            "[Batch 5] Current Loss: 6.0936\n",
            "[Batch 6] Current Loss: 5.9076\n",
            "[Batch 7] Current Loss: 6.4073\n",
            "[Batch 8] Current Loss: 5.2230\n",
            "[Batch 9] Current Loss: 6.2657\n",
            "Ep 5 (Step 037160): Train loss 2.301, Val loss 5.779\n",
            "[Batch 0] Current Loss: 2.1375\n",
            "[Batch 1] Current Loss: 2.2157\n",
            "[Batch 2] Current Loss: 2.1431\n",
            "[Batch 3] Current Loss: 2.3610\n",
            "[Batch 4] Current Loss: 2.2208\n",
            "[Batch 5] Current Loss: 2.4049\n",
            "[Batch 6] Current Loss: 2.0439\n",
            "[Batch 7] Current Loss: 2.1744\n",
            "[Batch 8] Current Loss: 1.9947\n",
            "[Batch 9] Current Loss: 2.1980\n",
            "[Batch 0] Current Loss: 6.4768\n",
            "[Batch 1] Current Loss: 4.7080\n",
            "[Batch 2] Current Loss: 5.9213\n",
            "[Batch 3] Current Loss: 6.2151\n",
            "[Batch 4] Current Loss: 6.0697\n",
            "[Batch 5] Current Loss: 5.6824\n",
            "[Batch 6] Current Loss: 5.3804\n",
            "[Batch 7] Current Loss: 4.0608\n",
            "[Batch 8] Current Loss: 5.0596\n",
            "[Batch 9] Current Loss: 5.7853\n",
            "Ep 5 (Step 037180): Train loss 2.189, Val loss 5.536\n",
            "[Batch 0] Current Loss: 2.4712\n",
            "[Batch 1] Current Loss: 1.8957\n",
            "[Batch 2] Current Loss: 2.3796\n",
            "[Batch 3] Current Loss: 2.5543\n",
            "[Batch 4] Current Loss: 2.2437\n",
            "[Batch 5] Current Loss: 2.0731\n",
            "[Batch 6] Current Loss: 2.0507\n",
            "[Batch 7] Current Loss: 1.8200\n",
            "[Batch 8] Current Loss: 2.2164\n",
            "[Batch 9] Current Loss: 1.9419\n",
            "[Batch 0] Current Loss: 5.9312\n",
            "[Batch 1] Current Loss: 5.6328\n",
            "[Batch 2] Current Loss: 5.2881\n",
            "[Batch 3] Current Loss: 5.3379\n",
            "[Batch 4] Current Loss: 5.2505\n",
            "[Batch 5] Current Loss: 5.0658\n",
            "[Batch 6] Current Loss: 6.3130\n",
            "[Batch 7] Current Loss: 6.4503\n",
            "[Batch 8] Current Loss: 5.1245\n",
            "[Batch 9] Current Loss: 6.0171\n",
            "Ep 5 (Step 037200): Train loss 2.165, Val loss 5.641\n",
            "[Batch 0] Current Loss: 2.6702\n",
            "[Batch 1] Current Loss: 2.2221\n",
            "[Batch 2] Current Loss: 1.8501\n",
            "[Batch 3] Current Loss: 2.5335\n",
            "[Batch 4] Current Loss: 1.9708\n",
            "[Batch 5] Current Loss: 2.1450\n",
            "[Batch 6] Current Loss: 2.2457\n",
            "[Batch 7] Current Loss: 2.1450\n",
            "[Batch 8] Current Loss: 2.3410\n",
            "[Batch 9] Current Loss: 2.8173\n",
            "[Batch 0] Current Loss: 5.2353\n",
            "[Batch 1] Current Loss: 5.4659\n",
            "[Batch 2] Current Loss: 5.5993\n",
            "[Batch 3] Current Loss: 4.8282\n",
            "[Batch 4] Current Loss: 5.3642\n",
            "[Batch 5] Current Loss: 5.7968\n",
            "[Batch 6] Current Loss: 5.2037\n",
            "[Batch 7] Current Loss: 5.8295\n",
            "[Batch 8] Current Loss: 6.1165\n",
            "[Batch 9] Current Loss: 5.9519\n",
            "Ep 5 (Step 037220): Train loss 2.294, Val loss 5.539\n",
            "[Batch 0] Current Loss: 1.9658\n",
            "[Batch 1] Current Loss: 2.1783\n",
            "[Batch 2] Current Loss: 2.2281\n",
            "[Batch 3] Current Loss: 2.0296\n",
            "[Batch 4] Current Loss: 2.3350\n",
            "[Batch 5] Current Loss: 2.6699\n",
            "[Batch 6] Current Loss: 1.9849\n",
            "[Batch 7] Current Loss: 1.7610\n",
            "[Batch 8] Current Loss: 2.0549\n",
            "[Batch 9] Current Loss: 2.5638\n",
            "[Batch 0] Current Loss: 5.8197\n",
            "[Batch 1] Current Loss: 6.0618\n",
            "[Batch 2] Current Loss: 5.6160\n",
            "[Batch 3] Current Loss: 5.0712\n",
            "[Batch 4] Current Loss: 5.3121\n",
            "[Batch 5] Current Loss: 5.0704\n",
            "[Batch 6] Current Loss: 6.1061\n",
            "[Batch 7] Current Loss: 4.6704\n",
            "[Batch 8] Current Loss: 6.2698\n",
            "[Batch 9] Current Loss: 6.5368\n",
            "Ep 5 (Step 037240): Train loss 2.177, Val loss 5.653\n",
            "[Batch 0] Current Loss: 2.4461\n",
            "[Batch 1] Current Loss: 2.1725\n",
            "[Batch 2] Current Loss: 1.9355\n",
            "[Batch 3] Current Loss: 2.2587\n",
            "[Batch 4] Current Loss: 1.9915\n",
            "[Batch 5] Current Loss: 2.6104\n",
            "[Batch 6] Current Loss: 1.6127\n",
            "[Batch 7] Current Loss: 1.4811\n",
            "[Batch 8] Current Loss: 2.6069\n",
            "[Batch 9] Current Loss: 2.5225\n",
            "[Batch 0] Current Loss: 5.8496\n",
            "[Batch 1] Current Loss: 6.3417\n",
            "[Batch 2] Current Loss: 5.5893\n",
            "[Batch 3] Current Loss: 5.9086\n",
            "[Batch 4] Current Loss: 5.5137\n",
            "[Batch 5] Current Loss: 5.5667\n",
            "[Batch 6] Current Loss: 5.0761\n",
            "[Batch 7] Current Loss: 5.8087\n",
            "[Batch 8] Current Loss: 5.7714\n",
            "[Batch 9] Current Loss: 5.7305\n",
            "Ep 5 (Step 037260): Train loss 2.164, Val loss 5.716\n",
            "[Batch 0] Current Loss: 2.4439\n",
            "[Batch 1] Current Loss: 2.2365\n",
            "[Batch 2] Current Loss: 2.5593\n",
            "[Batch 3] Current Loss: 2.3158\n",
            "[Batch 4] Current Loss: 2.4544\n",
            "[Batch 5] Current Loss: 2.1068\n",
            "[Batch 6] Current Loss: 2.3162\n",
            "[Batch 7] Current Loss: 2.6094\n",
            "[Batch 8] Current Loss: 2.0776\n",
            "[Batch 9] Current Loss: 2.1799\n",
            "[Batch 0] Current Loss: 5.7918\n",
            "[Batch 1] Current Loss: 5.7411\n",
            "[Batch 2] Current Loss: 5.5822\n",
            "[Batch 3] Current Loss: 5.5096\n",
            "[Batch 4] Current Loss: 5.9955\n",
            "[Batch 5] Current Loss: 5.3668\n",
            "[Batch 6] Current Loss: 6.6717\n",
            "[Batch 7] Current Loss: 6.2379\n",
            "[Batch 8] Current Loss: 6.4799\n",
            "[Batch 9] Current Loss: 5.0902\n",
            "Ep 5 (Step 037280): Train loss 2.330, Val loss 5.847\n",
            "[Batch 0] Current Loss: 2.6936\n",
            "[Batch 1] Current Loss: 1.5469\n",
            "[Batch 2] Current Loss: 2.2224\n",
            "[Batch 3] Current Loss: 1.8803\n",
            "[Batch 4] Current Loss: 1.8824\n",
            "[Batch 5] Current Loss: 2.2692\n",
            "[Batch 6] Current Loss: 1.8700\n",
            "[Batch 7] Current Loss: 1.6557\n",
            "[Batch 8] Current Loss: 2.2474\n",
            "[Batch 9] Current Loss: 2.0912\n",
            "[Batch 0] Current Loss: 4.4686\n",
            "[Batch 1] Current Loss: 4.9605\n",
            "[Batch 2] Current Loss: 5.5362\n",
            "[Batch 3] Current Loss: 5.4706\n",
            "[Batch 4] Current Loss: 5.9033\n",
            "[Batch 5] Current Loss: 5.4829\n",
            "[Batch 6] Current Loss: 5.5324\n",
            "[Batch 7] Current Loss: 5.4811\n",
            "[Batch 8] Current Loss: 5.5982\n",
            "[Batch 9] Current Loss: 5.7550\n",
            "Ep 5 (Step 037300): Train loss 2.036, Val loss 5.419\n",
            "[Batch 0] Current Loss: 2.6956\n",
            "[Batch 1] Current Loss: 1.7308\n",
            "[Batch 2] Current Loss: 2.2796\n",
            "[Batch 3] Current Loss: 2.1106\n",
            "[Batch 4] Current Loss: 2.2292\n",
            "[Batch 5] Current Loss: 2.1099\n",
            "[Batch 6] Current Loss: 2.0733\n",
            "[Batch 7] Current Loss: 2.3702\n",
            "[Batch 8] Current Loss: 2.0726\n",
            "[Batch 9] Current Loss: 2.1748\n",
            "[Batch 0] Current Loss: 5.3248\n",
            "[Batch 1] Current Loss: 5.8294\n",
            "[Batch 2] Current Loss: 5.8505\n",
            "[Batch 3] Current Loss: 5.4666\n",
            "[Batch 4] Current Loss: 5.5482\n",
            "[Batch 5] Current Loss: 5.2505\n",
            "[Batch 6] Current Loss: 5.9786\n",
            "[Batch 7] Current Loss: 4.7630\n",
            "[Batch 8] Current Loss: 5.1886\n",
            "[Batch 9] Current Loss: 5.8005\n",
            "Ep 5 (Step 037320): Train loss 2.185, Val loss 5.500\n",
            "[Batch 0] Current Loss: 2.4809\n",
            "[Batch 1] Current Loss: 2.2479\n",
            "[Batch 2] Current Loss: 2.5215\n",
            "[Batch 3] Current Loss: 2.5640\n",
            "[Batch 4] Current Loss: 2.9389\n",
            "[Batch 5] Current Loss: 2.8094\n",
            "[Batch 6] Current Loss: 2.2009\n",
            "[Batch 7] Current Loss: 2.4939\n",
            "[Batch 8] Current Loss: 2.3411\n",
            "[Batch 9] Current Loss: 1.6312\n",
            "[Batch 0] Current Loss: 5.2298\n",
            "[Batch 1] Current Loss: 6.4316\n",
            "[Batch 2] Current Loss: 5.6966\n",
            "[Batch 3] Current Loss: 5.5502\n",
            "[Batch 4] Current Loss: 5.9125\n",
            "[Batch 5] Current Loss: 6.0188\n",
            "[Batch 6] Current Loss: 5.6848\n",
            "[Batch 7] Current Loss: 5.4996\n",
            "[Batch 8] Current Loss: 6.1219\n",
            "[Batch 9] Current Loss: 5.3375\n",
            "Ep 5 (Step 037340): Train loss 2.423, Val loss 5.748\n",
            "[Batch 0] Current Loss: 1.9766\n",
            "[Batch 1] Current Loss: 2.7225\n",
            "[Batch 2] Current Loss: 1.7525\n",
            "[Batch 3] Current Loss: 1.9291\n",
            "[Batch 4] Current Loss: 1.7741\n",
            "[Batch 5] Current Loss: 2.6723\n",
            "[Batch 6] Current Loss: 2.4757\n",
            "[Batch 7] Current Loss: 2.1011\n",
            "[Batch 8] Current Loss: 2.4110\n",
            "[Batch 9] Current Loss: 1.9290\n",
            "[Batch 0] Current Loss: 6.0494\n",
            "[Batch 1] Current Loss: 5.9201\n",
            "[Batch 2] Current Loss: 5.9153\n",
            "[Batch 3] Current Loss: 6.2898\n",
            "[Batch 4] Current Loss: 5.5752\n",
            "[Batch 5] Current Loss: 5.6183\n",
            "[Batch 6] Current Loss: 5.5903\n",
            "[Batch 7] Current Loss: 6.2015\n",
            "[Batch 8] Current Loss: 5.0637\n",
            "[Batch 9] Current Loss: 5.2019\n",
            "Ep 5 (Step 037360): Train loss 2.174, Val loss 5.743\n",
            "[Batch 0] Current Loss: 2.2569\n",
            "[Batch 1] Current Loss: 2.3924\n",
            "[Batch 2] Current Loss: 1.7956\n",
            "[Batch 3] Current Loss: 2.7330\n",
            "[Batch 4] Current Loss: 2.2359\n",
            "[Batch 5] Current Loss: 2.5894\n",
            "[Batch 6] Current Loss: 2.8854\n",
            "[Batch 7] Current Loss: 1.9302\n",
            "[Batch 8] Current Loss: 2.5634\n",
            "[Batch 9] Current Loss: 1.8884\n",
            "[Batch 0] Current Loss: 5.6986\n",
            "[Batch 1] Current Loss: 5.9299\n",
            "[Batch 2] Current Loss: 5.1303\n",
            "[Batch 3] Current Loss: 5.8356\n",
            "[Batch 4] Current Loss: 6.3576\n",
            "[Batch 5] Current Loss: 5.2028\n",
            "[Batch 6] Current Loss: 5.3456\n",
            "[Batch 7] Current Loss: 5.4937\n",
            "[Batch 8] Current Loss: 5.5358\n",
            "[Batch 9] Current Loss: 5.8538\n",
            "Ep 5 (Step 037380): Train loss 2.327, Val loss 5.638\n",
            "[Batch 0] Current Loss: 1.9242\n",
            "[Batch 1] Current Loss: 2.2024\n",
            "[Batch 2] Current Loss: 2.0495\n",
            "[Batch 3] Current Loss: 2.1053\n",
            "[Batch 4] Current Loss: 1.8484\n",
            "[Batch 5] Current Loss: 2.2446\n",
            "[Batch 6] Current Loss: 2.6936\n",
            "[Batch 7] Current Loss: 1.8750\n",
            "[Batch 8] Current Loss: 1.7590\n",
            "[Batch 9] Current Loss: 2.4013\n",
            "[Batch 0] Current Loss: 5.2284\n",
            "[Batch 1] Current Loss: 5.8044\n",
            "[Batch 2] Current Loss: 5.0306\n",
            "[Batch 3] Current Loss: 6.2735\n",
            "[Batch 4] Current Loss: 6.4587\n",
            "[Batch 5] Current Loss: 5.8581\n",
            "[Batch 6] Current Loss: 6.1680\n",
            "[Batch 7] Current Loss: 6.6077\n",
            "[Batch 8] Current Loss: 6.0559\n",
            "[Batch 9] Current Loss: 4.6509\n",
            "Ep 5 (Step 037400): Train loss 2.110, Val loss 5.814\n",
            "[Batch 0] Current Loss: 2.5175\n",
            "[Batch 1] Current Loss: 1.7952\n",
            "[Batch 2] Current Loss: 2.2513\n",
            "[Batch 3] Current Loss: 2.4158\n",
            "[Batch 4] Current Loss: 2.3859\n",
            "[Batch 5] Current Loss: 1.9761\n",
            "[Batch 6] Current Loss: 1.8779\n",
            "[Batch 7] Current Loss: 2.2554\n",
            "[Batch 8] Current Loss: 3.0292\n",
            "[Batch 9] Current Loss: 2.7118\n",
            "[Batch 0] Current Loss: 5.7234\n",
            "[Batch 1] Current Loss: 5.5393\n",
            "[Batch 2] Current Loss: 5.2227\n",
            "[Batch 3] Current Loss: 5.7346\n",
            "[Batch 4] Current Loss: 5.4573\n",
            "[Batch 5] Current Loss: 5.3752\n",
            "[Batch 6] Current Loss: 6.4063\n",
            "[Batch 7] Current Loss: 6.1524\n",
            "[Batch 8] Current Loss: 5.8450\n",
            "[Batch 9] Current Loss: 6.8795\n",
            "Ep 5 (Step 037420): Train loss 2.322, Val loss 5.834\n",
            "[Batch 0] Current Loss: 2.0116\n",
            "[Batch 1] Current Loss: 2.1641\n",
            "[Batch 2] Current Loss: 1.7000\n",
            "[Batch 3] Current Loss: 2.3356\n",
            "[Batch 4] Current Loss: 1.6887\n",
            "[Batch 5] Current Loss: 2.0270\n",
            "[Batch 6] Current Loss: 2.0943\n",
            "[Batch 7] Current Loss: 1.8505\n",
            "[Batch 8] Current Loss: 2.0397\n",
            "[Batch 9] Current Loss: 2.6515\n",
            "[Batch 0] Current Loss: 5.8516\n",
            "[Batch 1] Current Loss: 5.8891\n",
            "[Batch 2] Current Loss: 6.4083\n",
            "[Batch 3] Current Loss: 5.2319\n",
            "[Batch 4] Current Loss: 5.5770\n",
            "[Batch 5] Current Loss: 5.7501\n",
            "[Batch 6] Current Loss: 5.8623\n",
            "[Batch 7] Current Loss: 5.9580\n",
            "[Batch 8] Current Loss: 6.0250\n",
            "[Batch 9] Current Loss: 6.4492\n",
            "Ep 5 (Step 037440): Train loss 2.056, Val loss 5.900\n",
            "[Batch 0] Current Loss: 2.4972\n",
            "[Batch 1] Current Loss: 2.3810\n",
            "[Batch 2] Current Loss: 2.5678\n",
            "[Batch 3] Current Loss: 2.5091\n",
            "[Batch 4] Current Loss: 1.9118\n",
            "[Batch 5] Current Loss: 2.2447\n",
            "[Batch 6] Current Loss: 2.1132\n",
            "[Batch 7] Current Loss: 2.1075\n",
            "[Batch 8] Current Loss: 1.2169\n",
            "[Batch 9] Current Loss: 1.8150\n",
            "[Batch 0] Current Loss: 5.7370\n",
            "[Batch 1] Current Loss: 6.4222\n",
            "[Batch 2] Current Loss: 6.4041\n",
            "[Batch 3] Current Loss: 5.6382\n",
            "[Batch 4] Current Loss: 5.0341\n",
            "[Batch 5] Current Loss: 4.5310\n",
            "[Batch 6] Current Loss: 5.3621\n",
            "[Batch 7] Current Loss: 5.4954\n",
            "[Batch 8] Current Loss: 5.8524\n",
            "[Batch 9] Current Loss: 5.6847\n",
            "Ep 5 (Step 037460): Train loss 2.136, Val loss 5.616\n",
            "[Batch 0] Current Loss: 2.2776\n",
            "[Batch 1] Current Loss: 2.0355\n",
            "[Batch 2] Current Loss: 2.5527\n",
            "[Batch 3] Current Loss: 2.4371\n",
            "[Batch 4] Current Loss: 1.7036\n",
            "[Batch 5] Current Loss: 2.4440\n",
            "[Batch 6] Current Loss: 2.3921\n",
            "[Batch 7] Current Loss: 2.9389\n",
            "[Batch 8] Current Loss: 2.4503\n",
            "[Batch 9] Current Loss: 2.2716\n",
            "[Batch 0] Current Loss: 6.0871\n",
            "[Batch 1] Current Loss: 5.7951\n",
            "[Batch 2] Current Loss: 6.3511\n",
            "[Batch 3] Current Loss: 4.4382\n",
            "[Batch 4] Current Loss: 5.8718\n",
            "[Batch 5] Current Loss: 6.7857\n",
            "[Batch 6] Current Loss: 6.4749\n",
            "[Batch 7] Current Loss: 5.7641\n",
            "[Batch 8] Current Loss: 5.8308\n",
            "[Batch 9] Current Loss: 5.9949\n",
            "Ep 5 (Step 037480): Train loss 2.350, Val loss 5.939\n",
            "[Batch 0] Current Loss: 2.2327\n",
            "[Batch 1] Current Loss: 2.1706\n",
            "[Batch 2] Current Loss: 2.0618\n",
            "[Batch 3] Current Loss: 1.6543\n",
            "[Batch 4] Current Loss: 1.8086\n",
            "[Batch 5] Current Loss: 1.9984\n",
            "[Batch 6] Current Loss: 1.7444\n",
            "[Batch 7] Current Loss: 2.4617\n",
            "[Batch 8] Current Loss: 2.4863\n",
            "[Batch 9] Current Loss: 2.2422\n",
            "[Batch 0] Current Loss: 5.7235\n",
            "[Batch 1] Current Loss: 6.0358\n",
            "[Batch 2] Current Loss: 6.0471\n",
            "[Batch 3] Current Loss: 5.9990\n",
            "[Batch 4] Current Loss: 5.6700\n",
            "[Batch 5] Current Loss: 5.3399\n",
            "[Batch 6] Current Loss: 6.0229\n",
            "[Batch 7] Current Loss: 4.5526\n",
            "[Batch 8] Current Loss: 5.8611\n",
            "[Batch 9] Current Loss: 6.3792\n",
            "Ep 5 (Step 037500): Train loss 2.086, Val loss 5.763\n",
            "[Batch 0] Current Loss: 2.3928\n",
            "[Batch 1] Current Loss: 2.9745\n",
            "[Batch 2] Current Loss: 2.2539\n",
            "[Batch 3] Current Loss: 2.3436\n",
            "[Batch 4] Current Loss: 2.5141\n",
            "[Batch 5] Current Loss: 2.1505\n",
            "[Batch 6] Current Loss: 2.3900\n",
            "[Batch 7] Current Loss: 2.2456\n",
            "[Batch 8] Current Loss: 2.1742\n",
            "[Batch 9] Current Loss: 2.2797\n",
            "[Batch 0] Current Loss: 5.9955\n",
            "[Batch 1] Current Loss: 6.3741\n",
            "[Batch 2] Current Loss: 5.7829\n",
            "[Batch 3] Current Loss: 5.2373\n",
            "[Batch 4] Current Loss: 5.8301\n",
            "[Batch 5] Current Loss: 6.2740\n",
            "[Batch 6] Current Loss: 6.0836\n",
            "[Batch 7] Current Loss: 5.2001\n",
            "[Batch 8] Current Loss: 6.1708\n",
            "[Batch 9] Current Loss: 5.1789\n",
            "Ep 5 (Step 037520): Train loss 2.372, Val loss 5.813\n",
            "[Batch 0] Current Loss: 1.9358\n",
            "[Batch 1] Current Loss: 2.1459\n",
            "[Batch 2] Current Loss: 2.2562\n",
            "[Batch 3] Current Loss: 2.2289\n",
            "[Batch 4] Current Loss: 2.0616\n",
            "[Batch 5] Current Loss: 2.2820\n",
            "[Batch 6] Current Loss: 2.3589\n",
            "[Batch 7] Current Loss: 2.4491\n",
            "[Batch 8] Current Loss: 1.9791\n",
            "[Batch 9] Current Loss: 2.1537\n",
            "[Batch 0] Current Loss: 5.7403\n",
            "[Batch 1] Current Loss: 6.0863\n",
            "[Batch 2] Current Loss: 5.3865\n",
            "[Batch 3] Current Loss: 6.3560\n",
            "[Batch 4] Current Loss: 5.4779\n",
            "[Batch 5] Current Loss: 5.8421\n",
            "[Batch 6] Current Loss: 5.3185\n",
            "[Batch 7] Current Loss: 5.6543\n",
            "[Batch 8] Current Loss: 6.0772\n",
            "[Batch 9] Current Loss: 4.3980\n",
            "Ep 5 (Step 037540): Train loss 2.185, Val loss 5.634\n",
            "[Batch 0] Current Loss: 1.9077\n",
            "[Batch 1] Current Loss: 2.5939\n",
            "[Batch 2] Current Loss: 2.7402\n",
            "[Batch 3] Current Loss: 2.7454\n",
            "[Batch 4] Current Loss: 2.3178\n",
            "[Batch 5] Current Loss: 2.3236\n",
            "[Batch 6] Current Loss: 2.0405\n",
            "[Batch 7] Current Loss: 1.8708\n",
            "[Batch 8] Current Loss: 2.2728\n",
            "[Batch 9] Current Loss: 3.1750\n",
            "[Batch 0] Current Loss: 5.3512\n",
            "[Batch 1] Current Loss: 5.6556\n",
            "[Batch 2] Current Loss: 6.2397\n",
            "[Batch 3] Current Loss: 5.5999\n",
            "[Batch 4] Current Loss: 5.7490\n",
            "[Batch 5] Current Loss: 5.0334\n",
            "[Batch 6] Current Loss: 5.6952\n",
            "[Batch 7] Current Loss: 5.5797\n",
            "[Batch 8] Current Loss: 4.8100\n",
            "[Batch 9] Current Loss: 5.4953\n",
            "Ep 5 (Step 037560): Train loss 2.399, Val loss 5.521\n",
            "[Batch 0] Current Loss: 2.2083\n",
            "[Batch 1] Current Loss: 2.7120\n",
            "[Batch 2] Current Loss: 2.2798\n",
            "[Batch 3] Current Loss: 1.6292\n",
            "[Batch 4] Current Loss: 3.0612\n",
            "[Batch 5] Current Loss: 1.7965\n",
            "[Batch 6] Current Loss: 2.2033\n",
            "[Batch 7] Current Loss: 1.5049\n",
            "[Batch 8] Current Loss: 2.3824\n",
            "[Batch 9] Current Loss: 1.9218\n",
            "[Batch 0] Current Loss: 5.4601\n",
            "[Batch 1] Current Loss: 5.9697\n",
            "[Batch 2] Current Loss: 5.0978\n",
            "[Batch 3] Current Loss: 6.0614\n",
            "[Batch 4] Current Loss: 4.8506\n",
            "[Batch 5] Current Loss: 5.1580\n",
            "[Batch 6] Current Loss: 4.9676\n",
            "[Batch 7] Current Loss: 6.0654\n",
            "[Batch 8] Current Loss: 5.6507\n",
            "[Batch 9] Current Loss: 6.1805\n",
            "Ep 5 (Step 037580): Train loss 2.170, Val loss 5.546\n",
            "[Batch 0] Current Loss: 2.0154\n",
            "[Batch 1] Current Loss: 3.0178\n",
            "[Batch 2] Current Loss: 2.0835\n",
            "[Batch 3] Current Loss: 2.5381\n",
            "[Batch 4] Current Loss: 2.6695\n",
            "[Batch 5] Current Loss: 1.7477\n",
            "[Batch 6] Current Loss: 1.9551\n",
            "[Batch 7] Current Loss: 2.3862\n",
            "[Batch 8] Current Loss: 2.3086\n",
            "[Batch 9] Current Loss: 2.4230\n",
            "[Batch 0] Current Loss: 5.1232\n",
            "[Batch 1] Current Loss: 5.5870\n",
            "[Batch 2] Current Loss: 5.6805\n",
            "[Batch 3] Current Loss: 5.2878\n",
            "[Batch 4] Current Loss: 4.9019\n",
            "[Batch 5] Current Loss: 5.8346\n",
            "[Batch 6] Current Loss: 5.8832\n",
            "[Batch 7] Current Loss: 5.9013\n",
            "[Batch 8] Current Loss: 5.2277\n",
            "[Batch 9] Current Loss: 4.5639\n",
            "Ep 5 (Step 037600): Train loss 2.314, Val loss 5.399\n",
            "[Batch 0] Current Loss: 1.7608\n",
            "[Batch 1] Current Loss: 1.6961\n",
            "[Batch 2] Current Loss: 1.6155\n",
            "[Batch 3] Current Loss: 2.6956\n",
            "[Batch 4] Current Loss: 2.0851\n",
            "[Batch 5] Current Loss: 1.9433\n",
            "[Batch 6] Current Loss: 2.0559\n",
            "[Batch 7] Current Loss: 2.3136\n",
            "[Batch 8] Current Loss: 1.5741\n",
            "[Batch 9] Current Loss: 2.3916\n",
            "[Batch 0] Current Loss: 5.4281\n",
            "[Batch 1] Current Loss: 6.1936\n",
            "[Batch 2] Current Loss: 5.6406\n",
            "[Batch 3] Current Loss: 5.9237\n",
            "[Batch 4] Current Loss: 6.0793\n",
            "[Batch 5] Current Loss: 5.4314\n",
            "[Batch 6] Current Loss: 5.7918\n",
            "[Batch 7] Current Loss: 4.3448\n",
            "[Batch 8] Current Loss: 5.3464\n",
            "[Batch 9] Current Loss: 5.7510\n",
            "Ep 5 (Step 037620): Train loss 2.013, Val loss 5.593\n",
            "[Batch 0] Current Loss: 1.8588\n",
            "[Batch 1] Current Loss: 1.9047\n",
            "[Batch 2] Current Loss: 2.2497\n",
            "[Batch 3] Current Loss: 1.7991\n",
            "[Batch 4] Current Loss: 1.9462\n",
            "[Batch 5] Current Loss: 2.6033\n",
            "[Batch 6] Current Loss: 1.9544\n",
            "[Batch 7] Current Loss: 2.2144\n",
            "[Batch 8] Current Loss: 2.2340\n",
            "[Batch 9] Current Loss: 1.9630\n",
            "[Batch 0] Current Loss: 6.5488\n",
            "[Batch 1] Current Loss: 5.8196\n",
            "[Batch 2] Current Loss: 5.4083\n",
            "[Batch 3] Current Loss: 5.3788\n",
            "[Batch 4] Current Loss: 4.7747\n",
            "[Batch 5] Current Loss: 6.0091\n",
            "[Batch 6] Current Loss: 5.7113\n",
            "[Batch 7] Current Loss: 5.6233\n",
            "[Batch 8] Current Loss: 5.7079\n",
            "[Batch 9] Current Loss: 5.6965\n",
            "Ep 5 (Step 037640): Train loss 2.073, Val loss 5.668\n",
            "[Batch 0] Current Loss: 1.4325\n",
            "[Batch 1] Current Loss: 2.2840\n",
            "[Batch 2] Current Loss: 2.2127\n",
            "[Batch 3] Current Loss: 2.2746\n",
            "[Batch 4] Current Loss: 3.0175\n",
            "[Batch 5] Current Loss: 2.2578\n",
            "[Batch 6] Current Loss: 2.4240\n",
            "[Batch 7] Current Loss: 1.2813\n",
            "[Batch 8] Current Loss: 2.2407\n",
            "[Batch 9] Current Loss: 2.3269\n",
            "[Batch 0] Current Loss: 6.1325\n",
            "[Batch 1] Current Loss: 6.4672\n",
            "[Batch 2] Current Loss: 5.2244\n",
            "[Batch 3] Current Loss: 5.3579\n",
            "[Batch 4] Current Loss: 6.1718\n",
            "[Batch 5] Current Loss: 5.0309\n",
            "[Batch 6] Current Loss: 6.6210\n",
            "[Batch 7] Current Loss: 6.6946\n",
            "[Batch 8] Current Loss: 5.5548\n",
            "[Batch 9] Current Loss: 6.5267\n",
            "Ep 5 (Step 037660): Train loss 2.175, Val loss 5.978\n",
            "[Batch 0] Current Loss: 2.3243\n",
            "[Batch 1] Current Loss: 1.7821\n",
            "[Batch 2] Current Loss: 1.9177\n",
            "[Batch 3] Current Loss: 1.9753\n",
            "[Batch 4] Current Loss: 2.1178\n",
            "[Batch 5] Current Loss: 2.6784\n",
            "[Batch 6] Current Loss: 2.7090\n",
            "[Batch 7] Current Loss: 2.8498\n",
            "[Batch 8] Current Loss: 1.9141\n",
            "[Batch 9] Current Loss: 2.7118\n",
            "[Batch 0] Current Loss: 5.7583\n",
            "[Batch 1] Current Loss: 5.9489\n",
            "[Batch 2] Current Loss: 5.4721\n",
            "[Batch 3] Current Loss: 5.4037\n",
            "[Batch 4] Current Loss: 5.4001\n",
            "[Batch 5] Current Loss: 4.9435\n",
            "[Batch 6] Current Loss: 5.1462\n",
            "[Batch 7] Current Loss: 4.4186\n",
            "[Batch 8] Current Loss: 5.5355\n",
            "[Batch 9] Current Loss: 5.5069\n",
            "Ep 5 (Step 037680): Train loss 2.298, Val loss 5.353\n",
            "[Batch 0] Current Loss: 2.1140\n",
            "[Batch 1] Current Loss: 1.9184\n",
            "[Batch 2] Current Loss: 2.0970\n",
            "[Batch 3] Current Loss: 2.3219\n",
            "[Batch 4] Current Loss: 1.6344\n",
            "[Batch 5] Current Loss: 1.8779\n",
            "[Batch 6] Current Loss: 2.4454\n",
            "[Batch 7] Current Loss: 2.0612\n",
            "[Batch 8] Current Loss: 2.5550\n",
            "[Batch 9] Current Loss: 1.7287\n",
            "[Batch 0] Current Loss: 5.6126\n",
            "[Batch 1] Current Loss: 5.1205\n",
            "[Batch 2] Current Loss: 6.2340\n",
            "[Batch 3] Current Loss: 5.5275\n",
            "[Batch 4] Current Loss: 5.4799\n",
            "[Batch 5] Current Loss: 5.8977\n",
            "[Batch 6] Current Loss: 5.2011\n",
            "[Batch 7] Current Loss: 5.2969\n",
            "[Batch 8] Current Loss: 5.8877\n",
            "[Batch 9] Current Loss: 5.3634\n",
            "Ep 5 (Step 037700): Train loss 2.075, Val loss 5.562\n",
            "[Batch 0] Current Loss: 2.5972\n",
            "[Batch 1] Current Loss: 2.1096\n",
            "[Batch 2] Current Loss: 1.8357\n",
            "[Batch 3] Current Loss: 1.5087\n",
            "[Batch 4] Current Loss: 2.1053\n",
            "[Batch 5] Current Loss: 2.4027\n",
            "[Batch 6] Current Loss: 1.7292\n",
            "[Batch 7] Current Loss: 2.0712\n",
            "[Batch 8] Current Loss: 2.0327\n",
            "[Batch 9] Current Loss: 2.0122\n",
            "[Batch 0] Current Loss: 6.2119\n",
            "[Batch 1] Current Loss: 6.4528\n",
            "[Batch 2] Current Loss: 6.4387\n",
            "[Batch 3] Current Loss: 5.5806\n",
            "[Batch 4] Current Loss: 6.4232\n",
            "[Batch 5] Current Loss: 4.9243\n",
            "[Batch 6] Current Loss: 6.3952\n",
            "[Batch 7] Current Loss: 5.3421\n",
            "[Batch 8] Current Loss: 5.3221\n",
            "[Batch 9] Current Loss: 4.9383\n",
            "Ep 5 (Step 037720): Train loss 2.040, Val loss 5.803\n",
            "[Batch 0] Current Loss: 2.3879\n",
            "[Batch 1] Current Loss: 2.4489\n",
            "[Batch 2] Current Loss: 2.2038\n",
            "[Batch 3] Current Loss: 2.5939\n",
            "[Batch 4] Current Loss: 2.2205\n",
            "[Batch 5] Current Loss: 1.8248\n",
            "[Batch 6] Current Loss: 2.3520\n",
            "[Batch 7] Current Loss: 1.8676\n",
            "[Batch 8] Current Loss: 2.5406\n",
            "[Batch 9] Current Loss: 2.0937\n",
            "[Batch 0] Current Loss: 5.7282\n",
            "[Batch 1] Current Loss: 5.6873\n",
            "[Batch 2] Current Loss: 5.9213\n",
            "[Batch 3] Current Loss: 5.8730\n",
            "[Batch 4] Current Loss: 5.4289\n",
            "[Batch 5] Current Loss: 6.2286\n",
            "[Batch 6] Current Loss: 5.4544\n",
            "[Batch 7] Current Loss: 6.1565\n",
            "[Batch 8] Current Loss: 5.7507\n",
            "[Batch 9] Current Loss: 5.0113\n",
            "Ep 5 (Step 037740): Train loss 2.253, Val loss 5.724\n",
            "[Batch 0] Current Loss: 2.5771\n",
            "[Batch 1] Current Loss: 2.4944\n",
            "[Batch 2] Current Loss: 1.6873\n",
            "[Batch 3] Current Loss: 2.3492\n",
            "[Batch 4] Current Loss: 2.1189\n",
            "[Batch 5] Current Loss: 1.9982\n",
            "[Batch 6] Current Loss: 2.4609\n",
            "[Batch 7] Current Loss: 2.0875\n",
            "[Batch 8] Current Loss: 2.4349\n",
            "[Batch 9] Current Loss: 2.8663\n",
            "[Batch 0] Current Loss: 5.4898\n",
            "[Batch 1] Current Loss: 5.3691\n",
            "[Batch 2] Current Loss: 5.4189\n",
            "[Batch 3] Current Loss: 5.4529\n",
            "[Batch 4] Current Loss: 6.2988\n",
            "[Batch 5] Current Loss: 5.5768\n",
            "[Batch 6] Current Loss: 5.8823\n",
            "[Batch 7] Current Loss: 5.9734\n",
            "[Batch 8] Current Loss: 5.2227\n",
            "[Batch 9] Current Loss: 6.5528\n",
            "Ep 5 (Step 037760): Train loss 2.307, Val loss 5.724\n",
            "[Batch 0] Current Loss: 2.2031\n",
            "[Batch 1] Current Loss: 2.1482\n",
            "[Batch 2] Current Loss: 2.4228\n",
            "[Batch 3] Current Loss: 1.7690\n",
            "[Batch 4] Current Loss: 1.6338\n",
            "[Batch 5] Current Loss: 2.8803\n",
            "[Batch 6] Current Loss: 2.4328\n",
            "[Batch 7] Current Loss: 2.2429\n",
            "[Batch 8] Current Loss: 2.4275\n",
            "[Batch 9] Current Loss: 2.2247\n",
            "[Batch 0] Current Loss: 5.2871\n",
            "[Batch 1] Current Loss: 6.4607\n",
            "[Batch 2] Current Loss: 5.9899\n",
            "[Batch 3] Current Loss: 6.4770\n",
            "[Batch 4] Current Loss: 5.4583\n",
            "[Batch 5] Current Loss: 6.1063\n",
            "[Batch 6] Current Loss: 5.7935\n",
            "[Batch 7] Current Loss: 6.1491\n",
            "[Batch 8] Current Loss: 5.2507\n",
            "[Batch 9] Current Loss: 5.4385\n",
            "Ep 5 (Step 037780): Train loss 2.239, Val loss 5.841\n",
            "[Batch 0] Current Loss: 2.6134\n",
            "[Batch 1] Current Loss: 2.1921\n",
            "[Batch 2] Current Loss: 2.2573\n",
            "[Batch 3] Current Loss: 2.0176\n",
            "[Batch 4] Current Loss: 1.9064\n",
            "[Batch 5] Current Loss: 2.1117\n",
            "[Batch 6] Current Loss: 1.8509\n",
            "[Batch 7] Current Loss: 2.0873\n",
            "[Batch 8] Current Loss: 1.6651\n",
            "[Batch 9] Current Loss: 1.2441\n",
            "[Batch 0] Current Loss: 5.6904\n",
            "[Batch 1] Current Loss: 6.0686\n",
            "[Batch 2] Current Loss: 4.8570\n",
            "[Batch 3] Current Loss: 5.9468\n",
            "[Batch 4] Current Loss: 5.5764\n",
            "[Batch 5] Current Loss: 5.2813\n",
            "[Batch 6] Current Loss: 6.1030\n",
            "[Batch 7] Current Loss: 5.0253\n",
            "[Batch 8] Current Loss: 5.3273\n",
            "[Batch 9] Current Loss: 5.7967\n",
            "Ep 5 (Step 037800): Train loss 1.995, Val loss 5.567\n",
            "[Batch 0] Current Loss: 1.6445\n",
            "[Batch 1] Current Loss: 2.7144\n",
            "[Batch 2] Current Loss: 2.1867\n",
            "[Batch 3] Current Loss: 1.9416\n",
            "[Batch 4] Current Loss: 2.9010\n",
            "[Batch 5] Current Loss: 2.7169\n",
            "[Batch 6] Current Loss: 2.2895\n",
            "[Batch 7] Current Loss: 1.8584\n",
            "[Batch 8] Current Loss: 2.0503\n",
            "[Batch 9] Current Loss: 2.3809\n",
            "[Batch 0] Current Loss: 5.7502\n",
            "[Batch 1] Current Loss: 5.9740\n",
            "[Batch 2] Current Loss: 5.4017\n",
            "[Batch 3] Current Loss: 6.2594\n",
            "[Batch 4] Current Loss: 5.6647\n",
            "[Batch 5] Current Loss: 5.8024\n",
            "[Batch 6] Current Loss: 5.7789\n",
            "[Batch 7] Current Loss: 5.9420\n",
            "[Batch 8] Current Loss: 6.2095\n",
            "[Batch 9] Current Loss: 5.8923\n",
            "Ep 5 (Step 037820): Train loss 2.268, Val loss 5.868\n",
            "[Batch 0] Current Loss: 1.9152\n",
            "[Batch 1] Current Loss: 2.1907\n",
            "[Batch 2] Current Loss: 1.7558\n",
            "[Batch 3] Current Loss: 2.2043\n",
            "[Batch 4] Current Loss: 2.3429\n",
            "[Batch 5] Current Loss: 1.6822\n",
            "[Batch 6] Current Loss: 2.9886\n",
            "[Batch 7] Current Loss: 1.7495\n",
            "[Batch 8] Current Loss: 2.8152\n",
            "[Batch 9] Current Loss: 1.7747\n",
            "[Batch 0] Current Loss: 5.5178\n",
            "[Batch 1] Current Loss: 6.2216\n",
            "[Batch 2] Current Loss: 5.2905\n",
            "[Batch 3] Current Loss: 4.9088\n",
            "[Batch 4] Current Loss: 5.1942\n",
            "[Batch 5] Current Loss: 5.6481\n",
            "[Batch 6] Current Loss: 5.2985\n",
            "[Batch 7] Current Loss: 6.6207\n",
            "[Batch 8] Current Loss: 6.0605\n",
            "[Batch 9] Current Loss: 4.9645\n",
            "Ep 5 (Step 037840): Train loss 2.142, Val loss 5.573\n",
            "[Batch 0] Current Loss: 1.6589\n",
            "[Batch 1] Current Loss: 1.7290\n",
            "[Batch 2] Current Loss: 2.1376\n",
            "[Batch 3] Current Loss: 2.1283\n",
            "[Batch 4] Current Loss: 2.1820\n",
            "[Batch 5] Current Loss: 2.4753\n",
            "[Batch 6] Current Loss: 2.2365\n",
            "[Batch 7] Current Loss: 2.0685\n",
            "[Batch 8] Current Loss: 2.0303\n",
            "[Batch 9] Current Loss: 2.3355\n",
            "[Batch 0] Current Loss: 4.9494\n",
            "[Batch 1] Current Loss: 6.1920\n",
            "[Batch 2] Current Loss: 5.6253\n",
            "[Batch 3] Current Loss: 5.2840\n",
            "[Batch 4] Current Loss: 6.1972\n",
            "[Batch 5] Current Loss: 5.4106\n",
            "[Batch 6] Current Loss: 6.1839\n",
            "[Batch 7] Current Loss: 6.0493\n",
            "[Batch 8] Current Loss: 6.4039\n",
            "[Batch 9] Current Loss: 6.1758\n",
            "Ep 5 (Step 037860): Train loss 2.098, Val loss 5.847\n",
            "[Batch 0] Current Loss: 2.1483\n",
            "[Batch 1] Current Loss: 2.4613\n",
            "[Batch 2] Current Loss: 2.3496\n",
            "[Batch 3] Current Loss: 1.1468\n",
            "[Batch 4] Current Loss: 2.2659\n",
            "[Batch 5] Current Loss: 2.5286\n",
            "[Batch 6] Current Loss: 2.9441\n",
            "[Batch 7] Current Loss: 1.5125\n",
            "[Batch 8] Current Loss: 1.8326\n",
            "[Batch 9] Current Loss: 2.0324\n",
            "[Batch 0] Current Loss: 4.7573\n",
            "[Batch 1] Current Loss: 5.8484\n",
            "[Batch 2] Current Loss: 5.9380\n",
            "[Batch 3] Current Loss: 6.0813\n",
            "[Batch 4] Current Loss: 5.8066\n",
            "[Batch 5] Current Loss: 6.4986\n",
            "[Batch 6] Current Loss: 5.8513\n",
            "[Batch 7] Current Loss: 5.8811\n",
            "[Batch 8] Current Loss: 5.0980\n",
            "[Batch 9] Current Loss: 5.6538\n",
            "Ep 5 (Step 037880): Train loss 2.122, Val loss 5.741\n",
            "[Batch 0] Current Loss: 1.7769\n",
            "[Batch 1] Current Loss: 2.0999\n",
            "[Batch 2] Current Loss: 2.9270\n",
            "[Batch 3] Current Loss: 1.8431\n",
            "[Batch 4] Current Loss: 2.1858\n",
            "[Batch 5] Current Loss: 2.3543\n",
            "[Batch 6] Current Loss: 1.3947\n",
            "[Batch 7] Current Loss: 2.3338\n",
            "[Batch 8] Current Loss: 1.8312\n",
            "[Batch 9] Current Loss: 2.1693\n",
            "[Batch 0] Current Loss: 6.7807\n",
            "[Batch 1] Current Loss: 6.2297\n",
            "[Batch 2] Current Loss: 6.3990\n",
            "[Batch 3] Current Loss: 5.3485\n",
            "[Batch 4] Current Loss: 5.2651\n",
            "[Batch 5] Current Loss: 5.9149\n",
            "[Batch 6] Current Loss: 5.8245\n",
            "[Batch 7] Current Loss: 5.6527\n",
            "[Batch 8] Current Loss: 5.0256\n",
            "[Batch 9] Current Loss: 6.0158\n",
            "Ep 5 (Step 037900): Train loss 2.092, Val loss 5.846\n",
            "[Batch 0] Current Loss: 2.7710\n",
            "[Batch 1] Current Loss: 1.7806\n",
            "[Batch 2] Current Loss: 1.7930\n",
            "[Batch 3] Current Loss: 2.6364\n",
            "[Batch 4] Current Loss: 2.2951\n",
            "[Batch 5] Current Loss: 2.3029\n",
            "[Batch 6] Current Loss: 2.1616\n",
            "[Batch 7] Current Loss: 1.6352\n",
            "[Batch 8] Current Loss: 2.7341\n",
            "[Batch 9] Current Loss: 2.7734\n",
            "[Batch 0] Current Loss: 5.2031\n",
            "[Batch 1] Current Loss: 5.2064\n",
            "[Batch 2] Current Loss: 5.8066\n",
            "[Batch 3] Current Loss: 5.7117\n",
            "[Batch 4] Current Loss: 6.2322\n",
            "[Batch 5] Current Loss: 5.4673\n",
            "[Batch 6] Current Loss: 5.3359\n",
            "[Batch 7] Current Loss: 5.8395\n",
            "[Batch 8] Current Loss: 5.0532\n",
            "[Batch 9] Current Loss: 5.4830\n",
            "Ep 5 (Step 037920): Train loss 2.288, Val loss 5.534\n",
            "[Batch 0] Current Loss: 1.6917\n",
            "[Batch 1] Current Loss: 1.5297\n",
            "[Batch 2] Current Loss: 1.8455\n",
            "[Batch 3] Current Loss: 2.2062\n",
            "[Batch 4] Current Loss: 2.1598\n",
            "[Batch 5] Current Loss: 2.5734\n",
            "[Batch 6] Current Loss: 2.7439\n",
            "[Batch 7] Current Loss: 2.2020\n",
            "[Batch 8] Current Loss: 1.7883\n",
            "[Batch 9] Current Loss: 1.8212\n",
            "[Batch 0] Current Loss: 5.2065\n",
            "[Batch 1] Current Loss: 5.8316\n",
            "[Batch 2] Current Loss: 5.9702\n",
            "[Batch 3] Current Loss: 6.2435\n",
            "[Batch 4] Current Loss: 5.1480\n",
            "[Batch 5] Current Loss: 5.6219\n",
            "[Batch 6] Current Loss: 4.7153\n",
            "[Batch 7] Current Loss: 6.1685\n",
            "[Batch 8] Current Loss: 6.1209\n",
            "[Batch 9] Current Loss: 5.2736\n",
            "Ep 5 (Step 037940): Train loss 2.056, Val loss 5.630\n",
            "[Batch 0] Current Loss: 2.8968\n",
            "[Batch 1] Current Loss: 2.3930\n",
            "[Batch 2] Current Loss: 2.0158\n",
            "[Batch 3] Current Loss: 2.2316\n",
            "[Batch 4] Current Loss: 1.6724\n",
            "[Batch 5] Current Loss: 2.9967\n",
            "[Batch 6] Current Loss: 2.3129\n",
            "[Batch 7] Current Loss: 2.3558\n",
            "[Batch 8] Current Loss: 1.7091\n",
            "[Batch 9] Current Loss: 2.7257\n",
            "[Batch 0] Current Loss: 5.9258\n",
            "[Batch 1] Current Loss: 5.7445\n",
            "[Batch 2] Current Loss: 6.1215\n",
            "[Batch 3] Current Loss: 5.7376\n",
            "[Batch 4] Current Loss: 6.4792\n",
            "[Batch 5] Current Loss: 6.1804\n",
            "[Batch 6] Current Loss: 5.6193\n",
            "[Batch 7] Current Loss: 5.6744\n",
            "[Batch 8] Current Loss: 5.6893\n",
            "[Batch 9] Current Loss: 5.5775\n",
            "Ep 5 (Step 037960): Train loss 2.331, Val loss 5.875\n",
            "[Batch 0] Current Loss: 1.8363\n",
            "[Batch 1] Current Loss: 2.2540\n",
            "[Batch 2] Current Loss: 1.7149\n",
            "[Batch 3] Current Loss: 2.6414\n",
            "[Batch 4] Current Loss: 2.0300\n",
            "[Batch 5] Current Loss: 2.1482\n",
            "[Batch 6] Current Loss: 2.3950\n",
            "[Batch 7] Current Loss: 2.4812\n",
            "[Batch 8] Current Loss: 2.2022\n",
            "[Batch 9] Current Loss: 1.4315\n",
            "[Batch 0] Current Loss: 5.6267\n",
            "[Batch 1] Current Loss: 5.8731\n",
            "[Batch 2] Current Loss: 5.7571\n",
            "[Batch 3] Current Loss: 4.5804\n",
            "[Batch 4] Current Loss: 5.6375\n",
            "[Batch 5] Current Loss: 5.8664\n",
            "[Batch 6] Current Loss: 6.0621\n",
            "[Batch 7] Current Loss: 6.1555\n",
            "[Batch 8] Current Loss: 5.9608\n",
            "[Batch 9] Current Loss: 5.1732\n",
            "Ep 5 (Step 037980): Train loss 2.113, Val loss 5.669\n",
            "[Batch 0] Current Loss: 2.7260\n",
            "[Batch 1] Current Loss: 1.6515\n",
            "[Batch 2] Current Loss: 1.8485\n",
            "[Batch 3] Current Loss: 1.8282\n",
            "[Batch 4] Current Loss: 2.0951\n",
            "[Batch 5] Current Loss: 2.7622\n",
            "[Batch 6] Current Loss: 2.4181\n",
            "[Batch 7] Current Loss: 2.5840\n",
            "[Batch 8] Current Loss: 2.5506\n",
            "[Batch 9] Current Loss: 2.4647\n",
            "[Batch 0] Current Loss: 6.0235\n",
            "[Batch 1] Current Loss: 6.1759\n",
            "[Batch 2] Current Loss: 5.7060\n",
            "[Batch 3] Current Loss: 5.8403\n",
            "[Batch 4] Current Loss: 6.1851\n",
            "[Batch 5] Current Loss: 6.0819\n",
            "[Batch 6] Current Loss: 5.9294\n",
            "[Batch 7] Current Loss: 5.6912\n",
            "[Batch 8] Current Loss: 5.7325\n",
            "[Batch 9] Current Loss: 6.2013\n",
            "Ep 5 (Step 038000): Train loss 2.293, Val loss 5.957\n",
            "[Batch 0] Current Loss: 2.2793\n",
            "[Batch 1] Current Loss: 1.9888\n",
            "[Batch 2] Current Loss: 2.2526\n",
            "[Batch 3] Current Loss: 1.8534\n",
            "[Batch 4] Current Loss: 2.1806\n",
            "[Batch 5] Current Loss: 2.1274\n",
            "[Batch 6] Current Loss: 2.3398\n",
            "[Batch 7] Current Loss: 2.5397\n",
            "[Batch 8] Current Loss: 2.3851\n",
            "[Batch 9] Current Loss: 2.5198\n",
            "[Batch 0] Current Loss: 5.8570\n",
            "[Batch 1] Current Loss: 6.2727\n",
            "[Batch 2] Current Loss: 5.8586\n",
            "[Batch 3] Current Loss: 4.6045\n",
            "[Batch 4] Current Loss: 5.7211\n",
            "[Batch 5] Current Loss: 5.6541\n",
            "[Batch 6] Current Loss: 5.8277\n",
            "[Batch 7] Current Loss: 5.3828\n",
            "[Batch 8] Current Loss: 6.5607\n",
            "[Batch 9] Current Loss: 5.4065\n",
            "Ep 5 (Step 038020): Train loss 2.247, Val loss 5.715\n",
            "[Batch 0] Current Loss: 2.2696\n",
            "[Batch 1] Current Loss: 2.6538\n",
            "[Batch 2] Current Loss: 1.6952\n",
            "[Batch 3] Current Loss: 2.0531\n",
            "[Batch 4] Current Loss: 2.1111\n",
            "[Batch 5] Current Loss: 2.3739\n",
            "[Batch 6] Current Loss: 1.8747\n",
            "[Batch 7] Current Loss: 2.2475\n",
            "[Batch 8] Current Loss: 2.2814\n",
            "[Batch 9] Current Loss: 2.0978\n",
            "[Batch 0] Current Loss: 5.5456\n",
            "[Batch 1] Current Loss: 6.3155\n",
            "[Batch 2] Current Loss: 6.0293\n",
            "[Batch 3] Current Loss: 6.0964\n",
            "[Batch 4] Current Loss: 4.9704\n",
            "[Batch 5] Current Loss: 5.7156\n",
            "[Batch 6] Current Loss: 6.3284\n",
            "[Batch 7] Current Loss: 4.8950\n",
            "[Batch 8] Current Loss: 5.8356\n",
            "[Batch 9] Current Loss: 6.1699\n",
            "Ep 5 (Step 038040): Train loss 2.166, Val loss 5.790\n",
            "[Batch 0] Current Loss: 2.7741\n",
            "[Batch 1] Current Loss: 2.6110\n",
            "[Batch 2] Current Loss: 1.9915\n",
            "[Batch 3] Current Loss: 2.5846\n",
            "[Batch 4] Current Loss: 1.6154\n",
            "[Batch 5] Current Loss: 1.9876\n",
            "[Batch 6] Current Loss: 2.1492\n",
            "[Batch 7] Current Loss: 2.6535\n",
            "[Batch 8] Current Loss: 2.1942\n",
            "[Batch 9] Current Loss: 1.9562\n",
            "[Batch 0] Current Loss: 5.3603\n",
            "[Batch 1] Current Loss: 5.4732\n",
            "[Batch 2] Current Loss: 5.3539\n",
            "[Batch 3] Current Loss: 5.0711\n",
            "[Batch 4] Current Loss: 5.9616\n",
            "[Batch 5] Current Loss: 5.6830\n",
            "[Batch 6] Current Loss: 4.9677\n",
            "[Batch 7] Current Loss: 5.4881\n",
            "[Batch 8] Current Loss: 5.5953\n",
            "[Batch 9] Current Loss: 5.0178\n",
            "Ep 5 (Step 038060): Train loss 2.252, Val loss 5.397\n",
            "[Batch 0] Current Loss: 1.8201\n",
            "[Batch 1] Current Loss: 1.4756\n",
            "[Batch 2] Current Loss: 2.6821\n",
            "[Batch 3] Current Loss: 2.6240\n",
            "[Batch 4] Current Loss: 1.6298\n",
            "[Batch 5] Current Loss: 2.4277\n",
            "[Batch 6] Current Loss: 2.2464\n",
            "[Batch 7] Current Loss: 2.3441\n",
            "[Batch 8] Current Loss: 2.1268\n",
            "[Batch 9] Current Loss: 2.0000\n",
            "[Batch 0] Current Loss: 5.2055\n",
            "[Batch 1] Current Loss: 6.0756\n",
            "[Batch 2] Current Loss: 5.2127\n",
            "[Batch 3] Current Loss: 5.4682\n",
            "[Batch 4] Current Loss: 5.0754\n",
            "[Batch 5] Current Loss: 5.9152\n",
            "[Batch 6] Current Loss: 5.7856\n",
            "[Batch 7] Current Loss: 5.5171\n",
            "[Batch 8] Current Loss: 6.2178\n",
            "[Batch 9] Current Loss: 5.3349\n",
            "Ep 5 (Step 038080): Train loss 2.138, Val loss 5.581\n",
            "[Batch 0] Current Loss: 2.2327\n",
            "[Batch 1] Current Loss: 1.9861\n",
            "[Batch 2] Current Loss: 2.8294\n",
            "[Batch 3] Current Loss: 2.0782\n",
            "[Batch 4] Current Loss: 2.3713\n",
            "[Batch 5] Current Loss: 1.5960\n",
            "[Batch 6] Current Loss: 2.6874\n",
            "[Batch 7] Current Loss: 2.1146\n",
            "[Batch 8] Current Loss: 2.0695\n",
            "[Batch 9] Current Loss: 2.5704\n",
            "[Batch 0] Current Loss: 6.2036\n",
            "[Batch 1] Current Loss: 5.6823\n",
            "[Batch 2] Current Loss: 6.5708\n",
            "[Batch 3] Current Loss: 6.0805\n",
            "[Batch 4] Current Loss: 5.2967\n",
            "[Batch 5] Current Loss: 5.3830\n",
            "[Batch 6] Current Loss: 6.3748\n",
            "[Batch 7] Current Loss: 6.6621\n",
            "[Batch 8] Current Loss: 5.2969\n",
            "[Batch 9] Current Loss: 4.7352\n",
            "Ep 5 (Step 038100): Train loss 2.254, Val loss 5.829\n",
            "[Batch 0] Current Loss: 2.1371\n",
            "[Batch 1] Current Loss: 2.2635\n",
            "[Batch 2] Current Loss: 2.1837\n",
            "[Batch 3] Current Loss: 1.9290\n",
            "[Batch 4] Current Loss: 1.5583\n",
            "[Batch 5] Current Loss: 1.7073\n",
            "[Batch 6] Current Loss: 1.7747\n",
            "[Batch 7] Current Loss: 1.7958\n",
            "[Batch 8] Current Loss: 2.0706\n",
            "[Batch 9] Current Loss: 2.1365\n",
            "[Batch 0] Current Loss: 6.3475\n",
            "[Batch 1] Current Loss: 6.5131\n",
            "[Batch 2] Current Loss: 5.6335\n",
            "[Batch 3] Current Loss: 6.0192\n",
            "[Batch 4] Current Loss: 5.0457\n",
            "[Batch 5] Current Loss: 5.9803\n",
            "[Batch 6] Current Loss: 5.3017\n",
            "[Batch 7] Current Loss: 6.6718\n",
            "[Batch 8] Current Loss: 5.4672\n",
            "[Batch 9] Current Loss: 5.5076\n",
            "Ep 5 (Step 038120): Train loss 1.956, Val loss 5.849\n",
            "[Batch 0] Current Loss: 2.3007\n",
            "[Batch 1] Current Loss: 2.0423\n",
            "[Batch 2] Current Loss: 2.0003\n",
            "[Batch 3] Current Loss: 2.2151\n",
            "[Batch 4] Current Loss: 1.6978\n",
            "[Batch 5] Current Loss: 2.2016\n",
            "[Batch 6] Current Loss: 2.1343\n",
            "[Batch 7] Current Loss: 2.2576\n",
            "[Batch 8] Current Loss: 2.7902\n",
            "[Batch 9] Current Loss: 2.3376\n",
            "[Batch 0] Current Loss: 6.2352\n",
            "[Batch 1] Current Loss: 5.2765\n",
            "[Batch 2] Current Loss: 6.2775\n",
            "[Batch 3] Current Loss: 5.3396\n",
            "[Batch 4] Current Loss: 5.8847\n",
            "[Batch 5] Current Loss: 6.4306\n",
            "[Batch 6] Current Loss: 6.0351\n",
            "[Batch 7] Current Loss: 6.1808\n",
            "[Batch 8] Current Loss: 5.6483\n",
            "[Batch 9] Current Loss: 4.8784\n",
            "Ep 5 (Step 038140): Train loss 2.198, Val loss 5.819\n",
            "[Batch 0] Current Loss: 2.0726\n",
            "[Batch 1] Current Loss: 1.6984\n",
            "[Batch 2] Current Loss: 2.2237\n",
            "[Batch 3] Current Loss: 2.1026\n",
            "[Batch 4] Current Loss: 2.6321\n",
            "[Batch 5] Current Loss: 2.0444\n",
            "[Batch 6] Current Loss: 1.9451\n",
            "[Batch 7] Current Loss: 1.8965\n",
            "[Batch 8] Current Loss: 2.1406\n",
            "[Batch 9] Current Loss: 2.4574\n",
            "[Batch 0] Current Loss: 6.1879\n",
            "[Batch 1] Current Loss: 5.6536\n",
            "[Batch 2] Current Loss: 6.1523\n",
            "[Batch 3] Current Loss: 5.4611\n",
            "[Batch 4] Current Loss: 5.7199\n",
            "[Batch 5] Current Loss: 5.0917\n",
            "[Batch 6] Current Loss: 5.4058\n",
            "[Batch 7] Current Loss: 5.8091\n",
            "[Batch 8] Current Loss: 5.8804\n",
            "[Batch 9] Current Loss: 6.1377\n",
            "Ep 5 (Step 038160): Train loss 2.121, Val loss 5.750\n",
            "[Batch 0] Current Loss: 1.9236\n",
            "[Batch 1] Current Loss: 2.2417\n",
            "[Batch 2] Current Loss: 2.2163\n",
            "[Batch 3] Current Loss: 2.1192\n",
            "[Batch 4] Current Loss: 2.0418\n",
            "[Batch 5] Current Loss: 2.1939\n",
            "[Batch 6] Current Loss: 2.1165\n",
            "[Batch 7] Current Loss: 2.5881\n",
            "[Batch 8] Current Loss: 2.3957\n",
            "[Batch 9] Current Loss: 2.5120\n",
            "[Batch 0] Current Loss: 5.9495\n",
            "[Batch 1] Current Loss: 5.6589\n",
            "[Batch 2] Current Loss: 5.6177\n",
            "[Batch 3] Current Loss: 5.7430\n",
            "[Batch 4] Current Loss: 5.4384\n",
            "[Batch 5] Current Loss: 4.6776\n",
            "[Batch 6] Current Loss: 6.4094\n",
            "[Batch 7] Current Loss: 5.6256\n",
            "[Batch 8] Current Loss: 6.5981\n",
            "[Batch 9] Current Loss: 5.0701\n",
            "Ep 5 (Step 038180): Train loss 2.235, Val loss 5.679\n",
            "[Batch 0] Current Loss: 1.4878\n",
            "[Batch 1] Current Loss: 2.6693\n",
            "[Batch 2] Current Loss: 2.4249\n",
            "[Batch 3] Current Loss: 1.7274\n",
            "[Batch 4] Current Loss: 1.8439\n",
            "[Batch 5] Current Loss: 2.0843\n",
            "[Batch 6] Current Loss: 1.7081\n",
            "[Batch 7] Current Loss: 2.0256\n",
            "[Batch 8] Current Loss: 2.0928\n",
            "[Batch 9] Current Loss: 2.3238\n",
            "[Batch 0] Current Loss: 5.2327\n",
            "[Batch 1] Current Loss: 5.0033\n",
            "[Batch 2] Current Loss: 5.5841\n",
            "[Batch 3] Current Loss: 6.8279\n",
            "[Batch 4] Current Loss: 6.0411\n",
            "[Batch 5] Current Loss: 7.0715\n",
            "[Batch 6] Current Loss: 5.6922\n",
            "[Batch 7] Current Loss: 5.1393\n",
            "[Batch 8] Current Loss: 6.0940\n",
            "[Batch 9] Current Loss: 5.0846\n",
            "Ep 5 (Step 038200): Train loss 2.039, Val loss 5.777\n",
            "[Batch 0] Current Loss: 1.4414\n",
            "[Batch 1] Current Loss: 2.0454\n",
            "[Batch 2] Current Loss: 1.9848\n",
            "[Batch 3] Current Loss: 2.3082\n",
            "[Batch 4] Current Loss: 2.6048\n",
            "[Batch 5] Current Loss: 1.9010\n",
            "[Batch 6] Current Loss: 2.6094\n",
            "[Batch 7] Current Loss: 2.1882\n",
            "[Batch 8] Current Loss: 3.0503\n",
            "[Batch 9] Current Loss: 2.3106\n",
            "[Batch 0] Current Loss: 5.6239\n",
            "[Batch 1] Current Loss: 6.6741\n",
            "[Batch 2] Current Loss: 6.3891\n",
            "[Batch 3] Current Loss: 4.8664\n",
            "[Batch 4] Current Loss: 6.1576\n",
            "[Batch 5] Current Loss: 5.1893\n",
            "[Batch 6] Current Loss: 5.4900\n",
            "[Batch 7] Current Loss: 5.6074\n",
            "[Batch 8] Current Loss: 5.9652\n",
            "[Batch 9] Current Loss: 6.1247\n",
            "Ep 5 (Step 038220): Train loss 2.244, Val loss 5.809\n",
            "[Batch 0] Current Loss: 2.2598\n",
            "[Batch 1] Current Loss: 2.1463\n",
            "[Batch 2] Current Loss: 1.7255\n",
            "[Batch 3] Current Loss: 1.8708\n",
            "[Batch 4] Current Loss: 2.0040\n",
            "[Batch 5] Current Loss: 2.3484\n",
            "[Batch 6] Current Loss: 1.9706\n",
            "[Batch 7] Current Loss: 2.2735\n",
            "[Batch 8] Current Loss: 1.7624\n",
            "[Batch 9] Current Loss: 1.8833\n",
            "[Batch 0] Current Loss: 5.1886\n",
            "[Batch 1] Current Loss: 5.3718\n",
            "[Batch 2] Current Loss: 6.3125\n",
            "[Batch 3] Current Loss: 4.6087\n",
            "[Batch 4] Current Loss: 6.4779\n",
            "[Batch 5] Current Loss: 6.0428\n",
            "[Batch 6] Current Loss: 5.8745\n",
            "[Batch 7] Current Loss: 5.7796\n",
            "[Batch 8] Current Loss: 4.9125\n",
            "[Batch 9] Current Loss: 5.4545\n",
            "Ep 5 (Step 038240): Train loss 2.024, Val loss 5.602\n",
            "[Batch 0] Current Loss: 2.4059\n",
            "[Batch 1] Current Loss: 1.7446\n",
            "[Batch 2] Current Loss: 1.8042\n",
            "[Batch 3] Current Loss: 2.7366\n",
            "[Batch 4] Current Loss: 2.2861\n",
            "[Batch 5] Current Loss: 1.9780\n",
            "[Batch 6] Current Loss: 2.1655\n",
            "[Batch 7] Current Loss: 1.9862\n",
            "[Batch 8] Current Loss: 2.4096\n",
            "[Batch 9] Current Loss: 2.3781\n",
            "[Batch 0] Current Loss: 5.6427\n",
            "[Batch 1] Current Loss: 5.5275\n",
            "[Batch 2] Current Loss: 4.9889\n",
            "[Batch 3] Current Loss: 5.2239\n",
            "[Batch 4] Current Loss: 5.5051\n",
            "[Batch 5] Current Loss: 5.8489\n",
            "[Batch 6] Current Loss: 5.9348\n",
            "[Batch 7] Current Loss: 7.0056\n",
            "[Batch 8] Current Loss: 5.6578\n",
            "[Batch 9] Current Loss: 6.1635\n",
            "Ep 5 (Step 038260): Train loss 2.189, Val loss 5.750\n",
            "[Batch 0] Current Loss: 2.2399\n",
            "[Batch 1] Current Loss: 1.9092\n",
            "[Batch 2] Current Loss: 2.3858\n",
            "[Batch 3] Current Loss: 2.1903\n",
            "[Batch 4] Current Loss: 2.3164\n",
            "[Batch 5] Current Loss: 1.9220\n",
            "[Batch 6] Current Loss: 2.2876\n",
            "[Batch 7] Current Loss: 1.7314\n",
            "[Batch 8] Current Loss: 1.9995\n",
            "[Batch 9] Current Loss: 2.2712\n",
            "[Batch 0] Current Loss: 5.4733\n",
            "[Batch 1] Current Loss: 5.0217\n",
            "[Batch 2] Current Loss: 6.0834\n",
            "[Batch 3] Current Loss: 5.2093\n",
            "[Batch 4] Current Loss: 5.4562\n",
            "[Batch 5] Current Loss: 6.3590\n",
            "[Batch 6] Current Loss: 6.3289\n",
            "[Batch 7] Current Loss: 4.8568\n",
            "[Batch 8] Current Loss: 5.8167\n",
            "[Batch 9] Current Loss: 5.8362\n",
            "Ep 5 (Step 038280): Train loss 2.125, Val loss 5.644\n",
            "[Batch 0] Current Loss: 2.3677\n",
            "[Batch 1] Current Loss: 2.3714\n",
            "[Batch 2] Current Loss: 2.6628\n",
            "[Batch 3] Current Loss: 2.1314\n",
            "[Batch 4] Current Loss: 2.0327\n",
            "[Batch 5] Current Loss: 2.0390\n",
            "[Batch 6] Current Loss: 2.5978\n",
            "[Batch 7] Current Loss: 2.1532\n",
            "[Batch 8] Current Loss: 2.2331\n",
            "[Batch 9] Current Loss: 1.9442\n",
            "[Batch 0] Current Loss: 5.3081\n",
            "[Batch 1] Current Loss: 6.4536\n",
            "[Batch 2] Current Loss: 6.2289\n",
            "[Batch 3] Current Loss: 5.6894\n",
            "[Batch 4] Current Loss: 5.9872\n",
            "[Batch 5] Current Loss: 6.1582\n",
            "[Batch 6] Current Loss: 5.5419\n",
            "[Batch 7] Current Loss: 6.7213\n",
            "[Batch 8] Current Loss: 5.6504\n",
            "[Batch 9] Current Loss: 5.3268\n",
            "Ep 5 (Step 038300): Train loss 2.253, Val loss 5.907\n",
            "[Batch 0] Current Loss: 2.7051\n",
            "[Batch 1] Current Loss: 2.0792\n",
            "[Batch 2] Current Loss: 1.7188\n",
            "[Batch 3] Current Loss: 2.0444\n",
            "[Batch 4] Current Loss: 1.8763\n",
            "[Batch 5] Current Loss: 1.9378\n",
            "[Batch 6] Current Loss: 3.0098\n",
            "[Batch 7] Current Loss: 2.5553\n",
            "[Batch 8] Current Loss: 2.3067\n",
            "[Batch 9] Current Loss: 2.2168\n",
            "[Batch 0] Current Loss: 5.6108\n",
            "[Batch 1] Current Loss: 5.5757\n",
            "[Batch 2] Current Loss: 6.5045\n",
            "[Batch 3] Current Loss: 6.6957\n",
            "[Batch 4] Current Loss: 5.9193\n",
            "[Batch 5] Current Loss: 5.9018\n",
            "[Batch 6] Current Loss: 5.2431\n",
            "[Batch 7] Current Loss: 6.3739\n",
            "[Batch 8] Current Loss: 6.0704\n",
            "[Batch 9] Current Loss: 5.6830\n",
            "Ep 5 (Step 038320): Train loss 2.245, Val loss 5.958\n",
            "[Batch 0] Current Loss: 1.8151\n",
            "[Batch 1] Current Loss: 2.2371\n",
            "[Batch 2] Current Loss: 2.1156\n",
            "[Batch 3] Current Loss: 1.9909\n",
            "[Batch 4] Current Loss: 1.7917\n",
            "[Batch 5] Current Loss: 2.3885\n",
            "[Batch 6] Current Loss: 1.9318\n",
            "[Batch 7] Current Loss: 2.2106\n",
            "[Batch 8] Current Loss: 2.3010\n",
            "[Batch 9] Current Loss: 1.9706\n",
            "[Batch 0] Current Loss: 5.1332\n",
            "[Batch 1] Current Loss: 5.5536\n",
            "[Batch 2] Current Loss: 5.0129\n",
            "[Batch 3] Current Loss: 5.5021\n",
            "[Batch 4] Current Loss: 5.2435\n",
            "[Batch 5] Current Loss: 5.1085\n",
            "[Batch 6] Current Loss: 6.2019\n",
            "[Batch 7] Current Loss: 5.1539\n",
            "[Batch 8] Current Loss: 4.9332\n",
            "[Batch 9] Current Loss: 6.0123\n",
            "Ep 5 (Step 038340): Train loss 2.075, Val loss 5.386\n",
            "[Batch 0] Current Loss: 2.6478\n",
            "[Batch 1] Current Loss: 2.8262\n",
            "[Batch 2] Current Loss: 2.7272\n",
            "[Batch 3] Current Loss: 2.2925\n",
            "[Batch 4] Current Loss: 2.5528\n",
            "[Batch 5] Current Loss: 2.1907\n",
            "[Batch 6] Current Loss: 1.8880\n",
            "[Batch 7] Current Loss: 2.3112\n",
            "[Batch 8] Current Loss: 1.9006\n",
            "[Batch 9] Current Loss: 2.0845\n",
            "[Batch 0] Current Loss: 6.6519\n",
            "[Batch 1] Current Loss: 4.9118\n",
            "[Batch 2] Current Loss: 5.2173\n",
            "[Batch 3] Current Loss: 6.4809\n",
            "[Batch 4] Current Loss: 6.0552\n",
            "[Batch 5] Current Loss: 6.4394\n",
            "[Batch 6] Current Loss: 5.0728\n",
            "[Batch 7] Current Loss: 4.9611\n",
            "[Batch 8] Current Loss: 5.3388\n",
            "[Batch 9] Current Loss: 6.0031\n",
            "Ep 5 (Step 038360): Train loss 2.342, Val loss 5.713\n",
            "[Batch 0] Current Loss: 2.2662\n",
            "[Batch 1] Current Loss: 2.3277\n",
            "[Batch 2] Current Loss: 1.7340\n",
            "[Batch 3] Current Loss: 1.9736\n",
            "[Batch 4] Current Loss: 2.2679\n",
            "[Batch 5] Current Loss: 2.2836\n",
            "[Batch 6] Current Loss: 2.7268\n",
            "[Batch 7] Current Loss: 1.7400\n",
            "[Batch 8] Current Loss: 1.9478\n",
            "[Batch 9] Current Loss: 2.5191\n",
            "[Batch 0] Current Loss: 5.5348\n",
            "[Batch 1] Current Loss: 5.5729\n",
            "[Batch 2] Current Loss: 6.2264\n",
            "[Batch 3] Current Loss: 5.8953\n",
            "[Batch 4] Current Loss: 5.6697\n",
            "[Batch 5] Current Loss: 5.8956\n",
            "[Batch 6] Current Loss: 6.2388\n",
            "[Batch 7] Current Loss: 5.5897\n",
            "[Batch 8] Current Loss: 5.3502\n",
            "[Batch 9] Current Loss: 5.5813\n",
            "Ep 5 (Step 038380): Train loss 2.179, Val loss 5.755\n",
            "[Batch 0] Current Loss: 1.9451\n",
            "[Batch 1] Current Loss: 1.6029\n",
            "[Batch 2] Current Loss: 2.4736\n",
            "[Batch 3] Current Loss: 1.9902\n",
            "[Batch 4] Current Loss: 2.1149\n",
            "[Batch 5] Current Loss: 2.2459\n",
            "[Batch 6] Current Loss: 2.1395\n",
            "[Batch 7] Current Loss: 2.2677\n",
            "[Batch 8] Current Loss: 2.2302\n",
            "[Batch 9] Current Loss: 2.5846\n",
            "[Batch 0] Current Loss: 5.7745\n",
            "[Batch 1] Current Loss: 5.3788\n",
            "[Batch 2] Current Loss: 5.8430\n",
            "[Batch 3] Current Loss: 4.6909\n",
            "[Batch 4] Current Loss: 5.9823\n",
            "[Batch 5] Current Loss: 6.2157\n",
            "[Batch 6] Current Loss: 6.1798\n",
            "[Batch 7] Current Loss: 6.4626\n",
            "[Batch 8] Current Loss: 6.4656\n",
            "[Batch 9] Current Loss: 5.8079\n",
            "Ep 5 (Step 038400): Train loss 2.159, Val loss 5.880\n",
            "[Batch 0] Current Loss: 1.9837\n",
            "[Batch 1] Current Loss: 2.3513\n",
            "[Batch 2] Current Loss: 2.6318\n",
            "[Batch 3] Current Loss: 2.3877\n",
            "[Batch 4] Current Loss: 2.6521\n",
            "[Batch 5] Current Loss: 1.9413\n",
            "[Batch 6] Current Loss: 2.5220\n",
            "[Batch 7] Current Loss: 2.0982\n",
            "[Batch 8] Current Loss: 2.2208\n",
            "[Batch 9] Current Loss: 2.1331\n",
            "[Batch 0] Current Loss: 5.3716\n",
            "[Batch 1] Current Loss: 5.0020\n",
            "[Batch 2] Current Loss: 5.8626\n",
            "[Batch 3] Current Loss: 5.8242\n",
            "[Batch 4] Current Loss: 5.4209\n",
            "[Batch 5] Current Loss: 5.6526\n",
            "[Batch 6] Current Loss: 5.7666\n",
            "[Batch 7] Current Loss: 5.4892\n",
            "[Batch 8] Current Loss: 6.3411\n",
            "[Batch 9] Current Loss: 5.1687\n",
            "Ep 5 (Step 038420): Train loss 2.292, Val loss 5.590\n",
            "[Batch 0] Current Loss: 2.1374\n",
            "[Batch 1] Current Loss: 2.1689\n",
            "[Batch 2] Current Loss: 1.5083\n",
            "[Batch 3] Current Loss: 2.3164\n",
            "[Batch 4] Current Loss: 2.5835\n",
            "[Batch 5] Current Loss: 2.4367\n",
            "[Batch 6] Current Loss: 1.8021\n",
            "[Batch 7] Current Loss: 2.2321\n",
            "[Batch 8] Current Loss: 1.8142\n",
            "[Batch 9] Current Loss: 1.9731\n",
            "[Batch 0] Current Loss: 4.9772\n",
            "[Batch 1] Current Loss: 5.3837\n",
            "[Batch 2] Current Loss: 6.3780\n",
            "[Batch 3] Current Loss: 5.8094\n",
            "[Batch 4] Current Loss: 5.9943\n",
            "[Batch 5] Current Loss: 5.7337\n",
            "[Batch 6] Current Loss: 6.1793\n",
            "[Batch 7] Current Loss: 5.0619\n",
            "[Batch 8] Current Loss: 4.8023\n",
            "[Batch 9] Current Loss: 6.4223\n",
            "Ep 5 (Step 038440): Train loss 2.097, Val loss 5.674\n",
            "[Batch 0] Current Loss: 2.3486\n",
            "[Batch 1] Current Loss: 2.3533\n",
            "[Batch 2] Current Loss: 1.4759\n",
            "[Batch 3] Current Loss: 2.0364\n",
            "[Batch 4] Current Loss: 2.2221\n",
            "[Batch 5] Current Loss: 2.4483\n",
            "[Batch 6] Current Loss: 2.1176\n",
            "[Batch 7] Current Loss: 2.4707\n",
            "[Batch 8] Current Loss: 2.0155\n",
            "[Batch 9] Current Loss: 2.4667\n",
            "[Batch 0] Current Loss: 5.6297\n",
            "[Batch 1] Current Loss: 5.2122\n",
            "[Batch 2] Current Loss: 5.6966\n",
            "[Batch 3] Current Loss: 5.5782\n",
            "[Batch 4] Current Loss: 6.0761\n",
            "[Batch 5] Current Loss: 4.9841\n",
            "[Batch 6] Current Loss: 5.9946\n",
            "[Batch 7] Current Loss: 5.5324\n",
            "[Batch 8] Current Loss: 6.0514\n",
            "[Batch 9] Current Loss: 5.8585\n",
            "Ep 5 (Step 038460): Train loss 2.195, Val loss 5.661\n",
            "[Batch 0] Current Loss: 2.2573\n",
            "[Batch 1] Current Loss: 1.8450\n",
            "[Batch 2] Current Loss: 1.9673\n",
            "[Batch 3] Current Loss: 1.9495\n",
            "[Batch 4] Current Loss: 1.8220\n",
            "[Batch 5] Current Loss: 1.9428\n",
            "[Batch 6] Current Loss: 2.0845\n",
            "[Batch 7] Current Loss: 2.4294\n",
            "[Batch 8] Current Loss: 2.4707\n",
            "[Batch 9] Current Loss: 1.4025\n",
            "[Batch 0] Current Loss: 5.1984\n",
            "[Batch 1] Current Loss: 6.1168\n",
            "[Batch 2] Current Loss: 4.7749\n",
            "[Batch 3] Current Loss: 4.3504\n",
            "[Batch 4] Current Loss: 5.5285\n",
            "[Batch 5] Current Loss: 5.2795\n",
            "[Batch 6] Current Loss: 4.7045\n",
            "[Batch 7] Current Loss: 5.3034\n",
            "[Batch 8] Current Loss: 5.5743\n",
            "[Batch 9] Current Loss: 5.3197\n",
            "Ep 5 (Step 038480): Train loss 2.017, Val loss 5.215\n",
            "[Batch 0] Current Loss: 2.4114\n",
            "[Batch 1] Current Loss: 2.6347\n",
            "[Batch 2] Current Loss: 1.9242\n",
            "[Batch 3] Current Loss: 2.4133\n",
            "[Batch 4] Current Loss: 2.2770\n",
            "[Batch 5] Current Loss: 2.4301\n",
            "[Batch 6] Current Loss: 2.1409\n",
            "[Batch 7] Current Loss: 2.1753\n",
            "[Batch 8] Current Loss: 2.3434\n",
            "[Batch 9] Current Loss: 2.3073\n",
            "[Batch 0] Current Loss: 5.0143\n",
            "[Batch 1] Current Loss: 5.8710\n",
            "[Batch 2] Current Loss: 5.2606\n",
            "[Batch 3] Current Loss: 5.5001\n",
            "[Batch 4] Current Loss: 5.8123\n",
            "[Batch 5] Current Loss: 5.1316\n",
            "[Batch 6] Current Loss: 6.3260\n",
            "[Batch 7] Current Loss: 5.4464\n",
            "[Batch 8] Current Loss: 6.3429\n",
            "[Batch 9] Current Loss: 6.0312\n",
            "Ep 5 (Step 038500): Train loss 2.306, Val loss 5.674\n",
            "[Batch 0] Current Loss: 2.3132\n",
            "[Batch 1] Current Loss: 2.6048\n",
            "[Batch 2] Current Loss: 2.1183\n",
            "[Batch 3] Current Loss: 2.4136\n",
            "[Batch 4] Current Loss: 1.9719\n",
            "[Batch 5] Current Loss: 2.2945\n",
            "[Batch 6] Current Loss: 1.5839\n",
            "[Batch 7] Current Loss: 2.5169\n",
            "[Batch 8] Current Loss: 2.3740\n",
            "[Batch 9] Current Loss: 1.8150\n",
            "[Batch 0] Current Loss: 5.5983\n",
            "[Batch 1] Current Loss: 5.6406\n",
            "[Batch 2] Current Loss: 4.3750\n",
            "[Batch 3] Current Loss: 6.1170\n",
            "[Batch 4] Current Loss: 5.6948\n",
            "[Batch 5] Current Loss: 5.7959\n",
            "[Batch 6] Current Loss: 6.2547\n",
            "[Batch 7] Current Loss: 6.3296\n",
            "[Batch 8] Current Loss: 5.9288\n",
            "[Batch 9] Current Loss: 5.1250\n",
            "Ep 5 (Step 038520): Train loss 2.201, Val loss 5.686\n",
            "[Batch 0] Current Loss: 2.2813\n",
            "[Batch 1] Current Loss: 2.5606\n",
            "[Batch 2] Current Loss: 2.0687\n",
            "[Batch 3] Current Loss: 2.3322\n",
            "[Batch 4] Current Loss: 1.9450\n",
            "[Batch 5] Current Loss: 2.2747\n",
            "[Batch 6] Current Loss: 1.6239\n",
            "[Batch 7] Current Loss: 1.7985\n",
            "[Batch 8] Current Loss: 2.8510\n",
            "[Batch 9] Current Loss: 2.4307\n",
            "[Batch 0] Current Loss: 6.6193\n",
            "[Batch 1] Current Loss: 5.4785\n",
            "[Batch 2] Current Loss: 5.4041\n",
            "[Batch 3] Current Loss: 6.1780\n",
            "[Batch 4] Current Loss: 5.8145\n",
            "[Batch 5] Current Loss: 5.5760\n",
            "[Batch 6] Current Loss: 4.5583\n",
            "[Batch 7] Current Loss: 5.7100\n",
            "[Batch 8] Current Loss: 5.4398\n",
            "[Batch 9] Current Loss: 5.1692\n",
            "Ep 5 (Step 038540): Train loss 2.217, Val loss 5.595\n",
            "[Batch 0] Current Loss: 1.6593\n",
            "[Batch 1] Current Loss: 1.9997\n",
            "[Batch 2] Current Loss: 1.6166\n",
            "[Batch 3] Current Loss: 1.9637\n",
            "[Batch 4] Current Loss: 1.9104\n",
            "[Batch 5] Current Loss: 1.5367\n",
            "[Batch 6] Current Loss: 2.2437\n",
            "[Batch 7] Current Loss: 2.0236\n",
            "[Batch 8] Current Loss: 2.6538\n",
            "[Batch 9] Current Loss: 1.4092\n",
            "[Batch 0] Current Loss: 5.7379\n",
            "[Batch 1] Current Loss: 5.0959\n",
            "[Batch 2] Current Loss: 5.0259\n",
            "[Batch 3] Current Loss: 5.3485\n",
            "[Batch 4] Current Loss: 5.5521\n",
            "[Batch 5] Current Loss: 6.0016\n",
            "[Batch 6] Current Loss: 5.7038\n",
            "[Batch 7] Current Loss: 6.2109\n",
            "[Batch 8] Current Loss: 5.7743\n",
            "[Batch 9] Current Loss: 5.0765\n",
            "Ep 5 (Step 038560): Train loss 1.902, Val loss 5.553\n",
            "[Batch 0] Current Loss: 1.8668\n",
            "[Batch 1] Current Loss: 1.7242\n",
            "[Batch 2] Current Loss: 1.9898\n",
            "[Batch 3] Current Loss: 2.1478\n",
            "[Batch 4] Current Loss: 2.2000\n",
            "[Batch 5] Current Loss: 1.7479\n",
            "[Batch 6] Current Loss: 1.9050\n",
            "[Batch 7] Current Loss: 1.7270\n",
            "[Batch 8] Current Loss: 2.0328\n",
            "[Batch 9] Current Loss: 1.9324\n",
            "[Batch 0] Current Loss: 5.7714\n",
            "[Batch 1] Current Loss: 5.7365\n",
            "[Batch 2] Current Loss: 5.4939\n",
            "[Batch 3] Current Loss: 5.4506\n",
            "[Batch 4] Current Loss: 5.8829\n",
            "[Batch 5] Current Loss: 5.5121\n",
            "[Batch 6] Current Loss: 5.9919\n",
            "[Batch 7] Current Loss: 4.8604\n",
            "[Batch 8] Current Loss: 5.5999\n",
            "[Batch 9] Current Loss: 5.9152\n",
            "Ep 5 (Step 038580): Train loss 1.927, Val loss 5.621\n",
            "[Batch 0] Current Loss: 1.7001\n",
            "[Batch 1] Current Loss: 1.9419\n",
            "[Batch 2] Current Loss: 2.2076\n",
            "[Batch 3] Current Loss: 1.7388\n",
            "[Batch 4] Current Loss: 2.1687\n",
            "[Batch 5] Current Loss: 1.7788\n",
            "[Batch 6] Current Loss: 2.1369\n",
            "[Batch 7] Current Loss: 2.4634\n",
            "[Batch 8] Current Loss: 2.0431\n",
            "[Batch 9] Current Loss: 2.1536\n",
            "[Batch 0] Current Loss: 5.5139\n",
            "[Batch 1] Current Loss: 5.3858\n",
            "[Batch 2] Current Loss: 5.8107\n",
            "[Batch 3] Current Loss: 4.9297\n",
            "[Batch 4] Current Loss: 6.1723\n",
            "[Batch 5] Current Loss: 5.3219\n",
            "[Batch 6] Current Loss: 6.1632\n",
            "[Batch 7] Current Loss: 5.2631\n",
            "[Batch 8] Current Loss: 6.1658\n",
            "[Batch 9] Current Loss: 5.4573\n",
            "Ep 5 (Step 038600): Train loss 2.033, Val loss 5.618\n",
            "[Batch 0] Current Loss: 1.8728\n",
            "[Batch 1] Current Loss: 2.2967\n",
            "[Batch 2] Current Loss: 2.7274\n",
            "[Batch 3] Current Loss: 2.2364\n",
            "[Batch 4] Current Loss: 2.3874\n",
            "[Batch 5] Current Loss: 2.7638\n",
            "[Batch 6] Current Loss: 1.8999\n",
            "[Batch 7] Current Loss: 1.9149\n",
            "[Batch 8] Current Loss: 1.6861\n",
            "[Batch 9] Current Loss: 1.4013\n",
            "[Batch 0] Current Loss: 5.1313\n",
            "[Batch 1] Current Loss: 5.1449\n",
            "[Batch 2] Current Loss: 5.0164\n",
            "[Batch 3] Current Loss: 6.1832\n",
            "[Batch 4] Current Loss: 5.9302\n",
            "[Batch 5] Current Loss: 6.3093\n",
            "[Batch 6] Current Loss: 5.4976\n",
            "[Batch 7] Current Loss: 5.1697\n",
            "[Batch 8] Current Loss: 6.6540\n",
            "[Batch 9] Current Loss: 5.1103\n",
            "Ep 5 (Step 038620): Train loss 2.119, Val loss 5.615\n",
            "[Batch 0] Current Loss: 2.1071\n",
            "[Batch 1] Current Loss: 2.0754\n",
            "[Batch 2] Current Loss: 2.2410\n",
            "[Batch 3] Current Loss: 2.4773\n",
            "[Batch 4] Current Loss: 1.5238\n",
            "[Batch 5] Current Loss: 2.4368\n",
            "[Batch 6] Current Loss: 1.9466\n",
            "[Batch 7] Current Loss: 2.1710\n",
            "[Batch 8] Current Loss: 1.7936\n",
            "[Batch 9] Current Loss: 1.5365\n",
            "[Batch 0] Current Loss: 5.5242\n",
            "[Batch 1] Current Loss: 5.1521\n",
            "[Batch 2] Current Loss: 4.5767\n",
            "[Batch 3] Current Loss: 6.0678\n",
            "[Batch 4] Current Loss: 6.0695\n",
            "[Batch 5] Current Loss: 4.9226\n",
            "[Batch 6] Current Loss: 6.4003\n",
            "[Batch 7] Current Loss: 5.5292\n",
            "[Batch 8] Current Loss: 5.1809\n",
            "[Batch 9] Current Loss: 5.1005\n",
            "Ep 5 (Step 038640): Train loss 2.031, Val loss 5.452\n",
            "[Batch 0] Current Loss: 1.8096\n",
            "[Batch 1] Current Loss: 2.3908\n",
            "[Batch 2] Current Loss: 2.1053\n",
            "[Batch 3] Current Loss: 1.8346\n",
            "[Batch 4] Current Loss: 2.6600\n",
            "[Batch 5] Current Loss: 2.0143\n",
            "[Batch 6] Current Loss: 2.5223\n",
            "[Batch 7] Current Loss: 2.0751\n",
            "[Batch 8] Current Loss: 2.2455\n",
            "[Batch 9] Current Loss: 1.8585\n",
            "[Batch 0] Current Loss: 5.6560\n",
            "[Batch 1] Current Loss: 5.7500\n",
            "[Batch 2] Current Loss: 6.0738\n",
            "[Batch 3] Current Loss: 5.1244\n",
            "[Batch 4] Current Loss: 5.9431\n",
            "[Batch 5] Current Loss: 5.2935\n",
            "[Batch 6] Current Loss: 6.7449\n",
            "[Batch 7] Current Loss: 6.0551\n",
            "[Batch 8] Current Loss: 6.4911\n",
            "[Batch 9] Current Loss: 5.3314\n",
            "Ep 5 (Step 038660): Train loss 2.152, Val loss 5.846\n",
            "[Batch 0] Current Loss: 2.1000\n",
            "[Batch 1] Current Loss: 2.5719\n",
            "[Batch 2] Current Loss: 2.0074\n",
            "[Batch 3] Current Loss: 2.8482\n",
            "[Batch 4] Current Loss: 1.9340\n",
            "[Batch 5] Current Loss: 2.4474\n",
            "[Batch 6] Current Loss: 2.1878\n",
            "[Batch 7] Current Loss: 1.4740\n",
            "[Batch 8] Current Loss: 1.7847\n",
            "[Batch 9] Current Loss: 2.9443\n",
            "[Batch 0] Current Loss: 5.7016\n",
            "[Batch 1] Current Loss: 6.9245\n",
            "[Batch 2] Current Loss: 5.7222\n",
            "[Batch 3] Current Loss: 4.0425\n",
            "[Batch 4] Current Loss: 4.7137\n",
            "[Batch 5] Current Loss: 5.3606\n",
            "[Batch 6] Current Loss: 6.4281\n",
            "[Batch 7] Current Loss: 4.8501\n",
            "[Batch 8] Current Loss: 4.5867\n",
            "[Batch 9] Current Loss: 5.3374\n",
            "Ep 5 (Step 038680): Train loss 2.230, Val loss 5.367\n",
            "[Batch 0] Current Loss: 2.9203\n",
            "[Batch 1] Current Loss: 2.5233\n",
            "[Batch 2] Current Loss: 2.7638\n",
            "[Batch 3] Current Loss: 1.9393\n",
            "[Batch 4] Current Loss: 1.2319\n",
            "[Batch 5] Current Loss: 2.3105\n",
            "[Batch 6] Current Loss: 2.8446\n",
            "[Batch 7] Current Loss: 2.0653\n",
            "[Batch 8] Current Loss: 2.0706\n",
            "[Batch 9] Current Loss: 2.5788\n",
            "[Batch 0] Current Loss: 6.0782\n",
            "[Batch 1] Current Loss: 5.2569\n",
            "[Batch 2] Current Loss: 5.5133\n",
            "[Batch 3] Current Loss: 5.6697\n",
            "[Batch 4] Current Loss: 5.4026\n",
            "[Batch 5] Current Loss: 6.2203\n",
            "[Batch 6] Current Loss: 4.9823\n",
            "[Batch 7] Current Loss: 5.5563\n",
            "[Batch 8] Current Loss: 5.7917\n",
            "[Batch 9] Current Loss: 5.6369\n",
            "Ep 5 (Step 038700): Train loss 2.325, Val loss 5.611\n",
            "[Batch 0] Current Loss: 1.5288\n",
            "[Batch 1] Current Loss: 1.8908\n",
            "[Batch 2] Current Loss: 2.4767\n",
            "[Batch 3] Current Loss: 1.8735\n",
            "[Batch 4] Current Loss: 1.9815\n",
            "[Batch 5] Current Loss: 1.6301\n",
            "[Batch 6] Current Loss: 2.2045\n",
            "[Batch 7] Current Loss: 1.8221\n",
            "[Batch 8] Current Loss: 2.3535\n",
            "[Batch 9] Current Loss: 2.2912\n",
            "[Batch 0] Current Loss: 5.6222\n",
            "[Batch 1] Current Loss: 5.6498\n",
            "[Batch 2] Current Loss: 5.2057\n",
            "[Batch 3] Current Loss: 5.7742\n",
            "[Batch 4] Current Loss: 5.4661\n",
            "[Batch 5] Current Loss: 5.4850\n",
            "[Batch 6] Current Loss: 5.2951\n",
            "[Batch 7] Current Loss: 5.4268\n",
            "[Batch 8] Current Loss: 5.7030\n",
            "[Batch 9] Current Loss: 5.9425\n",
            "Ep 5 (Step 038720): Train loss 2.005, Val loss 5.557\n",
            "[Batch 0] Current Loss: 2.3117\n",
            "[Batch 1] Current Loss: 2.1712\n",
            "[Batch 2] Current Loss: 2.2709\n",
            "[Batch 3] Current Loss: 1.8862\n",
            "[Batch 4] Current Loss: 2.1332\n",
            "[Batch 5] Current Loss: 2.9395\n",
            "[Batch 6] Current Loss: 1.9058\n",
            "[Batch 7] Current Loss: 2.1429\n",
            "[Batch 8] Current Loss: 1.5501\n",
            "[Batch 9] Current Loss: 2.1338\n",
            "[Batch 0] Current Loss: 4.7980\n",
            "[Batch 1] Current Loss: 5.2589\n",
            "[Batch 2] Current Loss: 6.0579\n",
            "[Batch 3] Current Loss: 5.8078\n",
            "[Batch 4] Current Loss: 5.2071\n",
            "[Batch 5] Current Loss: 5.3218\n",
            "[Batch 6] Current Loss: 6.6537\n",
            "[Batch 7] Current Loss: 5.2966\n",
            "[Batch 8] Current Loss: 6.0642\n",
            "[Batch 9] Current Loss: 5.0258\n",
            "Ep 5 (Step 038740): Train loss 2.145, Val loss 5.549\n",
            "[Batch 0] Current Loss: 2.2234\n",
            "[Batch 1] Current Loss: 1.8820\n",
            "[Batch 2] Current Loss: 2.3207\n",
            "[Batch 3] Current Loss: 2.4859\n",
            "[Batch 4] Current Loss: 2.1470\n",
            "[Batch 5] Current Loss: 2.0615\n",
            "[Batch 6] Current Loss: 1.7260\n",
            "[Batch 7] Current Loss: 1.7258\n",
            "[Batch 8] Current Loss: 2.0648\n",
            "[Batch 9] Current Loss: 1.9201\n",
            "[Batch 0] Current Loss: 6.3902\n",
            "[Batch 1] Current Loss: 6.4260\n",
            "[Batch 2] Current Loss: 5.9419\n",
            "[Batch 3] Current Loss: 5.5054\n",
            "[Batch 4] Current Loss: 6.2642\n",
            "[Batch 5] Current Loss: 5.5748\n",
            "[Batch 6] Current Loss: 5.4870\n",
            "[Batch 7] Current Loss: 6.3098\n",
            "[Batch 8] Current Loss: 6.7394\n",
            "[Batch 9] Current Loss: 5.9245\n",
            "Ep 5 (Step 038760): Train loss 2.056, Val loss 6.056\n",
            "[Batch 0] Current Loss: 2.3603\n",
            "[Batch 1] Current Loss: 2.1491\n",
            "[Batch 2] Current Loss: 1.9049\n",
            "[Batch 3] Current Loss: 1.8640\n",
            "[Batch 4] Current Loss: 2.3412\n",
            "[Batch 5] Current Loss: 2.2649\n",
            "[Batch 6] Current Loss: 2.7952\n",
            "[Batch 7] Current Loss: 2.1580\n",
            "[Batch 8] Current Loss: 1.8066\n",
            "[Batch 9] Current Loss: 1.2836\n",
            "[Batch 0] Current Loss: 5.7805\n",
            "[Batch 1] Current Loss: 5.8160\n",
            "[Batch 2] Current Loss: 4.5370\n",
            "[Batch 3] Current Loss: 5.2186\n",
            "[Batch 4] Current Loss: 6.1181\n",
            "[Batch 5] Current Loss: 5.9466\n",
            "[Batch 6] Current Loss: 6.0495\n",
            "[Batch 7] Current Loss: 5.3933\n",
            "[Batch 8] Current Loss: 5.7898\n",
            "[Batch 9] Current Loss: 6.0524\n",
            "Ep 5 (Step 038780): Train loss 2.093, Val loss 5.670\n",
            "[Batch 0] Current Loss: 1.8468\n",
            "[Batch 1] Current Loss: 1.8819\n",
            "[Batch 2] Current Loss: 2.5519\n",
            "[Batch 3] Current Loss: 1.3714\n",
            "[Batch 4] Current Loss: 1.7346\n",
            "[Batch 5] Current Loss: 2.1843\n",
            "[Batch 6] Current Loss: 1.5638\n",
            "[Batch 7] Current Loss: 1.9779\n",
            "[Batch 8] Current Loss: 2.2464\n",
            "[Batch 9] Current Loss: 2.3764\n",
            "[Batch 0] Current Loss: 5.5593\n",
            "[Batch 1] Current Loss: 5.8186\n",
            "[Batch 2] Current Loss: 5.2898\n",
            "[Batch 3] Current Loss: 5.7959\n",
            "[Batch 4] Current Loss: 5.7630\n",
            "[Batch 5] Current Loss: 5.9533\n",
            "[Batch 6] Current Loss: 6.6551\n",
            "[Batch 7] Current Loss: 6.2402\n",
            "[Batch 8] Current Loss: 6.1434\n",
            "[Batch 9] Current Loss: 5.6014\n",
            "Ep 5 (Step 038800): Train loss 1.974, Val loss 5.882\n",
            "[Batch 0] Current Loss: 2.1517\n",
            "[Batch 1] Current Loss: 1.8152\n",
            "[Batch 2] Current Loss: 2.2200\n",
            "[Batch 3] Current Loss: 2.2988\n",
            "[Batch 4] Current Loss: 2.0698\n",
            "[Batch 5] Current Loss: 1.6868\n",
            "[Batch 6] Current Loss: 1.8545\n",
            "[Batch 7] Current Loss: 2.0491\n",
            "[Batch 8] Current Loss: 2.0569\n",
            "[Batch 9] Current Loss: 2.4636\n",
            "[Batch 0] Current Loss: 5.4271\n",
            "[Batch 1] Current Loss: 5.3290\n",
            "[Batch 2] Current Loss: 6.1154\n",
            "[Batch 3] Current Loss: 5.3603\n",
            "[Batch 4] Current Loss: 5.7418\n",
            "[Batch 5] Current Loss: 5.0748\n",
            "[Batch 6] Current Loss: 5.7821\n",
            "[Batch 7] Current Loss: 5.3735\n",
            "[Batch 8] Current Loss: 5.0134\n",
            "[Batch 9] Current Loss: 5.5273\n",
            "Ep 5 (Step 038820): Train loss 2.067, Val loss 5.474\n",
            "[Batch 0] Current Loss: 1.5046\n",
            "[Batch 1] Current Loss: 2.1795\n",
            "[Batch 2] Current Loss: 1.7960\n",
            "[Batch 3] Current Loss: 2.2456\n",
            "[Batch 4] Current Loss: 1.9230\n",
            "[Batch 5] Current Loss: 1.4648\n",
            "[Batch 6] Current Loss: 1.4862\n",
            "[Batch 7] Current Loss: 2.6891\n",
            "[Batch 8] Current Loss: 3.0022\n",
            "[Batch 9] Current Loss: 2.1673\n",
            "[Batch 0] Current Loss: 4.7624\n",
            "[Batch 1] Current Loss: 6.4670\n",
            "[Batch 2] Current Loss: 5.3590\n",
            "[Batch 3] Current Loss: 6.1453\n",
            "[Batch 4] Current Loss: 5.8867\n",
            "[Batch 5] Current Loss: 5.4103\n",
            "[Batch 6] Current Loss: 5.0037\n",
            "[Batch 7] Current Loss: 5.3264\n",
            "[Batch 8] Current Loss: 5.5886\n",
            "[Batch 9] Current Loss: 5.6876\n",
            "Ep 5 (Step 038840): Train loss 2.046, Val loss 5.564\n",
            "[Batch 0] Current Loss: 2.1075\n",
            "[Batch 1] Current Loss: 2.2670\n",
            "[Batch 2] Current Loss: 2.5421\n",
            "[Batch 3] Current Loss: 1.8021\n",
            "[Batch 4] Current Loss: 2.6508\n",
            "[Batch 5] Current Loss: 1.6369\n",
            "[Batch 6] Current Loss: 2.6385\n",
            "[Batch 7] Current Loss: 1.8914\n",
            "[Batch 8] Current Loss: 2.0381\n",
            "[Batch 9] Current Loss: 2.0509\n",
            "[Batch 0] Current Loss: 4.9679\n",
            "[Batch 1] Current Loss: 6.2726\n",
            "[Batch 2] Current Loss: 5.9576\n",
            "[Batch 3] Current Loss: 6.0477\n",
            "[Batch 4] Current Loss: 5.9582\n",
            "[Batch 5] Current Loss: 5.3723\n",
            "[Batch 6] Current Loss: 5.9104\n",
            "[Batch 7] Current Loss: 5.8852\n",
            "[Batch 8] Current Loss: 5.1651\n",
            "[Batch 9] Current Loss: 6.0868\n",
            "Ep 5 (Step 038860): Train loss 2.163, Val loss 5.762\n",
            "[Batch 0] Current Loss: 2.2866\n",
            "[Batch 1] Current Loss: 2.3771\n",
            "[Batch 2] Current Loss: 2.1139\n",
            "[Batch 3] Current Loss: 2.8744\n",
            "[Batch 4] Current Loss: 2.5096\n",
            "[Batch 5] Current Loss: 1.9569\n",
            "[Batch 6] Current Loss: 1.6575\n",
            "[Batch 7] Current Loss: 2.6186\n",
            "[Batch 8] Current Loss: 2.1322\n",
            "[Batch 9] Current Loss: 2.0610\n",
            "[Batch 0] Current Loss: 6.3083\n",
            "[Batch 1] Current Loss: 5.2123\n",
            "[Batch 2] Current Loss: 5.5129\n",
            "[Batch 3] Current Loss: 6.0272\n",
            "[Batch 4] Current Loss: 6.3855\n",
            "[Batch 5] Current Loss: 5.8651\n",
            "[Batch 6] Current Loss: 5.0869\n",
            "[Batch 7] Current Loss: 5.1948\n",
            "[Batch 8] Current Loss: 5.6368\n",
            "[Batch 9] Current Loss: 5.4922\n",
            "Ep 5 (Step 038880): Train loss 2.259, Val loss 5.672\n",
            "[Batch 0] Current Loss: 2.4776\n",
            "[Batch 1] Current Loss: 2.2569\n",
            "[Batch 2] Current Loss: 1.8790\n",
            "[Batch 3] Current Loss: 2.1260\n",
            "[Batch 4] Current Loss: 1.4545\n",
            "[Batch 5] Current Loss: 1.7115\n",
            "[Batch 6] Current Loss: 2.3569\n",
            "[Batch 7] Current Loss: 2.2792\n",
            "[Batch 8] Current Loss: 1.6463\n",
            "[Batch 9] Current Loss: 2.6875\n",
            "[Batch 0] Current Loss: 6.2181\n",
            "[Batch 1] Current Loss: 5.5713\n",
            "[Batch 2] Current Loss: 5.7357\n",
            "[Batch 3] Current Loss: 6.6161\n",
            "[Batch 4] Current Loss: 5.8997\n",
            "[Batch 5] Current Loss: 5.3190\n",
            "[Batch 6] Current Loss: 5.2702\n",
            "[Batch 7] Current Loss: 5.5989\n",
            "[Batch 8] Current Loss: 6.6900\n",
            "[Batch 9] Current Loss: 6.4814\n",
            "Ep 5 (Step 038900): Train loss 2.088, Val loss 5.940\n",
            "[Batch 0] Current Loss: 2.0596\n",
            "[Batch 1] Current Loss: 1.7711\n",
            "[Batch 2] Current Loss: 2.2047\n",
            "[Batch 3] Current Loss: 1.7579\n",
            "[Batch 4] Current Loss: 2.2319\n",
            "[Batch 5] Current Loss: 2.2170\n",
            "[Batch 6] Current Loss: 2.4326\n",
            "[Batch 7] Current Loss: 1.8354\n",
            "[Batch 8] Current Loss: 1.7137\n",
            "[Batch 9] Current Loss: 1.6493\n",
            "[Batch 0] Current Loss: 6.4390\n",
            "[Batch 1] Current Loss: 5.8094\n",
            "[Batch 2] Current Loss: 5.8961\n",
            "[Batch 3] Current Loss: 5.6677\n",
            "[Batch 4] Current Loss: 6.1781\n",
            "[Batch 5] Current Loss: 5.5689\n",
            "[Batch 6] Current Loss: 5.8095\n",
            "[Batch 7] Current Loss: 5.3057\n",
            "[Batch 8] Current Loss: 5.5253\n",
            "[Batch 9] Current Loss: 6.1441\n",
            "Ep 5 (Step 038920): Train loss 1.987, Val loss 5.834\n",
            "[Batch 0] Current Loss: 2.0265\n",
            "[Batch 1] Current Loss: 2.0207\n",
            "[Batch 2] Current Loss: 1.7527\n",
            "[Batch 3] Current Loss: 2.0049\n",
            "[Batch 4] Current Loss: 2.0940\n",
            "[Batch 5] Current Loss: 1.6292\n",
            "[Batch 6] Current Loss: 1.7651\n",
            "[Batch 7] Current Loss: 1.9125\n",
            "[Batch 8] Current Loss: 1.7986\n",
            "[Batch 9] Current Loss: 1.9762\n",
            "[Batch 0] Current Loss: 5.8176\n",
            "[Batch 1] Current Loss: 5.2697\n",
            "[Batch 2] Current Loss: 6.0668\n",
            "[Batch 3] Current Loss: 5.8102\n",
            "[Batch 4] Current Loss: 5.0972\n",
            "[Batch 5] Current Loss: 5.2043\n",
            "[Batch 6] Current Loss: 5.4465\n",
            "[Batch 7] Current Loss: 6.0366\n",
            "[Batch 8] Current Loss: 5.0893\n",
            "[Batch 9] Current Loss: 7.0362\n",
            "Ep 5 (Step 038940): Train loss 1.898, Val loss 5.687\n",
            "[Batch 0] Current Loss: 2.7166\n",
            "[Batch 1] Current Loss: 2.6427\n",
            "[Batch 2] Current Loss: 1.9717\n",
            "[Batch 3] Current Loss: 1.7483\n",
            "[Batch 4] Current Loss: 1.6555\n",
            "[Batch 5] Current Loss: 2.4811\n",
            "[Batch 6] Current Loss: 1.5646\n",
            "[Batch 7] Current Loss: 2.8123\n",
            "[Batch 8] Current Loss: 1.9695\n",
            "[Batch 9] Current Loss: 1.5324\n",
            "[Batch 0] Current Loss: 5.5936\n",
            "[Batch 1] Current Loss: 5.0767\n",
            "[Batch 2] Current Loss: 6.1409\n",
            "[Batch 3] Current Loss: 5.0028\n",
            "[Batch 4] Current Loss: 5.2488\n",
            "[Batch 5] Current Loss: 5.6676\n",
            "[Batch 6] Current Loss: 5.2116\n",
            "[Batch 7] Current Loss: 5.4188\n",
            "[Batch 8] Current Loss: 4.9930\n",
            "[Batch 9] Current Loss: 5.8284\n",
            "Ep 5 (Step 038960): Train loss 2.109, Val loss 5.418\n",
            "[Batch 0] Current Loss: 2.7172\n",
            "[Batch 1] Current Loss: 2.5365\n",
            "[Batch 2] Current Loss: 2.0945\n",
            "[Batch 3] Current Loss: 2.1419\n",
            "[Batch 4] Current Loss: 2.3170\n",
            "[Batch 5] Current Loss: 2.1044\n",
            "[Batch 6] Current Loss: 2.3351\n",
            "[Batch 7] Current Loss: 2.2387\n",
            "[Batch 8] Current Loss: 2.2380\n",
            "[Batch 9] Current Loss: 1.8747\n",
            "[Batch 0] Current Loss: 5.7705\n",
            "[Batch 1] Current Loss: 5.9882\n",
            "[Batch 2] Current Loss: 5.6833\n",
            "[Batch 3] Current Loss: 6.5181\n",
            "[Batch 4] Current Loss: 5.5825\n",
            "[Batch 5] Current Loss: 5.8449\n",
            "[Batch 6] Current Loss: 5.8780\n",
            "[Batch 7] Current Loss: 6.0004\n",
            "[Batch 8] Current Loss: 5.2184\n",
            "[Batch 9] Current Loss: 6.1469\n",
            "Ep 5 (Step 038980): Train loss 2.260, Val loss 5.863\n",
            "[Batch 0] Current Loss: 1.7329\n",
            "[Batch 1] Current Loss: 2.3331\n",
            "[Batch 2] Current Loss: 2.0526\n",
            "[Batch 3] Current Loss: 1.2570\n",
            "[Batch 4] Current Loss: 2.2454\n",
            "[Batch 5] Current Loss: 2.0843\n",
            "[Batch 6] Current Loss: 2.6430\n",
            "[Batch 7] Current Loss: 3.1797\n",
            "[Batch 8] Current Loss: 2.8031\n",
            "[Batch 9] Current Loss: 2.3169\n",
            "[Batch 0] Current Loss: 5.8888\n",
            "[Batch 1] Current Loss: 5.7977\n",
            "[Batch 2] Current Loss: 5.7965\n",
            "[Batch 3] Current Loss: 6.5211\n",
            "[Batch 4] Current Loss: 5.1428\n",
            "[Batch 5] Current Loss: 6.1796\n",
            "[Batch 6] Current Loss: 6.0168\n",
            "[Batch 7] Current Loss: 5.7419\n",
            "[Batch 8] Current Loss: 5.7721\n",
            "[Batch 9] Current Loss: 5.4455\n",
            "Ep 5 (Step 039000): Train loss 2.265, Val loss 5.830\n",
            "[Batch 0] Current Loss: 1.7213\n",
            "[Batch 1] Current Loss: 2.1652\n",
            "[Batch 2] Current Loss: 2.4904\n",
            "[Batch 3] Current Loss: 2.1538\n",
            "[Batch 4] Current Loss: 1.9168\n",
            "[Batch 5] Current Loss: 2.3856\n",
            "[Batch 6] Current Loss: 2.1850\n",
            "[Batch 7] Current Loss: 2.8534\n",
            "[Batch 8] Current Loss: 2.8400\n",
            "[Batch 9] Current Loss: 2.5390\n",
            "[Batch 0] Current Loss: 5.3315\n",
            "[Batch 1] Current Loss: 4.8614\n",
            "[Batch 2] Current Loss: 6.3448\n",
            "[Batch 3] Current Loss: 5.4939\n",
            "[Batch 4] Current Loss: 5.7325\n",
            "[Batch 5] Current Loss: 6.3202\n",
            "[Batch 6] Current Loss: 5.2292\n",
            "[Batch 7] Current Loss: 6.4569\n",
            "[Batch 8] Current Loss: 6.2028\n",
            "[Batch 9] Current Loss: 6.2258\n",
            "Ep 5 (Step 039020): Train loss 2.325, Val loss 5.820\n",
            "[Batch 0] Current Loss: 2.4607\n",
            "[Batch 1] Current Loss: 2.1606\n",
            "[Batch 2] Current Loss: 2.0343\n",
            "[Batch 3] Current Loss: 2.4408\n",
            "[Batch 4] Current Loss: 2.3320\n",
            "[Batch 5] Current Loss: 2.5003\n",
            "[Batch 6] Current Loss: 2.1158\n",
            "[Batch 7] Current Loss: 1.8065\n",
            "[Batch 8] Current Loss: 2.3239\n",
            "[Batch 9] Current Loss: 2.1534\n",
            "[Batch 0] Current Loss: 5.1212\n",
            "[Batch 1] Current Loss: 6.0113\n",
            "[Batch 2] Current Loss: 5.8306\n",
            "[Batch 3] Current Loss: 4.9831\n",
            "[Batch 4] Current Loss: 5.9537\n",
            "[Batch 5] Current Loss: 6.1792\n",
            "[Batch 6] Current Loss: 5.5644\n",
            "[Batch 7] Current Loss: 5.9068\n",
            "[Batch 8] Current Loss: 5.7751\n",
            "[Batch 9] Current Loss: 6.4206\n",
            "Ep 5 (Step 039040): Train loss 2.233, Val loss 5.775\n",
            "[Batch 0] Current Loss: 1.8952\n",
            "[Batch 1] Current Loss: 2.4805\n",
            "[Batch 2] Current Loss: 2.0523\n",
            "[Batch 3] Current Loss: 2.5761\n",
            "[Batch 4] Current Loss: 2.3267\n",
            "[Batch 5] Current Loss: 2.3682\n",
            "[Batch 6] Current Loss: 1.6263\n",
            "[Batch 7] Current Loss: 1.5315\n",
            "[Batch 8] Current Loss: 2.2103\n",
            "[Batch 9] Current Loss: 2.2311\n",
            "[Batch 0] Current Loss: 5.0171\n",
            "[Batch 1] Current Loss: 6.4437\n",
            "[Batch 2] Current Loss: 6.1751\n",
            "[Batch 3] Current Loss: 4.6628\n",
            "[Batch 4] Current Loss: 5.5693\n",
            "[Batch 5] Current Loss: 6.0007\n",
            "[Batch 6] Current Loss: 5.0160\n",
            "[Batch 7] Current Loss: 4.8709\n",
            "[Batch 8] Current Loss: 5.9762\n",
            "[Batch 9] Current Loss: 5.9094\n",
            "Ep 5 (Step 039060): Train loss 2.130, Val loss 5.564\n",
            "[Batch 0] Current Loss: 1.9789\n",
            "[Batch 1] Current Loss: 2.5595\n",
            "[Batch 2] Current Loss: 2.1375\n",
            "[Batch 3] Current Loss: 2.3361\n",
            "[Batch 4] Current Loss: 1.9631\n",
            "[Batch 5] Current Loss: 2.2485\n",
            "[Batch 6] Current Loss: 2.4060\n",
            "[Batch 7] Current Loss: 1.6550\n",
            "[Batch 8] Current Loss: 1.9806\n",
            "[Batch 9] Current Loss: 2.2059\n",
            "[Batch 0] Current Loss: 6.0522\n",
            "[Batch 1] Current Loss: 5.7596\n",
            "[Batch 2] Current Loss: 5.8599\n",
            "[Batch 3] Current Loss: 6.7882\n",
            "[Batch 4] Current Loss: 5.2035\n",
            "[Batch 5] Current Loss: 5.9326\n",
            "[Batch 6] Current Loss: 5.5417\n",
            "[Batch 7] Current Loss: 5.6591\n",
            "[Batch 8] Current Loss: 5.7962\n",
            "[Batch 9] Current Loss: 5.8041\n",
            "Ep 5 (Step 039080): Train loss 2.147, Val loss 5.840\n",
            "[Batch 0] Current Loss: 1.8887\n",
            "[Batch 1] Current Loss: 2.2836\n",
            "[Batch 2] Current Loss: 2.6048\n",
            "[Batch 3] Current Loss: 1.7232\n",
            "[Batch 4] Current Loss: 2.5575\n",
            "[Batch 5] Current Loss: 2.1115\n",
            "[Batch 6] Current Loss: 2.8889\n",
            "[Batch 7] Current Loss: 1.6200\n",
            "[Batch 8] Current Loss: 1.3844\n",
            "[Batch 9] Current Loss: 2.0558\n",
            "[Batch 0] Current Loss: 5.4563\n",
            "[Batch 1] Current Loss: 5.6509\n",
            "[Batch 2] Current Loss: 5.4301\n",
            "[Batch 3] Current Loss: 5.7624\n",
            "[Batch 4] Current Loss: 5.2746\n",
            "[Batch 5] Current Loss: 4.9780\n",
            "[Batch 6] Current Loss: 5.6447\n",
            "[Batch 7] Current Loss: 5.2493\n",
            "[Batch 8] Current Loss: 4.9286\n",
            "[Batch 9] Current Loss: 4.8887\n",
            "Ep 5 (Step 039100): Train loss 2.112, Val loss 5.326\n",
            "[Batch 0] Current Loss: 2.0789\n",
            "[Batch 1] Current Loss: 2.1201\n",
            "[Batch 2] Current Loss: 2.6521\n",
            "[Batch 3] Current Loss: 2.2633\n",
            "[Batch 4] Current Loss: 2.4138\n",
            "[Batch 5] Current Loss: 2.1383\n",
            "[Batch 6] Current Loss: 2.1622\n",
            "[Batch 7] Current Loss: 2.2266\n",
            "[Batch 8] Current Loss: 1.8545\n",
            "[Batch 9] Current Loss: 2.1331\n",
            "[Batch 0] Current Loss: 5.4587\n",
            "[Batch 1] Current Loss: 5.9297\n",
            "[Batch 2] Current Loss: 5.9664\n",
            "[Batch 3] Current Loss: 5.9436\n",
            "[Batch 4] Current Loss: 5.3976\n",
            "[Batch 5] Current Loss: 5.2252\n",
            "[Batch 6] Current Loss: 6.3141\n",
            "[Batch 7] Current Loss: 6.5858\n",
            "[Batch 8] Current Loss: 5.7084\n",
            "[Batch 9] Current Loss: 5.9112\n",
            "Ep 5 (Step 039120): Train loss 2.204, Val loss 5.844\n",
            "[Batch 0] Current Loss: 2.5296\n",
            "[Batch 1] Current Loss: 1.5589\n",
            "[Batch 2] Current Loss: 2.4112\n",
            "[Batch 3] Current Loss: 1.8899\n",
            "[Batch 4] Current Loss: 2.6922\n",
            "[Batch 5] Current Loss: 2.3515\n",
            "[Batch 6] Current Loss: 2.5450\n",
            "[Batch 7] Current Loss: 2.4376\n",
            "[Batch 8] Current Loss: 2.2873\n",
            "[Batch 9] Current Loss: 1.9224\n",
            "[Batch 0] Current Loss: 6.0234\n",
            "[Batch 1] Current Loss: 5.2696\n",
            "[Batch 2] Current Loss: 6.1938\n",
            "[Batch 3] Current Loss: 6.0807\n",
            "[Batch 4] Current Loss: 5.7292\n",
            "[Batch 5] Current Loss: 5.4308\n",
            "[Batch 6] Current Loss: 5.4678\n",
            "[Batch 7] Current Loss: 6.2272\n",
            "[Batch 8] Current Loss: 5.8059\n",
            "[Batch 9] Current Loss: 5.9536\n",
            "Ep 5 (Step 039140): Train loss 2.263, Val loss 5.818\n",
            "[Batch 0] Current Loss: 2.2928\n",
            "[Batch 1] Current Loss: 2.6727\n",
            "[Batch 2] Current Loss: 2.2748\n",
            "[Batch 3] Current Loss: 1.3033\n",
            "[Batch 4] Current Loss: 2.2643\n",
            "[Batch 5] Current Loss: 1.9056\n",
            "[Batch 6] Current Loss: 1.9103\n",
            "[Batch 7] Current Loss: 2.5005\n",
            "[Batch 8] Current Loss: 2.7998\n",
            "[Batch 9] Current Loss: 1.8736\n",
            "[Batch 0] Current Loss: 5.2903\n",
            "[Batch 1] Current Loss: 5.2696\n",
            "[Batch 2] Current Loss: 6.0225\n",
            "[Batch 3] Current Loss: 4.7284\n",
            "[Batch 4] Current Loss: 5.9819\n",
            "[Batch 5] Current Loss: 5.4202\n",
            "[Batch 6] Current Loss: 5.6270\n",
            "[Batch 7] Current Loss: 5.7689\n",
            "[Batch 8] Current Loss: 6.5376\n",
            "[Batch 9] Current Loss: 5.7678\n",
            "Ep 5 (Step 039160): Train loss 2.180, Val loss 5.641\n",
            "[Batch 0] Current Loss: 1.8866\n",
            "[Batch 1] Current Loss: 1.8797\n",
            "[Batch 2] Current Loss: 1.6867\n",
            "[Batch 3] Current Loss: 1.7677\n",
            "[Batch 4] Current Loss: 2.6517\n",
            "[Batch 5] Current Loss: 2.0625\n",
            "[Batch 6] Current Loss: 1.5932\n",
            "[Batch 7] Current Loss: 1.9468\n",
            "[Batch 8] Current Loss: 2.4593\n",
            "[Batch 9] Current Loss: 1.9702\n",
            "[Batch 0] Current Loss: 5.9020\n",
            "[Batch 1] Current Loss: 5.2177\n",
            "[Batch 2] Current Loss: 5.6455\n",
            "[Batch 3] Current Loss: 4.9364\n",
            "[Batch 4] Current Loss: 5.1392\n",
            "[Batch 5] Current Loss: 5.1699\n",
            "[Batch 6] Current Loss: 4.9788\n",
            "[Batch 7] Current Loss: 5.8731\n",
            "[Batch 8] Current Loss: 6.0883\n",
            "[Batch 9] Current Loss: 4.8363\n",
            "Ep 5 (Step 039180): Train loss 1.990, Val loss 5.379\n",
            "[Batch 0] Current Loss: 2.6160\n",
            "[Batch 1] Current Loss: 1.8946\n",
            "[Batch 2] Current Loss: 2.1528\n",
            "[Batch 3] Current Loss: 1.8560\n",
            "[Batch 4] Current Loss: 1.9582\n",
            "[Batch 5] Current Loss: 2.1392\n",
            "[Batch 6] Current Loss: 2.8075\n",
            "[Batch 7] Current Loss: 1.9982\n",
            "[Batch 8] Current Loss: 2.1844\n",
            "[Batch 9] Current Loss: 2.0504\n",
            "[Batch 0] Current Loss: 6.2511\n",
            "[Batch 1] Current Loss: 5.3069\n",
            "[Batch 2] Current Loss: 5.3118\n",
            "[Batch 3] Current Loss: 5.7721\n",
            "[Batch 4] Current Loss: 5.8486\n",
            "[Batch 5] Current Loss: 4.3931\n",
            "[Batch 6] Current Loss: 5.2744\n",
            "[Batch 7] Current Loss: 5.1454\n",
            "[Batch 8] Current Loss: 5.7449\n",
            "[Batch 9] Current Loss: 5.3745\n",
            "Ep 5 (Step 039200): Train loss 2.166, Val loss 5.442\n",
            "[Batch 0] Current Loss: 1.8188\n",
            "[Batch 1] Current Loss: 2.0990\n",
            "[Batch 2] Current Loss: 2.3119\n",
            "[Batch 3] Current Loss: 1.3882\n",
            "[Batch 4] Current Loss: 2.5291\n",
            "[Batch 5] Current Loss: 2.6308\n",
            "[Batch 6] Current Loss: 1.4854\n",
            "[Batch 7] Current Loss: 1.4681\n",
            "[Batch 8] Current Loss: 2.2451\n",
            "[Batch 9] Current Loss: 1.7294\n",
            "[Batch 0] Current Loss: 5.6039\n",
            "[Batch 1] Current Loss: 5.4210\n",
            "[Batch 2] Current Loss: 5.5781\n",
            "[Batch 3] Current Loss: 6.6661\n",
            "[Batch 4] Current Loss: 5.3383\n",
            "[Batch 5] Current Loss: 5.3765\n",
            "[Batch 6] Current Loss: 6.0851\n",
            "[Batch 7] Current Loss: 5.5558\n",
            "[Batch 8] Current Loss: 5.7100\n",
            "[Batch 9] Current Loss: 6.1486\n",
            "Ep 5 (Step 039220): Train loss 1.971, Val loss 5.748\n",
            "[Batch 0] Current Loss: 1.7835\n",
            "[Batch 1] Current Loss: 2.3126\n",
            "[Batch 2] Current Loss: 2.3920\n",
            "[Batch 3] Current Loss: 2.6938\n",
            "[Batch 4] Current Loss: 1.9459\n",
            "[Batch 5] Current Loss: 2.1105\n",
            "[Batch 6] Current Loss: 1.9955\n",
            "[Batch 7] Current Loss: 1.8073\n",
            "[Batch 8] Current Loss: 2.8528\n",
            "[Batch 9] Current Loss: 2.8325\n",
            "[Batch 0] Current Loss: 5.4945\n",
            "[Batch 1] Current Loss: 5.0659\n",
            "[Batch 2] Current Loss: 6.3747\n",
            "[Batch 3] Current Loss: 6.3540\n",
            "[Batch 4] Current Loss: 5.1417\n",
            "[Batch 5] Current Loss: 4.9477\n",
            "[Batch 6] Current Loss: 5.7402\n",
            "[Batch 7] Current Loss: 5.3931\n",
            "[Batch 8] Current Loss: 5.1749\n",
            "[Batch 9] Current Loss: 5.6768\n",
            "Ep 5 (Step 039240): Train loss 2.273, Val loss 5.536\n",
            "[Batch 0] Current Loss: 2.4517\n",
            "[Batch 1] Current Loss: 1.9977\n",
            "[Batch 2] Current Loss: 2.7096\n",
            "[Batch 3] Current Loss: 2.0841\n",
            "[Batch 4] Current Loss: 2.1551\n",
            "[Batch 5] Current Loss: 2.1578\n",
            "[Batch 6] Current Loss: 2.2292\n",
            "[Batch 7] Current Loss: 1.7724\n",
            "[Batch 8] Current Loss: 2.0758\n",
            "[Batch 9] Current Loss: 2.4728\n",
            "[Batch 0] Current Loss: 5.6029\n",
            "[Batch 1] Current Loss: 5.9222\n",
            "[Batch 2] Current Loss: 5.7035\n",
            "[Batch 3] Current Loss: 5.8153\n",
            "[Batch 4] Current Loss: 6.2230\n",
            "[Batch 5] Current Loss: 6.3340\n",
            "[Batch 6] Current Loss: 5.4001\n",
            "[Batch 7] Current Loss: 5.2553\n",
            "[Batch 8] Current Loss: 6.0902\n",
            "[Batch 9] Current Loss: 5.3400\n",
            "Ep 5 (Step 039260): Train loss 2.211, Val loss 5.769\n",
            "[Batch 0] Current Loss: 1.9699\n",
            "[Batch 1] Current Loss: 1.5165\n",
            "[Batch 2] Current Loss: 1.3350\n",
            "[Batch 3] Current Loss: 1.9659\n",
            "[Batch 4] Current Loss: 1.4673\n",
            "[Batch 5] Current Loss: 1.5528\n",
            "[Batch 6] Current Loss: 2.6662\n",
            "[Batch 7] Current Loss: 1.9282\n",
            "[Batch 8] Current Loss: 2.4531\n",
            "[Batch 9] Current Loss: 1.9102\n",
            "[Batch 0] Current Loss: 6.1268\n",
            "[Batch 1] Current Loss: 5.7630\n",
            "[Batch 2] Current Loss: 5.6752\n",
            "[Batch 3] Current Loss: 5.5692\n",
            "[Batch 4] Current Loss: 5.6753\n",
            "[Batch 5] Current Loss: 6.4668\n",
            "[Batch 6] Current Loss: 6.0351\n",
            "[Batch 7] Current Loss: 4.7846\n",
            "[Batch 8] Current Loss: 5.8341\n",
            "[Batch 9] Current Loss: 5.5048\n",
            "Ep 5 (Step 039280): Train loss 1.877, Val loss 5.743\n",
            "[Batch 0] Current Loss: 1.9030\n",
            "[Batch 1] Current Loss: 2.0620\n",
            "[Batch 2] Current Loss: 1.6787\n",
            "[Batch 3] Current Loss: 1.6694\n",
            "[Batch 4] Current Loss: 2.1721\n",
            "[Batch 5] Current Loss: 2.6064\n",
            "[Batch 6] Current Loss: 2.4071\n",
            "[Batch 7] Current Loss: 2.2122\n",
            "[Batch 8] Current Loss: 2.4631\n",
            "[Batch 9] Current Loss: 2.0822\n",
            "[Batch 0] Current Loss: 6.0153\n",
            "[Batch 1] Current Loss: 5.8357\n",
            "[Batch 2] Current Loss: 6.2239\n",
            "[Batch 3] Current Loss: 5.9026\n",
            "[Batch 4] Current Loss: 5.8758\n",
            "[Batch 5] Current Loss: 5.6068\n",
            "[Batch 6] Current Loss: 5.5232\n",
            "[Batch 7] Current Loss: 5.3190\n",
            "[Batch 8] Current Loss: 4.4144\n",
            "[Batch 9] Current Loss: 5.3772\n",
            "Ep 5 (Step 039300): Train loss 2.126, Val loss 5.609\n",
            "[Batch 0] Current Loss: 2.8961\n",
            "[Batch 1] Current Loss: 2.2046\n",
            "[Batch 2] Current Loss: 1.8571\n",
            "[Batch 3] Current Loss: 1.8006\n",
            "[Batch 4] Current Loss: 2.1867\n",
            "[Batch 5] Current Loss: 1.9339\n",
            "[Batch 6] Current Loss: 1.9360\n",
            "[Batch 7] Current Loss: 2.1326\n",
            "[Batch 8] Current Loss: 1.7717\n",
            "[Batch 9] Current Loss: 2.1921\n",
            "[Batch 0] Current Loss: 5.5003\n",
            "[Batch 1] Current Loss: 5.2251\n",
            "[Batch 2] Current Loss: 5.5694\n",
            "[Batch 3] Current Loss: 5.6112\n",
            "[Batch 4] Current Loss: 5.3200\n",
            "[Batch 5] Current Loss: 6.1843\n",
            "[Batch 6] Current Loss: 5.9726\n",
            "[Batch 7] Current Loss: 5.8343\n",
            "[Batch 8] Current Loss: 5.6122\n",
            "[Batch 9] Current Loss: 5.2275\n",
            "Ep 5 (Step 039320): Train loss 2.091, Val loss 5.606\n",
            "[Batch 0] Current Loss: 2.5719\n",
            "[Batch 1] Current Loss: 2.3640\n",
            "[Batch 2] Current Loss: 2.0976\n",
            "[Batch 3] Current Loss: 2.4218\n",
            "[Batch 4] Current Loss: 2.0669\n",
            "[Batch 5] Current Loss: 2.2594\n",
            "[Batch 6] Current Loss: 2.3738\n",
            "[Batch 7] Current Loss: 2.3621\n",
            "[Batch 8] Current Loss: 1.8898\n",
            "[Batch 9] Current Loss: 1.4216\n",
            "[Batch 0] Current Loss: 5.6003\n",
            "[Batch 1] Current Loss: 5.0093\n",
            "[Batch 2] Current Loss: 5.5091\n",
            "[Batch 3] Current Loss: 4.9900\n",
            "[Batch 4] Current Loss: 5.1801\n",
            "[Batch 5] Current Loss: 5.8093\n",
            "[Batch 6] Current Loss: 5.6710\n",
            "[Batch 7] Current Loss: 5.2725\n",
            "[Batch 8] Current Loss: 5.3906\n",
            "[Batch 9] Current Loss: 5.5072\n",
            "Ep 5 (Step 039340): Train loss 2.183, Val loss 5.394\n",
            "[Batch 0] Current Loss: 2.1587\n",
            "[Batch 1] Current Loss: 2.0260\n",
            "[Batch 2] Current Loss: 1.9805\n",
            "[Batch 3] Current Loss: 1.9521\n",
            "[Batch 4] Current Loss: 1.8594\n",
            "[Batch 5] Current Loss: 2.4337\n",
            "[Batch 6] Current Loss: 1.6387\n",
            "[Batch 7] Current Loss: 2.3218\n",
            "[Batch 8] Current Loss: 2.4632\n",
            "[Batch 9] Current Loss: 2.4217\n",
            "[Batch 0] Current Loss: 6.0877\n",
            "[Batch 1] Current Loss: 5.0990\n",
            "[Batch 2] Current Loss: 6.0714\n",
            "[Batch 3] Current Loss: 4.2083\n",
            "[Batch 4] Current Loss: 6.0543\n",
            "[Batch 5] Current Loss: 5.1187\n",
            "[Batch 6] Current Loss: 6.0381\n",
            "[Batch 7] Current Loss: 5.0689\n",
            "[Batch 8] Current Loss: 5.8791\n",
            "[Batch 9] Current Loss: 5.6654\n",
            "Ep 5 (Step 039360): Train loss 2.126, Val loss 5.529\n",
            "[Batch 0] Current Loss: 2.4074\n",
            "[Batch 1] Current Loss: 2.6433\n",
            "[Batch 2] Current Loss: 2.1938\n",
            "[Batch 3] Current Loss: 2.1205\n",
            "[Batch 4] Current Loss: 2.2821\n",
            "[Batch 5] Current Loss: 2.1006\n",
            "[Batch 6] Current Loss: 2.0581\n",
            "[Batch 7] Current Loss: 2.0402\n",
            "[Batch 8] Current Loss: 2.2413\n",
            "[Batch 9] Current Loss: 1.3269\n",
            "[Batch 0] Current Loss: 5.8531\n",
            "[Batch 1] Current Loss: 5.5553\n",
            "[Batch 2] Current Loss: 5.5027\n",
            "[Batch 3] Current Loss: 5.0232\n",
            "[Batch 4] Current Loss: 5.0364\n",
            "[Batch 5] Current Loss: 4.9103\n",
            "[Batch 6] Current Loss: 5.5627\n",
            "[Batch 7] Current Loss: 5.2256\n",
            "[Batch 8] Current Loss: 6.2475\n",
            "[Batch 9] Current Loss: 6.0500\n",
            "Ep 5 (Step 039380): Train loss 2.141, Val loss 5.497\n",
            "[Batch 0] Current Loss: 2.1762\n",
            "[Batch 1] Current Loss: 2.3203\n",
            "[Batch 2] Current Loss: 2.1299\n",
            "[Batch 3] Current Loss: 1.9145\n",
            "[Batch 4] Current Loss: 2.2792\n",
            "[Batch 5] Current Loss: 3.0204\n",
            "[Batch 6] Current Loss: 2.1420\n",
            "[Batch 7] Current Loss: 1.7476\n",
            "[Batch 8] Current Loss: 2.1058\n",
            "[Batch 9] Current Loss: 1.6344\n",
            "[Batch 0] Current Loss: 5.5808\n",
            "[Batch 1] Current Loss: 5.5038\n",
            "[Batch 2] Current Loss: 5.7881\n",
            "[Batch 3] Current Loss: 5.5207\n",
            "[Batch 4] Current Loss: 5.4873\n",
            "[Batch 5] Current Loss: 4.9287\n",
            "[Batch 6] Current Loss: 5.7207\n",
            "[Batch 7] Current Loss: 4.9183\n",
            "[Batch 8] Current Loss: 5.2352\n",
            "[Batch 9] Current Loss: 6.3548\n",
            "Ep 5 (Step 039400): Train loss 2.147, Val loss 5.504\n",
            "[Batch 0] Current Loss: 1.6321\n",
            "[Batch 1] Current Loss: 2.0388\n",
            "[Batch 2] Current Loss: 2.6542\n",
            "[Batch 3] Current Loss: 1.8703\n",
            "[Batch 4] Current Loss: 1.6734\n",
            "[Batch 5] Current Loss: 2.1453\n",
            "[Batch 6] Current Loss: 1.9777\n",
            "[Batch 7] Current Loss: 2.0555\n",
            "[Batch 8] Current Loss: 2.4618\n",
            "[Batch 9] Current Loss: 2.6814\n",
            "[Batch 0] Current Loss: 5.3181\n",
            "[Batch 1] Current Loss: 6.2275\n",
            "[Batch 2] Current Loss: 5.1630\n",
            "[Batch 3] Current Loss: 5.6933\n",
            "[Batch 4] Current Loss: 5.2125\n",
            "[Batch 5] Current Loss: 6.1492\n",
            "[Batch 6] Current Loss: 6.1235\n",
            "[Batch 7] Current Loss: 5.6400\n",
            "[Batch 8] Current Loss: 5.2451\n",
            "[Batch 9] Current Loss: 6.6046\n",
            "Ep 5 (Step 039420): Train loss 2.119, Val loss 5.738\n",
            "[Batch 0] Current Loss: 2.4167\n",
            "[Batch 1] Current Loss: 1.9421\n",
            "[Batch 2] Current Loss: 2.3919\n",
            "[Batch 3] Current Loss: 1.6654\n",
            "[Batch 4] Current Loss: 1.8062\n",
            "[Batch 5] Current Loss: 2.0896\n",
            "[Batch 6] Current Loss: 2.4763\n",
            "[Batch 7] Current Loss: 2.0302\n",
            "[Batch 8] Current Loss: 2.0886\n",
            "[Batch 9] Current Loss: 1.5920\n",
            "[Batch 0] Current Loss: 5.3367\n",
            "[Batch 1] Current Loss: 6.1319\n",
            "[Batch 2] Current Loss: 6.0557\n",
            "[Batch 3] Current Loss: 5.5885\n",
            "[Batch 4] Current Loss: 5.3983\n",
            "[Batch 5] Current Loss: 6.2288\n",
            "[Batch 6] Current Loss: 5.6628\n",
            "[Batch 7] Current Loss: 6.3379\n",
            "[Batch 8] Current Loss: 5.9228\n",
            "[Batch 9] Current Loss: 5.7885\n",
            "Ep 5 (Step 039440): Train loss 2.050, Val loss 5.845\n",
            "[Batch 0] Current Loss: 1.7759\n",
            "[Batch 1] Current Loss: 2.0322\n",
            "[Batch 2] Current Loss: 2.3973\n",
            "[Batch 3] Current Loss: 2.2136\n",
            "[Batch 4] Current Loss: 2.2178\n",
            "[Batch 5] Current Loss: 2.0308\n",
            "[Batch 6] Current Loss: 2.1095\n",
            "[Batch 7] Current Loss: 1.9238\n",
            "[Batch 8] Current Loss: 1.6638\n",
            "[Batch 9] Current Loss: 1.5849\n",
            "[Batch 0] Current Loss: 6.7015\n",
            "[Batch 1] Current Loss: 5.5053\n",
            "[Batch 2] Current Loss: 5.4514\n",
            "[Batch 3] Current Loss: 5.1064\n",
            "[Batch 4] Current Loss: 5.7258\n",
            "[Batch 5] Current Loss: 5.6771\n",
            "[Batch 6] Current Loss: 5.8245\n",
            "[Batch 7] Current Loss: 5.6668\n",
            "[Batch 8] Current Loss: 6.4055\n",
            "[Batch 9] Current Loss: 5.4871\n",
            "Ep 5 (Step 039460): Train loss 1.995, Val loss 5.755\n",
            "[Batch 0] Current Loss: 2.3683\n",
            "[Batch 1] Current Loss: 2.6008\n",
            "[Batch 2] Current Loss: 2.6634\n",
            "[Batch 3] Current Loss: 2.7353\n",
            "[Batch 4] Current Loss: 1.5778\n",
            "[Batch 5] Current Loss: 1.9125\n",
            "[Batch 6] Current Loss: 2.1933\n",
            "[Batch 7] Current Loss: 2.2467\n",
            "[Batch 8] Current Loss: 1.6661\n",
            "[Batch 9] Current Loss: 1.6570\n",
            "[Batch 0] Current Loss: 5.2069\n",
            "[Batch 1] Current Loss: 5.6911\n",
            "[Batch 2] Current Loss: 5.3210\n",
            "[Batch 3] Current Loss: 5.6269\n",
            "[Batch 4] Current Loss: 6.3134\n",
            "[Batch 5] Current Loss: 5.9266\n",
            "[Batch 6] Current Loss: 5.9958\n",
            "[Batch 7] Current Loss: 5.0530\n",
            "[Batch 8] Current Loss: 6.1640\n",
            "[Batch 9] Current Loss: 6.0277\n",
            "Ep 5 (Step 039480): Train loss 2.162, Val loss 5.733\n",
            "[Batch 0] Current Loss: 1.5608\n",
            "[Batch 1] Current Loss: 2.3911\n",
            "[Batch 2] Current Loss: 2.3716\n",
            "[Batch 3] Current Loss: 2.3295\n",
            "[Batch 4] Current Loss: 1.9539\n",
            "[Batch 5] Current Loss: 2.0612\n",
            "[Batch 6] Current Loss: 2.1425\n",
            "[Batch 7] Current Loss: 2.1400\n",
            "[Batch 8] Current Loss: 2.0324\n",
            "[Batch 9] Current Loss: 1.8573\n",
            "[Batch 0] Current Loss: 6.0024\n",
            "[Batch 1] Current Loss: 5.6461\n",
            "[Batch 2] Current Loss: 5.8984\n",
            "[Batch 3] Current Loss: 4.6884\n",
            "[Batch 4] Current Loss: 5.7692\n",
            "[Batch 5] Current Loss: 5.8001\n",
            "[Batch 6] Current Loss: 5.4210\n",
            "[Batch 7] Current Loss: 5.3466\n",
            "[Batch 8] Current Loss: 5.3387\n",
            "[Batch 9] Current Loss: 5.0185\n",
            "Ep 5 (Step 039500): Train loss 2.084, Val loss 5.493\n",
            "[Batch 0] Current Loss: 2.6066\n",
            "[Batch 1] Current Loss: 2.2014\n",
            "[Batch 2] Current Loss: 2.0734\n",
            "[Batch 3] Current Loss: 2.3146\n",
            "[Batch 4] Current Loss: 1.9475\n",
            "[Batch 5] Current Loss: 2.0746\n",
            "[Batch 6] Current Loss: 1.7618\n",
            "[Batch 7] Current Loss: 1.8959\n",
            "[Batch 8] Current Loss: 2.0038\n",
            "[Batch 9] Current Loss: 2.5907\n",
            "[Batch 0] Current Loss: 5.9338\n",
            "[Batch 1] Current Loss: 5.5578\n",
            "[Batch 2] Current Loss: 5.3193\n",
            "[Batch 3] Current Loss: 5.3008\n",
            "[Batch 4] Current Loss: 4.9680\n",
            "[Batch 5] Current Loss: 5.2413\n",
            "[Batch 6] Current Loss: 5.8120\n",
            "[Batch 7] Current Loss: 5.8215\n",
            "[Batch 8] Current Loss: 4.7184\n",
            "[Batch 9] Current Loss: 5.3396\n",
            "Ep 5 (Step 039520): Train loss 2.147, Val loss 5.401\n",
            "[Batch 0] Current Loss: 1.9903\n",
            "[Batch 1] Current Loss: 2.9855\n",
            "[Batch 2] Current Loss: 2.3970\n",
            "[Batch 3] Current Loss: 1.8162\n",
            "[Batch 4] Current Loss: 2.1385\n",
            "[Batch 5] Current Loss: 1.8824\n",
            "[Batch 6] Current Loss: 1.2180\n",
            "[Batch 7] Current Loss: 1.5818\n",
            "[Batch 8] Current Loss: 1.6132\n",
            "[Batch 9] Current Loss: 2.0878\n",
            "[Batch 0] Current Loss: 5.1717\n",
            "[Batch 1] Current Loss: 6.3311\n",
            "[Batch 2] Current Loss: 5.4589\n",
            "[Batch 3] Current Loss: 6.0030\n",
            "[Batch 4] Current Loss: 5.6719\n",
            "[Batch 5] Current Loss: 6.0017\n",
            "[Batch 6] Current Loss: 5.7821\n",
            "[Batch 7] Current Loss: 4.8257\n",
            "[Batch 8] Current Loss: 5.9976\n",
            "[Batch 9] Current Loss: 5.7203\n",
            "Ep 5 (Step 039540): Train loss 1.971, Val loss 5.696\n",
            "[Batch 0] Current Loss: 2.4294\n",
            "[Batch 1] Current Loss: 2.0098\n",
            "[Batch 2] Current Loss: 1.9990\n",
            "[Batch 3] Current Loss: 2.3744\n",
            "[Batch 4] Current Loss: 1.5510\n",
            "[Batch 5] Current Loss: 2.4877\n",
            "[Batch 6] Current Loss: 2.0700\n",
            "[Batch 7] Current Loss: 1.8563\n",
            "[Batch 8] Current Loss: 1.9179\n",
            "[Batch 9] Current Loss: 2.1322\n",
            "[Batch 0] Current Loss: 5.7236\n",
            "[Batch 1] Current Loss: 5.4581\n",
            "[Batch 2] Current Loss: 5.7383\n",
            "[Batch 3] Current Loss: 5.9031\n",
            "[Batch 4] Current Loss: 6.0383\n",
            "[Batch 5] Current Loss: 5.8135\n",
            "[Batch 6] Current Loss: 5.2031\n",
            "[Batch 7] Current Loss: 4.9461\n",
            "[Batch 8] Current Loss: 5.2360\n",
            "[Batch 9] Current Loss: 6.0747\n",
            "Ep 5 (Step 039560): Train loss 2.083, Val loss 5.613\n",
            "[Batch 0] Current Loss: 2.6923\n",
            "[Batch 1] Current Loss: 1.6756\n",
            "[Batch 2] Current Loss: 1.8355\n",
            "[Batch 3] Current Loss: 2.0801\n",
            "[Batch 4] Current Loss: 2.2918\n",
            "[Batch 5] Current Loss: 2.1487\n",
            "[Batch 6] Current Loss: 1.9141\n",
            "[Batch 7] Current Loss: 1.6239\n",
            "[Batch 8] Current Loss: 2.1541\n",
            "[Batch 9] Current Loss: 2.0294\n",
            "[Batch 0] Current Loss: 5.4639\n",
            "[Batch 1] Current Loss: 5.8014\n",
            "[Batch 2] Current Loss: 6.0346\n",
            "[Batch 3] Current Loss: 5.3276\n",
            "[Batch 4] Current Loss: 5.9267\n",
            "[Batch 5] Current Loss: 5.6432\n",
            "[Batch 6] Current Loss: 5.7220\n",
            "[Batch 7] Current Loss: 5.7576\n",
            "[Batch 8] Current Loss: 5.5940\n",
            "[Batch 9] Current Loss: 5.7858\n",
            "Ep 5 (Step 039580): Train loss 2.045, Val loss 5.706\n",
            "[Batch 0] Current Loss: 1.7380\n",
            "[Batch 1] Current Loss: 1.9061\n",
            "[Batch 2] Current Loss: 2.2858\n",
            "[Batch 3] Current Loss: 2.0587\n",
            "[Batch 4] Current Loss: 2.0223\n",
            "[Batch 5] Current Loss: 1.8931\n",
            "[Batch 6] Current Loss: 2.2654\n",
            "[Batch 7] Current Loss: 1.8749\n",
            "[Batch 8] Current Loss: 1.8863\n",
            "[Batch 9] Current Loss: 1.9368\n",
            "[Batch 0] Current Loss: 5.8715\n",
            "[Batch 1] Current Loss: 5.3537\n",
            "[Batch 2] Current Loss: 5.4355\n",
            "[Batch 3] Current Loss: 5.1979\n",
            "[Batch 4] Current Loss: 6.9314\n",
            "[Batch 5] Current Loss: 5.5419\n",
            "[Batch 6] Current Loss: 5.6229\n",
            "[Batch 7] Current Loss: 5.9732\n",
            "[Batch 8] Current Loss: 5.7314\n",
            "[Batch 9] Current Loss: 6.3527\n",
            "Ep 5 (Step 039600): Train loss 1.987, Val loss 5.801\n",
            "[Batch 0] Current Loss: 2.2736\n",
            "[Batch 1] Current Loss: 2.3513\n",
            "[Batch 2] Current Loss: 2.2341\n",
            "[Batch 3] Current Loss: 2.1357\n",
            "[Batch 4] Current Loss: 1.8835\n",
            "[Batch 5] Current Loss: 1.7999\n",
            "[Batch 6] Current Loss: 1.9816\n",
            "[Batch 7] Current Loss: 2.6083\n",
            "[Batch 8] Current Loss: 2.3819\n",
            "[Batch 9] Current Loss: 2.4556\n",
            "[Batch 0] Current Loss: 5.3294\n",
            "[Batch 1] Current Loss: 5.7818\n",
            "[Batch 2] Current Loss: 5.8775\n",
            "[Batch 3] Current Loss: 4.9809\n",
            "[Batch 4] Current Loss: 5.7445\n",
            "[Batch 5] Current Loss: 5.7241\n",
            "[Batch 6] Current Loss: 5.7210\n",
            "[Batch 7] Current Loss: 6.3974\n",
            "[Batch 8] Current Loss: 5.6954\n",
            "[Batch 9] Current Loss: 5.8507\n",
            "Ep 5 (Step 039620): Train loss 2.211, Val loss 5.710\n",
            "[Batch 0] Current Loss: 2.6555\n",
            "[Batch 1] Current Loss: 1.5296\n",
            "[Batch 2] Current Loss: 2.4461\n",
            "[Batch 3] Current Loss: 1.7339\n",
            "[Batch 4] Current Loss: 1.6795\n",
            "[Batch 5] Current Loss: 2.0638\n",
            "[Batch 6] Current Loss: 2.3647\n",
            "[Batch 7] Current Loss: 2.2499\n",
            "[Batch 8] Current Loss: 2.9305\n",
            "[Batch 9] Current Loss: 2.0557\n",
            "[Batch 0] Current Loss: 6.1883\n",
            "[Batch 1] Current Loss: 5.2070\n",
            "[Batch 2] Current Loss: 6.0819\n",
            "[Batch 3] Current Loss: 6.0945\n",
            "[Batch 4] Current Loss: 5.5596\n",
            "[Batch 5] Current Loss: 5.1305\n",
            "[Batch 6] Current Loss: 5.2665\n",
            "[Batch 7] Current Loss: 5.7086\n",
            "[Batch 8] Current Loss: 4.6070\n",
            "[Batch 9] Current Loss: 5.4546\n",
            "Ep 5 (Step 039640): Train loss 2.171, Val loss 5.530\n",
            "[Batch 0] Current Loss: 1.4111\n",
            "[Batch 1] Current Loss: 2.3815\n",
            "[Batch 2] Current Loss: 2.0519\n",
            "[Batch 3] Current Loss: 1.6254\n",
            "[Batch 4] Current Loss: 1.9276\n",
            "[Batch 5] Current Loss: 1.9605\n",
            "[Batch 6] Current Loss: 3.2472\n",
            "[Batch 7] Current Loss: 2.1185\n",
            "[Batch 8] Current Loss: 2.6558\n",
            "[Batch 9] Current Loss: 2.0196\n",
            "[Batch 0] Current Loss: 5.9805\n",
            "[Batch 1] Current Loss: 5.0696\n",
            "[Batch 2] Current Loss: 4.5619\n",
            "[Batch 3] Current Loss: 5.3289\n",
            "[Batch 4] Current Loss: 4.7468\n",
            "[Batch 5] Current Loss: 4.9337\n",
            "[Batch 6] Current Loss: 6.1786\n",
            "[Batch 7] Current Loss: 6.2993\n",
            "[Batch 8] Current Loss: 5.9087\n",
            "[Batch 9] Current Loss: 5.9169\n",
            "Ep 5 (Step 039660): Train loss 2.140, Val loss 5.492\n",
            "[Batch 0] Current Loss: 2.3219\n",
            "[Batch 1] Current Loss: 2.0313\n",
            "[Batch 2] Current Loss: 1.9442\n",
            "[Batch 3] Current Loss: 1.6747\n",
            "[Batch 4] Current Loss: 1.8413\n",
            "[Batch 5] Current Loss: 1.7145\n",
            "[Batch 6] Current Loss: 2.2731\n",
            "[Batch 7] Current Loss: 2.0307\n",
            "[Batch 8] Current Loss: 2.0937\n",
            "[Batch 9] Current Loss: 2.5486\n",
            "[Batch 0] Current Loss: 5.9317\n",
            "[Batch 1] Current Loss: 5.1051\n",
            "[Batch 2] Current Loss: 5.5605\n",
            "[Batch 3] Current Loss: 4.8801\n",
            "[Batch 4] Current Loss: 6.1267\n",
            "[Batch 5] Current Loss: 5.6066\n",
            "[Batch 6] Current Loss: 5.6479\n",
            "[Batch 7] Current Loss: 5.4742\n",
            "[Batch 8] Current Loss: 5.3556\n",
            "[Batch 9] Current Loss: 5.8995\n",
            "Ep 5 (Step 039680): Train loss 2.047, Val loss 5.559\n",
            "[Batch 0] Current Loss: 1.4191\n",
            "[Batch 1] Current Loss: 2.0502\n",
            "[Batch 2] Current Loss: 1.7017\n",
            "[Batch 3] Current Loss: 2.2402\n",
            "[Batch 4] Current Loss: 2.0881\n",
            "[Batch 5] Current Loss: 1.7213\n",
            "[Batch 6] Current Loss: 1.8103\n",
            "[Batch 7] Current Loss: 2.0510\n",
            "[Batch 8] Current Loss: 1.9790\n",
            "[Batch 9] Current Loss: 2.7639\n",
            "[Batch 0] Current Loss: 4.8460\n",
            "[Batch 1] Current Loss: 5.2882\n",
            "[Batch 2] Current Loss: 5.7380\n",
            "[Batch 3] Current Loss: 5.4128\n",
            "[Batch 4] Current Loss: 5.7274\n",
            "[Batch 5] Current Loss: 5.7441\n",
            "[Batch 6] Current Loss: 5.5769\n",
            "[Batch 7] Current Loss: 4.4198\n",
            "[Batch 8] Current Loss: 5.1518\n",
            "[Batch 9] Current Loss: 5.6660\n",
            "Ep 5 (Step 039700): Train loss 1.982, Val loss 5.357\n",
            "[Batch 0] Current Loss: 1.8139\n",
            "[Batch 1] Current Loss: 2.5900\n",
            "[Batch 2] Current Loss: 2.8976\n",
            "[Batch 3] Current Loss: 2.0199\n",
            "[Batch 4] Current Loss: 1.8620\n",
            "[Batch 5] Current Loss: 2.3594\n",
            "[Batch 6] Current Loss: 1.9874\n",
            "[Batch 7] Current Loss: 2.2336\n",
            "[Batch 8] Current Loss: 2.2019\n",
            "[Batch 9] Current Loss: 2.7126\n",
            "[Batch 0] Current Loss: 5.4951\n",
            "[Batch 1] Current Loss: 5.7263\n",
            "[Batch 2] Current Loss: 4.7275\n",
            "[Batch 3] Current Loss: 5.4496\n",
            "[Batch 4] Current Loss: 6.3701\n",
            "[Batch 5] Current Loss: 5.4126\n",
            "[Batch 6] Current Loss: 5.6701\n",
            "[Batch 7] Current Loss: 4.8495\n",
            "[Batch 8] Current Loss: 4.7198\n",
            "[Batch 9] Current Loss: 5.9490\n",
            "Ep 5 (Step 039720): Train loss 2.268, Val loss 5.437\n",
            "[Batch 0] Current Loss: 1.7772\n",
            "[Batch 1] Current Loss: 2.4337\n",
            "[Batch 2] Current Loss: 1.7422\n",
            "[Batch 3] Current Loss: 1.9086\n",
            "[Batch 4] Current Loss: 2.1973\n",
            "[Batch 5] Current Loss: 2.2250\n",
            "[Batch 6] Current Loss: 1.8193\n",
            "[Batch 7] Current Loss: 2.4768\n",
            "[Batch 8] Current Loss: 2.4136\n",
            "[Batch 9] Current Loss: 1.8325\n",
            "[Batch 0] Current Loss: 5.6228\n",
            "[Batch 1] Current Loss: 5.3261\n",
            "[Batch 2] Current Loss: 5.8058\n",
            "[Batch 3] Current Loss: 5.7322\n",
            "[Batch 4] Current Loss: 6.3811\n",
            "[Batch 5] Current Loss: 5.5346\n",
            "[Batch 6] Current Loss: 5.9322\n",
            "[Batch 7] Current Loss: 5.2090\n",
            "[Batch 8] Current Loss: 6.3774\n",
            "[Batch 9] Current Loss: 5.5323\n",
            "Ep 5 (Step 039740): Train loss 2.083, Val loss 5.745\n",
            "[Batch 0] Current Loss: 2.3264\n",
            "[Batch 1] Current Loss: 2.2653\n",
            "[Batch 2] Current Loss: 1.7532\n",
            "[Batch 3] Current Loss: 2.0644\n",
            "[Batch 4] Current Loss: 3.0479\n",
            "[Batch 5] Current Loss: 1.7611\n",
            "[Batch 6] Current Loss: 1.9506\n",
            "[Batch 7] Current Loss: 1.8431\n",
            "[Batch 8] Current Loss: 2.1708\n",
            "[Batch 9] Current Loss: 2.0580\n",
            "[Batch 0] Current Loss: 5.5049\n",
            "[Batch 1] Current Loss: 5.8998\n",
            "[Batch 2] Current Loss: 5.6160\n",
            "[Batch 3] Current Loss: 5.8839\n",
            "[Batch 4] Current Loss: 4.8086\n",
            "[Batch 5] Current Loss: 6.4900\n",
            "[Batch 6] Current Loss: 6.3167\n",
            "[Batch 7] Current Loss: 5.9038\n",
            "[Batch 8] Current Loss: 4.8072\n",
            "[Batch 9] Current Loss: 7.0012\n",
            "Ep 5 (Step 039760): Train loss 2.124, Val loss 5.823\n",
            "[Batch 0] Current Loss: 1.9155\n",
            "[Batch 1] Current Loss: 1.6026\n",
            "[Batch 2] Current Loss: 2.1899\n",
            "[Batch 3] Current Loss: 2.0522\n",
            "[Batch 4] Current Loss: 2.6505\n",
            "[Batch 5] Current Loss: 2.6035\n",
            "[Batch 6] Current Loss: 2.3101\n",
            "[Batch 7] Current Loss: 2.2085\n",
            "[Batch 8] Current Loss: 1.8827\n",
            "[Batch 9] Current Loss: 1.7166\n",
            "[Batch 0] Current Loss: 5.5172\n",
            "[Batch 1] Current Loss: 5.1106\n",
            "[Batch 2] Current Loss: 6.0685\n",
            "[Batch 3] Current Loss: 5.4198\n",
            "[Batch 4] Current Loss: 6.0410\n",
            "[Batch 5] Current Loss: 6.0640\n",
            "[Batch 6] Current Loss: 5.5661\n",
            "[Batch 7] Current Loss: 5.6684\n",
            "[Batch 8] Current Loss: 6.4251\n",
            "[Batch 9] Current Loss: 5.3072\n",
            "Ep 5 (Step 039780): Train loss 2.113, Val loss 5.719\n",
            "[Batch 0] Current Loss: 2.0589\n",
            "[Batch 1] Current Loss: 1.7894\n",
            "[Batch 2] Current Loss: 2.3384\n",
            "[Batch 3] Current Loss: 2.3351\n",
            "[Batch 4] Current Loss: 2.6412\n",
            "[Batch 5] Current Loss: 2.0392\n",
            "[Batch 6] Current Loss: 2.0157\n",
            "[Batch 7] Current Loss: 1.9685\n",
            "[Batch 8] Current Loss: 2.4858\n",
            "[Batch 9] Current Loss: 2.4806\n",
            "[Batch 0] Current Loss: 5.3158\n",
            "[Batch 1] Current Loss: 5.8517\n",
            "[Batch 2] Current Loss: 5.9249\n",
            "[Batch 3] Current Loss: 4.7730\n",
            "[Batch 4] Current Loss: 5.8619\n",
            "[Batch 5] Current Loss: 5.0442\n",
            "[Batch 6] Current Loss: 5.7257\n",
            "[Batch 7] Current Loss: 5.3729\n",
            "[Batch 8] Current Loss: 5.5352\n",
            "[Batch 9] Current Loss: 5.7413\n",
            "Ep 5 (Step 039800): Train loss 2.215, Val loss 5.515\n",
            "[Batch 0] Current Loss: 2.4868\n",
            "[Batch 1] Current Loss: 2.3727\n",
            "[Batch 2] Current Loss: 1.6395\n",
            "[Batch 3] Current Loss: 2.6172\n",
            "[Batch 4] Current Loss: 1.9999\n",
            "[Batch 5] Current Loss: 2.5236\n",
            "[Batch 6] Current Loss: 2.1255\n",
            "[Batch 7] Current Loss: 2.2821\n",
            "[Batch 8] Current Loss: 2.1721\n",
            "[Batch 9] Current Loss: 1.8498\n",
            "[Batch 0] Current Loss: 5.5648\n",
            "[Batch 1] Current Loss: 5.3682\n",
            "[Batch 2] Current Loss: 5.0073\n",
            "[Batch 3] Current Loss: 6.1179\n",
            "[Batch 4] Current Loss: 4.8563\n",
            "[Batch 5] Current Loss: 6.0025\n",
            "[Batch 6] Current Loss: 5.7113\n",
            "[Batch 7] Current Loss: 5.7649\n",
            "[Batch 8] Current Loss: 5.8066\n",
            "[Batch 9] Current Loss: 6.2738\n",
            "Ep 5 (Step 039820): Train loss 2.207, Val loss 5.647\n",
            "[Batch 0] Current Loss: 1.9309\n",
            "[Batch 1] Current Loss: 2.2938\n",
            "[Batch 2] Current Loss: 2.6146\n",
            "[Batch 3] Current Loss: 2.3758\n",
            "[Batch 4] Current Loss: 1.8093\n",
            "[Batch 5] Current Loss: 1.8481\n",
            "[Batch 6] Current Loss: 1.8654\n",
            "[Batch 7] Current Loss: 2.2311\n",
            "[Batch 8] Current Loss: 1.4160\n",
            "[Batch 9] Current Loss: 2.7032\n",
            "[Batch 0] Current Loss: 6.0076\n",
            "[Batch 1] Current Loss: 5.9346\n",
            "[Batch 2] Current Loss: 6.1544\n",
            "[Batch 3] Current Loss: 5.7479\n",
            "[Batch 4] Current Loss: 4.2081\n",
            "[Batch 5] Current Loss: 5.6012\n",
            "[Batch 6] Current Loss: 5.2372\n",
            "[Batch 7] Current Loss: 6.0999\n",
            "[Batch 8] Current Loss: 5.9680\n",
            "[Batch 9] Current Loss: 5.1144\n",
            "Ep 5 (Step 039840): Train loss 2.109, Val loss 5.607\n",
            "[Batch 0] Current Loss: 1.9950\n",
            "[Batch 1] Current Loss: 1.5351\n",
            "[Batch 2] Current Loss: 1.9424\n",
            "[Batch 3] Current Loss: 2.5158\n",
            "[Batch 4] Current Loss: 1.8640\n",
            "[Batch 5] Current Loss: 2.6462\n",
            "[Batch 6] Current Loss: 2.0781\n",
            "[Batch 7] Current Loss: 1.5513\n",
            "[Batch 8] Current Loss: 2.6316\n",
            "[Batch 9] Current Loss: 2.3924\n",
            "[Batch 0] Current Loss: 6.1207\n",
            "[Batch 1] Current Loss: 5.9268\n",
            "[Batch 2] Current Loss: 4.7120\n",
            "[Batch 3] Current Loss: 5.0101\n",
            "[Batch 4] Current Loss: 5.2837\n",
            "[Batch 5] Current Loss: 4.9132\n",
            "[Batch 6] Current Loss: 6.4065\n",
            "[Batch 7] Current Loss: 6.0606\n",
            "[Batch 8] Current Loss: 5.2440\n",
            "[Batch 9] Current Loss: 6.2799\n",
            "Ep 5 (Step 039860): Train loss 2.115, Val loss 5.596\n",
            "[Batch 0] Current Loss: 2.2012\n",
            "[Batch 1] Current Loss: 1.5110\n",
            "[Batch 2] Current Loss: 1.4933\n",
            "[Batch 3] Current Loss: 2.1598\n",
            "[Batch 4] Current Loss: 2.9499\n",
            "[Batch 5] Current Loss: 2.3464\n",
            "[Batch 6] Current Loss: 2.0687\n",
            "[Batch 7] Current Loss: 1.7221\n",
            "[Batch 8] Current Loss: 2.4494\n",
            "[Batch 9] Current Loss: 2.2225\n",
            "[Batch 0] Current Loss: 4.8327\n",
            "[Batch 1] Current Loss: 5.2522\n",
            "[Batch 2] Current Loss: 6.8305\n",
            "[Batch 3] Current Loss: 5.4129\n",
            "[Batch 4] Current Loss: 6.2684\n",
            "[Batch 5] Current Loss: 5.5233\n",
            "[Batch 6] Current Loss: 5.3787\n",
            "[Batch 7] Current Loss: 5.6120\n",
            "[Batch 8] Current Loss: 5.2262\n",
            "[Batch 9] Current Loss: 5.9489\n",
            "Ep 5 (Step 039880): Train loss 2.112, Val loss 5.629\n",
            "[Batch 0] Current Loss: 2.0284\n",
            "[Batch 1] Current Loss: 2.1323\n",
            "[Batch 2] Current Loss: 1.6760\n",
            "[Batch 3] Current Loss: 2.8886\n",
            "[Batch 4] Current Loss: 1.9670\n",
            "[Batch 5] Current Loss: 2.2262\n",
            "[Batch 6] Current Loss: 2.1952\n",
            "[Batch 7] Current Loss: 2.4901\n",
            "[Batch 8] Current Loss: 2.0360\n",
            "[Batch 9] Current Loss: 1.5301\n",
            "[Batch 0] Current Loss: 6.2448\n",
            "[Batch 1] Current Loss: 4.2971\n",
            "[Batch 2] Current Loss: 5.8574\n",
            "[Batch 3] Current Loss: 5.1554\n",
            "[Batch 4] Current Loss: 5.9904\n",
            "[Batch 5] Current Loss: 6.3515\n",
            "[Batch 6] Current Loss: 5.5075\n",
            "[Batch 7] Current Loss: 5.0909\n",
            "[Batch 8] Current Loss: 5.9925\n",
            "[Batch 9] Current Loss: 5.7185\n",
            "Ep 5 (Step 039900): Train loss 2.117, Val loss 5.621\n",
            "[Batch 0] Current Loss: 1.3618\n",
            "[Batch 1] Current Loss: 2.3705\n",
            "[Batch 2] Current Loss: 1.9758\n",
            "[Batch 3] Current Loss: 1.9275\n",
            "[Batch 4] Current Loss: 2.1557\n",
            "[Batch 5] Current Loss: 2.3663\n",
            "[Batch 6] Current Loss: 2.0305\n",
            "[Batch 7] Current Loss: 1.8148\n",
            "[Batch 8] Current Loss: 1.7053\n",
            "[Batch 9] Current Loss: 2.0989\n",
            "[Batch 0] Current Loss: 4.9996\n",
            "[Batch 1] Current Loss: 4.9843\n",
            "[Batch 2] Current Loss: 5.6465\n",
            "[Batch 3] Current Loss: 4.8893\n",
            "[Batch 4] Current Loss: 5.8423\n",
            "[Batch 5] Current Loss: 6.3820\n",
            "[Batch 6] Current Loss: 5.0730\n",
            "[Batch 7] Current Loss: 5.4764\n",
            "[Batch 8] Current Loss: 4.9236\n",
            "[Batch 9] Current Loss: 5.9941\n",
            "Ep 5 (Step 039920): Train loss 1.981, Val loss 5.421\n",
            "[Batch 0] Current Loss: 2.3849\n",
            "[Batch 1] Current Loss: 1.7311\n",
            "[Batch 2] Current Loss: 2.0401\n",
            "[Batch 3] Current Loss: 1.9302\n",
            "[Batch 4] Current Loss: 1.9807\n",
            "[Batch 5] Current Loss: 2.5487\n",
            "[Batch 6] Current Loss: 2.0964\n",
            "[Batch 7] Current Loss: 2.1510\n",
            "[Batch 8] Current Loss: 2.2469\n",
            "[Batch 9] Current Loss: 2.0657\n",
            "[Batch 0] Current Loss: 5.5046\n",
            "[Batch 1] Current Loss: 4.9686\n",
            "[Batch 2] Current Loss: 5.5492\n",
            "[Batch 3] Current Loss: 6.5642\n",
            "[Batch 4] Current Loss: 5.7169\n",
            "[Batch 5] Current Loss: 5.9265\n",
            "[Batch 6] Current Loss: 5.8076\n",
            "[Batch 7] Current Loss: 5.6911\n",
            "[Batch 8] Current Loss: 5.2401\n",
            "[Batch 9] Current Loss: 6.4822\n",
            "Ep 5 (Step 039940): Train loss 2.118, Val loss 5.745\n",
            "[Batch 0] Current Loss: 2.3504\n",
            "[Batch 1] Current Loss: 1.7975\n",
            "[Batch 2] Current Loss: 1.9871\n",
            "[Batch 3] Current Loss: 1.7108\n",
            "[Batch 4] Current Loss: 2.2966\n",
            "[Batch 5] Current Loss: 2.5467\n",
            "[Batch 6] Current Loss: 1.5497\n",
            "[Batch 7] Current Loss: 2.6725\n",
            "[Batch 8] Current Loss: 2.0976\n",
            "[Batch 9] Current Loss: 2.4475\n",
            "[Batch 0] Current Loss: 4.9182\n",
            "[Batch 1] Current Loss: 5.1224\n",
            "[Batch 2] Current Loss: 6.0327\n",
            "[Batch 3] Current Loss: 5.5699\n",
            "[Batch 4] Current Loss: 5.1426\n",
            "[Batch 5] Current Loss: 5.3470\n",
            "[Batch 6] Current Loss: 7.0632\n",
            "[Batch 7] Current Loss: 5.2339\n",
            "[Batch 8] Current Loss: 5.7174\n",
            "[Batch 9] Current Loss: 4.9425\n",
            "Ep 5 (Step 039960): Train loss 2.146, Val loss 5.509\n",
            "[Batch 0] Current Loss: 2.4224\n",
            "[Batch 1] Current Loss: 1.5719\n",
            "[Batch 2] Current Loss: 2.4401\n",
            "[Batch 3] Current Loss: 2.2809\n",
            "[Batch 4] Current Loss: 2.0533\n",
            "[Batch 5] Current Loss: 2.4304\n",
            "[Batch 6] Current Loss: 1.7628\n",
            "[Batch 7] Current Loss: 1.9960\n",
            "[Batch 8] Current Loss: 2.3889\n",
            "[Batch 9] Current Loss: 2.3405\n",
            "[Batch 0] Current Loss: 6.0432\n",
            "[Batch 1] Current Loss: 5.6298\n",
            "[Batch 2] Current Loss: 5.7593\n",
            "[Batch 3] Current Loss: 4.9710\n",
            "[Batch 4] Current Loss: 6.4600\n",
            "[Batch 5] Current Loss: 6.6723\n",
            "[Batch 6] Current Loss: 5.7135\n",
            "[Batch 7] Current Loss: 5.7772\n",
            "[Batch 8] Current Loss: 5.5493\n",
            "[Batch 9] Current Loss: 5.8683\n",
            "Ep 5 (Step 039980): Train loss 2.169, Val loss 5.844\n",
            "[Batch 0] Current Loss: 2.1435\n",
            "[Batch 1] Current Loss: 2.4225\n",
            "[Batch 2] Current Loss: 2.3540\n",
            "[Batch 3] Current Loss: 2.1036\n",
            "[Batch 4] Current Loss: 1.7879\n",
            "[Batch 5] Current Loss: 2.6784\n",
            "[Batch 6] Current Loss: 2.5276\n",
            "[Batch 7] Current Loss: 2.5389\n",
            "[Batch 8] Current Loss: 1.8544\n",
            "[Batch 9] Current Loss: 2.5855\n",
            "[Batch 0] Current Loss: 5.4106\n",
            "[Batch 1] Current Loss: 5.2687\n",
            "[Batch 2] Current Loss: 6.0406\n",
            "[Batch 3] Current Loss: 6.1514\n",
            "[Batch 4] Current Loss: 5.6211\n",
            "[Batch 5] Current Loss: 6.4257\n",
            "[Batch 6] Current Loss: 5.4561\n",
            "[Batch 7] Current Loss: 6.6511\n",
            "[Batch 8] Current Loss: 6.0495\n",
            "[Batch 9] Current Loss: 6.1241\n",
            "Ep 5 (Step 040000): Train loss 2.300, Val loss 5.920\n",
            "[Batch 0] Current Loss: 2.6749\n",
            "[Batch 1] Current Loss: 1.5802\n",
            "[Batch 2] Current Loss: 2.2444\n",
            "[Batch 3] Current Loss: 1.7511\n",
            "[Batch 4] Current Loss: 2.2647\n",
            "[Batch 5] Current Loss: 1.7352\n",
            "[Batch 6] Current Loss: 2.6102\n",
            "[Batch 7] Current Loss: 2.6279\n",
            "[Batch 8] Current Loss: 2.2837\n",
            "[Batch 9] Current Loss: 1.7992\n",
            "[Batch 0] Current Loss: 5.7571\n",
            "[Batch 1] Current Loss: 5.8846\n",
            "[Batch 2] Current Loss: 5.4875\n",
            "[Batch 3] Current Loss: 5.8768\n",
            "[Batch 4] Current Loss: 4.9846\n",
            "[Batch 5] Current Loss: 5.4117\n",
            "[Batch 6] Current Loss: 5.0190\n",
            "[Batch 7] Current Loss: 5.4244\n",
            "[Batch 8] Current Loss: 6.4895\n",
            "[Batch 9] Current Loss: 5.6011\n",
            "Ep 5 (Step 040020): Train loss 2.157, Val loss 5.594\n",
            "[Batch 0] Current Loss: 1.9828\n",
            "[Batch 1] Current Loss: 1.8358\n",
            "[Batch 2] Current Loss: 1.8382\n",
            "[Batch 3] Current Loss: 2.2312\n",
            "[Batch 4] Current Loss: 2.3198\n",
            "[Batch 5] Current Loss: 1.8452\n",
            "[Batch 6] Current Loss: 2.4067\n",
            "[Batch 7] Current Loss: 2.0079\n",
            "[Batch 8] Current Loss: 2.4108\n",
            "[Batch 9] Current Loss: 1.7972\n",
            "[Batch 0] Current Loss: 4.9932\n",
            "[Batch 1] Current Loss: 4.8156\n",
            "[Batch 2] Current Loss: 5.6832\n",
            "[Batch 3] Current Loss: 6.4365\n",
            "[Batch 4] Current Loss: 5.5612\n",
            "[Batch 5] Current Loss: 5.7425\n",
            "[Batch 6] Current Loss: 6.2335\n",
            "[Batch 7] Current Loss: 6.6017\n",
            "[Batch 8] Current Loss: 5.8438\n",
            "[Batch 9] Current Loss: 5.3240\n",
            "Ep 5 (Step 040040): Train loss 2.068, Val loss 5.723\n",
            "[Batch 0] Current Loss: 2.9019\n",
            "[Batch 1] Current Loss: 2.3700\n",
            "[Batch 2] Current Loss: 2.4393\n",
            "[Batch 3] Current Loss: 2.2445\n",
            "[Batch 4] Current Loss: 2.6239\n",
            "[Batch 5] Current Loss: 2.1358\n",
            "[Batch 6] Current Loss: 2.1406\n",
            "[Batch 7] Current Loss: 2.0436\n",
            "[Batch 8] Current Loss: 2.1113\n",
            "[Batch 9] Current Loss: 1.8738\n",
            "[Batch 0] Current Loss: 5.8802\n",
            "[Batch 1] Current Loss: 5.3696\n",
            "[Batch 2] Current Loss: 5.7438\n",
            "[Batch 3] Current Loss: 6.7686\n",
            "[Batch 4] Current Loss: 5.7159\n",
            "[Batch 5] Current Loss: 6.2149\n",
            "[Batch 6] Current Loss: 4.9879\n",
            "[Batch 7] Current Loss: 5.6475\n",
            "[Batch 8] Current Loss: 5.6244\n",
            "[Batch 9] Current Loss: 5.8940\n",
            "Ep 5 (Step 040060): Train loss 2.288, Val loss 5.785\n",
            "[Batch 0] Current Loss: 2.3411\n",
            "[Batch 1] Current Loss: 2.3556\n",
            "[Batch 2] Current Loss: 1.6544\n",
            "[Batch 3] Current Loss: 2.2475\n",
            "[Batch 4] Current Loss: 1.4438\n",
            "[Batch 5] Current Loss: 2.1492\n",
            "[Batch 6] Current Loss: 2.0171\n",
            "[Batch 7] Current Loss: 1.9980\n",
            "[Batch 8] Current Loss: 2.1746\n",
            "[Batch 9] Current Loss: 2.0097\n",
            "[Batch 0] Current Loss: 5.4495\n",
            "[Batch 1] Current Loss: 5.7554\n",
            "[Batch 2] Current Loss: 5.5213\n",
            "[Batch 3] Current Loss: 5.1717\n",
            "[Batch 4] Current Loss: 5.6871\n",
            "[Batch 5] Current Loss: 4.4601\n",
            "[Batch 6] Current Loss: 4.5306\n",
            "[Batch 7] Current Loss: 5.1185\n",
            "[Batch 8] Current Loss: 4.5150\n",
            "[Batch 9] Current Loss: 6.9354\n",
            "Ep 5 (Step 040080): Train loss 2.039, Val loss 5.314\n",
            "[Batch 0] Current Loss: 2.0581\n",
            "[Batch 1] Current Loss: 2.1560\n",
            "[Batch 2] Current Loss: 2.1234\n",
            "[Batch 3] Current Loss: 2.0407\n",
            "[Batch 4] Current Loss: 1.8230\n",
            "[Batch 5] Current Loss: 1.5838\n",
            "[Batch 6] Current Loss: 1.6690\n",
            "[Batch 7] Current Loss: 1.5311\n",
            "[Batch 8] Current Loss: 1.5351\n",
            "[Batch 9] Current Loss: 1.9678\n",
            "[Batch 0] Current Loss: 5.0806\n",
            "[Batch 1] Current Loss: 5.6759\n",
            "[Batch 2] Current Loss: 5.6392\n",
            "[Batch 3] Current Loss: 6.1771\n",
            "[Batch 4] Current Loss: 6.3784\n",
            "[Batch 5] Current Loss: 5.9038\n",
            "[Batch 6] Current Loss: 5.2895\n",
            "[Batch 7] Current Loss: 5.4205\n",
            "[Batch 8] Current Loss: 5.1374\n",
            "[Batch 9] Current Loss: 5.0423\n",
            "Ep 5 (Step 040100): Train loss 1.849, Val loss 5.574\n",
            "[Batch 0] Current Loss: 2.3265\n",
            "[Batch 1] Current Loss: 2.4901\n",
            "[Batch 2] Current Loss: 2.1880\n",
            "[Batch 3] Current Loss: 2.2996\n",
            "[Batch 4] Current Loss: 2.7120\n",
            "[Batch 5] Current Loss: 1.7832\n",
            "[Batch 6] Current Loss: 2.8334\n",
            "[Batch 7] Current Loss: 1.3984\n",
            "[Batch 8] Current Loss: 1.6283\n",
            "[Batch 9] Current Loss: 1.9059\n",
            "[Batch 0] Current Loss: 5.6085\n",
            "[Batch 1] Current Loss: 4.8291\n",
            "[Batch 2] Current Loss: 5.4182\n",
            "[Batch 3] Current Loss: 5.7032\n",
            "[Batch 4] Current Loss: 5.4113\n",
            "[Batch 5] Current Loss: 5.2744\n",
            "[Batch 6] Current Loss: 5.1500\n",
            "[Batch 7] Current Loss: 6.1667\n",
            "[Batch 8] Current Loss: 5.7598\n",
            "[Batch 9] Current Loss: 5.5757\n",
            "Ep 5 (Step 040120): Train loss 2.157, Val loss 5.490\n",
            "[Batch 0] Current Loss: 2.0567\n",
            "[Batch 1] Current Loss: 2.3334\n",
            "[Batch 2] Current Loss: 2.3497\n",
            "[Batch 3] Current Loss: 1.5303\n",
            "[Batch 4] Current Loss: 2.5772\n",
            "[Batch 5] Current Loss: 1.9662\n",
            "[Batch 6] Current Loss: 1.9013\n",
            "[Batch 7] Current Loss: 1.7625\n",
            "[Batch 8] Current Loss: 2.4900\n",
            "[Batch 9] Current Loss: 2.3296\n",
            "[Batch 0] Current Loss: 5.8326\n",
            "[Batch 1] Current Loss: 5.6647\n",
            "[Batch 2] Current Loss: 5.0711\n",
            "[Batch 3] Current Loss: 5.0406\n",
            "[Batch 4] Current Loss: 5.6094\n",
            "[Batch 5] Current Loss: 5.9945\n",
            "[Batch 6] Current Loss: 5.7851\n",
            "[Batch 7] Current Loss: 5.6548\n",
            "[Batch 8] Current Loss: 5.1687\n",
            "[Batch 9] Current Loss: 5.7309\n",
            "Ep 5 (Step 040140): Train loss 2.130, Val loss 5.555\n",
            "[Batch 0] Current Loss: 2.2529\n",
            "[Batch 1] Current Loss: 2.4721\n",
            "[Batch 2] Current Loss: 2.3512\n",
            "[Batch 3] Current Loss: 2.4448\n",
            "[Batch 4] Current Loss: 2.3058\n",
            "[Batch 5] Current Loss: 2.0677\n",
            "[Batch 6] Current Loss: 2.4491\n",
            "[Batch 7] Current Loss: 1.4364\n",
            "[Batch 8] Current Loss: 1.6540\n",
            "[Batch 9] Current Loss: 1.9727\n",
            "[Batch 0] Current Loss: 5.4065\n",
            "[Batch 1] Current Loss: 5.4307\n",
            "[Batch 2] Current Loss: 5.5940\n",
            "[Batch 3] Current Loss: 6.0987\n",
            "[Batch 4] Current Loss: 5.0231\n",
            "[Batch 5] Current Loss: 5.7481\n",
            "[Batch 6] Current Loss: 5.0842\n",
            "[Batch 7] Current Loss: 5.1451\n",
            "[Batch 8] Current Loss: 6.2890\n",
            "[Batch 9] Current Loss: 5.8461\n",
            "Ep 5 (Step 040160): Train loss 2.141, Val loss 5.567\n",
            "[Batch 0] Current Loss: 1.8433\n",
            "[Batch 1] Current Loss: 2.6755\n",
            "[Batch 2] Current Loss: 2.3913\n",
            "[Batch 3] Current Loss: 2.5733\n",
            "[Batch 4] Current Loss: 2.2222\n",
            "[Batch 5] Current Loss: 2.2105\n",
            "[Batch 6] Current Loss: 2.5721\n",
            "[Batch 7] Current Loss: 1.2573\n",
            "[Batch 8] Current Loss: 2.2902\n",
            "[Batch 9] Current Loss: 2.1608\n",
            "[Batch 0] Current Loss: 6.4861\n",
            "[Batch 1] Current Loss: 4.9598\n",
            "[Batch 2] Current Loss: 5.6612\n",
            "[Batch 3] Current Loss: 4.9230\n",
            "[Batch 4] Current Loss: 6.0299\n",
            "[Batch 5] Current Loss: 5.0582\n",
            "[Batch 6] Current Loss: 5.7835\n",
            "[Batch 7] Current Loss: 5.8030\n",
            "[Batch 8] Current Loss: 4.3234\n",
            "[Batch 9] Current Loss: 5.4735\n",
            "Ep 5 (Step 040180): Train loss 2.220, Val loss 5.450\n",
            "[Batch 0] Current Loss: 2.4544\n",
            "[Batch 1] Current Loss: 2.5602\n",
            "[Batch 2] Current Loss: 2.6534\n",
            "[Batch 3] Current Loss: 2.1525\n",
            "[Batch 4] Current Loss: 2.3029\n",
            "[Batch 5] Current Loss: 1.9043\n",
            "[Batch 6] Current Loss: 1.9324\n",
            "[Batch 7] Current Loss: 2.3925\n",
            "[Batch 8] Current Loss: 1.8404\n",
            "[Batch 9] Current Loss: 2.0016\n",
            "[Batch 0] Current Loss: 4.3580\n",
            "[Batch 1] Current Loss: 5.5558\n",
            "[Batch 2] Current Loss: 6.0486\n",
            "[Batch 3] Current Loss: 5.4675\n",
            "[Batch 4] Current Loss: 5.0613\n",
            "[Batch 5] Current Loss: 5.7030\n",
            "[Batch 6] Current Loss: 6.2200\n",
            "[Batch 7] Current Loss: 6.6642\n",
            "[Batch 8] Current Loss: 5.6489\n",
            "[Batch 9] Current Loss: 6.1480\n",
            "Ep 5 (Step 040200): Train loss 2.219, Val loss 5.688\n",
            "[Batch 0] Current Loss: 1.8111\n",
            "[Batch 1] Current Loss: 1.8733\n",
            "[Batch 2] Current Loss: 2.4484\n",
            "[Batch 3] Current Loss: 2.1639\n",
            "[Batch 4] Current Loss: 2.0535\n",
            "[Batch 5] Current Loss: 2.2641\n",
            "[Batch 6] Current Loss: 2.2197\n",
            "[Batch 7] Current Loss: 1.8394\n",
            "[Batch 8] Current Loss: 2.0640\n",
            "[Batch 9] Current Loss: 1.8289\n",
            "[Batch 0] Current Loss: 5.9264\n",
            "[Batch 1] Current Loss: 6.0257\n",
            "[Batch 2] Current Loss: 5.8969\n",
            "[Batch 3] Current Loss: 5.2879\n",
            "[Batch 4] Current Loss: 6.1704\n",
            "[Batch 5] Current Loss: 5.7642\n",
            "[Batch 6] Current Loss: 5.6223\n",
            "[Batch 7] Current Loss: 6.0741\n",
            "[Batch 8] Current Loss: 5.1391\n",
            "[Batch 9] Current Loss: 5.6071\n",
            "Ep 5 (Step 040220): Train loss 2.057, Val loss 5.751\n",
            "[Batch 0] Current Loss: 1.5843\n",
            "[Batch 1] Current Loss: 2.0438\n",
            "[Batch 2] Current Loss: 2.1190\n",
            "[Batch 3] Current Loss: 1.8116\n",
            "[Batch 4] Current Loss: 1.5695\n",
            "[Batch 5] Current Loss: 1.9378\n",
            "[Batch 6] Current Loss: 2.1810\n",
            "[Batch 7] Current Loss: 2.0335\n",
            "[Batch 8] Current Loss: 2.4791\n",
            "[Batch 9] Current Loss: 2.1187\n",
            "[Batch 0] Current Loss: 4.6039\n",
            "[Batch 1] Current Loss: 5.7329\n",
            "[Batch 2] Current Loss: 5.8374\n",
            "[Batch 3] Current Loss: 6.1659\n",
            "[Batch 4] Current Loss: 5.3083\n",
            "[Batch 5] Current Loss: 5.0960\n",
            "[Batch 6] Current Loss: 5.8477\n",
            "[Batch 7] Current Loss: 6.2123\n",
            "[Batch 8] Current Loss: 5.3015\n",
            "[Batch 9] Current Loss: 5.0065\n",
            "Ep 5 (Step 040240): Train loss 1.988, Val loss 5.511\n",
            "[Batch 0] Current Loss: 1.7412\n",
            "[Batch 1] Current Loss: 2.3165\n",
            "[Batch 2] Current Loss: 1.7467\n",
            "[Batch 3] Current Loss: 2.0868\n",
            "[Batch 4] Current Loss: 1.8648\n",
            "[Batch 5] Current Loss: 1.9536\n",
            "[Batch 6] Current Loss: 2.1298\n",
            "[Batch 7] Current Loss: 2.1199\n",
            "[Batch 8] Current Loss: 2.2331\n",
            "[Batch 9] Current Loss: 1.8062\n",
            "[Batch 0] Current Loss: 5.8202\n",
            "[Batch 1] Current Loss: 5.3028\n",
            "[Batch 2] Current Loss: 5.7219\n",
            "[Batch 3] Current Loss: 5.8547\n",
            "[Batch 4] Current Loss: 6.3396\n",
            "[Batch 5] Current Loss: 5.2447\n",
            "[Batch 6] Current Loss: 5.3686\n",
            "[Batch 7] Current Loss: 5.4336\n",
            "[Batch 8] Current Loss: 5.5311\n",
            "[Batch 9] Current Loss: 5.6380\n",
            "Ep 5 (Step 040260): Train loss 2.000, Val loss 5.626\n",
            "[Batch 0] Current Loss: 2.2777\n",
            "[Batch 1] Current Loss: 2.2751\n",
            "[Batch 2] Current Loss: 1.0757\n",
            "[Batch 3] Current Loss: 2.3308\n",
            "[Batch 4] Current Loss: 2.4879\n",
            "[Batch 5] Current Loss: 2.2993\n",
            "[Batch 6] Current Loss: 1.8400\n",
            "[Batch 7] Current Loss: 1.9444\n",
            "[Batch 8] Current Loss: 1.6193\n",
            "[Batch 9] Current Loss: 2.0700\n",
            "[Batch 0] Current Loss: 5.8277\n",
            "[Batch 1] Current Loss: 4.7829\n",
            "[Batch 2] Current Loss: 5.5532\n",
            "[Batch 3] Current Loss: 5.3748\n",
            "[Batch 4] Current Loss: 5.0939\n",
            "[Batch 5] Current Loss: 4.7924\n",
            "[Batch 6] Current Loss: 5.0081\n",
            "[Batch 7] Current Loss: 4.9717\n",
            "[Batch 8] Current Loss: 5.8255\n",
            "[Batch 9] Current Loss: 5.0118\n",
            "Ep 5 (Step 040280): Train loss 2.022, Val loss 5.224\n",
            "[Batch 0] Current Loss: 1.7388\n",
            "[Batch 1] Current Loss: 1.6435\n",
            "[Batch 2] Current Loss: 1.8465\n",
            "[Batch 3] Current Loss: 1.9120\n",
            "[Batch 4] Current Loss: 2.2012\n",
            "[Batch 5] Current Loss: 2.4043\n",
            "[Batch 6] Current Loss: 2.4439\n",
            "[Batch 7] Current Loss: 1.5836\n",
            "[Batch 8] Current Loss: 2.5677\n",
            "[Batch 9] Current Loss: 2.5901\n",
            "[Batch 0] Current Loss: 5.9054\n",
            "[Batch 1] Current Loss: 6.5121\n",
            "[Batch 2] Current Loss: 5.4112\n",
            "[Batch 3] Current Loss: 5.7406\n",
            "[Batch 4] Current Loss: 5.4479\n",
            "[Batch 5] Current Loss: 5.7999\n",
            "[Batch 6] Current Loss: 6.1653\n",
            "[Batch 7] Current Loss: 5.6051\n",
            "[Batch 8] Current Loss: 5.3451\n",
            "[Batch 9] Current Loss: 6.3959\n",
            "Ep 5 (Step 040300): Train loss 2.093, Val loss 5.833\n",
            "[Batch 0] Current Loss: 1.8681\n",
            "[Batch 1] Current Loss: 2.3952\n",
            "[Batch 2] Current Loss: 1.6915\n",
            "[Batch 3] Current Loss: 2.2276\n",
            "[Batch 4] Current Loss: 2.4044\n",
            "[Batch 5] Current Loss: 2.3000\n",
            "[Batch 6] Current Loss: 1.7387\n",
            "[Batch 7] Current Loss: 2.2237\n",
            "[Batch 8] Current Loss: 2.2326\n",
            "[Batch 9] Current Loss: 2.0086\n",
            "[Batch 0] Current Loss: 6.5628\n",
            "[Batch 1] Current Loss: 6.1938\n",
            "[Batch 2] Current Loss: 5.6739\n",
            "[Batch 3] Current Loss: 5.3843\n",
            "[Batch 4] Current Loss: 5.8779\n",
            "[Batch 5] Current Loss: 5.9974\n",
            "[Batch 6] Current Loss: 4.9692\n",
            "[Batch 7] Current Loss: 5.9584\n",
            "[Batch 8] Current Loss: 5.9187\n",
            "[Batch 9] Current Loss: 4.4678\n",
            "Ep 5 (Step 040320): Train loss 2.109, Val loss 5.700\n",
            "[Batch 0] Current Loss: 2.1186\n",
            "[Batch 1] Current Loss: 2.1288\n",
            "[Batch 2] Current Loss: 2.5723\n",
            "[Batch 3] Current Loss: 2.7167\n",
            "[Batch 4] Current Loss: 1.7126\n",
            "[Batch 5] Current Loss: 1.5941\n",
            "[Batch 6] Current Loss: 1.5450\n",
            "[Batch 7] Current Loss: 2.1259\n",
            "[Batch 8] Current Loss: 1.9459\n",
            "[Batch 9] Current Loss: 2.2703\n",
            "[Batch 0] Current Loss: 5.2199\n",
            "[Batch 1] Current Loss: 6.2717\n",
            "[Batch 2] Current Loss: 5.1360\n",
            "[Batch 3] Current Loss: 5.2933\n",
            "[Batch 4] Current Loss: 5.2036\n",
            "[Batch 5] Current Loss: 5.9128\n",
            "[Batch 6] Current Loss: 5.6694\n",
            "[Batch 7] Current Loss: 6.1841\n",
            "[Batch 8] Current Loss: 5.8482\n",
            "[Batch 9] Current Loss: 5.5234\n",
            "Ep 5 (Step 040340): Train loss 2.073, Val loss 5.626\n",
            "[Batch 0] Current Loss: 2.9663\n",
            "[Batch 1] Current Loss: 2.1772\n",
            "[Batch 2] Current Loss: 2.2191\n",
            "[Batch 3] Current Loss: 2.0343\n",
            "[Batch 4] Current Loss: 1.8416\n",
            "[Batch 5] Current Loss: 2.2597\n",
            "[Batch 6] Current Loss: 2.2338\n",
            "[Batch 7] Current Loss: 2.1957\n",
            "[Batch 8] Current Loss: 1.9713\n",
            "[Batch 9] Current Loss: 2.1496\n",
            "[Batch 0] Current Loss: 5.0256\n",
            "[Batch 1] Current Loss: 5.5095\n",
            "[Batch 2] Current Loss: 5.1125\n",
            "[Batch 3] Current Loss: 5.6964\n",
            "[Batch 4] Current Loss: 6.3244\n",
            "[Batch 5] Current Loss: 5.6272\n",
            "[Batch 6] Current Loss: 5.8313\n",
            "[Batch 7] Current Loss: 5.2931\n",
            "[Batch 8] Current Loss: 5.1400\n",
            "[Batch 9] Current Loss: 5.1509\n",
            "Ep 5 (Step 040360): Train loss 2.205, Val loss 5.471\n",
            "[Batch 0] Current Loss: 2.1744\n",
            "[Batch 1] Current Loss: 2.0150\n",
            "[Batch 2] Current Loss: 2.4180\n",
            "[Batch 3] Current Loss: 1.7837\n",
            "[Batch 4] Current Loss: 2.0193\n",
            "[Batch 5] Current Loss: 2.4764\n",
            "[Batch 6] Current Loss: 1.8443\n",
            "[Batch 7] Current Loss: 2.1828\n",
            "[Batch 8] Current Loss: 2.1681\n",
            "[Batch 9] Current Loss: 2.3296\n",
            "[Batch 0] Current Loss: 6.4389\n",
            "[Batch 1] Current Loss: 6.1929\n",
            "[Batch 2] Current Loss: 5.7306\n",
            "[Batch 3] Current Loss: 5.0891\n",
            "[Batch 4] Current Loss: 5.8760\n",
            "[Batch 5] Current Loss: 5.1414\n",
            "[Batch 6] Current Loss: 5.8008\n",
            "[Batch 7] Current Loss: 5.2070\n",
            "[Batch 8] Current Loss: 5.4768\n",
            "[Batch 9] Current Loss: 5.3700\n",
            "Ep 5 (Step 040380): Train loss 2.141, Val loss 5.632\n",
            "[Batch 0] Current Loss: 1.8738\n",
            "[Batch 1] Current Loss: 1.8890\n",
            "[Batch 2] Current Loss: 3.0142\n",
            "[Batch 3] Current Loss: 2.0696\n",
            "[Batch 4] Current Loss: 1.6439\n",
            "[Batch 5] Current Loss: 2.3766\n",
            "[Batch 6] Current Loss: 2.1358\n",
            "[Batch 7] Current Loss: 2.1445\n",
            "[Batch 8] Current Loss: 1.8479\n",
            "[Batch 9] Current Loss: 2.2886\n",
            "[Batch 0] Current Loss: 5.9089\n",
            "[Batch 1] Current Loss: 4.5939\n",
            "[Batch 2] Current Loss: 5.8554\n",
            "[Batch 3] Current Loss: 5.8296\n",
            "[Batch 4] Current Loss: 5.7338\n",
            "[Batch 5] Current Loss: 5.2177\n",
            "[Batch 6] Current Loss: 5.5397\n",
            "[Batch 7] Current Loss: 5.8085\n",
            "[Batch 8] Current Loss: 5.3302\n",
            "[Batch 9] Current Loss: 6.3147\n",
            "Ep 5 (Step 040400): Train loss 2.128, Val loss 5.613\n",
            "[Batch 0] Current Loss: 2.5530\n",
            "[Batch 1] Current Loss: 2.1451\n",
            "[Batch 2] Current Loss: 1.7438\n",
            "[Batch 3] Current Loss: 1.9018\n",
            "[Batch 4] Current Loss: 2.5481\n",
            "[Batch 5] Current Loss: 1.3965\n",
            "[Batch 6] Current Loss: 2.2411\n",
            "[Batch 7] Current Loss: 2.4191\n",
            "[Batch 8] Current Loss: 2.3148\n",
            "[Batch 9] Current Loss: 1.7387\n",
            "[Batch 0] Current Loss: 6.4796\n",
            "[Batch 1] Current Loss: 5.2929\n",
            "[Batch 2] Current Loss: 5.9724\n",
            "[Batch 3] Current Loss: 6.2154\n",
            "[Batch 4] Current Loss: 5.3161\n",
            "[Batch 5] Current Loss: 4.9360\n",
            "[Batch 6] Current Loss: 5.2183\n",
            "[Batch 7] Current Loss: 6.3091\n",
            "[Batch 8] Current Loss: 4.9549\n",
            "[Batch 9] Current Loss: 6.1408\n",
            "Ep 5 (Step 040420): Train loss 2.100, Val loss 5.684\n",
            "[Batch 0] Current Loss: 2.6007\n",
            "[Batch 1] Current Loss: 2.0371\n",
            "[Batch 2] Current Loss: 1.6035\n",
            "[Batch 3] Current Loss: 1.9839\n",
            "[Batch 4] Current Loss: 2.3386\n",
            "[Batch 5] Current Loss: 1.8403\n",
            "[Batch 6] Current Loss: 1.5143\n",
            "[Batch 7] Current Loss: 2.4698\n",
            "[Batch 8] Current Loss: 2.2655\n",
            "[Batch 9] Current Loss: 1.7938\n",
            "[Batch 0] Current Loss: 5.5874\n",
            "[Batch 1] Current Loss: 5.3138\n",
            "[Batch 2] Current Loss: 5.1235\n",
            "[Batch 3] Current Loss: 5.6953\n",
            "[Batch 4] Current Loss: 5.1544\n",
            "[Batch 5] Current Loss: 6.1013\n",
            "[Batch 6] Current Loss: 5.6813\n",
            "[Batch 7] Current Loss: 5.8739\n",
            "[Batch 8] Current Loss: 5.4628\n",
            "[Batch 9] Current Loss: 6.4719\n",
            "Ep 5 (Step 040440): Train loss 2.045, Val loss 5.647\n",
            "[Batch 0] Current Loss: 1.7039\n",
            "[Batch 1] Current Loss: 2.2050\n",
            "[Batch 2] Current Loss: 2.0050\n",
            "[Batch 3] Current Loss: 1.9352\n",
            "[Batch 4] Current Loss: 2.8607\n",
            "[Batch 5] Current Loss: 1.9236\n",
            "[Batch 6] Current Loss: 2.1641\n",
            "[Batch 7] Current Loss: 1.9812\n",
            "[Batch 8] Current Loss: 1.9360\n",
            "[Batch 9] Current Loss: 1.4772\n",
            "[Batch 0] Current Loss: 5.3102\n",
            "[Batch 1] Current Loss: 6.3902\n",
            "[Batch 2] Current Loss: 5.1570\n",
            "[Batch 3] Current Loss: 5.9963\n",
            "[Batch 4] Current Loss: 5.6063\n",
            "[Batch 5] Current Loss: 6.1712\n",
            "[Batch 6] Current Loss: 6.1829\n",
            "[Batch 7] Current Loss: 4.9656\n",
            "[Batch 8] Current Loss: 6.1319\n",
            "[Batch 9] Current Loss: 5.4009\n",
            "Ep 5 (Step 040460): Train loss 2.019, Val loss 5.731\n",
            "[Batch 0] Current Loss: 2.2672\n",
            "[Batch 1] Current Loss: 1.6618\n",
            "[Batch 2] Current Loss: 1.5354\n",
            "[Batch 3] Current Loss: 2.0850\n",
            "[Batch 4] Current Loss: 2.2413\n",
            "[Batch 5] Current Loss: 2.4366\n",
            "[Batch 6] Current Loss: 2.3393\n",
            "[Batch 7] Current Loss: 1.9693\n",
            "[Batch 8] Current Loss: 2.3394\n",
            "[Batch 9] Current Loss: 1.5794\n",
            "[Batch 0] Current Loss: 5.4741\n",
            "[Batch 1] Current Loss: 5.8608\n",
            "[Batch 2] Current Loss: 4.7341\n",
            "[Batch 3] Current Loss: 5.3665\n",
            "[Batch 4] Current Loss: 5.5480\n",
            "[Batch 5] Current Loss: 5.7098\n",
            "[Batch 6] Current Loss: 5.3418\n",
            "[Batch 7] Current Loss: 6.3423\n",
            "[Batch 8] Current Loss: 5.6970\n",
            "[Batch 9] Current Loss: 5.6912\n",
            "Ep 5 (Step 040480): Train loss 2.045, Val loss 5.577\n",
            "[Batch 0] Current Loss: 2.1604\n",
            "[Batch 1] Current Loss: 2.6041\n",
            "[Batch 2] Current Loss: 2.4754\n",
            "[Batch 3] Current Loss: 2.5240\n",
            "[Batch 4] Current Loss: 2.2757\n",
            "[Batch 5] Current Loss: 1.9931\n",
            "[Batch 6] Current Loss: 2.0814\n",
            "[Batch 7] Current Loss: 2.1821\n",
            "[Batch 8] Current Loss: 2.0997\n",
            "[Batch 9] Current Loss: 2.0335\n",
            "[Batch 0] Current Loss: 5.8569\n",
            "[Batch 1] Current Loss: 5.7905\n",
            "[Batch 2] Current Loss: 5.2850\n",
            "[Batch 3] Current Loss: 5.5735\n",
            "[Batch 4] Current Loss: 5.8842\n",
            "[Batch 5] Current Loss: 6.1939\n",
            "[Batch 6] Current Loss: 5.7571\n",
            "[Batch 7] Current Loss: 6.0494\n",
            "[Batch 8] Current Loss: 4.9033\n",
            "[Batch 9] Current Loss: 5.0613\n",
            "Ep 5 (Step 040500): Train loss 2.243, Val loss 5.636\n",
            "[Batch 0] Current Loss: 2.0269\n",
            "[Batch 1] Current Loss: 2.1234\n",
            "[Batch 2] Current Loss: 1.5500\n",
            "[Batch 3] Current Loss: 1.7328\n",
            "[Batch 4] Current Loss: 2.6499\n",
            "[Batch 5] Current Loss: 1.6476\n",
            "[Batch 6] Current Loss: 1.8054\n",
            "[Batch 7] Current Loss: 2.1359\n",
            "[Batch 8] Current Loss: 2.1709\n",
            "[Batch 9] Current Loss: 2.1913\n",
            "[Batch 0] Current Loss: 5.9657\n",
            "[Batch 1] Current Loss: 4.9317\n",
            "[Batch 2] Current Loss: 5.7623\n",
            "[Batch 3] Current Loss: 5.4560\n",
            "[Batch 4] Current Loss: 6.0523\n",
            "[Batch 5] Current Loss: 5.9822\n",
            "[Batch 6] Current Loss: 6.1882\n",
            "[Batch 7] Current Loss: 5.5333\n",
            "[Batch 8] Current Loss: 5.9005\n",
            "[Batch 9] Current Loss: 5.5486\n",
            "Ep 5 (Step 040520): Train loss 2.003, Val loss 5.732\n",
            "[Batch 0] Current Loss: 2.0651\n",
            "[Batch 1] Current Loss: 3.1343\n",
            "[Batch 2] Current Loss: 1.9400\n",
            "[Batch 3] Current Loss: 2.4518\n",
            "[Batch 4] Current Loss: 2.2066\n",
            "[Batch 5] Current Loss: 2.4481\n",
            "[Batch 6] Current Loss: 2.6378\n",
            "[Batch 7] Current Loss: 2.0712\n",
            "[Batch 8] Current Loss: 1.7309\n",
            "[Batch 9] Current Loss: 1.9991\n",
            "[Batch 0] Current Loss: 5.8742\n",
            "[Batch 1] Current Loss: 5.6978\n",
            "[Batch 2] Current Loss: 5.8500\n",
            "[Batch 3] Current Loss: 5.2552\n",
            "[Batch 4] Current Loss: 5.4267\n",
            "[Batch 5] Current Loss: 4.6761\n",
            "[Batch 6] Current Loss: 5.9152\n",
            "[Batch 7] Current Loss: 5.9644\n",
            "[Batch 8] Current Loss: 5.8305\n",
            "[Batch 9] Current Loss: 5.5684\n",
            "Ep 5 (Step 040540): Train loss 2.268, Val loss 5.606\n",
            "[Batch 0] Current Loss: 2.3917\n",
            "[Batch 1] Current Loss: 1.6578\n",
            "[Batch 2] Current Loss: 2.9004\n",
            "[Batch 3] Current Loss: 2.3954\n",
            "[Batch 4] Current Loss: 1.8060\n",
            "[Batch 5] Current Loss: 1.8992\n",
            "[Batch 6] Current Loss: 2.1666\n",
            "[Batch 7] Current Loss: 2.4490\n",
            "[Batch 8] Current Loss: 1.9154\n",
            "[Batch 9] Current Loss: 2.8032\n",
            "[Batch 0] Current Loss: 6.1155\n",
            "[Batch 1] Current Loss: 5.2874\n",
            "[Batch 2] Current Loss: 5.2891\n",
            "[Batch 3] Current Loss: 5.8831\n",
            "[Batch 4] Current Loss: 5.2196\n",
            "[Batch 5] Current Loss: 6.0041\n",
            "[Batch 6] Current Loss: 6.1831\n",
            "[Batch 7] Current Loss: 5.9180\n",
            "[Batch 8] Current Loss: 6.4105\n",
            "[Batch 9] Current Loss: 5.3061\n",
            "Ep 5 (Step 040560): Train loss 2.238, Val loss 5.762\n",
            "[Batch 0] Current Loss: 2.2004\n",
            "[Batch 1] Current Loss: 1.4538\n",
            "[Batch 2] Current Loss: 2.3499\n",
            "[Batch 3] Current Loss: 2.5776\n",
            "[Batch 4] Current Loss: 1.9092\n",
            "[Batch 5] Current Loss: 2.0538\n",
            "[Batch 6] Current Loss: 2.1609\n",
            "[Batch 7] Current Loss: 1.8758\n",
            "[Batch 8] Current Loss: 1.8198\n",
            "[Batch 9] Current Loss: 2.6727\n",
            "[Batch 0] Current Loss: 5.3543\n",
            "[Batch 1] Current Loss: 5.9066\n",
            "[Batch 2] Current Loss: 5.9479\n",
            "[Batch 3] Current Loss: 6.2253\n",
            "[Batch 4] Current Loss: 4.9830\n",
            "[Batch 5] Current Loss: 5.8150\n",
            "[Batch 6] Current Loss: 5.3698\n",
            "[Batch 7] Current Loss: 5.2350\n",
            "[Batch 8] Current Loss: 4.8987\n",
            "[Batch 9] Current Loss: 5.6106\n",
            "Ep 5 (Step 040580): Train loss 2.107, Val loss 5.535\n",
            "[Batch 0] Current Loss: 2.3421\n",
            "[Batch 1] Current Loss: 1.5898\n",
            "[Batch 2] Current Loss: 2.1231\n",
            "[Batch 3] Current Loss: 1.4380\n",
            "[Batch 4] Current Loss: 1.7775\n",
            "[Batch 5] Current Loss: 2.2273\n",
            "[Batch 6] Current Loss: 1.5023\n",
            "[Batch 7] Current Loss: 2.3748\n",
            "[Batch 8] Current Loss: 2.0459\n",
            "[Batch 9] Current Loss: 2.2835\n",
            "[Batch 0] Current Loss: 5.1315\n",
            "[Batch 1] Current Loss: 6.4351\n",
            "[Batch 2] Current Loss: 6.5046\n",
            "[Batch 3] Current Loss: 5.5581\n",
            "[Batch 4] Current Loss: 6.0216\n",
            "[Batch 5] Current Loss: 5.4390\n",
            "[Batch 6] Current Loss: 5.9514\n",
            "[Batch 7] Current Loss: 5.7259\n",
            "[Batch 8] Current Loss: 5.4744\n",
            "[Batch 9] Current Loss: 5.8290\n",
            "Ep 5 (Step 040600): Train loss 1.970, Val loss 5.807\n",
            "[Batch 0] Current Loss: 1.4965\n",
            "[Batch 1] Current Loss: 2.7372\n",
            "[Batch 2] Current Loss: 1.9105\n",
            "[Batch 3] Current Loss: 1.8105\n",
            "[Batch 4] Current Loss: 2.6750\n",
            "[Batch 5] Current Loss: 2.3188\n",
            "[Batch 6] Current Loss: 2.1487\n",
            "[Batch 7] Current Loss: 2.8048\n",
            "[Batch 8] Current Loss: 2.6593\n",
            "[Batch 9] Current Loss: 1.9523\n",
            "[Batch 0] Current Loss: 5.9596\n",
            "[Batch 1] Current Loss: 5.8242\n",
            "[Batch 2] Current Loss: 5.1660\n",
            "[Batch 3] Current Loss: 6.6107\n",
            "[Batch 4] Current Loss: 5.1633\n",
            "[Batch 5] Current Loss: 5.3139\n",
            "[Batch 6] Current Loss: 5.3238\n",
            "[Batch 7] Current Loss: 6.0531\n",
            "[Batch 8] Current Loss: 4.3884\n",
            "[Batch 9] Current Loss: 5.6528\n",
            "Ep 5 (Step 040620): Train loss 2.251, Val loss 5.546\n",
            "[Batch 0] Current Loss: 2.6144\n",
            "[Batch 1] Current Loss: 2.0637\n",
            "[Batch 2] Current Loss: 1.8670\n",
            "[Batch 3] Current Loss: 2.7488\n",
            "[Batch 4] Current Loss: 1.3843\n",
            "[Batch 5] Current Loss: 2.2629\n",
            "[Batch 6] Current Loss: 1.7509\n",
            "[Batch 7] Current Loss: 2.3821\n",
            "[Batch 8] Current Loss: 1.8634\n",
            "[Batch 9] Current Loss: 2.2118\n",
            "[Batch 0] Current Loss: 5.6173\n",
            "[Batch 1] Current Loss: 5.9347\n",
            "[Batch 2] Current Loss: 5.5382\n",
            "[Batch 3] Current Loss: 5.1388\n",
            "[Batch 4] Current Loss: 5.8359\n",
            "[Batch 5] Current Loss: 6.0573\n",
            "[Batch 6] Current Loss: 5.2176\n",
            "[Batch 7] Current Loss: 6.0297\n",
            "[Batch 8] Current Loss: 6.0253\n",
            "[Batch 9] Current Loss: 5.7567\n",
            "Ep 5 (Step 040640): Train loss 2.115, Val loss 5.715\n",
            "[Batch 0] Current Loss: 2.2329\n",
            "[Batch 1] Current Loss: 2.3939\n",
            "[Batch 2] Current Loss: 2.2687\n",
            "[Batch 3] Current Loss: 1.6429\n",
            "[Batch 4] Current Loss: 2.1673\n",
            "[Batch 5] Current Loss: 1.7807\n",
            "[Batch 6] Current Loss: 1.9284\n",
            "[Batch 7] Current Loss: 2.4993\n",
            "[Batch 8] Current Loss: 1.4501\n",
            "[Batch 9] Current Loss: 1.7680\n",
            "[Batch 0] Current Loss: 5.9437\n",
            "[Batch 1] Current Loss: 5.8494\n",
            "[Batch 2] Current Loss: 5.0752\n",
            "[Batch 3] Current Loss: 5.7188\n",
            "[Batch 4] Current Loss: 6.0733\n",
            "[Batch 5] Current Loss: 6.2813\n",
            "[Batch 6] Current Loss: 6.7160\n",
            "[Batch 7] Current Loss: 5.7069\n",
            "[Batch 8] Current Loss: 6.1449\n",
            "[Batch 9] Current Loss: 5.0890\n",
            "Ep 5 (Step 040660): Train loss 2.013, Val loss 5.860\n",
            "[Batch 0] Current Loss: 2.3635\n",
            "[Batch 1] Current Loss: 2.5245\n",
            "[Batch 2] Current Loss: 2.5109\n",
            "[Batch 3] Current Loss: 2.2260\n",
            "[Batch 4] Current Loss: 2.1617\n",
            "[Batch 5] Current Loss: 2.1735\n",
            "[Batch 6] Current Loss: 2.2062\n",
            "[Batch 7] Current Loss: 1.9038\n",
            "[Batch 8] Current Loss: 2.1684\n",
            "[Batch 9] Current Loss: 1.3338\n",
            "[Batch 0] Current Loss: 6.2759\n",
            "[Batch 1] Current Loss: 5.2443\n",
            "[Batch 2] Current Loss: 5.1828\n",
            "[Batch 3] Current Loss: 5.1305\n",
            "[Batch 4] Current Loss: 5.5458\n",
            "[Batch 5] Current Loss: 6.3263\n",
            "[Batch 6] Current Loss: 6.1019\n",
            "[Batch 7] Current Loss: 5.9195\n",
            "[Batch 8] Current Loss: 5.7079\n",
            "[Batch 9] Current Loss: 5.4634\n",
            "Ep 5 (Step 040680): Train loss 2.157, Val loss 5.690\n",
            "[Batch 0] Current Loss: 2.2470\n",
            "[Batch 1] Current Loss: 2.0872\n",
            "[Batch 2] Current Loss: 1.6665\n",
            "[Batch 3] Current Loss: 2.1834\n",
            "[Batch 4] Current Loss: 2.3152\n",
            "[Batch 5] Current Loss: 2.2246\n",
            "[Batch 6] Current Loss: 2.1010\n",
            "[Batch 7] Current Loss: 2.0724\n",
            "[Batch 8] Current Loss: 1.6969\n",
            "[Batch 9] Current Loss: 1.8231\n",
            "[Batch 0] Current Loss: 6.0039\n",
            "[Batch 1] Current Loss: 4.9059\n",
            "[Batch 2] Current Loss: 5.4102\n",
            "[Batch 3] Current Loss: 6.0613\n",
            "[Batch 4] Current Loss: 5.5224\n",
            "[Batch 5] Current Loss: 4.4049\n",
            "[Batch 6] Current Loss: 5.1313\n",
            "[Batch 7] Current Loss: 6.1365\n",
            "[Batch 8] Current Loss: 6.3547\n",
            "[Batch 9] Current Loss: 6.0285\n",
            "Ep 5 (Step 040700): Train loss 2.042, Val loss 5.596\n",
            "[Batch 0] Current Loss: 1.5565\n",
            "[Batch 1] Current Loss: 2.6790\n",
            "[Batch 2] Current Loss: 1.9243\n",
            "[Batch 3] Current Loss: 2.0236\n",
            "[Batch 4] Current Loss: 1.6224\n",
            "[Batch 5] Current Loss: 2.1311\n",
            "[Batch 6] Current Loss: 2.5666\n",
            "[Batch 7] Current Loss: 1.9877\n",
            "[Batch 8] Current Loss: 2.3622\n",
            "[Batch 9] Current Loss: 1.6277\n",
            "[Batch 0] Current Loss: 5.7399\n",
            "[Batch 1] Current Loss: 6.0865\n",
            "[Batch 2] Current Loss: 5.6366\n",
            "[Batch 3] Current Loss: 5.4108\n",
            "[Batch 4] Current Loss: 5.4411\n",
            "[Batch 5] Current Loss: 5.5309\n",
            "[Batch 6] Current Loss: 5.1392\n",
            "[Batch 7] Current Loss: 6.0155\n",
            "[Batch 8] Current Loss: 5.8163\n",
            "[Batch 9] Current Loss: 5.3216\n",
            "Ep 5 (Step 040720): Train loss 2.048, Val loss 5.614\n",
            "[Batch 0] Current Loss: 1.6845\n",
            "[Batch 1] Current Loss: 2.1919\n",
            "[Batch 2] Current Loss: 2.3818\n",
            "[Batch 3] Current Loss: 2.2035\n",
            "[Batch 4] Current Loss: 2.1345\n",
            "[Batch 5] Current Loss: 2.4055\n",
            "[Batch 6] Current Loss: 1.9442\n",
            "[Batch 7] Current Loss: 2.3258\n",
            "[Batch 8] Current Loss: 2.1654\n",
            "[Batch 9] Current Loss: 2.4701\n",
            "[Batch 0] Current Loss: 5.8911\n",
            "[Batch 1] Current Loss: 5.9966\n",
            "[Batch 2] Current Loss: 4.6471\n",
            "[Batch 3] Current Loss: 5.9297\n",
            "[Batch 4] Current Loss: 6.5193\n",
            "[Batch 5] Current Loss: 5.0410\n",
            "[Batch 6] Current Loss: 5.9584\n",
            "[Batch 7] Current Loss: 5.3700\n",
            "[Batch 8] Current Loss: 6.0644\n",
            "[Batch 9] Current Loss: 6.3076\n",
            "Ep 5 (Step 040740): Train loss 2.191, Val loss 5.773\n",
            "[Batch 0] Current Loss: 2.4559\n",
            "[Batch 1] Current Loss: 2.2845\n",
            "[Batch 2] Current Loss: 1.9873\n",
            "[Batch 3] Current Loss: 2.6112\n",
            "[Batch 4] Current Loss: 2.1501\n",
            "[Batch 5] Current Loss: 1.8826\n",
            "[Batch 6] Current Loss: 2.4321\n",
            "[Batch 7] Current Loss: 1.8743\n",
            "[Batch 8] Current Loss: 1.7967\n",
            "[Batch 9] Current Loss: 2.2343\n",
            "[Batch 0] Current Loss: 5.2891\n",
            "[Batch 1] Current Loss: 5.6005\n",
            "[Batch 2] Current Loss: 5.9221\n",
            "[Batch 3] Current Loss: 5.9559\n",
            "[Batch 4] Current Loss: 6.4531\n",
            "[Batch 5] Current Loss: 5.5658\n",
            "[Batch 6] Current Loss: 4.6794\n",
            "[Batch 7] Current Loss: 5.3730\n",
            "[Batch 8] Current Loss: 5.5639\n",
            "[Batch 9] Current Loss: 4.2964\n",
            "Ep 5 (Step 040760): Train loss 2.171, Val loss 5.470\n",
            "[Batch 0] Current Loss: 2.2142\n",
            "[Batch 1] Current Loss: 1.9360\n",
            "[Batch 2] Current Loss: 2.0215\n",
            "[Batch 3] Current Loss: 1.5414\n",
            "[Batch 4] Current Loss: 1.6884\n",
            "[Batch 5] Current Loss: 2.4783\n",
            "[Batch 6] Current Loss: 2.2148\n",
            "[Batch 7] Current Loss: 2.5036\n",
            "[Batch 8] Current Loss: 1.8811\n",
            "[Batch 9] Current Loss: 1.6247\n",
            "[Batch 0] Current Loss: 5.6619\n",
            "[Batch 1] Current Loss: 5.6761\n",
            "[Batch 2] Current Loss: 5.4145\n",
            "[Batch 3] Current Loss: 4.6008\n",
            "[Batch 4] Current Loss: 5.6922\n",
            "[Batch 5] Current Loss: 5.2805\n",
            "[Batch 6] Current Loss: 6.1713\n",
            "[Batch 7] Current Loss: 5.7395\n",
            "[Batch 8] Current Loss: 6.3002\n",
            "[Batch 9] Current Loss: 6.6754\n",
            "Ep 5 (Step 040780): Train loss 2.010, Val loss 5.721\n",
            "[Batch 0] Current Loss: 2.1380\n",
            "[Batch 1] Current Loss: 2.1537\n",
            "[Batch 2] Current Loss: 1.7375\n",
            "[Batch 3] Current Loss: 2.3282\n",
            "[Batch 4] Current Loss: 1.8628\n",
            "[Batch 5] Current Loss: 2.0217\n",
            "[Batch 6] Current Loss: 2.0041\n",
            "[Batch 7] Current Loss: 1.8718\n",
            "[Batch 8] Current Loss: 1.5200\n",
            "[Batch 9] Current Loss: 1.8371\n",
            "[Batch 0] Current Loss: 5.7253\n",
            "[Batch 1] Current Loss: 4.7298\n",
            "[Batch 2] Current Loss: 5.4941\n",
            "[Batch 3] Current Loss: 5.2000\n",
            "[Batch 4] Current Loss: 5.4200\n",
            "[Batch 5] Current Loss: 5.6333\n",
            "[Batch 6] Current Loss: 6.3017\n",
            "[Batch 7] Current Loss: 4.8003\n",
            "[Batch 8] Current Loss: 6.1365\n",
            "[Batch 9] Current Loss: 5.7542\n",
            "Ep 5 (Step 040800): Train loss 1.947, Val loss 5.520\n",
            "[Batch 0] Current Loss: 2.2169\n",
            "[Batch 1] Current Loss: 2.3993\n",
            "[Batch 2] Current Loss: 1.9236\n",
            "[Batch 3] Current Loss: 2.1804\n",
            "[Batch 4] Current Loss: 2.2993\n",
            "[Batch 5] Current Loss: 2.1529\n",
            "[Batch 6] Current Loss: 2.2929\n",
            "[Batch 7] Current Loss: 2.0237\n",
            "[Batch 8] Current Loss: 2.1038\n",
            "[Batch 9] Current Loss: 2.6659\n",
            "[Batch 0] Current Loss: 5.7632\n",
            "[Batch 1] Current Loss: 5.5717\n",
            "[Batch 2] Current Loss: 4.6846\n",
            "[Batch 3] Current Loss: 6.0417\n",
            "[Batch 4] Current Loss: 5.2392\n",
            "[Batch 5] Current Loss: 4.7399\n",
            "[Batch 6] Current Loss: 5.1084\n",
            "[Batch 7] Current Loss: 6.0805\n",
            "[Batch 8] Current Loss: 6.5764\n",
            "[Batch 9] Current Loss: 5.5060\n",
            "Ep 5 (Step 040820): Train loss 2.226, Val loss 5.531\n",
            "[Batch 0] Current Loss: 1.8059\n",
            "[Batch 1] Current Loss: 2.0002\n",
            "[Batch 2] Current Loss: 1.8492\n",
            "[Batch 3] Current Loss: 2.1454\n",
            "[Batch 4] Current Loss: 2.4255\n",
            "[Batch 5] Current Loss: 1.9650\n",
            "[Batch 6] Current Loss: 1.5739\n",
            "[Batch 7] Current Loss: 2.2148\n",
            "[Batch 8] Current Loss: 2.0507\n",
            "[Batch 9] Current Loss: 2.4793\n",
            "[Batch 0] Current Loss: 6.1346\n",
            "[Batch 1] Current Loss: 6.3077\n",
            "[Batch 2] Current Loss: 5.8977\n",
            "[Batch 3] Current Loss: 5.8334\n",
            "[Batch 4] Current Loss: 6.1348\n",
            "[Batch 5] Current Loss: 5.7288\n",
            "[Batch 6] Current Loss: 5.3317\n",
            "[Batch 7] Current Loss: 6.2581\n",
            "[Batch 8] Current Loss: 5.6551\n",
            "[Batch 9] Current Loss: 6.2578\n",
            "Ep 5 (Step 040840): Train loss 2.051, Val loss 5.954\n",
            "[Batch 0] Current Loss: 2.8288\n",
            "[Batch 1] Current Loss: 2.0968\n",
            "[Batch 2] Current Loss: 2.2468\n",
            "[Batch 3] Current Loss: 1.6868\n",
            "[Batch 4] Current Loss: 1.6972\n",
            "[Batch 5] Current Loss: 2.0123\n",
            "[Batch 6] Current Loss: 1.8777\n",
            "[Batch 7] Current Loss: 1.7879\n",
            "[Batch 8] Current Loss: 2.3751\n",
            "[Batch 9] Current Loss: 2.4029\n",
            "[Batch 0] Current Loss: 5.9491\n",
            "[Batch 1] Current Loss: 5.6905\n",
            "[Batch 2] Current Loss: 6.3142\n",
            "[Batch 3] Current Loss: 6.0103\n",
            "[Batch 4] Current Loss: 5.2787\n",
            "[Batch 5] Current Loss: 6.2543\n",
            "[Batch 6] Current Loss: 5.8304\n",
            "[Batch 7] Current Loss: 5.4903\n",
            "[Batch 8] Current Loss: 6.1760\n",
            "[Batch 9] Current Loss: 5.6290\n",
            "Ep 5 (Step 040860): Train loss 2.101, Val loss 5.862\n",
            "[Batch 0] Current Loss: 1.8486\n",
            "[Batch 1] Current Loss: 2.0039\n",
            "[Batch 2] Current Loss: 2.1824\n",
            "[Batch 3] Current Loss: 2.0099\n",
            "[Batch 4] Current Loss: 2.0001\n",
            "[Batch 5] Current Loss: 1.7840\n",
            "[Batch 6] Current Loss: 2.0230\n",
            "[Batch 7] Current Loss: 1.7021\n",
            "[Batch 8] Current Loss: 2.1662\n",
            "[Batch 9] Current Loss: 2.4508\n",
            "[Batch 0] Current Loss: 5.6065\n",
            "[Batch 1] Current Loss: 5.7897\n",
            "[Batch 2] Current Loss: 4.7932\n",
            "[Batch 3] Current Loss: 5.7101\n",
            "[Batch 4] Current Loss: 5.8958\n",
            "[Batch 5] Current Loss: 5.2286\n",
            "[Batch 6] Current Loss: 5.8244\n",
            "[Batch 7] Current Loss: 5.5947\n",
            "[Batch 8] Current Loss: 6.1924\n",
            "[Batch 9] Current Loss: 5.5017\n",
            "Ep 5 (Step 040880): Train loss 2.017, Val loss 5.614\n",
            "[Batch 0] Current Loss: 1.8604\n",
            "[Batch 1] Current Loss: 1.6200\n",
            "[Batch 2] Current Loss: 2.4267\n",
            "[Batch 3] Current Loss: 1.6711\n",
            "[Batch 4] Current Loss: 1.7176\n",
            "[Batch 5] Current Loss: 2.6197\n",
            "[Batch 6] Current Loss: 2.0954\n",
            "[Batch 7] Current Loss: 2.0923\n",
            "[Batch 8] Current Loss: 2.9702\n",
            "[Batch 9] Current Loss: 1.2150\n",
            "[Batch 0] Current Loss: 5.0867\n",
            "[Batch 1] Current Loss: 5.7017\n",
            "[Batch 2] Current Loss: 6.0749\n",
            "[Batch 3] Current Loss: 5.0986\n",
            "[Batch 4] Current Loss: 5.1201\n",
            "[Batch 5] Current Loss: 5.5369\n",
            "[Batch 6] Current Loss: 5.3785\n",
            "[Batch 7] Current Loss: 5.5326\n",
            "[Batch 8] Current Loss: 5.5546\n",
            "[Batch 9] Current Loss: 4.7228\n",
            "Ep 5 (Step 040900): Train loss 2.029, Val loss 5.381\n",
            "[Batch 0] Current Loss: 2.0577\n",
            "[Batch 1] Current Loss: 2.3229\n",
            "[Batch 2] Current Loss: 2.3098\n",
            "[Batch 3] Current Loss: 2.2866\n",
            "[Batch 4] Current Loss: 1.5278\n",
            "[Batch 5] Current Loss: 2.2175\n",
            "[Batch 6] Current Loss: 2.1729\n",
            "[Batch 7] Current Loss: 1.5805\n",
            "[Batch 8] Current Loss: 2.1214\n",
            "[Batch 9] Current Loss: 1.6482\n",
            "[Batch 0] Current Loss: 6.2492\n",
            "[Batch 1] Current Loss: 5.8306\n",
            "[Batch 2] Current Loss: 6.1951\n",
            "[Batch 3] Current Loss: 5.4183\n",
            "[Batch 4] Current Loss: 5.6405\n",
            "[Batch 5] Current Loss: 5.8292\n",
            "[Batch 6] Current Loss: 5.9789\n",
            "[Batch 7] Current Loss: 4.6533\n",
            "[Batch 8] Current Loss: 6.5044\n",
            "[Batch 9] Current Loss: 5.1449\n",
            "Ep 5 (Step 040920): Train loss 2.025, Val loss 5.744\n",
            "[Batch 0] Current Loss: 2.2794\n",
            "[Batch 1] Current Loss: 2.2233\n",
            "[Batch 2] Current Loss: 2.1314\n",
            "[Batch 3] Current Loss: 2.6583\n",
            "[Batch 4] Current Loss: 1.5331\n",
            "[Batch 5] Current Loss: 2.1537\n",
            "[Batch 6] Current Loss: 2.3165\n",
            "[Batch 7] Current Loss: 2.5282\n",
            "[Batch 8] Current Loss: 1.2421\n",
            "[Batch 9] Current Loss: 2.0565\n",
            "[Batch 0] Current Loss: 4.8497\n",
            "[Batch 1] Current Loss: 5.9704\n",
            "[Batch 2] Current Loss: 5.9526\n",
            "[Batch 3] Current Loss: 4.4763\n",
            "[Batch 4] Current Loss: 5.5168\n",
            "[Batch 5] Current Loss: 5.7496\n",
            "[Batch 6] Current Loss: 5.7462\n",
            "[Batch 7] Current Loss: 5.8894\n",
            "[Batch 8] Current Loss: 6.1720\n",
            "[Batch 9] Current Loss: 6.0569\n",
            "Ep 5 (Step 040940): Train loss 2.112, Val loss 5.638\n",
            "[Batch 0] Current Loss: 1.7512\n",
            "[Batch 1] Current Loss: 2.3866\n",
            "[Batch 2] Current Loss: 2.4368\n",
            "[Batch 3] Current Loss: 2.7060\n",
            "[Batch 4] Current Loss: 1.8789\n",
            "[Batch 5] Current Loss: 1.8491\n",
            "[Batch 6] Current Loss: 1.8013\n",
            "[Batch 7] Current Loss: 2.6438\n",
            "[Batch 8] Current Loss: 1.4097\n",
            "[Batch 9] Current Loss: 2.4725\n",
            "[Batch 0] Current Loss: 4.8925\n",
            "[Batch 1] Current Loss: 5.3871\n",
            "[Batch 2] Current Loss: 5.6031\n",
            "[Batch 3] Current Loss: 5.7085\n",
            "[Batch 4] Current Loss: 6.0642\n",
            "[Batch 5] Current Loss: 4.0515\n",
            "[Batch 6] Current Loss: 5.9474\n",
            "[Batch 7] Current Loss: 5.7444\n",
            "[Batch 8] Current Loss: 6.6101\n",
            "[Batch 9] Current Loss: 6.0883\n",
            "Ep 5 (Step 040960): Train loss 2.134, Val loss 5.610\n",
            "[Batch 0] Current Loss: 1.9749\n",
            "[Batch 1] Current Loss: 2.1326\n",
            "[Batch 2] Current Loss: 2.2401\n",
            "[Batch 3] Current Loss: 1.9400\n",
            "[Batch 4] Current Loss: 2.5902\n",
            "[Batch 5] Current Loss: 2.1624\n",
            "[Batch 6] Current Loss: 2.2721\n",
            "[Batch 7] Current Loss: 1.5082\n",
            "[Batch 8] Current Loss: 1.6461\n",
            "[Batch 9] Current Loss: 2.2819\n",
            "[Batch 0] Current Loss: 5.8861\n",
            "[Batch 1] Current Loss: 5.1333\n",
            "[Batch 2] Current Loss: 5.1180\n",
            "[Batch 3] Current Loss: 5.7897\n",
            "[Batch 4] Current Loss: 5.9921\n",
            "[Batch 5] Current Loss: 5.4605\n",
            "[Batch 6] Current Loss: 5.6877\n",
            "[Batch 7] Current Loss: 5.8949\n",
            "[Batch 8] Current Loss: 6.5863\n",
            "[Batch 9] Current Loss: 6.4876\n",
            "Ep 5 (Step 040980): Train loss 2.075, Val loss 5.804\n",
            "[Batch 0] Current Loss: 3.0740\n",
            "[Batch 1] Current Loss: 1.7720\n",
            "[Batch 2] Current Loss: 2.0004\n",
            "[Batch 3] Current Loss: 2.5094\n",
            "[Batch 4] Current Loss: 1.9420\n",
            "[Batch 5] Current Loss: 2.6635\n",
            "[Batch 6] Current Loss: 1.8445\n",
            "[Batch 7] Current Loss: 2.3004\n",
            "[Batch 8] Current Loss: 2.0482\n",
            "[Batch 9] Current Loss: 2.2778\n",
            "[Batch 0] Current Loss: 5.7630\n",
            "[Batch 1] Current Loss: 5.0373\n",
            "[Batch 2] Current Loss: 5.9287\n",
            "[Batch 3] Current Loss: 5.3306\n",
            "[Batch 4] Current Loss: 4.7042\n",
            "[Batch 5] Current Loss: 5.5522\n",
            "[Batch 6] Current Loss: 5.4810\n",
            "[Batch 7] Current Loss: 6.5905\n",
            "[Batch 8] Current Loss: 5.9606\n",
            "[Batch 9] Current Loss: 6.1713\n",
            "Ep 5 (Step 041000): Train loss 2.243, Val loss 5.652\n",
            "[Batch 0] Current Loss: 2.0549\n",
            "[Batch 1] Current Loss: 1.7681\n",
            "[Batch 2] Current Loss: 2.4074\n",
            "[Batch 3] Current Loss: 1.7906\n",
            "[Batch 4] Current Loss: 1.9670\n",
            "[Batch 5] Current Loss: 1.6838\n",
            "[Batch 6] Current Loss: 1.8196\n",
            "[Batch 7] Current Loss: 2.4482\n",
            "[Batch 8] Current Loss: 1.6883\n",
            "[Batch 9] Current Loss: 1.8744\n",
            "[Batch 0] Current Loss: 4.7020\n",
            "[Batch 1] Current Loss: 6.2207\n",
            "[Batch 2] Current Loss: 5.8419\n",
            "[Batch 3] Current Loss: 5.7273\n",
            "[Batch 4] Current Loss: 6.1713\n",
            "[Batch 5] Current Loss: 5.7331\n",
            "[Batch 6] Current Loss: 5.2918\n",
            "[Batch 7] Current Loss: 6.4981\n",
            "[Batch 8] Current Loss: 6.1103\n",
            "[Batch 9] Current Loss: 5.9394\n",
            "Ep 5 (Step 041020): Train loss 1.950, Val loss 5.824\n",
            "[Batch 0] Current Loss: 1.7483\n",
            "[Batch 1] Current Loss: 2.2927\n",
            "[Batch 2] Current Loss: 2.5545\n",
            "[Batch 3] Current Loss: 1.6637\n",
            "[Batch 4] Current Loss: 2.0995\n",
            "[Batch 5] Current Loss: 1.7499\n",
            "[Batch 6] Current Loss: 1.9580\n",
            "[Batch 7] Current Loss: 1.7460\n",
            "[Batch 8] Current Loss: 2.0749\n",
            "[Batch 9] Current Loss: 2.1823\n",
            "[Batch 0] Current Loss: 6.1349\n",
            "[Batch 1] Current Loss: 5.4729\n",
            "[Batch 2] Current Loss: 6.7070\n",
            "[Batch 3] Current Loss: 5.8826\n",
            "[Batch 4] Current Loss: 5.2780\n",
            "[Batch 5] Current Loss: 5.7671\n",
            "[Batch 6] Current Loss: 5.3165\n",
            "[Batch 7] Current Loss: 5.5976\n",
            "[Batch 8] Current Loss: 6.0569\n",
            "[Batch 9] Current Loss: 6.5616\n",
            "Ep 5 (Step 041040): Train loss 2.007, Val loss 5.877\n",
            "[Batch 0] Current Loss: 1.4937\n",
            "[Batch 1] Current Loss: 2.3553\n",
            "[Batch 2] Current Loss: 1.7863\n",
            "[Batch 3] Current Loss: 2.3968\n",
            "[Batch 4] Current Loss: 1.6745\n",
            "[Batch 5] Current Loss: 1.9553\n",
            "[Batch 6] Current Loss: 2.5618\n",
            "[Batch 7] Current Loss: 2.2865\n",
            "[Batch 8] Current Loss: 2.6869\n",
            "[Batch 9] Current Loss: 2.6586\n",
            "[Batch 0] Current Loss: 4.6910\n",
            "[Batch 1] Current Loss: 6.3938\n",
            "[Batch 2] Current Loss: 5.0187\n",
            "[Batch 3] Current Loss: 4.8374\n",
            "[Batch 4] Current Loss: 6.1946\n",
            "[Batch 5] Current Loss: 5.0884\n",
            "[Batch 6] Current Loss: 5.7507\n",
            "[Batch 7] Current Loss: 5.0347\n",
            "[Batch 8] Current Loss: 6.3209\n",
            "[Batch 9] Current Loss: 6.4030\n",
            "Ep 5 (Step 041060): Train loss 2.186, Val loss 5.573\n",
            "[Batch 0] Current Loss: 2.0545\n",
            "[Batch 1] Current Loss: 1.8781\n",
            "[Batch 2] Current Loss: 1.9127\n",
            "[Batch 3] Current Loss: 1.7752\n",
            "[Batch 4] Current Loss: 2.2360\n",
            "[Batch 5] Current Loss: 2.0096\n",
            "[Batch 6] Current Loss: 1.9666\n",
            "[Batch 7] Current Loss: 2.1320\n",
            "[Batch 8] Current Loss: 2.6375\n",
            "[Batch 9] Current Loss: 1.9259\n",
            "[Batch 0] Current Loss: 5.1564\n",
            "[Batch 1] Current Loss: 5.0469\n",
            "[Batch 2] Current Loss: 5.9025\n",
            "[Batch 3] Current Loss: 4.9897\n",
            "[Batch 4] Current Loss: 5.3028\n",
            "[Batch 5] Current Loss: 6.0214\n",
            "[Batch 6] Current Loss: 5.4601\n",
            "[Batch 7] Current Loss: 5.0549\n",
            "[Batch 8] Current Loss: 6.0393\n",
            "[Batch 9] Current Loss: 5.5317\n",
            "Ep 5 (Step 041080): Train loss 2.053, Val loss 5.451\n",
            "[Batch 0] Current Loss: 2.8442\n",
            "[Batch 1] Current Loss: 1.4596\n",
            "[Batch 2] Current Loss: 2.0079\n",
            "[Batch 3] Current Loss: 1.9014\n",
            "[Batch 4] Current Loss: 2.0004\n",
            "[Batch 5] Current Loss: 1.8699\n",
            "[Batch 6] Current Loss: 1.9830\n",
            "[Batch 7] Current Loss: 1.8748\n",
            "[Batch 8] Current Loss: 2.1547\n",
            "[Batch 9] Current Loss: 2.4653\n",
            "[Batch 0] Current Loss: 4.9461\n",
            "[Batch 1] Current Loss: 5.5869\n",
            "[Batch 2] Current Loss: 6.2404\n",
            "[Batch 3] Current Loss: 5.8443\n",
            "[Batch 4] Current Loss: 5.5791\n",
            "[Batch 5] Current Loss: 6.3561\n",
            "[Batch 6] Current Loss: 6.3266\n",
            "[Batch 7] Current Loss: 5.5217\n",
            "[Batch 8] Current Loss: 6.1239\n",
            "[Batch 9] Current Loss: 6.0818\n",
            "Ep 5 (Step 041100): Train loss 2.056, Val loss 5.861\n",
            "[Batch 0] Current Loss: 2.3958\n",
            "[Batch 1] Current Loss: 1.3419\n",
            "[Batch 2] Current Loss: 1.3791\n",
            "[Batch 3] Current Loss: 1.9641\n",
            "[Batch 4] Current Loss: 2.7030\n",
            "[Batch 5] Current Loss: 1.8755\n",
            "[Batch 6] Current Loss: 2.3020\n",
            "[Batch 7] Current Loss: 2.2301\n",
            "[Batch 8] Current Loss: 2.3211\n",
            "[Batch 9] Current Loss: 1.9103\n",
            "[Batch 0] Current Loss: 6.4162\n",
            "[Batch 1] Current Loss: 5.6274\n",
            "[Batch 2] Current Loss: 4.5374\n",
            "[Batch 3] Current Loss: 6.4334\n",
            "[Batch 4] Current Loss: 6.0837\n",
            "[Batch 5] Current Loss: 4.9130\n",
            "[Batch 6] Current Loss: 6.4244\n",
            "[Batch 7] Current Loss: 5.1656\n",
            "[Batch 8] Current Loss: 6.0175\n",
            "[Batch 9] Current Loss: 5.6086\n",
            "Ep 5 (Step 041120): Train loss 2.042, Val loss 5.723\n",
            "[Batch 0] Current Loss: 1.9455\n",
            "[Batch 1] Current Loss: 1.7651\n",
            "[Batch 2] Current Loss: 1.6524\n",
            "[Batch 3] Current Loss: 1.8501\n",
            "[Batch 4] Current Loss: 1.9812\n",
            "[Batch 5] Current Loss: 2.3516\n",
            "[Batch 6] Current Loss: 2.0152\n",
            "[Batch 7] Current Loss: 2.4689\n",
            "[Batch 8] Current Loss: 1.9226\n",
            "[Batch 9] Current Loss: 1.5950\n",
            "[Batch 0] Current Loss: 5.6800\n",
            "[Batch 1] Current Loss: 5.4736\n",
            "[Batch 2] Current Loss: 5.2691\n",
            "[Batch 3] Current Loss: 6.3643\n",
            "[Batch 4] Current Loss: 5.5673\n",
            "[Batch 5] Current Loss: 6.0063\n",
            "[Batch 6] Current Loss: 6.0337\n",
            "[Batch 7] Current Loss: 5.9811\n",
            "[Batch 8] Current Loss: 6.0744\n",
            "[Batch 9] Current Loss: 5.0659\n",
            "Ep 5 (Step 041140): Train loss 1.955, Val loss 5.752\n",
            "[Batch 0] Current Loss: 2.0621\n",
            "[Batch 1] Current Loss: 1.9236\n",
            "[Batch 2] Current Loss: 1.9546\n",
            "[Batch 3] Current Loss: 2.5851\n",
            "[Batch 4] Current Loss: 1.6695\n",
            "[Batch 5] Current Loss: 1.5009\n",
            "[Batch 6] Current Loss: 2.5220\n",
            "[Batch 7] Current Loss: 2.1288\n",
            "[Batch 8] Current Loss: 2.1654\n",
            "[Batch 9] Current Loss: 2.5851\n",
            "[Batch 0] Current Loss: 6.1430\n",
            "[Batch 1] Current Loss: 5.0089\n",
            "[Batch 2] Current Loss: 5.1799\n",
            "[Batch 3] Current Loss: 5.3852\n",
            "[Batch 4] Current Loss: 6.1893\n",
            "[Batch 5] Current Loss: 6.5536\n",
            "[Batch 6] Current Loss: 5.5688\n",
            "[Batch 7] Current Loss: 5.3626\n",
            "[Batch 8] Current Loss: 6.1754\n",
            "[Batch 9] Current Loss: 5.6765\n",
            "Ep 5 (Step 041160): Train loss 2.110, Val loss 5.724\n",
            "[Batch 0] Current Loss: 1.7741\n",
            "[Batch 1] Current Loss: 1.7638\n",
            "[Batch 2] Current Loss: 2.1557\n",
            "[Batch 3] Current Loss: 2.4460\n",
            "[Batch 4] Current Loss: 2.1370\n",
            "[Batch 5] Current Loss: 2.3652\n",
            "[Batch 6] Current Loss: 1.5838\n",
            "[Batch 7] Current Loss: 1.7199\n",
            "[Batch 8] Current Loss: 2.2634\n",
            "[Batch 9] Current Loss: 1.8256\n",
            "[Batch 0] Current Loss: 5.4227\n",
            "[Batch 1] Current Loss: 6.3209\n",
            "[Batch 2] Current Loss: 5.7351\n",
            "[Batch 3] Current Loss: 6.3661\n",
            "[Batch 4] Current Loss: 6.1788\n",
            "[Batch 5] Current Loss: 6.1027\n",
            "[Batch 6] Current Loss: 5.8083\n",
            "[Batch 7] Current Loss: 5.6414\n",
            "[Batch 8] Current Loss: 6.3185\n",
            "[Batch 9] Current Loss: 5.2441\n",
            "Ep 5 (Step 041180): Train loss 2.003, Val loss 5.914\n",
            "[Batch 0] Current Loss: 2.2867\n",
            "[Batch 1] Current Loss: 1.8875\n",
            "[Batch 2] Current Loss: 2.4154\n",
            "[Batch 3] Current Loss: 1.7042\n",
            "[Batch 4] Current Loss: 2.5106\n",
            "[Batch 5] Current Loss: 1.4884\n",
            "[Batch 6] Current Loss: 2.1681\n",
            "[Batch 7] Current Loss: 1.9891\n",
            "[Batch 8] Current Loss: 2.4593\n",
            "[Batch 9] Current Loss: 1.8286\n",
            "[Batch 0] Current Loss: 6.0759\n",
            "[Batch 1] Current Loss: 6.7617\n",
            "[Batch 2] Current Loss: 5.9318\n",
            "[Batch 3] Current Loss: 5.3527\n",
            "[Batch 4] Current Loss: 5.5048\n",
            "[Batch 5] Current Loss: 5.9189\n",
            "[Batch 6] Current Loss: 6.3799\n",
            "[Batch 7] Current Loss: 5.8255\n",
            "[Batch 8] Current Loss: 5.0268\n",
            "[Batch 9] Current Loss: 5.4325\n",
            "Ep 5 (Step 041200): Train loss 2.074, Val loss 5.821\n",
            "[Batch 0] Current Loss: 1.8173\n",
            "[Batch 1] Current Loss: 2.3289\n",
            "[Batch 2] Current Loss: 2.2460\n",
            "[Batch 3] Current Loss: 1.9006\n",
            "[Batch 4] Current Loss: 1.7213\n",
            "[Batch 5] Current Loss: 2.3610\n",
            "[Batch 6] Current Loss: 2.1055\n",
            "[Batch 7] Current Loss: 1.8036\n",
            "[Batch 8] Current Loss: 1.6906\n",
            "[Batch 9] Current Loss: 1.5730\n",
            "[Batch 0] Current Loss: 5.5515\n",
            "[Batch 1] Current Loss: 5.9371\n",
            "[Batch 2] Current Loss: 4.9617\n",
            "[Batch 3] Current Loss: 5.9660\n",
            "[Batch 4] Current Loss: 6.1001\n",
            "[Batch 5] Current Loss: 6.0131\n",
            "[Batch 6] Current Loss: 5.1356\n",
            "[Batch 7] Current Loss: 3.9715\n",
            "[Batch 8] Current Loss: 5.2114\n",
            "[Batch 9] Current Loss: 4.8159\n",
            "Ep 5 (Step 041220): Train loss 1.955, Val loss 5.366\n",
            "[Batch 0] Current Loss: 1.5531\n",
            "[Batch 1] Current Loss: 1.7916\n",
            "[Batch 2] Current Loss: 2.0857\n",
            "[Batch 3] Current Loss: 1.6304\n",
            "[Batch 4] Current Loss: 1.7727\n",
            "[Batch 5] Current Loss: 2.3934\n",
            "[Batch 6] Current Loss: 2.0872\n",
            "[Batch 7] Current Loss: 2.4111\n",
            "[Batch 8] Current Loss: 1.9975\n",
            "[Batch 9] Current Loss: 1.7873\n",
            "[Batch 0] Current Loss: 6.1801\n",
            "[Batch 1] Current Loss: 5.9668\n",
            "[Batch 2] Current Loss: 6.8621\n",
            "[Batch 3] Current Loss: 5.6043\n",
            "[Batch 4] Current Loss: 5.1326\n",
            "[Batch 5] Current Loss: 5.4513\n",
            "[Batch 6] Current Loss: 5.3241\n",
            "[Batch 7] Current Loss: 5.9032\n",
            "[Batch 8] Current Loss: 5.3867\n",
            "[Batch 9] Current Loss: 5.3700\n",
            "Ep 5 (Step 041240): Train loss 1.951, Val loss 5.718\n",
            "[Batch 0] Current Loss: 2.6185\n",
            "[Batch 1] Current Loss: 2.2055\n",
            "[Batch 2] Current Loss: 1.8250\n",
            "[Batch 3] Current Loss: 2.0295\n",
            "[Batch 4] Current Loss: 2.3145\n",
            "[Batch 5] Current Loss: 1.8364\n",
            "[Batch 6] Current Loss: 2.3807\n",
            "[Batch 7] Current Loss: 1.9270\n",
            "[Batch 8] Current Loss: 2.2975\n",
            "[Batch 9] Current Loss: 2.1880\n",
            "[Batch 0] Current Loss: 6.0196\n",
            "[Batch 1] Current Loss: 5.3022\n",
            "[Batch 2] Current Loss: 6.2651\n",
            "[Batch 3] Current Loss: 4.3021\n",
            "[Batch 4] Current Loss: 6.2633\n",
            "[Batch 5] Current Loss: 5.3537\n",
            "[Batch 6] Current Loss: 5.3653\n",
            "[Batch 7] Current Loss: 4.7431\n",
            "[Batch 8] Current Loss: 5.7150\n",
            "[Batch 9] Current Loss: 5.9879\n",
            "Ep 5 (Step 041260): Train loss 2.162, Val loss 5.532\n",
            "[Batch 0] Current Loss: 1.1016\n",
            "[Batch 1] Current Loss: 2.4570\n",
            "[Batch 2] Current Loss: 2.6668\n",
            "[Batch 3] Current Loss: 2.0889\n",
            "[Batch 4] Current Loss: 2.1211\n",
            "[Batch 5] Current Loss: 2.0132\n",
            "[Batch 6] Current Loss: 2.2730\n",
            "[Batch 7] Current Loss: 1.4440\n",
            "[Batch 8] Current Loss: 2.1830\n",
            "[Batch 9] Current Loss: 1.9695\n",
            "[Batch 0] Current Loss: 5.9257\n",
            "[Batch 1] Current Loss: 5.5710\n",
            "[Batch 2] Current Loss: 4.9268\n",
            "[Batch 3] Current Loss: 5.7116\n",
            "[Batch 4] Current Loss: 5.4824\n",
            "[Batch 5] Current Loss: 5.1726\n",
            "[Batch 6] Current Loss: 5.4650\n",
            "[Batch 7] Current Loss: 5.7834\n",
            "[Batch 8] Current Loss: 5.9292\n",
            "[Batch 9] Current Loss: 4.7651\n",
            "Ep 5 (Step 041280): Train loss 2.032, Val loss 5.473\n",
            "[Batch 0] Current Loss: 1.9397\n",
            "[Batch 1] Current Loss: 2.2236\n",
            "[Batch 2] Current Loss: 2.4845\n",
            "[Batch 3] Current Loss: 2.0513\n",
            "[Batch 4] Current Loss: 1.6147\n",
            "[Batch 5] Current Loss: 2.2021\n",
            "[Batch 6] Current Loss: 1.9154\n",
            "[Batch 7] Current Loss: 2.0496\n",
            "[Batch 8] Current Loss: 2.0866\n",
            "[Batch 9] Current Loss: 2.1073\n",
            "[Batch 0] Current Loss: 5.8360\n",
            "[Batch 1] Current Loss: 6.2169\n",
            "[Batch 2] Current Loss: 5.6565\n",
            "[Batch 3] Current Loss: 5.0092\n",
            "[Batch 4] Current Loss: 5.6155\n",
            "[Batch 5] Current Loss: 5.9322\n",
            "[Batch 6] Current Loss: 6.4481\n",
            "[Batch 7] Current Loss: 4.8446\n",
            "[Batch 8] Current Loss: 5.4420\n",
            "[Batch 9] Current Loss: 5.8932\n",
            "Ep 5 (Step 041300): Train loss 2.067, Val loss 5.689\n",
            "[Batch 0] Current Loss: 1.5542\n",
            "[Batch 1] Current Loss: 2.0861\n",
            "[Batch 2] Current Loss: 2.4102\n",
            "[Batch 3] Current Loss: 2.3212\n",
            "[Batch 4] Current Loss: 1.5522\n",
            "[Batch 5] Current Loss: 2.5137\n",
            "[Batch 6] Current Loss: 2.5424\n",
            "[Batch 7] Current Loss: 2.0312\n",
            "[Batch 8] Current Loss: 1.9385\n",
            "[Batch 9] Current Loss: 1.9618\n",
            "[Batch 0] Current Loss: 5.6332\n",
            "[Batch 1] Current Loss: 6.3644\n",
            "[Batch 2] Current Loss: 5.3921\n",
            "[Batch 3] Current Loss: 6.3971\n",
            "[Batch 4] Current Loss: 4.8369\n",
            "[Batch 5] Current Loss: 5.9013\n",
            "[Batch 6] Current Loss: 5.6343\n",
            "[Batch 7] Current Loss: 5.9579\n",
            "[Batch 8] Current Loss: 5.2516\n",
            "[Batch 9] Current Loss: 5.2454\n",
            "Ep 5 (Step 041320): Train loss 2.091, Val loss 5.661\n",
            "[Batch 0] Current Loss: 2.7331\n",
            "[Batch 1] Current Loss: 1.9941\n",
            "[Batch 2] Current Loss: 2.0053\n",
            "[Batch 3] Current Loss: 1.7299\n",
            "[Batch 4] Current Loss: 2.8632\n",
            "[Batch 5] Current Loss: 1.2539\n",
            "[Batch 6] Current Loss: 1.8918\n",
            "[Batch 7] Current Loss: 1.5205\n",
            "[Batch 8] Current Loss: 1.6046\n",
            "[Batch 9] Current Loss: 2.0992\n",
            "[Batch 0] Current Loss: 5.6372\n",
            "[Batch 1] Current Loss: 5.1877\n",
            "[Batch 2] Current Loss: 5.8897\n",
            "[Batch 3] Current Loss: 5.5433\n",
            "[Batch 4] Current Loss: 4.9330\n",
            "[Batch 5] Current Loss: 4.9871\n",
            "[Batch 6] Current Loss: 5.4120\n",
            "[Batch 7] Current Loss: 5.7511\n",
            "[Batch 8] Current Loss: 6.0984\n",
            "[Batch 9] Current Loss: 5.5014\n",
            "Ep 5 (Step 041340): Train loss 1.970, Val loss 5.494\n",
            "[Batch 0] Current Loss: 2.0495\n",
            "[Batch 1] Current Loss: 1.9464\n",
            "[Batch 2] Current Loss: 2.8422\n",
            "[Batch 3] Current Loss: 1.5475\n",
            "[Batch 4] Current Loss: 1.8996\n",
            "[Batch 5] Current Loss: 2.0974\n",
            "[Batch 6] Current Loss: 2.1915\n",
            "[Batch 7] Current Loss: 1.8268\n",
            "[Batch 8] Current Loss: 1.8608\n",
            "[Batch 9] Current Loss: 2.3049\n",
            "[Batch 0] Current Loss: 5.8490\n",
            "[Batch 1] Current Loss: 4.7632\n",
            "[Batch 2] Current Loss: 5.9156\n",
            "[Batch 3] Current Loss: 6.3284\n",
            "[Batch 4] Current Loss: 4.4788\n",
            "[Batch 5] Current Loss: 5.1234\n",
            "[Batch 6] Current Loss: 5.6857\n",
            "[Batch 7] Current Loss: 5.3045\n",
            "[Batch 8] Current Loss: 5.6022\n",
            "[Batch 9] Current Loss: 5.8416\n",
            "Ep 5 (Step 041360): Train loss 2.057, Val loss 5.489\n",
            "[Batch 0] Current Loss: 1.6795\n",
            "[Batch 1] Current Loss: 2.2569\n",
            "[Batch 2] Current Loss: 2.4813\n",
            "[Batch 3] Current Loss: 2.0753\n",
            "[Batch 4] Current Loss: 2.1668\n",
            "[Batch 5] Current Loss: 1.4643\n",
            "[Batch 6] Current Loss: 1.9259\n",
            "[Batch 7] Current Loss: 2.0472\n",
            "[Batch 8] Current Loss: 2.0084\n",
            "[Batch 9] Current Loss: 1.3911\n",
            "[Batch 0] Current Loss: 4.9904\n",
            "[Batch 1] Current Loss: 5.0904\n",
            "[Batch 2] Current Loss: 5.7663\n",
            "[Batch 3] Current Loss: 5.5549\n",
            "[Batch 4] Current Loss: 6.3178\n",
            "[Batch 5] Current Loss: 5.2808\n",
            "[Batch 6] Current Loss: 5.6930\n",
            "[Batch 7] Current Loss: 4.4003\n",
            "[Batch 8] Current Loss: 6.0401\n",
            "[Batch 9] Current Loss: 6.0138\n",
            "Ep 5 (Step 041380): Train loss 1.950, Val loss 5.515\n",
            "[Batch 0] Current Loss: 2.4347\n",
            "[Batch 1] Current Loss: 1.8101\n",
            "[Batch 2] Current Loss: 2.0091\n",
            "[Batch 3] Current Loss: 1.6549\n",
            "[Batch 4] Current Loss: 2.0514\n",
            "[Batch 5] Current Loss: 1.9537\n",
            "[Batch 6] Current Loss: 1.6918\n",
            "[Batch 7] Current Loss: 1.4196\n",
            "[Batch 8] Current Loss: 2.6922\n",
            "[Batch 9] Current Loss: 2.1412\n",
            "[Batch 0] Current Loss: 5.7111\n",
            "[Batch 1] Current Loss: 6.2453\n",
            "[Batch 2] Current Loss: 5.3741\n",
            "[Batch 3] Current Loss: 5.7563\n",
            "[Batch 4] Current Loss: 5.9697\n",
            "[Batch 5] Current Loss: 5.3055\n",
            "[Batch 6] Current Loss: 5.1038\n",
            "[Batch 7] Current Loss: 5.7761\n",
            "[Batch 8] Current Loss: 6.4452\n",
            "[Batch 9] Current Loss: 4.8187\n",
            "Ep 5 (Step 041400): Train loss 1.986, Val loss 5.651\n",
            "[Batch 0] Current Loss: 2.1271\n",
            "[Batch 1] Current Loss: 2.3820\n",
            "[Batch 2] Current Loss: 2.4497\n",
            "[Batch 3] Current Loss: 1.9056\n",
            "[Batch 4] Current Loss: 2.5547\n",
            "[Batch 5] Current Loss: 2.2572\n",
            "[Batch 6] Current Loss: 1.7468\n",
            "[Batch 7] Current Loss: 2.2522\n",
            "[Batch 8] Current Loss: 2.0649\n",
            "[Batch 9] Current Loss: 1.9303\n",
            "[Batch 0] Current Loss: 6.2435\n",
            "[Batch 1] Current Loss: 5.8941\n",
            "[Batch 2] Current Loss: 5.7819\n",
            "[Batch 3] Current Loss: 5.5939\n",
            "[Batch 4] Current Loss: 5.3050\n",
            "[Batch 5] Current Loss: 6.2194\n",
            "[Batch 6] Current Loss: 6.5168\n",
            "[Batch 7] Current Loss: 5.2409\n",
            "[Batch 8] Current Loss: 5.1564\n",
            "[Batch 9] Current Loss: 6.6184\n",
            "Ep 5 (Step 041420): Train loss 2.167, Val loss 5.857\n",
            "[Batch 0] Current Loss: 2.2172\n",
            "[Batch 1] Current Loss: 2.0014\n",
            "[Batch 2] Current Loss: 1.4488\n",
            "[Batch 3] Current Loss: 2.6317\n",
            "[Batch 4] Current Loss: 2.4478\n",
            "[Batch 5] Current Loss: 2.3540\n",
            "[Batch 6] Current Loss: 1.6582\n",
            "[Batch 7] Current Loss: 2.1339\n",
            "[Batch 8] Current Loss: 2.0975\n",
            "[Batch 9] Current Loss: 1.5578\n",
            "[Batch 0] Current Loss: 4.9912\n",
            "[Batch 1] Current Loss: 5.6561\n",
            "[Batch 2] Current Loss: 6.3579\n",
            "[Batch 3] Current Loss: 5.5569\n",
            "[Batch 4] Current Loss: 4.8687\n",
            "[Batch 5] Current Loss: 6.8689\n",
            "[Batch 6] Current Loss: 5.9253\n",
            "[Batch 7] Current Loss: 5.8028\n",
            "[Batch 8] Current Loss: 5.2511\n",
            "[Batch 9] Current Loss: 5.6768\n",
            "Ep 5 (Step 041440): Train loss 2.055, Val loss 5.696\n",
            "[Batch 0] Current Loss: 2.7001\n",
            "[Batch 1] Current Loss: 1.9982\n",
            "[Batch 2] Current Loss: 2.0159\n",
            "[Batch 3] Current Loss: 2.2785\n",
            "[Batch 4] Current Loss: 2.4681\n",
            "[Batch 5] Current Loss: 2.3120\n",
            "[Batch 6] Current Loss: 1.6098\n",
            "[Batch 7] Current Loss: 2.0373\n",
            "[Batch 8] Current Loss: 1.9637\n",
            "[Batch 9] Current Loss: 1.8230\n",
            "[Batch 0] Current Loss: 5.4895\n",
            "[Batch 1] Current Loss: 6.0458\n",
            "[Batch 2] Current Loss: 6.2300\n",
            "[Batch 3] Current Loss: 5.4403\n",
            "[Batch 4] Current Loss: 6.7173\n",
            "[Batch 5] Current Loss: 6.0208\n",
            "[Batch 6] Current Loss: 6.1989\n",
            "[Batch 7] Current Loss: 5.4196\n",
            "[Batch 8] Current Loss: 5.8897\n",
            "[Batch 9] Current Loss: 5.6423\n",
            "Ep 5 (Step 041460): Train loss 2.121, Val loss 5.909\n",
            "[Batch 0] Current Loss: 2.2554\n",
            "[Batch 1] Current Loss: 1.7501\n",
            "[Batch 2] Current Loss: 2.5100\n",
            "[Batch 3] Current Loss: 2.1206\n",
            "[Batch 4] Current Loss: 1.9857\n",
            "[Batch 5] Current Loss: 1.9703\n",
            "[Batch 6] Current Loss: 1.7445\n",
            "[Batch 7] Current Loss: 2.3827\n",
            "[Batch 8] Current Loss: 2.2753\n",
            "[Batch 9] Current Loss: 1.8820\n",
            "[Batch 0] Current Loss: 5.8633\n",
            "[Batch 1] Current Loss: 4.9586\n",
            "[Batch 2] Current Loss: 4.5647\n",
            "[Batch 3] Current Loss: 6.2736\n",
            "[Batch 4] Current Loss: 5.4737\n",
            "[Batch 5] Current Loss: 4.8878\n",
            "[Batch 6] Current Loss: 5.6247\n",
            "[Batch 7] Current Loss: 4.8770\n",
            "[Batch 8] Current Loss: 5.5574\n",
            "[Batch 9] Current Loss: 5.5315\n",
            "Ep 5 (Step 041480): Train loss 2.088, Val loss 5.361\n",
            "[Batch 0] Current Loss: 2.5788\n",
            "[Batch 1] Current Loss: 1.9615\n",
            "[Batch 2] Current Loss: 1.4475\n",
            "[Batch 3] Current Loss: 2.2348\n",
            "[Batch 4] Current Loss: 1.9039\n",
            "[Batch 5] Current Loss: 2.5294\n",
            "[Batch 6] Current Loss: 2.1379\n",
            "[Batch 7] Current Loss: 1.9869\n",
            "[Batch 8] Current Loss: 1.5356\n",
            "[Batch 9] Current Loss: 1.8602\n",
            "[Batch 0] Current Loss: 5.5002\n",
            "[Batch 1] Current Loss: 5.5886\n",
            "[Batch 2] Current Loss: 5.2069\n",
            "[Batch 3] Current Loss: 5.3118\n",
            "[Batch 4] Current Loss: 5.1282\n",
            "[Batch 5] Current Loss: 5.8670\n",
            "[Batch 6] Current Loss: 6.1720\n",
            "[Batch 7] Current Loss: 6.2375\n",
            "[Batch 8] Current Loss: 5.5542\n",
            "[Batch 9] Current Loss: 5.1807\n",
            "Ep 5 (Step 041500): Train loss 2.018, Val loss 5.575\n",
            "[Batch 0] Current Loss: 2.1754\n",
            "[Batch 1] Current Loss: 2.0043\n",
            "[Batch 2] Current Loss: 1.9245\n",
            "[Batch 3] Current Loss: 1.7211\n",
            "[Batch 4] Current Loss: 1.4601\n",
            "[Batch 5] Current Loss: 2.0647\n",
            "[Batch 6] Current Loss: 2.1612\n",
            "[Batch 7] Current Loss: 1.6769\n",
            "[Batch 8] Current Loss: 1.9502\n",
            "[Batch 9] Current Loss: 1.8663\n",
            "[Batch 0] Current Loss: 5.8005\n",
            "[Batch 1] Current Loss: 4.9267\n",
            "[Batch 2] Current Loss: 5.8174\n",
            "[Batch 3] Current Loss: 5.6564\n",
            "[Batch 4] Current Loss: 5.0512\n",
            "[Batch 5] Current Loss: 6.2508\n",
            "[Batch 6] Current Loss: 5.8086\n",
            "[Batch 7] Current Loss: 5.7059\n",
            "[Batch 8] Current Loss: 5.0022\n",
            "[Batch 9] Current Loss: 5.8965\n",
            "Ep 5 (Step 041520): Train loss 1.900, Val loss 5.592\n",
            "[Batch 0] Current Loss: 1.9609\n",
            "[Batch 1] Current Loss: 1.9576\n",
            "[Batch 2] Current Loss: 2.1098\n",
            "[Batch 3] Current Loss: 2.1574\n",
            "[Batch 4] Current Loss: 1.5297\n",
            "[Batch 5] Current Loss: 1.6389\n",
            "[Batch 6] Current Loss: 2.1624\n",
            "[Batch 7] Current Loss: 1.9539\n",
            "[Batch 8] Current Loss: 2.2398\n",
            "[Batch 9] Current Loss: 1.7478\n",
            "[Batch 0] Current Loss: 5.6477\n",
            "[Batch 1] Current Loss: 5.7179\n",
            "[Batch 2] Current Loss: 5.5117\n",
            "[Batch 3] Current Loss: 5.9748\n",
            "[Batch 4] Current Loss: 4.9220\n",
            "[Batch 5] Current Loss: 6.3243\n",
            "[Batch 6] Current Loss: 5.9767\n",
            "[Batch 7] Current Loss: 6.1106\n",
            "[Batch 8] Current Loss: 5.2819\n",
            "[Batch 9] Current Loss: 5.6670\n",
            "Ep 5 (Step 041540): Train loss 1.946, Val loss 5.713\n",
            "[Batch 0] Current Loss: 1.5798\n",
            "[Batch 1] Current Loss: 1.0012\n",
            "[Batch 2] Current Loss: 2.6976\n",
            "[Batch 3] Current Loss: 1.8392\n",
            "[Batch 4] Current Loss: 1.7832\n",
            "[Batch 5] Current Loss: 1.4761\n",
            "[Batch 6] Current Loss: 2.4212\n",
            "[Batch 7] Current Loss: 1.8882\n",
            "[Batch 8] Current Loss: 2.5871\n",
            "[Batch 9] Current Loss: 1.5709\n",
            "[Batch 0] Current Loss: 4.8696\n",
            "[Batch 1] Current Loss: 5.9930\n",
            "[Batch 2] Current Loss: 4.7306\n",
            "[Batch 3] Current Loss: 5.8954\n",
            "[Batch 4] Current Loss: 5.3503\n",
            "[Batch 5] Current Loss: 6.0018\n",
            "[Batch 6] Current Loss: 5.4074\n",
            "[Batch 7] Current Loss: 6.2440\n",
            "[Batch 8] Current Loss: 6.1268\n",
            "[Batch 9] Current Loss: 5.8535\n",
            "Ep 5 (Step 041560): Train loss 1.884, Val loss 5.647\n",
            "[Batch 0] Current Loss: 2.4650\n",
            "[Batch 1] Current Loss: 1.8318\n",
            "[Batch 2] Current Loss: 2.2744\n",
            "[Batch 3] Current Loss: 1.7254\n",
            "[Batch 4] Current Loss: 2.0922\n",
            "[Batch 5] Current Loss: 2.6095\n",
            "[Batch 6] Current Loss: 2.4373\n",
            "[Batch 7] Current Loss: 1.8661\n",
            "[Batch 8] Current Loss: 1.7425\n",
            "[Batch 9] Current Loss: 1.9658\n",
            "[Batch 0] Current Loss: 6.4004\n",
            "[Batch 1] Current Loss: 6.1492\n",
            "[Batch 2] Current Loss: 5.6296\n",
            "[Batch 3] Current Loss: 4.7887\n",
            "[Batch 4] Current Loss: 5.4173\n",
            "[Batch 5] Current Loss: 5.7530\n",
            "[Batch 6] Current Loss: 6.0527\n",
            "[Batch 7] Current Loss: 5.9991\n",
            "[Batch 8] Current Loss: 6.0770\n",
            "[Batch 9] Current Loss: 5.7046\n",
            "Ep 5 (Step 041580): Train loss 2.101, Val loss 5.797\n",
            "[Batch 0] Current Loss: 2.1307\n",
            "[Batch 1] Current Loss: 2.2715\n",
            "[Batch 2] Current Loss: 2.4217\n",
            "[Batch 3] Current Loss: 1.9202\n",
            "[Batch 4] Current Loss: 2.2200\n",
            "[Batch 5] Current Loss: 2.0251\n",
            "[Batch 6] Current Loss: 1.7612\n",
            "[Batch 7] Current Loss: 2.4707\n",
            "[Batch 8] Current Loss: 2.0724\n",
            "[Batch 9] Current Loss: 1.9726\n",
            "[Batch 0] Current Loss: 5.4873\n",
            "[Batch 1] Current Loss: 4.8043\n",
            "[Batch 2] Current Loss: 5.6107\n",
            "[Batch 3] Current Loss: 5.6220\n",
            "[Batch 4] Current Loss: 5.1446\n",
            "[Batch 5] Current Loss: 5.4189\n",
            "[Batch 6] Current Loss: 5.2294\n",
            "[Batch 7] Current Loss: 6.5190\n",
            "[Batch 8] Current Loss: 5.6934\n",
            "[Batch 9] Current Loss: 5.9705\n",
            "Ep 5 (Step 041600): Train loss 2.127, Val loss 5.550\n",
            "[Batch 0] Current Loss: 1.8926\n",
            "[Batch 1] Current Loss: 1.8144\n",
            "[Batch 2] Current Loss: 1.8554\n",
            "[Batch 3] Current Loss: 2.4127\n",
            "[Batch 4] Current Loss: 1.8506\n",
            "[Batch 5] Current Loss: 1.9013\n",
            "[Batch 6] Current Loss: 2.0778\n",
            "[Batch 7] Current Loss: 2.0840\n",
            "[Batch 8] Current Loss: 1.7477\n",
            "[Batch 9] Current Loss: 1.5596\n",
            "[Batch 0] Current Loss: 5.1822\n",
            "[Batch 1] Current Loss: 5.4488\n",
            "[Batch 2] Current Loss: 6.4623\n",
            "[Batch 3] Current Loss: 5.4429\n",
            "[Batch 4] Current Loss: 5.2841\n",
            "[Batch 5] Current Loss: 5.4679\n",
            "[Batch 6] Current Loss: 5.6706\n",
            "[Batch 7] Current Loss: 5.7759\n",
            "[Batch 8] Current Loss: 5.2401\n",
            "[Batch 9] Current Loss: 4.9913\n",
            "Ep 5 (Step 041620): Train loss 1.920, Val loss 5.497\n",
            "[Batch 0] Current Loss: 2.2425\n",
            "[Batch 1] Current Loss: 2.1838\n",
            "[Batch 2] Current Loss: 1.6083\n",
            "[Batch 3] Current Loss: 2.6092\n",
            "[Batch 4] Current Loss: 2.1813\n",
            "[Batch 5] Current Loss: 1.9243\n",
            "[Batch 6] Current Loss: 1.6606\n",
            "[Batch 7] Current Loss: 2.0824\n",
            "[Batch 8] Current Loss: 2.1927\n",
            "[Batch 9] Current Loss: 2.2415\n",
            "[Batch 0] Current Loss: 5.0572\n",
            "[Batch 1] Current Loss: 5.2787\n",
            "[Batch 2] Current Loss: 6.4265\n",
            "[Batch 3] Current Loss: 6.3937\n",
            "[Batch 4] Current Loss: 4.6445\n",
            "[Batch 5] Current Loss: 5.6923\n",
            "[Batch 6] Current Loss: 5.6538\n",
            "[Batch 7] Current Loss: 6.3534\n",
            "[Batch 8] Current Loss: 5.9124\n",
            "[Batch 9] Current Loss: 4.6816\n",
            "Ep 5 (Step 041640): Train loss 2.093, Val loss 5.609\n",
            "[Batch 0] Current Loss: 1.6966\n",
            "[Batch 1] Current Loss: 2.1202\n",
            "[Batch 2] Current Loss: 1.8904\n",
            "[Batch 3] Current Loss: 1.9403\n",
            "[Batch 4] Current Loss: 1.7687\n",
            "[Batch 5] Current Loss: 2.4730\n",
            "[Batch 6] Current Loss: 1.8459\n",
            "[Batch 7] Current Loss: 1.5484\n",
            "[Batch 8] Current Loss: 2.1563\n",
            "[Batch 9] Current Loss: 1.8024\n",
            "[Batch 0] Current Loss: 5.7525\n",
            "[Batch 1] Current Loss: 5.6234\n",
            "[Batch 2] Current Loss: 5.8268\n",
            "[Batch 3] Current Loss: 5.9348\n",
            "[Batch 4] Current Loss: 5.6770\n",
            "[Batch 5] Current Loss: 5.2404\n",
            "[Batch 6] Current Loss: 4.8631\n",
            "[Batch 7] Current Loss: 6.6813\n",
            "[Batch 8] Current Loss: 5.7400\n",
            "[Batch 9] Current Loss: 4.8990\n",
            "Ep 5 (Step 041660): Train loss 1.924, Val loss 5.624\n",
            "[Batch 0] Current Loss: 1.7640\n",
            "[Batch 1] Current Loss: 2.3561\n",
            "[Batch 2] Current Loss: 2.0805\n",
            "[Batch 3] Current Loss: 1.9380\n",
            "[Batch 4] Current Loss: 2.2054\n",
            "[Batch 5] Current Loss: 1.7374\n",
            "[Batch 6] Current Loss: 2.2121\n",
            "[Batch 7] Current Loss: 1.8800\n",
            "[Batch 8] Current Loss: 2.0292\n",
            "[Batch 9] Current Loss: 1.7454\n",
            "[Batch 0] Current Loss: 5.8789\n",
            "[Batch 1] Current Loss: 6.2506\n",
            "[Batch 2] Current Loss: 5.7907\n",
            "[Batch 3] Current Loss: 5.1523\n",
            "[Batch 4] Current Loss: 6.0742\n",
            "[Batch 5] Current Loss: 5.6335\n",
            "[Batch 6] Current Loss: 5.6224\n",
            "[Batch 7] Current Loss: 5.8202\n",
            "[Batch 8] Current Loss: 5.4461\n",
            "[Batch 9] Current Loss: 6.2062\n",
            "Ep 5 (Step 041680): Train loss 1.995, Val loss 5.788\n",
            "[Batch 0] Current Loss: 2.1388\n",
            "[Batch 1] Current Loss: 1.8209\n",
            "[Batch 2] Current Loss: 2.1571\n",
            "[Batch 3] Current Loss: 1.7002\n",
            "[Batch 4] Current Loss: 2.5421\n",
            "[Batch 5] Current Loss: 2.2317\n",
            "[Batch 6] Current Loss: 2.1424\n",
            "[Batch 7] Current Loss: 1.6411\n",
            "[Batch 8] Current Loss: 1.7397\n",
            "[Batch 9] Current Loss: 2.3395\n",
            "[Batch 0] Current Loss: 6.5972\n",
            "[Batch 1] Current Loss: 5.6431\n",
            "[Batch 2] Current Loss: 5.4112\n",
            "[Batch 3] Current Loss: 5.4678\n",
            "[Batch 4] Current Loss: 6.9657\n",
            "[Batch 5] Current Loss: 4.8510\n",
            "[Batch 6] Current Loss: 5.6086\n",
            "[Batch 7] Current Loss: 5.8358\n",
            "[Batch 8] Current Loss: 6.0692\n",
            "[Batch 9] Current Loss: 5.0741\n",
            "Ep 5 (Step 041700): Train loss 2.045, Val loss 5.752\n",
            "[Batch 0] Current Loss: 1.9051\n",
            "[Batch 1] Current Loss: 1.8384\n",
            "[Batch 2] Current Loss: 1.4297\n",
            "[Batch 3] Current Loss: 2.4580\n",
            "[Batch 4] Current Loss: 1.8748\n",
            "[Batch 5] Current Loss: 2.3416\n",
            "[Batch 6] Current Loss: 2.5983\n",
            "[Batch 7] Current Loss: 2.5084\n",
            "[Batch 8] Current Loss: 1.9189\n",
            "[Batch 9] Current Loss: 1.7260\n",
            "[Batch 0] Current Loss: 5.4943\n",
            "[Batch 1] Current Loss: 4.5165\n",
            "[Batch 2] Current Loss: 5.2924\n",
            "[Batch 3] Current Loss: 5.7318\n",
            "[Batch 4] Current Loss: 5.9133\n",
            "[Batch 5] Current Loss: 6.3338\n",
            "[Batch 6] Current Loss: 5.7087\n",
            "[Batch 7] Current Loss: 5.9555\n",
            "[Batch 8] Current Loss: 5.5489\n",
            "[Batch 9] Current Loss: 5.4524\n",
            "Ep 5 (Step 041720): Train loss 2.060, Val loss 5.595\n",
            "[Batch 0] Current Loss: 1.7297\n",
            "[Batch 1] Current Loss: 1.6025\n",
            "[Batch 2] Current Loss: 1.7815\n",
            "[Batch 3] Current Loss: 1.9910\n",
            "[Batch 4] Current Loss: 2.3669\n",
            "[Batch 5] Current Loss: 1.8799\n",
            "[Batch 6] Current Loss: 2.3584\n",
            "[Batch 7] Current Loss: 1.8747\n",
            "[Batch 8] Current Loss: 1.8098\n",
            "[Batch 9] Current Loss: 2.6714\n",
            "[Batch 0] Current Loss: 5.7736\n",
            "[Batch 1] Current Loss: 6.0932\n",
            "[Batch 2] Current Loss: 5.7491\n",
            "[Batch 3] Current Loss: 6.0196\n",
            "[Batch 4] Current Loss: 5.9142\n",
            "[Batch 5] Current Loss: 5.2229\n",
            "[Batch 6] Current Loss: 6.0378\n",
            "[Batch 7] Current Loss: 5.7346\n",
            "[Batch 8] Current Loss: 5.7094\n",
            "[Batch 9] Current Loss: 5.7578\n",
            "Ep 5 (Step 041740): Train loss 2.007, Val loss 5.801\n",
            "[Batch 0] Current Loss: 1.8176\n",
            "[Batch 1] Current Loss: 2.0872\n",
            "[Batch 2] Current Loss: 1.9375\n",
            "[Batch 3] Current Loss: 1.8631\n",
            "[Batch 4] Current Loss: 2.1686\n",
            "[Batch 5] Current Loss: 2.5108\n",
            "[Batch 6] Current Loss: 2.2628\n",
            "[Batch 7] Current Loss: 1.5556\n",
            "[Batch 8] Current Loss: 2.3665\n",
            "[Batch 9] Current Loss: 1.9784\n",
            "[Batch 0] Current Loss: 5.1266\n",
            "[Batch 1] Current Loss: 5.4679\n",
            "[Batch 2] Current Loss: 5.7839\n",
            "[Batch 3] Current Loss: 6.2514\n",
            "[Batch 4] Current Loss: 5.8820\n",
            "[Batch 5] Current Loss: 5.9348\n",
            "[Batch 6] Current Loss: 5.6113\n",
            "[Batch 7] Current Loss: 5.2768\n",
            "[Batch 8] Current Loss: 6.1112\n",
            "[Batch 9] Current Loss: 5.7750\n",
            "Ep 5 (Step 041760): Train loss 2.055, Val loss 5.722\n",
            "[Batch 0] Current Loss: 2.6379\n",
            "[Batch 1] Current Loss: 2.0128\n",
            "[Batch 2] Current Loss: 2.2069\n",
            "[Batch 3] Current Loss: 2.4601\n",
            "[Batch 4] Current Loss: 2.3609\n",
            "[Batch 5] Current Loss: 2.1067\n",
            "[Batch 6] Current Loss: 1.7428\n",
            "[Batch 7] Current Loss: 1.6135\n",
            "[Batch 8] Current Loss: 2.0174\n",
            "[Batch 9] Current Loss: 2.9763\n",
            "[Batch 0] Current Loss: 4.6222\n",
            "[Batch 1] Current Loss: 5.5754\n",
            "[Batch 2] Current Loss: 6.6008\n",
            "[Batch 3] Current Loss: 5.9307\n",
            "[Batch 4] Current Loss: 5.4871\n",
            "[Batch 5] Current Loss: 5.7738\n",
            "[Batch 6] Current Loss: 4.8737\n",
            "[Batch 7] Current Loss: 5.3065\n",
            "[Batch 8] Current Loss: 4.5720\n",
            "[Batch 9] Current Loss: 6.2856\n",
            "Ep 5 (Step 041780): Train loss 2.214, Val loss 5.503\n",
            "[Batch 0] Current Loss: 1.6710\n",
            "[Batch 1] Current Loss: 2.0800\n",
            "[Batch 2] Current Loss: 1.6154\n",
            "[Batch 3] Current Loss: 2.1465\n",
            "[Batch 4] Current Loss: 1.8152\n",
            "[Batch 5] Current Loss: 2.0261\n",
            "[Batch 6] Current Loss: 1.6208\n",
            "[Batch 7] Current Loss: 2.2516\n",
            "[Batch 8] Current Loss: 2.0429\n",
            "[Batch 9] Current Loss: 2.3157\n",
            "[Batch 0] Current Loss: 6.4233\n",
            "[Batch 1] Current Loss: 4.5511\n",
            "[Batch 2] Current Loss: 5.4700\n",
            "[Batch 3] Current Loss: 6.0364\n",
            "[Batch 4] Current Loss: 5.7302\n",
            "[Batch 5] Current Loss: 5.8490\n",
            "[Batch 6] Current Loss: 4.8721\n",
            "[Batch 7] Current Loss: 6.4478\n",
            "[Batch 8] Current Loss: 5.4904\n",
            "[Batch 9] Current Loss: 4.7610\n",
            "Ep 5 (Step 041800): Train loss 1.959, Val loss 5.563\n",
            "[Batch 0] Current Loss: 2.1711\n",
            "[Batch 1] Current Loss: 2.6297\n",
            "[Batch 2] Current Loss: 1.5287\n",
            "[Batch 3] Current Loss: 2.2204\n",
            "[Batch 4] Current Loss: 1.7184\n",
            "[Batch 5] Current Loss: 1.4142\n",
            "[Batch 6] Current Loss: 1.8990\n",
            "[Batch 7] Current Loss: 2.3000\n",
            "[Batch 8] Current Loss: 2.9554\n",
            "[Batch 9] Current Loss: 2.6650\n",
            "[Batch 0] Current Loss: 4.9379\n",
            "[Batch 1] Current Loss: 5.6097\n",
            "[Batch 2] Current Loss: 5.2840\n",
            "[Batch 3] Current Loss: 5.6828\n",
            "[Batch 4] Current Loss: 6.1031\n",
            "[Batch 5] Current Loss: 5.2961\n",
            "[Batch 6] Current Loss: 5.7930\n",
            "[Batch 7] Current Loss: 6.5163\n",
            "[Batch 8] Current Loss: 4.9807\n",
            "[Batch 9] Current Loss: 5.1824\n",
            "Ep 5 (Step 041820): Train loss 2.150, Val loss 5.539\n",
            "[Batch 0] Current Loss: 1.7934\n",
            "[Batch 1] Current Loss: 2.5162\n",
            "[Batch 2] Current Loss: 2.0285\n",
            "[Batch 3] Current Loss: 2.4921\n",
            "[Batch 4] Current Loss: 2.1619\n",
            "[Batch 5] Current Loss: 1.7144\n",
            "[Batch 6] Current Loss: 1.8470\n",
            "[Batch 7] Current Loss: 1.7565\n",
            "[Batch 8] Current Loss: 2.5530\n",
            "[Batch 9] Current Loss: 2.2557\n",
            "[Batch 0] Current Loss: 5.4802\n",
            "[Batch 1] Current Loss: 6.3099\n",
            "[Batch 2] Current Loss: 4.4224\n",
            "[Batch 3] Current Loss: 5.9591\n",
            "[Batch 4] Current Loss: 5.3069\n",
            "[Batch 5] Current Loss: 5.0968\n",
            "[Batch 6] Current Loss: 5.2058\n",
            "[Batch 7] Current Loss: 5.9934\n",
            "[Batch 8] Current Loss: 6.8399\n",
            "[Batch 9] Current Loss: 5.7569\n",
            "Ep 5 (Step 041840): Train loss 2.112, Val loss 5.637\n",
            "[Batch 0] Current Loss: 2.0421\n",
            "[Batch 1] Current Loss: 1.8223\n",
            "[Batch 2] Current Loss: 1.7703\n",
            "[Batch 3] Current Loss: 2.1855\n",
            "[Batch 4] Current Loss: 2.1650\n",
            "[Batch 5] Current Loss: 2.5836\n",
            "[Batch 6] Current Loss: 1.7962\n",
            "[Batch 7] Current Loss: 2.2080\n",
            "[Batch 8] Current Loss: 2.0307\n",
            "[Batch 9] Current Loss: 2.3326\n",
            "[Batch 0] Current Loss: 6.0770\n",
            "[Batch 1] Current Loss: 5.9466\n",
            "[Batch 2] Current Loss: 5.3808\n",
            "[Batch 3] Current Loss: 5.3526\n",
            "[Batch 4] Current Loss: 4.5985\n",
            "[Batch 5] Current Loss: 5.8108\n",
            "[Batch 6] Current Loss: 5.0146\n",
            "[Batch 7] Current Loss: 5.5373\n",
            "[Batch 8] Current Loss: 4.8728\n",
            "[Batch 9] Current Loss: 5.5737\n",
            "Ep 5 (Step 041860): Train loss 2.094, Val loss 5.416\n",
            "[Batch 0] Current Loss: 1.2871\n",
            "[Batch 1] Current Loss: 1.7183\n",
            "[Batch 2] Current Loss: 1.9259\n",
            "[Batch 3] Current Loss: 1.6697\n",
            "[Batch 4] Current Loss: 2.2338\n",
            "[Batch 5] Current Loss: 2.0856\n",
            "[Batch 6] Current Loss: 2.0469\n",
            "[Batch 7] Current Loss: 1.9621\n",
            "[Batch 8] Current Loss: 1.9450\n",
            "[Batch 9] Current Loss: 1.7693\n",
            "[Batch 0] Current Loss: 5.9507\n",
            "[Batch 1] Current Loss: 5.6578\n",
            "[Batch 2] Current Loss: 4.7606\n",
            "[Batch 3] Current Loss: 5.5426\n",
            "[Batch 4] Current Loss: 5.6083\n",
            "[Batch 5] Current Loss: 5.0483\n",
            "[Batch 6] Current Loss: 4.0772\n",
            "[Batch 7] Current Loss: 5.2280\n",
            "[Batch 8] Current Loss: 5.7223\n",
            "[Batch 9] Current Loss: 5.3189\n",
            "Ep 5 (Step 041880): Train loss 1.864, Val loss 5.291\n",
            "[Batch 0] Current Loss: 2.1039\n",
            "[Batch 1] Current Loss: 1.6910\n",
            "[Batch 2] Current Loss: 2.1956\n",
            "[Batch 3] Current Loss: 1.5095\n",
            "[Batch 4] Current Loss: 1.9327\n",
            "[Batch 5] Current Loss: 1.6855\n",
            "[Batch 6] Current Loss: 2.2390\n",
            "[Batch 7] Current Loss: 1.8393\n",
            "[Batch 8] Current Loss: 1.8045\n",
            "[Batch 9] Current Loss: 2.6190\n",
            "[Batch 0] Current Loss: 6.5863\n",
            "[Batch 1] Current Loss: 4.9511\n",
            "[Batch 2] Current Loss: 5.7985\n",
            "[Batch 3] Current Loss: 5.7407\n",
            "[Batch 4] Current Loss: 6.0144\n",
            "[Batch 5] Current Loss: 5.9557\n",
            "[Batch 6] Current Loss: 5.6872\n",
            "[Batch 7] Current Loss: 5.8166\n",
            "[Batch 8] Current Loss: 5.8866\n",
            "[Batch 9] Current Loss: 5.3361\n",
            "Ep 5 (Step 041900): Train loss 1.962, Val loss 5.777\n",
            "[Batch 0] Current Loss: 2.1832\n",
            "[Batch 1] Current Loss: 2.2890\n",
            "[Batch 2] Current Loss: 2.2835\n",
            "[Batch 3] Current Loss: 1.8647\n",
            "[Batch 4] Current Loss: 1.6964\n",
            "[Batch 5] Current Loss: 1.7361\n",
            "[Batch 6] Current Loss: 2.0413\n",
            "[Batch 7] Current Loss: 1.5188\n",
            "[Batch 8] Current Loss: 2.4839\n",
            "[Batch 9] Current Loss: 2.2055\n",
            "[Batch 0] Current Loss: 5.3910\n",
            "[Batch 1] Current Loss: 6.1298\n",
            "[Batch 2] Current Loss: 5.0690\n",
            "[Batch 3] Current Loss: 5.8944\n",
            "[Batch 4] Current Loss: 5.5246\n",
            "[Batch 5] Current Loss: 5.0275\n",
            "[Batch 6] Current Loss: 5.3082\n",
            "[Batch 7] Current Loss: 6.8367\n",
            "[Batch 8] Current Loss: 5.2596\n",
            "[Batch 9] Current Loss: 5.8019\n",
            "Ep 5 (Step 041920): Train loss 2.030, Val loss 5.624\n",
            "[Batch 0] Current Loss: 1.6045\n",
            "[Batch 1] Current Loss: 1.6196\n",
            "[Batch 2] Current Loss: 2.1930\n",
            "[Batch 3] Current Loss: 2.1660\n",
            "[Batch 4] Current Loss: 1.4821\n",
            "[Batch 5] Current Loss: 2.5604\n",
            "[Batch 6] Current Loss: 1.6310\n",
            "[Batch 7] Current Loss: 1.8258\n",
            "[Batch 8] Current Loss: 2.0155\n",
            "[Batch 9] Current Loss: 2.0953\n",
            "[Batch 0] Current Loss: 4.9615\n",
            "[Batch 1] Current Loss: 5.7217\n",
            "[Batch 2] Current Loss: 4.9272\n",
            "[Batch 3] Current Loss: 5.5368\n",
            "[Batch 4] Current Loss: 5.4248\n",
            "[Batch 5] Current Loss: 5.4952\n",
            "[Batch 6] Current Loss: 5.9997\n",
            "[Batch 7] Current Loss: 5.3784\n",
            "[Batch 8] Current Loss: 5.3662\n",
            "[Batch 9] Current Loss: 5.9048\n",
            "Ep 5 (Step 041940): Train loss 1.919, Val loss 5.472\n",
            "[Batch 0] Current Loss: 2.3280\n",
            "[Batch 1] Current Loss: 2.0425\n",
            "[Batch 2] Current Loss: 2.3892\n",
            "[Batch 3] Current Loss: 1.4998\n",
            "[Batch 4] Current Loss: 1.3445\n",
            "[Batch 5] Current Loss: 2.2971\n",
            "[Batch 6] Current Loss: 2.4921\n",
            "[Batch 7] Current Loss: 1.9832\n",
            "[Batch 8] Current Loss: 2.2697\n",
            "[Batch 9] Current Loss: 2.3594\n",
            "[Batch 0] Current Loss: 5.3224\n",
            "[Batch 1] Current Loss: 5.5404\n",
            "[Batch 2] Current Loss: 6.1724\n",
            "[Batch 3] Current Loss: 4.3916\n",
            "[Batch 4] Current Loss: 5.6325\n",
            "[Batch 5] Current Loss: 5.9669\n",
            "[Batch 6] Current Loss: 6.8088\n",
            "[Batch 7] Current Loss: 5.9759\n",
            "[Batch 8] Current Loss: 6.3225\n",
            "[Batch 9] Current Loss: 5.3497\n",
            "Ep 5 (Step 041960): Train loss 2.101, Val loss 5.748\n",
            "[Batch 0] Current Loss: 1.9671\n",
            "[Batch 1] Current Loss: 2.2513\n",
            "[Batch 2] Current Loss: 1.8436\n",
            "[Batch 3] Current Loss: 1.7368\n",
            "[Batch 4] Current Loss: 1.6748\n",
            "[Batch 5] Current Loss: 1.9942\n",
            "[Batch 6] Current Loss: 2.0852\n",
            "[Batch 7] Current Loss: 2.2388\n",
            "[Batch 8] Current Loss: 2.2641\n",
            "[Batch 9] Current Loss: 2.2994\n",
            "[Batch 0] Current Loss: 5.4244\n",
            "[Batch 1] Current Loss: 5.0875\n",
            "[Batch 2] Current Loss: 5.7427\n",
            "[Batch 3] Current Loss: 5.1028\n",
            "[Batch 4] Current Loss: 6.1841\n",
            "[Batch 5] Current Loss: 5.1895\n",
            "[Batch 6] Current Loss: 6.4746\n",
            "[Batch 7] Current Loss: 5.4451\n",
            "[Batch 8] Current Loss: 6.0495\n",
            "[Batch 9] Current Loss: 4.9097\n",
            "Ep 5 (Step 041980): Train loss 2.036, Val loss 5.561\n",
            "[Batch 0] Current Loss: 2.2573\n",
            "[Batch 1] Current Loss: 2.0597\n",
            "[Batch 2] Current Loss: 2.1448\n",
            "[Batch 3] Current Loss: 2.7210\n",
            "[Batch 4] Current Loss: 2.4283\n",
            "[Batch 5] Current Loss: 1.8094\n",
            "[Batch 6] Current Loss: 2.1545\n",
            "[Batch 7] Current Loss: 1.6609\n",
            "[Batch 8] Current Loss: 2.0090\n",
            "[Batch 9] Current Loss: 1.8032\n",
            "[Batch 0] Current Loss: 5.7600\n",
            "[Batch 1] Current Loss: 5.2470\n",
            "[Batch 2] Current Loss: 5.4338\n",
            "[Batch 3] Current Loss: 5.6589\n",
            "[Batch 4] Current Loss: 5.3396\n",
            "[Batch 5] Current Loss: 5.7060\n",
            "[Batch 6] Current Loss: 5.6785\n",
            "[Batch 7] Current Loss: 5.4560\n",
            "[Batch 8] Current Loss: 5.6157\n",
            "[Batch 9] Current Loss: 5.8044\n",
            "Ep 5 (Step 042000): Train loss 2.105, Val loss 5.570\n",
            "[Batch 0] Current Loss: 2.0492\n",
            "[Batch 1] Current Loss: 2.3079\n",
            "[Batch 2] Current Loss: 1.6662\n",
            "[Batch 3] Current Loss: 1.9368\n",
            "[Batch 4] Current Loss: 2.3387\n",
            "[Batch 5] Current Loss: 2.4466\n",
            "[Batch 6] Current Loss: 2.0884\n",
            "[Batch 7] Current Loss: 1.9494\n",
            "[Batch 8] Current Loss: 2.3791\n",
            "[Batch 9] Current Loss: 1.9841\n",
            "[Batch 0] Current Loss: 5.6478\n",
            "[Batch 1] Current Loss: 5.4068\n",
            "[Batch 2] Current Loss: 4.7012\n",
            "[Batch 3] Current Loss: 6.0748\n",
            "[Batch 4] Current Loss: 5.4595\n",
            "[Batch 5] Current Loss: 5.6829\n",
            "[Batch 6] Current Loss: 5.6080\n",
            "[Batch 7] Current Loss: 5.3836\n",
            "[Batch 8] Current Loss: 5.7687\n",
            "[Batch 9] Current Loss: 5.1875\n",
            "Ep 5 (Step 042020): Train loss 2.115, Val loss 5.492\n",
            "[Batch 0] Current Loss: 1.6819\n",
            "[Batch 1] Current Loss: 1.7282\n",
            "[Batch 2] Current Loss: 1.4959\n",
            "[Batch 3] Current Loss: 2.5297\n",
            "[Batch 4] Current Loss: 2.0554\n",
            "[Batch 5] Current Loss: 2.0782\n",
            "[Batch 6] Current Loss: 2.0250\n",
            "[Batch 7] Current Loss: 2.7282\n",
            "[Batch 8] Current Loss: 1.9423\n",
            "[Batch 9] Current Loss: 1.8095\n",
            "[Batch 0] Current Loss: 4.2498\n",
            "[Batch 1] Current Loss: 6.1128\n",
            "[Batch 2] Current Loss: 5.8478\n",
            "[Batch 3] Current Loss: 4.7481\n",
            "[Batch 4] Current Loss: 5.9596\n",
            "[Batch 5] Current Loss: 4.8788\n",
            "[Batch 6] Current Loss: 5.6592\n",
            "[Batch 7] Current Loss: 6.0787\n",
            "[Batch 8] Current Loss: 4.9191\n",
            "[Batch 9] Current Loss: 4.9525\n",
            "Ep 5 (Step 042040): Train loss 2.007, Val loss 5.341\n",
            "[Batch 0] Current Loss: 1.7186\n",
            "[Batch 1] Current Loss: 2.0601\n",
            "[Batch 2] Current Loss: 2.4376\n",
            "[Batch 3] Current Loss: 2.0297\n",
            "[Batch 4] Current Loss: 2.2747\n",
            "[Batch 5] Current Loss: 1.7181\n",
            "[Batch 6] Current Loss: 1.8628\n",
            "[Batch 7] Current Loss: 2.2482\n",
            "[Batch 8] Current Loss: 1.9619\n",
            "[Batch 9] Current Loss: 1.6976\n",
            "[Batch 0] Current Loss: 5.7628\n",
            "[Batch 1] Current Loss: 5.1315\n",
            "[Batch 2] Current Loss: 4.7353\n",
            "[Batch 3] Current Loss: 5.9629\n",
            "[Batch 4] Current Loss: 5.4628\n",
            "[Batch 5] Current Loss: 6.1166\n",
            "[Batch 6] Current Loss: 6.0456\n",
            "[Batch 7] Current Loss: 6.0441\n",
            "[Batch 8] Current Loss: 5.3357\n",
            "[Batch 9] Current Loss: 6.1331\n",
            "Ep 5 (Step 042060): Train loss 2.001, Val loss 5.673\n",
            "[Batch 0] Current Loss: 1.9943\n",
            "[Batch 1] Current Loss: 2.6276\n",
            "[Batch 2] Current Loss: 2.4732\n",
            "[Batch 3] Current Loss: 1.9419\n",
            "[Batch 4] Current Loss: 2.3490\n",
            "[Batch 5] Current Loss: 2.6426\n",
            "[Batch 6] Current Loss: 2.4259\n",
            "[Batch 7] Current Loss: 2.0886\n",
            "[Batch 8] Current Loss: 2.4735\n",
            "[Batch 9] Current Loss: 1.9299\n",
            "[Batch 0] Current Loss: 6.0298\n",
            "[Batch 1] Current Loss: 5.3197\n",
            "[Batch 2] Current Loss: 6.0715\n",
            "[Batch 3] Current Loss: 4.6417\n",
            "[Batch 4] Current Loss: 6.0527\n",
            "[Batch 5] Current Loss: 6.1674\n",
            "[Batch 6] Current Loss: 3.9231\n",
            "[Batch 7] Current Loss: 5.9801\n",
            "[Batch 8] Current Loss: 5.6854\n",
            "[Batch 9] Current Loss: 5.6366\n",
            "Ep 5 (Step 042080): Train loss 2.295, Val loss 5.551\n",
            "[Batch 0] Current Loss: 2.2695\n",
            "[Batch 1] Current Loss: 2.6569\n",
            "[Batch 2] Current Loss: 1.7296\n",
            "[Batch 3] Current Loss: 2.1620\n",
            "[Batch 4] Current Loss: 1.8710\n",
            "[Batch 5] Current Loss: 1.5178\n",
            "[Batch 6] Current Loss: 1.7766\n",
            "[Batch 7] Current Loss: 2.3978\n",
            "[Batch 8] Current Loss: 2.0410\n",
            "[Batch 9] Current Loss: 1.9802\n",
            "[Batch 0] Current Loss: 6.1578\n",
            "[Batch 1] Current Loss: 5.8641\n",
            "[Batch 2] Current Loss: 5.6612\n",
            "[Batch 3] Current Loss: 5.5140\n",
            "[Batch 4] Current Loss: 5.4191\n",
            "[Batch 5] Current Loss: 6.1320\n",
            "[Batch 6] Current Loss: 5.0936\n",
            "[Batch 7] Current Loss: 4.2144\n",
            "[Batch 8] Current Loss: 5.0567\n",
            "[Batch 9] Current Loss: 5.7166\n",
            "Ep 5 (Step 042100): Train loss 2.040, Val loss 5.483\n",
            "[Batch 0] Current Loss: 1.5128\n",
            "[Batch 1] Current Loss: 2.2240\n",
            "[Batch 2] Current Loss: 2.3035\n",
            "[Batch 3] Current Loss: 2.2617\n",
            "[Batch 4] Current Loss: 1.8660\n",
            "[Batch 5] Current Loss: 2.2190\n",
            "[Batch 6] Current Loss: 1.9664\n",
            "[Batch 7] Current Loss: 1.9775\n",
            "[Batch 8] Current Loss: 1.9239\n",
            "[Batch 9] Current Loss: 2.3656\n",
            "[Batch 0] Current Loss: 4.8249\n",
            "[Batch 1] Current Loss: 5.7320\n",
            "[Batch 2] Current Loss: 6.4384\n",
            "[Batch 3] Current Loss: 6.4876\n",
            "[Batch 4] Current Loss: 5.3681\n",
            "[Batch 5] Current Loss: 5.5806\n",
            "[Batch 6] Current Loss: 5.7550\n",
            "[Batch 7] Current Loss: 6.4655\n",
            "[Batch 8] Current Loss: 5.8688\n",
            "[Batch 9] Current Loss: 5.0208\n",
            "Ep 5 (Step 042120): Train loss 2.062, Val loss 5.754\n",
            "[Batch 0] Current Loss: 1.9405\n",
            "[Batch 1] Current Loss: 1.8182\n",
            "[Batch 2] Current Loss: 2.0021\n",
            "[Batch 3] Current Loss: 2.1412\n",
            "[Batch 4] Current Loss: 2.0283\n",
            "[Batch 5] Current Loss: 2.3896\n",
            "[Batch 6] Current Loss: 2.1370\n",
            "[Batch 7] Current Loss: 2.2393\n",
            "[Batch 8] Current Loss: 1.9190\n",
            "[Batch 9] Current Loss: 2.0443\n",
            "[Batch 0] Current Loss: 5.4453\n",
            "[Batch 1] Current Loss: 5.7588\n",
            "[Batch 2] Current Loss: 5.6425\n",
            "[Batch 3] Current Loss: 5.7077\n",
            "[Batch 4] Current Loss: 5.0758\n",
            "[Batch 5] Current Loss: 5.9081\n",
            "[Batch 6] Current Loss: 5.5060\n",
            "[Batch 7] Current Loss: 5.5267\n",
            "[Batch 8] Current Loss: 6.2659\n",
            "[Batch 9] Current Loss: 5.2717\n",
            "Ep 5 (Step 042140): Train loss 2.066, Val loss 5.611\n",
            "[Batch 0] Current Loss: 2.3120\n",
            "[Batch 1] Current Loss: 2.1951\n",
            "[Batch 2] Current Loss: 1.6786\n",
            "[Batch 3] Current Loss: 1.8066\n",
            "[Batch 4] Current Loss: 1.3949\n",
            "[Batch 5] Current Loss: 1.9696\n",
            "[Batch 6] Current Loss: 2.2525\n",
            "[Batch 7] Current Loss: 1.9005\n",
            "[Batch 8] Current Loss: 2.3311\n",
            "[Batch 9] Current Loss: 2.0651\n",
            "[Batch 0] Current Loss: 5.8431\n",
            "[Batch 1] Current Loss: 5.5246\n",
            "[Batch 2] Current Loss: 5.4758\n",
            "[Batch 3] Current Loss: 5.8941\n",
            "[Batch 4] Current Loss: 4.3599\n",
            "[Batch 5] Current Loss: 5.3515\n",
            "[Batch 6] Current Loss: 5.3036\n",
            "[Batch 7] Current Loss: 6.3127\n",
            "[Batch 8] Current Loss: 5.7566\n",
            "[Batch 9] Current Loss: 5.9824\n",
            "Ep 5 (Step 042160): Train loss 1.991, Val loss 5.580\n",
            "[Batch 0] Current Loss: 2.0706\n",
            "[Batch 1] Current Loss: 2.1665\n",
            "[Batch 2] Current Loss: 1.3483\n",
            "[Batch 3] Current Loss: 1.7026\n",
            "[Batch 4] Current Loss: 3.1640\n",
            "[Batch 5] Current Loss: 2.2247\n",
            "[Batch 6] Current Loss: 1.9216\n",
            "[Batch 7] Current Loss: 2.3184\n",
            "[Batch 8] Current Loss: 2.0169\n",
            "[Batch 9] Current Loss: 1.8824\n",
            "[Batch 0] Current Loss: 5.9267\n",
            "[Batch 1] Current Loss: 4.9931\n",
            "[Batch 2] Current Loss: 5.4039\n",
            "[Batch 3] Current Loss: 5.1512\n",
            "[Batch 4] Current Loss: 5.6693\n",
            "[Batch 5] Current Loss: 5.0683\n",
            "[Batch 6] Current Loss: 5.5684\n",
            "[Batch 7] Current Loss: 5.0356\n",
            "[Batch 8] Current Loss: 6.2082\n",
            "[Batch 9] Current Loss: 4.8293\n",
            "Ep 5 (Step 042180): Train loss 2.082, Val loss 5.385\n",
            "[Batch 0] Current Loss: 2.3448\n",
            "[Batch 1] Current Loss: 1.9956\n",
            "[Batch 2] Current Loss: 2.2892\n",
            "[Batch 3] Current Loss: 1.7000\n",
            "[Batch 4] Current Loss: 1.6330\n",
            "[Batch 5] Current Loss: 1.3194\n",
            "[Batch 6] Current Loss: 1.7140\n",
            "[Batch 7] Current Loss: 1.5235\n",
            "[Batch 8] Current Loss: 1.9537\n",
            "[Batch 9] Current Loss: 2.0935\n",
            "[Batch 0] Current Loss: 4.5508\n",
            "[Batch 1] Current Loss: 5.1658\n",
            "[Batch 2] Current Loss: 6.4832\n",
            "[Batch 3] Current Loss: 5.8095\n",
            "[Batch 4] Current Loss: 6.0084\n",
            "[Batch 5] Current Loss: 5.8125\n",
            "[Batch 6] Current Loss: 6.3941\n",
            "[Batch 7] Current Loss: 5.3965\n",
            "[Batch 8] Current Loss: 6.1448\n",
            "[Batch 9] Current Loss: 5.6455\n",
            "Ep 5 (Step 042200): Train loss 1.857, Val loss 5.741\n",
            "[Batch 0] Current Loss: 1.9388\n",
            "[Batch 1] Current Loss: 2.4404\n",
            "[Batch 2] Current Loss: 1.7270\n",
            "[Batch 3] Current Loss: 2.0761\n",
            "[Batch 4] Current Loss: 2.0169\n",
            "[Batch 5] Current Loss: 1.5347\n",
            "[Batch 6] Current Loss: 1.7784\n",
            "[Batch 7] Current Loss: 2.1678\n",
            "[Batch 8] Current Loss: 1.9085\n",
            "[Batch 9] Current Loss: 1.5416\n",
            "[Batch 0] Current Loss: 6.6274\n",
            "[Batch 1] Current Loss: 5.8632\n",
            "[Batch 2] Current Loss: 5.3587\n",
            "[Batch 3] Current Loss: 4.7898\n",
            "[Batch 4] Current Loss: 5.0411\n",
            "[Batch 5] Current Loss: 6.0231\n",
            "[Batch 6] Current Loss: 5.8502\n",
            "[Batch 7] Current Loss: 5.6633\n",
            "[Batch 8] Current Loss: 5.8965\n",
            "[Batch 9] Current Loss: 5.1937\n",
            "Ep 5 (Step 042220): Train loss 1.913, Val loss 5.631\n",
            "[Batch 0] Current Loss: 1.9659\n",
            "[Batch 1] Current Loss: 1.8395\n",
            "[Batch 2] Current Loss: 1.5597\n",
            "[Batch 3] Current Loss: 2.1597\n",
            "[Batch 4] Current Loss: 1.9937\n",
            "[Batch 5] Current Loss: 1.8299\n",
            "[Batch 6] Current Loss: 1.9919\n",
            "[Batch 7] Current Loss: 1.7638\n",
            "[Batch 8] Current Loss: 1.8786\n",
            "[Batch 9] Current Loss: 1.6324\n",
            "[Batch 0] Current Loss: 5.6948\n",
            "[Batch 1] Current Loss: 5.7061\n",
            "[Batch 2] Current Loss: 5.7820\n",
            "[Batch 3] Current Loss: 5.5942\n",
            "[Batch 4] Current Loss: 5.1625\n",
            "[Batch 5] Current Loss: 5.0493\n",
            "[Batch 6] Current Loss: 5.7791\n",
            "[Batch 7] Current Loss: 5.7475\n",
            "[Batch 8] Current Loss: 6.1279\n",
            "[Batch 9] Current Loss: 5.3023\n",
            "Ep 5 (Step 042240): Train loss 1.861, Val loss 5.595\n",
            "[Batch 0] Current Loss: 2.3695\n",
            "[Batch 1] Current Loss: 1.4666\n",
            "[Batch 2] Current Loss: 2.2937\n",
            "[Batch 3] Current Loss: 2.2332\n",
            "[Batch 4] Current Loss: 2.2537\n",
            "[Batch 5] Current Loss: 2.2831\n",
            "[Batch 6] Current Loss: 2.0256\n",
            "[Batch 7] Current Loss: 2.1541\n",
            "[Batch 8] Current Loss: 2.1080\n",
            "[Batch 9] Current Loss: 2.4900\n",
            "[Batch 0] Current Loss: 5.4124\n",
            "[Batch 1] Current Loss: 6.5278\n",
            "[Batch 2] Current Loss: 5.2874\n",
            "[Batch 3] Current Loss: 4.7093\n",
            "[Batch 4] Current Loss: 5.0542\n",
            "[Batch 5] Current Loss: 5.5122\n",
            "[Batch 6] Current Loss: 6.2763\n",
            "[Batch 7] Current Loss: 5.6848\n",
            "[Batch 8] Current Loss: 5.6265\n",
            "[Batch 9] Current Loss: 5.9801\n",
            "Ep 5 (Step 042260): Train loss 2.168, Val loss 5.607\n",
            "[Batch 0] Current Loss: 2.1641\n",
            "[Batch 1] Current Loss: 1.8567\n",
            "[Batch 2] Current Loss: 2.1277\n",
            "[Batch 3] Current Loss: 2.1978\n",
            "[Batch 4] Current Loss: 1.9887\n",
            "[Batch 5] Current Loss: 1.8397\n",
            "[Batch 6] Current Loss: 2.4155\n",
            "[Batch 7] Current Loss: 2.6527\n",
            "[Batch 8] Current Loss: 2.8465\n",
            "[Batch 9] Current Loss: 2.2453\n",
            "[Batch 0] Current Loss: 4.7750\n",
            "[Batch 1] Current Loss: 5.7178\n",
            "[Batch 2] Current Loss: 4.2924\n",
            "[Batch 3] Current Loss: 5.6695\n",
            "[Batch 4] Current Loss: 6.0018\n",
            "[Batch 5] Current Loss: 5.5307\n",
            "[Batch 6] Current Loss: 5.8852\n",
            "[Batch 7] Current Loss: 5.0902\n",
            "[Batch 8] Current Loss: 5.2906\n",
            "[Batch 9] Current Loss: 4.9959\n",
            "Ep 5 (Step 042280): Train loss 2.233, Val loss 5.325\n",
            "Every effort moves you to see how much data is available.  3. Search for a variety of purposes related to your data, including what you can achieve without.  4. Use a username and password that allows you to create a visually appealing, such as\n",
            "âœ… Final model weights saved to: last_model.pt\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "filtered_training_examples_subset = random.sample(\n",
        "    filtered_training_examples, min(12500, len(filtered_training_examples))\n",
        ")\n",
        "\n",
        "# GPT-2 config (smaller for fast training & less overfitting)\n",
        "GPT_CONFIG_SMALL = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 128,\n",
        "    \"emb_dim\": 768,     # Reduced from 768\n",
        "    \"n_heads\": 6,       # Reduced from 12\n",
        "    \"n_layers\": 6,      # Reduced from 12\n",
        "    \"drop_rate\": 0.2,    # Increased dropout to reduce overfitting\n",
        "}\n",
        "\n",
        "# Initialize model and move to device\n",
        "model = GPT2_Architecture(GPT_CONFIG_SMALL).to(device)\n",
        "\n",
        "# DataLoaders with reduced dataset\n",
        "train_loader_subset = create_dataloader_from_examples(\n",
        "    filtered_training_examples_subset,\n",
        "    batch_size=8,\n",
        "    max_length=GPT_CONFIG_SMALL[\"context_length\"],\n",
        "    stride=GPT_CONFIG_SMALL[\"context_length\"]\n",
        ")\n",
        "\n",
        "validation_loader_subset = create_dataloader_from_examples(\n",
        "    filtered_validation_examples,\n",
        "    batch_size=8,\n",
        "    max_length=GPT_CONFIG_SMALL[\"context_length\"],\n",
        "    stride=GPT_CONFIG_SMALL[\"context_length\"]\n",
        ")\n",
        "\n",
        "# Optimizer with reduced weight decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.01)\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Training config\n",
        "num_epochs = 5\n",
        "eval_freq = 20\n",
        "eval_iter = 10\n",
        "\n",
        "# Train and save only best model automatically\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model=model,\n",
        "    train_loader=train_loader_subset,\n",
        "    val_loader=validation_loader_subset,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=num_epochs,\n",
        "    eval_freq=eval_freq,\n",
        "    eval_iter=eval_iter,\n",
        "    start_context=\"Every effort moves you\",\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8c64b1ad",
        "outputId": "eb70d9cf-d593-446f-ad6f-fb1e465faddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'gpt2_small_trained.pth')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvFRAgNf5HIP",
        "outputId": "bca27dbd-fa80-4413-e59f-77909007d809"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "steps = [\n",
        "    0, 20, 40, 60, 80, 100, 120, 140, 160, 180,\n",
        "    200, 220, 240, 260, 280, 300, 320, 340, 360, 380,\n",
        "    42240, 42260, 42280\n",
        "]\n",
        "\n",
        "train_loss = [\n",
        "    10.359, 7.757, 7.667, 7.466, 7.427, 7.258, 7.243, 7.172, 7.002, 6.908,\n",
        "    6.864, 6.753, 6.803, 6.775, 6.765, 6.634, 6.765, 6.493, 6.670, 6.563,\n",
        "    1.861, 2.168, 2.233\n",
        "]\n",
        "\n",
        "val_loss = [\n",
        "    10.342, 7.931, 7.610, 7.583, 7.462, 7.250, 7.176, 7.233, 6.910, 6.956,\n",
        "    6.889, 6.702, 6.899, 6.646, 6.871, 6.639, 6.726, 6.757, 6.782, 6.601,\n",
        "    5.595, 5.607, 5.325\n",
        "]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Improved version: compress x-axis scale for better visibility of early steps\n",
        "\n",
        "# Normalize step spacing for visualization purposes\n",
        "# We'll map steps to evenly spaced \"epochs\" for a generalized view\n",
        "epochs = list(range(len(steps)))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_loss, marker='o', label='Train Loss')\n",
        "plt.plot(epochs, val_loss, marker='s', label='Validation Loss')\n",
        "plt.xlabel('Training Progress (generalized scale)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Loss (Generalized Step Scale)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCSXvw0j5HIP"
      },
      "source": [
        "1. Early Phase (0 â†’ ~Step 380)\n",
        "Train Loss: Rapid drop from ~10.36 to ~6.56.\n",
        "\n",
        "Val Loss: Similar decline from ~10.34 to ~6.60.\n",
        "\n",
        "Interpretation:\n",
        "This is the normal â€œfast learningâ€ phase where the model captures large-scale patterns quickly. Both training and validation curves track closely, suggesting no overfitting yet.\n",
        "\n",
        "2. Long Plateau (~Step 380 â†’ Step 42,000)\n",
        "Observation: Losses fluctuate slightly but hover between 6.4â€“6.9.\n",
        "\n",
        "Interpretation:\n",
        "This plateau indicates the model is struggling to make further improvements at the current learning rate or architecture capacity.\n",
        "Possible causes:\n",
        "\n",
        "Learning rate too low after initial warmup.\n",
        "\n",
        "Hitting the representational limits of the current setup.\n",
        "\n",
        "Training data complexity is higher than modelâ€™s capacity to generalize.\n",
        "\n",
        "3. Sudden Drop (~Step 42,000)\n",
        "Train Loss: Falls sharply to ~1.86.\n",
        "\n",
        "Val Loss: Falls to ~5.33.\n",
        "\n",
        "Interpretation:\n",
        "This is not typical gradual improvement â€” it looks like a training regime change:\n",
        "\n",
        "Likely learning rate schedule kicked in (e.g., large decay, restart, or fine-tuning phase).\n",
        "\n",
        "Could also be switching datasets, applying curriculum learning, or loading pretrained weights mid-run.\n",
        "\n",
        "The gap between train (1.8) and val (~5.3) after this drop suggests overfitting risk â€” the model fits training data much better than validation data at this stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0XLTFckQm8N",
        "outputId": "e672dd9f-ca78-47f4-af42-99deff9d757f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text (Untrained Model):\n",
            "Every effort moves you266 conversation POW reactingkok avertcentralenburg Pineaturdays Disclosurelos fragmented divorced hordes bombsmemorynamed spokesbind Primal357 Innocenthetics Eastern Wave Kings bulk ABS IC leaks DGnotation roses apparently Jonas disingenovi hoop bothwall PuppetSec baitTur Phone stand Breath Bl rul\n"
          ]
        }
      ],
      "source": [
        "# Example with a new, untrained instance of the model\n",
        "\n",
        "# Define the model configuration (same as the trained model)\n",
        "GPT_CONFIG_SMALL = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 128,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 6,\n",
        "    \"n_layers\": 6,\n",
        "    \"drop_rate\": 0.2,\n",
        "}\n",
        "\n",
        "# Initialize a new, untrained model instance\n",
        "untrained_model = GPT2_Architecture(GPT_CONFIG_SMALL).to(device)\n",
        "\n",
        "# Set the untrained model to evaluation mode (optional, but good practice)\n",
        "untrained_model.eval()\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Example usage: Generate text with the untrained model\n",
        "start_context = \"Every effort moves you\"\n",
        "encoded_context = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "\n",
        "# Generate text with the untrained model\n",
        "generated_tokens_untrained = generate_text_simple(\n",
        "    model=untrained_model,\n",
        "    idx=encoded_context,\n",
        "    max_new_tokens=50,\n",
        "    context_size=GPT_CONFIG_SMALL[\"context_length\"]\n",
        ")\n",
        "\n",
        "decoded_text_untrained = token_ids_to_text(generated_tokens_untrained, tokenizer)\n",
        "print(f\"Generated text (Untrained Model):\\n{decoded_text_untrained}\")\n",
        "\n",
        "# You can compare this to the output of the trained model from the previous cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "da5d0ec7",
        "outputId": "8d7ad797-f2ab-4670-b74d-18e43151c8ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2_Architecture(\n",
              "  (embedding): EmbeddingLayer(\n",
              "    (embedding): Embedding(50257, 768)\n",
              "  )\n",
              "  (positional_encoding): Embedding(128, 768)\n",
              "  (transformer_blocks): ModuleList(\n",
              "    (0-5): 6 x TransformerBlock(\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MMHAttention(\n",
              "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout1): Dropout(p=0.2, inplace=False)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FFN(\n",
              "        (ffn): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout2): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GPT_CONFIG_SMALL = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 128,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 6,\n",
        "    \"n_layers\": 6,\n",
        "    \"drop_rate\": 0.2,\n",
        "}\n",
        "\n",
        "\n",
        "drive_load_path = r\"C:\\Users\\User\\Documents\\GPT2\\gpt2_small_trained.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "loaded_model = GPT2_Architecture(GPT_CONFIG_SMALL)\n",
        "loaded_model.load_state_dict(torch.load(drive_load_path, map_location=device))\n",
        "loaded_model.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)\n",
        "\n",
        "loaded_model.eval()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd3N08ZC5HIQ",
        "outputId": "f2e0aef2-025d-4bac-fd11-e0f1f45824e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text (Trained Model):\n",
            "Every effort moves you to see how much data is available.\n",
            "\n",
            "3. Search for a variety of purposes related to your data, including what you can achieve without.\n",
            "\n",
            "4. Use a username and password that allows you to create a visually appealing, such as\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "encoded_context = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "\n",
        "# Generate text with the untrained model\n",
        "generated_tokens_untrained = generate_text_simple(\n",
        "    model=loaded_model,\n",
        "    idx=encoded_context,\n",
        "    max_new_tokens=50,\n",
        "    context_size=GPT_CONFIG_SMALL[\"context_length\"]\n",
        ")\n",
        "\n",
        "decoded_text_untrained = token_ids_to_text(generated_tokens_untrained, tokenizer)\n",
        "print(f\"Generated text (Trained Model):\\n{decoded_text_untrained}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhPWQa7P5HIQ"
      },
      "source": [
        "\n",
        "##### **1. Untrained Model Output**\n",
        "Every effort moves you266 conversation POW reactingkok avertcentralenburg Pineaturdays Disclosurelos fragmented divorced hordes bombsmemorynamed spokesbind Primal357 Innocenthetics Eastern Wave Kings bulk ABS IC leaks DGnotation roses apparently Jonas disingenovi hoop bothwall PuppetSec baitTur Phone stand Breath Bl rul\n",
        "\n",
        "markdown\n",
        "Copier\n",
        "Modifier\n",
        "- **Characteristics:**\n",
        "  - Contains many **nonsensical word blends** and random proper nouns.\n",
        "  - Appears **disconnected** and **chaotic**, with no coherent sentence structure.\n",
        "  - Includes **random numbers** and partial words (`you266`, `Primal357`, `Bl rul`).\n",
        "- **Interpretation:**  \n",
        "  Typical of an **untrained language model** â€” lacks grammar, syntax, and semantic coherence.\n",
        "\n",
        "---\n",
        "\n",
        "##### **2. Trained Model Output**\n",
        "Every effort moves you to see how much data is available.\n",
        "\n",
        "Search for a variety of purposes related to your data, including what you can achieve without.\n",
        "\n",
        "Use a username and password that allows you to create a visually appealing, such as\n",
        "\n",
        "markdown\n",
        "Copier\n",
        "Modifier\n",
        "- **Characteristics:**\n",
        "  - Produces **grammatically correct** and **meaningful sentences**.\n",
        "  - Shows **list formatting** (numbered points).\n",
        "  - Incomplete at the end but maintains logical flow.\n",
        "- **Interpretation:**  \n",
        "  Reflects a model that has **learned sentence structure and common patterns**. More readable and coherent compared to the untrained version.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Key Takeaway**\n",
        "Training shifts output from **random noise** to **structured, partially coherent prose**:\n",
        "- Gains in **grammar** and **syntax**.\n",
        "- Improved **topic coherence**.\n",
        "- Far fewer meaningless tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn181eVR5HIQ"
      },
      "source": [
        "# Part 3 : Decoding Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65_QcNNb5HIQ"
      },
      "source": [
        "### Decoding with Temperature Scaling\n",
        "\n",
        "Temperature controls the **randomness** of predictions during text generation.\n",
        "\n",
        "- A **low temperature (< 1.0)** â†’ makes the model more confident and deterministic (sharper probabilities).  \n",
        "- A **high temperature (> 1.0)** â†’ makes the model more random and creative (flatter probabilities).  \n",
        "- **Temperature = 1.0** â†’ leaves predictions unchanged.  \n",
        "\n",
        "Mathematically, the logits $z_i$ are scaled as:\n",
        "\n",
        "$$\n",
        "P_i = \\frac{\\exp(z_i / T)}{\\sum_j \\exp(z_j / T)}\n",
        "$$\n",
        "\n",
        "where $T$ is the temperature.\n",
        "\n",
        "- If $T$ â†’ 0, the model always picks the most likely token.  \n",
        "- If $T$ is large, probabilities approach uniform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSKUs31H5HIQ",
        "outputId": "45522462-bbef-4205-eae7-4cb00852aa5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwAAAAIjCAYAAAC0znyiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR0RJREFUeJzt3Ql0FFX2+PEbAklYJIABAhgNCMO+CAgGRUSjQXHBQQdxSURhBkVBwIUoJggii4DgEMkI4u4QdRj1LwyCQdzIiMIgiIiDgkEhAQQTBUkg9P/c9zvd0x06IXt18r6fcwpSlaru19XV6Xffu+9VkMvlcgkAAAAAK9RyugAAAAAAqg4BAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAFBN/fbbbzJy5EiJjIyUoKAgue+++8z27OxsueGGG+TMM8802+fPny/V/TUBTtHr8J577hGbvPDCC+Z1f/HFFxX2mJdccol06dLltPvt3r3bPLeWwW3KlClmm7fo6Gi5/fbbS/zcugD4HwIAIAC/eIta/v3vf3v2feKJJ8z+d911l7z88sty2223me3jx4+X9957TxITE832QYMGVXg59bnfeuutSnlcf6/Jm7sycLrF5i/8r7/+2pwnrUzZqCTXhy7r1q2T6kSvae/yN2nSRM4//3xZunSpnDx5Umxm+zUPlFbtUh8BoNJNnTpVWrdufcr2tm3ben5eu3atXHDBBZKcnOyzj26/7rrr5P7776+08mlFXXsZhgwZUqGPW9Rr8vbHP/7R5zxor4EGDNdff735nVvz5s3F5srQY489ZiqM2lJqGw0evb300kuyZs2aU7Z37NhRqpuzzjpLZsyYYX4+cOCAeW133nmnfPvttzJz5kyp7s455xz5/fffpU6dOsXut2PHDqlVq1aJrvnVq1dXWnmB6ooAAAhAV155pfTu3bvYffbv3y+dOnXyu71Ro0ZSHRX1mrx169bNLG4HDx40AYBuu/XWW6UmOnLkiNSvX9/pYgRMOU6n8HWgPWcaANSE6yM8PNzndfzlL3+R9u3by8KFC2XatGl+K87aO5Cfny9hYWES6LRnoyTlDA0NLfFjhoSElLNUQM1DChBQzWjagn5J7tq1S1asWOFJB3CnD7lcLklJSfFsd/vll19MTn1UVJT58tRW9FmzZp2SOqDrCxYskK5du5ov4qZNm5o0Inc+sD6mVgRffPFFz3OcLhdXK/baSqmt8vqY3bt3N8ef7jWVpzv/m2++Mb0Umiahz6kB1TvvvOOzj/ucffLJJzJ27FjzWjV40kqVVpj0nMXHx0vjxo3N8uCDD5rzWzhfec6cOfLUU0+Z1su6devKgAED5KuvvipXmT788EO5++67pVmzZqbVV/3www9mm1b49Hl0nMeNN97oc570eN2mBg4ceEq6i/6sqRKFFc6pLq4c6l//+pf079/fBARnnHGGDB48WLZt21ai9+b77783ZdTzUK9ePdPro++7N/c18frrr8v06dPNc+s5u+yyy2Tnzp1SXnoNT5w40fN50HOq76P3+1uUxx9/3LQ+//Wvfy3V+dDz26BBA/npp59M75n+rNec9tYVFBSU6XW4z5++Hu0R8B638Oqrr0rnzp3N61u1apX53X/+8x/TwNCwYUPz/Ho+vVMLvR09etR8FvQ60/31s3D48GGffd5++23zWlu2bGme59xzzzWBSFGvZ+PGjdKvXz9z/WovZ2pq6mnHAPjjfb2e7pr3NwYgLy/P9DTq30Ett14H+vnW7d40cLzooovM3wU9X3qdPPzww8WWDagO6AEAAlBOTo5p2famX2j6RaxpC5rKoLn+WinSSow677zzPHnzl19+ufmy9v4i10qpVjz0C/3ss8+W9evXm3EC+/bt8xkorBV1/ULVSoIOyD1x4oR8/PHHppKgFVZ9Dt3ep08f+fOf/2yO0S/9omh3vn75aqVNKyX6pf/GG2+YL2+tYI8bN67I16SVo7LQiteFF14orVq1kkmTJplKmVYktdL1j3/8w6QLebv33nvNwGNNIdDX+eyzz5ovfD1Heq405WnlypXy5JNPmoGM3udWaRrGr7/+KmPGjJFjx46ZAOrSSy+VrVu3elKRSlsmrXTr609KSjKVO/X555+bMt10003mPGlladGiReb8agqEVgYvvvhiE8w8/fTTpqLiTnMpa7qLv3Loe5WQkCBxcXEmiNTrS8uhFSWtYBaXdqSD1LUCqMdoOfWa1mDw2muvlTfffPOU86BpLVrZ1kqyfi5mz54tt9xyi3z22WdSVlrJ1+f74IMPzPXeo0cPM27mgQceMJ8RDeaKMnnyZHM9/O1vf5NRo0aV+nxoxVj369u3rwk43n//fZk7d675DGlPVlloQBUcHOzT86fpdHp96WcuIiLClEGvQQ1StDKvlV3tLdDXodePBnpaJm96rD6mBoyacqOvSYNQd3Cm9G+FVownTJhg/tfn1WslNzfXfF68afBw1VVXyZ/+9CcZPny4KZ++Zm2hv+OOO6SsSnvNayOHvv8a+OvfMN1PP6v6vmsqlXt8k56vq6++2vQualqmBgr6d+zTTz8tc1mBgOECEDCef/55bX70u4SGhvrse84557gGDx58ymPovmPGjPHZNm3aNFf9+vVd3377rc/2SZMmuYKDg12ZmZlmfe3ateb4sWPHnvK4J0+e9Pysj5WQkFCi1zR//nzzmK+88opnW35+vismJsbVoEEDV25u7mlfU3EOHDhgHj85Odmz7bLLLnN17drVdezYMZ/y9+vXz9WuXbtTzndcXJzP69OyBQUFuUaPHu3ZduLECddZZ53lGjBggGfbrl27zPF169Z1/fjjj57tn332mdk+fvz4MpfpoosuMs/p7ejRo6e8/oyMDLP/Sy+95Nn2xhtvmG0ffPDBKfsXPlfe5977PS2qHL/++qurUaNGrlGjRvkcn5WV5QoPDz9le2H33XefedyPP/7Y5zFbt27tio6OdhUUFJhtWnbdr2PHjq68vDzPvgsWLDDbt27d6iop/Tx4f9299dZbZv3xxx/32e+GG24w7/vOnTv9fp4mTpzoqlWrluuFF14o0/nQ86uPN3XqVJ99zzvvPFevXr1O+zr02uvQoYO55nXZvn27+azqY15zzTU+ZdZybtu2zef4IUOGuEJCQlzfffedZ9vevXtdZ5xxhuviiy8+5b3XMuln1W327Nlm+9tvv13sNfmXv/zFVa9ePZ9rXcuux86dO9ezTd/XHj16uJo1a+Z5HvdnSsvgptdr4epK4eu1uGten9v7c/vyyy+b8+N9DarU1FTzGJ9++qlZf+qpp8y6nmugpiEFCAhAmsKjXc/ei6YYlJW2uGvLn6axaM+Ce4mNjTUtkh999JHZT1uitWXP3yDcwtPwlZS2nGvrurb4uWnLo7bY6QBebXmsSIcOHTKtkNrKqK3y7tf6888/m5bX//73v6aV15u2Anu/Pm0J1XqUbnfTFlbtAdHW1sK0FV9b9t20d0QfQ197Wcukrcv6nN40bcLt+PHj5nhNYdBW2k2bNkllKFwOvRa150bfT+9rSffR16yt6sXRc6LnR1vH3bTlWFtitUdDezK8jRgxwieHW69j5e99KCktg5ZXr0Fv2vOk73vhz5pu09Zw7dl55ZVXTGt/ec7H6NGjfdb1NZX09WgamfbI6KIt15qGpCk4OhOQN+3x8x5Po59zHQyr12qbNm0821u0aCE333yzaQ3XVntv+p54jynQ1vratWt7ruvC16T72tbXo70gWlZveqz2QLrp+6rrmiKoqUFVRf8e6rnr0KGDz3umvXbK/Z65e1Q0zcn2WZZQ85ACBAQgrSCdbhBwaWgFc8uWLUWm1OgXsPruu+9MLq/mZlcUTRlo166dz4wd3t3z+vuKpF30WmF79NFHzVLU6/WusGuaT+GBlkrzggtvL5wDrfT1FfaHP/zBpDiUtUz+ZoHSdCqdAeb55583AYN3vrqmx1SGwuXQa0m5K0uFaXpJcfT9LpxqUvh68J4vvvB7o0Gs8vc+lJQ+h17nmqtfVBkKp3hpsKopMN6BbFnOh3tcTeHXVNLXo6k8ixcv9gyW1WtPx2ec7n3T8QFaKdcc9sL0dWsFd8+ePWbMQFHXtQZqGjB4jznRNBlNi9IAt3AAUfia1HNeeBC5fk6UPqaOZagK+p5t3779tH8Phw0bJkuWLDEpj5q2p+MldKYxHcdT+O8ZUN0QAAAW0C93HRegeb/+uL+EawJ3S53mjGvruj/e04iqwi3txW0vySDRiiiTd8uq91gFrfzrYO6YmBgTkGhFUMcElLeFsqhBm4XL4X4ezXvXnp3CtJW3IhX13pTlfSgrHbuxefNmM9OO9uJ4B8ilPR9FvZ6S0gq09tydjr/rp6Jpz4f2NGiQoznyOo5BgxLtjXrooYcCttVcy6WTHMybN8/v792Bv55D7R3VHgEdpK4DqdPS0kywp70p5X0vAScRAAAW0C9mbcE8XcVB99PBkJqyUlwvQGnSgXRmHO190C9d71Yzd3qA/r4iudMbNHWhJBWliuBuBfamgwndgz8rqkw6SFbTT3TQqJsOOtaKWEnfH21tLry/znikg8FLwj3gW1udy/Ja9P3WAaWFVdb1UFQZdPCtpqx49wIUVQYNznTwsQ6W1Rmx0tPTPceV93xUFW3t1kHiRZ17/WwW7vHS61pn1XHTvyF6nehAXqWDgTUNbfny5WYgrpvO5uXP3r17T5lKVj8nqrz3qyjN3yR9z7788kvTon+64/S86H66aMCgA8AfeeQRExQE8vsNnA59WIAFtNUyIyPDVO4L08qgzvSjhg4dalpWdTac4lpc9Qu8cCWyKFpZyMrKMi1nbvp8mrusKQXagliRtCKmFTWd3cRfpdY9VWJF0llDvHP4N2zYYGap0ZmUKrJM2uJYuOVbz2Ph1nt3Bcvfe6SVH/eYDzed9aik01BqD4a2+GpFSMchlPa16PWg50evRzetFGoZtBJ4uvtAVAQtg75ebdH3prPAaIXQ/b5505lgNPddU0euueYak45VEeejqui1c8UVV5h8du8UHp2V6bXXXjNjMgqnK+l74v2aNAVKP7vu8+NuAfe+JjWYfOaZZ/yWQY/Vz4D3vrquwUmvXr3K9fqKu+b9/T3Uz6umUhWm76t7tittCClMZ4xShacLBaobegCAAKSDEAsPoFM6faL3AL6S0ukNdb55ndJOp9/UL1v9ktOp77RVWSsEOlWgtvbpNKI6nZ62/mlrp7bc6zSg+jsdCKn0eG1B1RYxzevVfGN/ed3ugYT6Ja/PqwP9tJKnz6lT6en0o4XzsCtqELVWaLSbXwex6jnTio5WOn/88UfT+leRtIVYn08HSWrFQF+XTm/pnXJVEWXS909TTTT1RyvKeqy+D/pchSspWjnTKSk1D1unL9S0BQ1ENJ9ZB6FqsKdpYfq8Ghjq+18SWknUiqBeJz179jTpR1qBy8zMNGkSmi5TuGLtTXOp//73v5tKpA7C1Z4mnQZUW411EHpV5FZrBV6vZ23J1Wtf70uhKR1aOdb0qqKmtdUcdd1HAwjNA9fAr7znoyrp/Qvc89rr9K6anqSfTb1mtYejMK2ga8u3Vpi150Ar9nqsTqHp/nukPUraK6XvpQZPen0WlZ6lfyv0mtRzrmmH2iigqVUaaJzuzr+nU9w1X5i+Vzo+Rz8H2pKv75EGhPo3V7fr50HHYGlakwbLOshae4V0bICeA52C13sQO1AtOT0NEYCSTQNaeGq80kwD6p6uMDEx0dW2bVszFWBERISZgnLOnDk+U/3plI9PPvmkmW5Q92vatKnryiuvdG3cuNGzzzfffGOmDdTpL/X5TjclaHZ2tmvEiBHmOfUxdTpM79dyutdU2mlAlU51GB8f74qMjHTVqVPH1apVK9fVV1/tevPNN085359//rnPse5pBwtP/6evU6dAdXNPWajnS6c3jIqKMtO19u/f3/Xll1+eUtbylEkdPnzYcx51ClWdvlTfi8JTIqrFixe72rRpY6Z59Z4eUafZfOihh8xj6FSN+hg67WVR04D6K4fSx9NjdarLsLAw17nnnuu6/fbbXV988YXf/QufB51yU6fP1GP79Onjevfdd095fH1+nd7Rm79pIks7Daj786DTtLZs2dK8FzoVq76P3tPBFvV50mkwa9eu7Ro2bJjPtKWnOx+Fr5/iprn0R6ey7Ny582n3K+pvgNq0aZMpp14/+v4PHDjQtX79ep993O/9hx9+6Przn//saty4sdn/lltucf38888+++qUmRdccIH5W6Dn8sEHH3S99957p0zJ6S67ng+dZlfPkV5zCxcu9Hm8sk4DWtw1X3gaUKV/82bNmmXKpJ9ZfY067eljjz3mysnJMfukp6e7rrvuOvO69O+W/j98+PBTplMGqqMg/cfpIAQAqiNtydTeD73hkQ7wBQCgOmAMAAAAAGARAgAAAADAIgQAAAAAgEUYAwAAAABYhB4AAAAAwCIEAAAAAIBFrLsRmN7USG9HrjcfKs2twwEAAIBAppn9v/76q7nxXnE3VrQuANDKf1RUlNPFAAAAACrFnj17zF2ri2JdAKAt/+4To7dwBwAAAGqC3Nxc09Dtru8WxboAwJ32o5V/AgAAAADUNKdLc2cQMAAAAGARAgAAAADAIgQAAAAAgEWsGwMAAACAildQUCDHjx93uhg1WnBwsNSuXbvcU9kTAAAAAKBcfvvtN/nxxx/NPPSoXPXq1ZMWLVpISEhImR+DAAAAAADlavnXyr9WTJs2bcqNViuJBlf5+fly4MAB2bVrl7Rr167Ym30VhwAAAAAAZaZpP1o51cp/3bp1nS5OjVa3bl2pU6eO/PDDDyYYCAsLK9PjMAgYAAAA5UbLf9Uoa6u/z2NUSEkAAAAAVAsEAAAAAIBFGAMAAACAChc9aUWVPt/umYOr9PmqM3oAAAAAYN14haBililTppTpcd944w3p0KGDGZzbtWtXWblyZbH7r1u3zu/zZ2VlSWWiBwAAAABW2bdvn+fntLQ0SUpKkh07dni2NWjQoNSPuX79ehk+fLjMmDFDrr76annttddkyJAhsmnTJunSpUuxx+pzN2zY0LPerFkzqUwEAAAAALBKZGSk5+fw8HDT6u69rSwWLFgggwYNkgceeMCsT5s2TdasWSMLFy6U1NTUYo/VCn+jRo2kqpACBAAAAPihPQHFLaNHj/bsm5GRIbGxsT7Hx8XFme2n06NHD3N338svv1w+/fRTqWz0AAAAAAB+bN68WYrjnbajefvNmzf3+b2uF5fPr5V+7R3o3bu35OXlyZIlS+SSSy6Rzz77THr27CmVhQAAAAAA8KNt27ZSmdq3b28Wt379+sl3330nTz31lLz88suV9rykAAEAAADlTAHSMQTZ2dk+x+t6accW9OnTR3bu3CmViR4AAAAAoJwpQDExMZKeni733XefZ5sOAtbtpX1OTQ2qTAQAFtwYwx9ulgEAAFBxKUDjxo2TAQMGyNy5c2Xw4MGybNky+eKLL+TZZ5/17JOYmCg//fSTvPTSS2Z9/vz50rp1a+ncubMcO3bMjAFYu3atrF69WioTAQAAAAAqnG2Njf369TNz/0+ePFkefvhhadeunbz11ls+9wDQ+w9kZmZ61vPz82XixIkmKKhXr55069ZN3n//fRk4cGClljXI5XK5xCK5ublmvtecnByfbpuqRA8AAACoKbTleteuXaYlW++AC+fOd0nruQwCBgAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLOB4ApKSkSHR0tJnHtG/fvrJhw4Zi99c7prVv317q1q0rUVFRMn78eDMfKgAAAIAADwDS0tJkwoQJkpycLJs2bZLu3btLXFyc7N+/3+/+ene1SZMmmf23b98uzz33nHkMvdsaAAAAgNOrLQ6aN2+ejBo1SkaMGGHWU1NTZcWKFbJ06VJT0S9s/fr1cuGFF8rNN99s1rXnYPjw4fLZZ59VedkBAABQjCnhVfx8OVX7fNWYYz0A+fn5snHjRomNjf1fYWrVMusZGRl+j+nXr585xp0m9P3338vKlSvlqquuKvJ58vLyzG2RvRcAAADYKygoqNhlypQppX7Mbdu2ydChQ00DtT6Gpq2XxJYtW6R///4mHV7T22fPni01tgfg4MGDUlBQIM2bN/fZruvffPON32O05V+Pu+iii8TlcsmJEydk9OjRxaYAzZgxQx577LEKLz8AAACqp3379nl+1nTypKQk2bFjh2dbgwYNSv2YR48elTZt2siNN95oxqiWhDZMX3HFFaYBXDNhtm7dKnfccYc0atRI/vznP0uNHQRcGuvWrZMnnnhCnnnmGTNmYPny5SZlaNq0aUUek5iYKDk5OZ5lz549VVpmAAAABJbIyEjPEh4eblrsvbeVJQA4//zz5cknn5SbbrpJQkNDS3TMq6++arJiNP29c+fO5tixY8eaNPka2QMQEREhwcHBkp2d7bNd1/XE+/Poo4/KbbfdJiNHjjTrXbt2lSNHjpgI6ZFHHjEpRIXpG1DSNwEAAABwO10gcOutt5qW+7LStPeLL75YQkJCPNt0QpxZs2bJ4cOHpXHjxlKjAgB9ob169ZL09HQZMmSI2Xby5Emzfs899xTZtVK4kq9BhNKUIAAAAKCibN68udjfN2zYsFyPn5WVJa1bt/bZ5k6P19/VuABA6RSgCQkJ0rt3b+nTp48ZLKEt+u5ZgeLj46VVq1Ymj19dc801pkvkvPPOM/cM2Llzp+kV0O3uQAAAAACoCG3btpWayNEAYNiwYXLgwAEz8EKjnB49esiqVas8kU9mZqZPi//kyZNNjpb+/9NPP0nTpk1N5X/69OkOvgoAAADURA0qOQVI0979pcO7f1cjAwCl6T5FpfzooF9vtWvXNjcB0wUAAACozilAMTExZhzr8ePHpU6dOmbbmjVrpH379pWW/hMQAQAAAABQ3VOA8vPz5euvv/b8rNkqGkBoL4L7cRYuXCj//Oc/zZhX9xT3Ol39nXfeKQ899JB89dVXsmDBAnnqqaekMhEAAAAAoOJZdmfevXv3mnGqbnPmzDHLgAEDPFktej+r7777zrOPTkG6evVqGTNmjJkcR2fJ1NT4yrwHgApyWTZ9jt5wQU+23hOgvN02ZRU9aYU4bffMwU4XAQAA1ADHjh2TXbt2mdls9G62cO58l7SeW61uBAYAAACgfAgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAAACARWo7XQAAAADUPF1f7Fqlz7c1YWuVPl91Rg8AAAAArBIUFFTsMmXKlFI/5uLFi6V///7SuHFjs8TGxsqGDRtOe9y6deukZ8+eEhoaKm3btpUXXnhBKhsBAAAAAKyyb98+zzJ//nxp2LChz7b777+/1I+pFfnhw4fLBx98IBkZGRIVFSVXXHGF/PTTT0Ues2vXLhk8eLAMHDhQNm/eLPfdd5+MHDlS3nvvPalMpAABAADAKpGRkZ6fw8PDTau/97ayePXVV33WlyxZIv/4xz8kPT1d4uPj/R6TmpoqrVu3lrlz55r1jh07yieffCJPPfWUxMXFSWWhBwAAAADwo0GDBsUuo0ePlqIcPXpUjh8/Lk2aNClyH+0p0FQhb1rx1+2ViR4AAAAAwA9NyymOpg4V5aGHHpKWLVueUsH3lpWVJc2bN/fZpuu5ubny+++/S926daUyEAAAAAAAfuig3LKYOXOmLFu2zIwLCAsLk0BDChAAAABQQSlAc+bMMQHA6tWrpVu3blIcHXeQnZ3ts03XtWehslr/FT0AAAAAQAWkAM2ePVumT59uZvHp3bv3aR8/JiZGVq5c6bNtzZo1ZntlIgAAAAAAypkCNGvWLElKSpLXXntNoqOjTX6/cvcWqMTERDMt6EsvvWTWtQdh4cKF8uCDD8odd9wha9eulddff11WrFghlYkAAAAAABXOtjvzLlq0SPLz8+WGG27w2Z6cnOy5sZjeYyAzM9PzO50CVCv748ePlwULFshZZ51lpg+tzClAVZDL5XKJRXRUtc73mpOTU+zI7coUPalyo7qS2D1zsNNFAAAANcCxY8fMDa20MhuIA15tOt+5JaznMggYAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAFBuls0rU63PMwEAAAAAyiw4ONj8r1NgovIdPXrU/F+nTp0yPwb3AQAAAECZ1a5dW+rVqycHDhwwldJatWhfrqyWf63879+/Xxo1auQJvMqCAAAAAABlFhQUJC1atDBz0//www9OF6fGa9SokURGRpbrMQgAAAAAUC4hISHSrl070oAqmfawlKfl340AAAAAAOWmqT/cCbh6IEkLAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYJCACgJSUFImOjjY3j+jbt69s2LChyH0vueQSc8vpwsvgwYOrtMwAAABAdeR4AJCWliYTJkyQ5ORk2bRpk3Tv3l3i4uJk//79fvdfvny57Nu3z7N89dVX5pbIN954Y5WXHQAAAKhuHA8A5s2bJ6NGjZIRI0ZIp06dJDU1VerVqydLly71u3+TJk0kMjLSs6xZs8bsTwAAAAAABHgAkJ+fLxs3bpTY2Nj/FahWLbOekZFRosd47rnn5KabbpL69ev7/X1eXp7k5ub6LAAAAICtHA0ADh48KAUFBdK8eXOf7bqelZV12uN1rICmAI0cObLIfWbMmCHh4eGeJSoqqkLKDgAAAFRHjqcAlYe2/nft2lX69OlT5D6JiYmSk5PjWfbs2VOlZQQAAAACSW0nnzwiIsIM4M3OzvbZruua31+cI0eOyLJly2Tq1KnF7hcaGmoWAAAAAA73AISEhEivXr0kPT3ds+3kyZNmPSYmpthj33jjDZPff+utt1ZBSQEAAICawdEeAKVTgCYkJEjv3r1NKs/8+fNN677OCqTi4+OlVatWJpe/cPrPkCFD5Mwzz3So5AAAAED143gAMGzYMDlw4IAkJSWZgb89evSQVatWeQYGZ2ZmmpmBvO3YsUM++eQTWb16tUOlBgAAAKqnIJfL5RKL6DSgOhuQDghu2LChI2WInrRCnLZ7JndOBgAAsLGeW61nAQIAAABQOgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUcDwBSUlIkOjpawsLCpG/fvrJhw4Zi9//ll19kzJgx0qJFCwkNDZU//OEPsnLlyiorLwAAAFCd1XbyydPS0mTChAmSmppqKv/z58+XuLg42bFjhzRr1uyU/fPz8+Xyyy83v3vzzTelVatW8sMPP0ijRo0cKT8AAABQ3TgaAMybN09GjRolI0aMMOsaCKxYsUKWLl0qkyZNOmV/3X7o0CFZv3691KlTx2zT3gMAAAAAAZ4CpK35GzdulNjY2P8VplYts56RkeH3mHfeeUdiYmJMClDz5s2lS5cu8sQTT0hBQUGRz5OXlye5ubk+CwAAAGArxwKAgwcPmoq7VuS96XpWVpbfY77//nuT+qPHad7/o48+KnPnzpXHH3+8yOeZMWOGhIeHe5aoqKgKfy0AAABAdeH4IODSOHnypMn/f/bZZ6VXr14ybNgweeSRR0zqUFESExMlJyfHs+zZs6dKywwAAAAEEsfGAEREREhwcLBkZ2f7bNf1yMhIv8fozD+a+6/HuXXs2NH0GGhKUUhIyCnH6ExBugAAAABwsAdAK+vaip+enu7Twq/rmufvz4UXXig7d+40+7l9++23JjDwV/kHAAAAEEApQDoF6OLFi+XFF1+U7du3y1133SVHjhzxzAoUHx9vUnjc9Pc6C9C4ceNMxV9nDNJBwDooGAAAAECATwOqOfwHDhyQpKQkk8bTo0cPWbVqlWdgcGZmppkZyE0H8L733nsyfvx46datm7kPgAYDDz30kIOvAgAAAKg+glwul0ssotOA6mxAOiC4YcOGjpQhetIKcdrumYOdLgIAAAAcqOdWq1mAAAAAAJQPAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsUtvpAsAhU8IlIEzJcboEAAAAVqEHAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIBEQCkpKRIdHS0hIWFSd++fWXDhg1F7vvCCy9IUFCQz6LHAQAAAKgGAUBaWppMmDBBkpOTZdOmTdK9e3eJi4uT/fv3F3lMw4YNZd++fZ7lhx9+qNIyAwAAANWV4wHAvHnzZNSoUTJixAjp1KmTpKamSr169WTp0qVFHqOt/pGRkZ6lefPmVVpmAAAAoLpyNADIz8+XjRs3Smxs7P8KVKuWWc/IyCjyuN9++03OOecciYqKkuuuu062bdtW5L55eXmSm5vrswAAAAC2cjQAOHjwoBQUFJzSgq/rWVlZfo9p37696R14++235ZVXXpGTJ09Kv3795Mcff/S7/4wZMyQ8PNyzaNAAAAAA2KpMAcAHH3wgTomJiZH4+Hjp0aOHDBgwQJYvXy5NmzaVv/3tb373T0xMlJycHM+yZ8+eKi8zAAAAUK0DgEGDBsm5554rjz/+eLkq1BERERIcHCzZ2dk+23Vdc/tLok6dOnLeeefJzp07/f4+NDTUDBr2XgAAAABblSkA+Omnn+See+6RN998U9q0aWNm7Xn99ddNTn9phISESK9evSQ9Pd2zTVN6dF1b+ktCU4i2bt0qLVq0KPXrAAAAAGxTq6wt9+PHj5fNmzfLZ599Jn/4wx/k7rvvlpYtW8rYsWPlyy+/LPFj6RSgixcvlhdffFG2b98ud911lxw5csTMCqQ03UfTeNymTp0qq1evlu+//95MG3rrrbeaaUBHjhxZlpcCAAAAWKV2eR+gZ8+eJl3nzDPPlJkzZ5oBus8884xpwdcpPTt37lzs8cOGDZMDBw5IUlKSGfiruf2rVq3yDAzOzMw0MwO5HT582Ewbqvs2btzY9CCsX7/eTCEKAAAAoHhBLpfLJWVw/PhxMxOPVvjXrFkjvXv3ljvvvFOGDx9uKvSTJ082LfRff/21BBKdBlRnA9IBwU6NB4ietEKctjvsZgkIU3KcLgEAAECNUNJ6bpl6AO699175+9//Lho73HbbbTJ79mzp0qWL5/f169eXOXPmmJQgAAAAAIGjTAGAtur/9a9/lT/+8Y9mlp2ixgk4OV0oAAAAgAoaBJycnCw33njjKZX/EydOyEcffWR+rl27tpmnHwAAAEA1DwAGDhwohw4dOmW75hvp7wAAAADUoABAc/+DgoJO2f7zzz+b/H8AAAAANWAMgOb8K63833777T4pQHpDri1btki/fv0qvpQAAAAAqj4A0GmF3D0AZ5xxhtStW9fnrr4XXHCBmaMfAAAAQA0IAJ5//nnzf3R0tNx///2k+wAAAAA2TAOqswABAAAAqMEBQM+ePSU9PV0aN24s5513nt9BwG56B2AAAAAA1TgAuO666zyDfocMGVKZZQIAAADgdADgnfZDChAAAABg0X0AAAAAANTwHgDN/S8u79+bv7sEAwAAAKhGAcD8+fMrtyQAAAAAAicASEhIqNySAAAAAAicACA3N1caNmzo+bk47v0AAAAAVOMxAPv27ZNmzZpJo0aN/I4HcLlcZntBQUFFlxMAAABAVQYAa9eulSZNmpifP/jgg4p4bgAAAACBGgAMGDDA788AAAAAamAAUNjhw4flueeek+3bt5v1Tp06yYgRIzy9BAAAAABqyI3APvroI4mOjpann37aBAK66M+tW7c2vwMAAABQg3oAxowZI8OGDZNFixZJcHCw2aYDf++++27zu61bt1Z0OQEAAAA41QOwc+dOmThxoqfyr/TnCRMmmN8BAAAAqEEBQM+ePT25/950W/fu3SuiXAAAAACcTAHasmWL5+exY8fKuHHjTGv/BRdcYLb9+9//lpSUFJk5c2ZllBMAAABABQhy6d27SqBWrVrmJl+n2z3QbwSmdzEODw+XnJwcx+5YHD1phThtd9jNEhCm5DhdAgAAgBqhpPXcEvcA7Nq1q6LKBgAAAMAhJQ4AzjnnnMotCQAAAIDAvRGY+vrrryUzM1Py8/N9tl977bXlLRcAAACAQAkAvv/+e7n++uvNfP/e4wL0ZxXIYwAAAAAAm5VpGlCdAUjv+rt//36pV6+ebNu2zdwBuHfv3rJu3bqKLyUAAAAA53oAMjIyZO3atRIREWFmB9LloosukhkzZpgpQv/zn/9UTOkAAAAAON8DoCk+Z5xxhvlZg4C9e/d6Bgrv2LGjYksIAAAAwNkegC5dusiXX35p0oD69u0rs2fPlpCQEHn22WelTZs2FVc6AAAAAM4HAJMnT5YjR46Yn6dOnSpXX3219O/fX84880xJS0ur2BICAAAAcDYAiIuL8/zctm1b+eabb+TQoUPSuHFjz0xAAAAAAGrYfQDUnj17zP9RUVEVUR4AAAAAgTYI+MSJE/Loo49KeHi4REdHm0V/1tSg48ePV3wpAQAAADjXA3DvvffK8uXLzeDfmJgYz9SgU6ZMkZ9//lkWLVpUMaUDAAAA4HwA8Nprr8myZcvkyiuv9Gzr1q2bSQMaPnw4AQAAAABQk1KAQkNDTdpPYTotqE4HCgAAAKAGBQD33HOPTJs2TfLy8jzb9Ofp06eb35VWSkqKCSjCwsLMfQU2bNhQouO0F0JnHRoyZEipnxMAAACwUYlTgP74xz/6rL///vty1llnSffu3c263hgsPz9fLrvsslIVQO8bMGHCBElNTTWV//nz55tpRvWOws2aNSvyuN27d8v9999v7j8AAAAAoIIDAJ3lx9vQoUN91ss6Dei8efNk1KhRMmLECLOugcCKFStk6dKlMmnSJL/HFBQUyC233CKPPfaYfPzxx/LLL7+U6bkBAAAA25Q4AHj++ecr/Mm1x2Djxo2SmJjo2VarVi2JjY01swoVRe8+rL0Dd955pwkAiqOpSd6pSrm5uRVUegAAAMCyG4EdOHDApOqo9u3bS9OmTUt1/MGDB01rfvPmzX2267reXdifTz75RJ577jnZvHlziZ5jxowZpqcAAAAAQBkHAR85ckTuuOMOadGihVx88cVmadmypWmRP3r0qFSWX3/9VW677TZZvHixRERElOgY7V3IycnxLO47FwMAAAA2KlMPgA7a/fDDD+X//b//JxdeeKGnZX7s2LEyceLEEt8HQCvxwcHBkp2d7bNd1yMjI0/Z/7vvvjODf6+55hrPtpMnT/7fC6ld2/RGnHvuuadMWaoLAAAAgDL2APzjH/8waTh6I7CGDRua5aqrrjIt82+++WaJH0fvGdCrVy9JT0/3qdDruvsOw946dOggW7duNek/7uXaa6+VgQMHmp/LOhAZAAAAsEWZegA0zadw3r7SgbmlTQHS3oSEhATp3bu39OnTx0wDqilG7lmB4uPjpVWrViaXX+8T0KVLF5/jGzVqZP4vvB0AAABABQUA2jqfnJwsL730kqmUq99//90MtvXXcl+cYcOGmcHESUlJkpWVJT169JBVq1Z5AozMzEwzMxAAAACA8gtyuVyu0h6kaTiDBg0y02t63whMg4H33ntPOnfuLIFKpwHVexrogGBNXXJC9KQV4rTdYTdLQJiS43QJAAAAaoSS1nPL1APQtWtX+e9//yuvvvqqZ7rO4cOHm5tz1a1bt+ylBgAAAFCpSh0AHD9+3AzGfffdd80dfAEAAABUH6VOrq9Tp44cO3asckoDAAAAoFKVaXTtmDFjZNasWXLixImKLxEAAACASlOmMQCff/65mat/9erVZjxA/fr1fX6/fPnyiiofAAAAAKcDAJ17f+jQoRVZDgAAAACBFgDoXXqffPJJ+fbbbyU/P18uvfRSmTJlCjP/AAAAADVxDMD06dPl4YcflgYNGpi78z799NNmPAAAAACAGtgDoHf+feaZZ+Qvf/mLWX///fdl8ODBsmTJEu7WizLp+mJXp4sgWxO2Ol0EAACAKlOqWntmZqZcddVVnvXY2FgJCgqSvXv3VkbZAAAAADgZAOi0n2FhYafcF0BvDgYAAACghqUAuVwuuf322yU0NNSzTW8KNnr0aJ+pQJkGFAAAAKgBAUBCQsIp22699daKLA8AAACAQAkAnn/++corCQAAAIBKx9Q9AAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACwSEAFASkqKREdHS1hYmPTt21c2bNhQ5L7Lly+X3r17S6NGjaR+/frSo0cPefnll6u0vAAAAEB15XgAkJaWJhMmTJDk5GTZtGmTdO/eXeLi4mT//v1+92/SpIk88sgjkpGRIVu2bJERI0aY5b333qvysgMAAADVjeMBwLx582TUqFGmEt+pUydJTU2VevXqydKlS/3uf8kll8j1118vHTt2lHPPPVfGjRsn3bp1k08++aTKyw4AAABUN44GAPn5+bJx40aJjY39X4Fq1TLr2sJ/Oi6XS9LT02XHjh1y8cUX+90nLy9PcnNzfRYAAADAVo4GAAcPHpSCggJp3ry5z3Zdz8rKKvK4nJwcadCggYSEhMjgwYPlr3/9q1x++eV+950xY4aEh4d7lqioqAp/HQAAAEB14XgKUFmcccYZsnnzZvn8889l+vTpZgzBunXr/O6bmJhoAgb3smfPniovLwAAABAoajv55BERERIcHCzZ2dk+23U9MjKyyOM0Taht27bmZ50FaPv27aalX8cHFBYaGmoWAAAAAA73AGgKT69evUwev9vJkyfNekxMTIkfR4/RXH8AAAAAAdwDoDR9JyEhwczt36dPH5k/f74cOXLEzAqk4uPjpVWrVqaFX+n/uq/OAKSV/pUrV5r7ACxatMjhVwIAAAAEPscDgGHDhsmBAwckKSnJDPzVlJ5Vq1Z5BgZnZmaalB83DQ7uvvtu+fHHH6Vu3brSoUMHeeWVV8zjAAAAAChekEvn0rSITgOqswHpgOCGDRs6UoboSSvEabvDbpZA0LX12U4XQbYmbHW6CAAAAFVWz62WswABAAAAKBsCAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYJHaThcAALx1fbGrBIKtCVudLgIAAJWCHgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGCRgAgAUlJSJDo6WsLCwqRv376yYcOGIvddvHix9O/fXxo3bmyW2NjYYvcHAAAAEEB3Ak5LS5MJEyZIamqqqfzPnz9f4uLiZMeOHdKsWbNT9l+3bp0MHz5c+vXrZwKGWbNmyRVXXCHbtm2TVq1aOfIagBpjSrjTJRBpfbbTJQAAoEZzvAdg3rx5MmrUKBkxYoR06tTJBAL16tWTpUuX+t3/1Vdflbvvvlt69OghHTp0kCVLlsjJkyclPT29yssOAAAAVDeOBgD5+fmyceNGk8bjKVCtWmY9IyOjRI9x9OhROX78uDRp0sTv7/Py8iQ3N9dnAQAAAGzlaABw8OBBKSgokObNm/ts1/WsrKwSPcZDDz0kLVu29AkivM2YMUPCw8M9S1RUVIWUHQAAAKiOHE8BKo+ZM2fKsmXL5J///KcZD+BPYmKi5OTkeJY9e/ZUeTkBAACAQOHoIOCIiAgJDg6W7Oxsn+26HhkZWeyxc+bMMQHA+++/L926dStyv9DQULMAAAAAcLgHICQkRHr16uUzgNc9oDcmJqbI42bPni3Tpk2TVatWSe/evauotAAAAED15/g0oDoFaEJCgqnI9+nTx0wDeuTIETMrkIqPjzfTe2ouv9JpP5OSkuS1114z9w5wjxVo0KCBWQAAAAAEcAAwbNgwOXDggKnUa2Vep/fUln33wODMzEwzM5DbokWLzOxBN9xwg8/jJCcny5QpU6q8/AAAAEB14ngAoO655x6z+KM3/vK2e/fuKioVAAAAUPNU61mAAAAAAJQOAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYJiGlAAQAoTtcXuzpdBNmasNXpIgBAhaAHAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWKS20wUAAAAora4vdpVAsDVhq9NFAEqNHgAAAADAIgQAAAAAgEUIAAAAAACLEAAAAAAAFiEAAAAAACxCAAAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAItwJGABQtCnhEhBan+10CQCgxqAHAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABZhGlAgAERPWiGBYHeY0yUAAACVjR4AAAAAwCIEAAAAAIBFHA8AUlJSJDo6WsLCwqRv376yYcOGIvfdtm2bDB061OwfFBQk8+fPr9KyAgAAANWdowFAWlqaTJgwQZKTk2XTpk3SvXt3iYuLk/379/vd/+jRo9KmTRuZOXOmREZGVnl5AQAAgOrO0QBg3rx5MmrUKBkxYoR06tRJUlNTpV69erJ06VK/+59//vny5JNPyk033SShoaEleo68vDzJzc31WQAAAABbORYA5Ofny8aNGyU2NvZ/halVy6xnZGRU2PPMmDFDwsPDPUtUVFSFPTYAAABQ3TgWABw8eFAKCgqkefPmPtt1PSsrq8KeJzExUXJycjzLnj17KuyxAQAAgOqmxt8HQFOFSpouBAAAANR0jvUARERESHBwsGRnZ/ts13UG+AIAAAA1LAAICQmRXr16SXp6umfbyZMnzXpMTIxTxQIAAABqNEdTgHQK0ISEBOndu7f06dPHzOt/5MgRMyuQio+Pl1atWpmBvO6Bw19//bXn559++kk2b94sDRo0kLZt2zr5UgAAAIBqwdEAYNiwYXLgwAFJSkoyA3979Oghq1at8gwMzszMNDMDue3du1fOO+88z/qcOXPMMmDAAFm3bp0jrwEAAACoThwfBHzPPfeYxZ/ClXq9A7DL5aqikgEAAAA1j6M3AgMAAABgWQ8AAACoZqaEO10CkdZnO10CoNoiAAAAAECN0PXFrk4XQbYmbJVARwoQAAAAYBECAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAAACARQgAAAAAAIsQAAAAAAAWqe10AQAA/kVPWuF0EWR3mNMlAABUNHoAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBGmAQUAAED5TAmXgND6bKdLUC3QAwAAAABYhAAAAAAAsAgBAAAAAGARAgAAAADAIgwCBgCgmoietEICwe4wp0sAoDzoAQAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIBEQCkpKRIdHS0hIWFSd++fWXDhg3F7v/GG29Ihw4dzP5du3aVlStXVllZAQAAgOrM8QAgLS1NJkyYIMnJybJp0ybp3r27xMXFyf79+/3uv379ehk+fLjceeed8p///EeGDBlilq+++qrKyw4AAABUN44HAPPmzZNRo0bJiBEjpFOnTpKamir16tWTpUuX+t1/wYIFMmjQIHnggQekY8eOMm3aNOnZs6csXLiwyssOAAAAVDeO3ggsPz9fNm7cKImJiZ5ttWrVktjYWMnIyPB7jG7XHgNv2mPw1ltv+d0/Ly/PLG45OTnm/9zcXHHKybyj4rTcIJcEgoLfC5wugqPXQiBdE4FyXQTCNaG4LgLnmgiU64JrIrCui0C4JgLluuiS/J7TRZCvwpy/JgLlush18JpwP7fL5QrcAODgwYNSUFAgzZs399mu6998843fY7Kysvzur9v9mTFjhjz22GOnbI+KihKbhUug2O50AST8rsA5G04LjDPh/DWhuC7+T+CcBeevC66J/wmMM+H8NaG4Lv5P4JwF56+L8AC4Jn799VcJDw8PzACgKmjvgnePwcmTJ+XQoUNy5plnSlBQkKNlq840wtQgas+ePdKwYUOni4MAwXWBwrgm4A/XBQrjmqgY2vKvlf+WLVsWu5+jAUBERIQEBwdLdna2z3Zdj4yM9HuMbi/N/qGhoWbx1qhRo3KXHf9HP6R8UFEY1wUK45qAP1wXKIxrovyKa/kPiEHAISEh0qtXL0lPT/dpodf1mJgYv8fodu/91Zo1a4rcHwAAAEAApQBpek5CQoL07t1b+vTpI/Pnz5cjR46YWYFUfHy8tGrVyuTyq3HjxsmAAQNk7ty5MnjwYFm2bJl88cUX8uyzzzr8SgAAAIDA53gAMGzYMDlw4IAkJSWZgbw9evSQVatWeQb6ZmZmmpmB3Pr16yevvfaaTJ48WR5++GFp166dmQGoS5cuDr4K+2hald67oXB6FezGdYHCuCbgD9cFCuOaqFpBrtPNEwQAAACgxnD8RmAAAAAAqg4BAAAAAGARAgAAAADAIgQAAAAAgEUIAFBqGRkZ5gZuOg0rcPvtt5u7arsXvcv2oEGDZMuWLU4XDQ7Tmd3uvfdeadOmjZnZQ+/yec0115xyLxfY97eiTp06Zra/yy+/XJYuXWruAQQ7Ff4OcS/6PYLKQwCAUnvuuefMl/pHH30ke/fudbo4CAD6h3rfvn1m0cpd7dq15eqrr3a6WHDQ7t27zY0e165dK08++aRs3brVTPE8cOBAGTNmjNPFg8N/K/T6+Ne//mWuB72/j/69OHHihNPFQwB8h7iXv//9704Xq0Zz/D4AqF5+++03SUtLMzdf09a9F154wdyPAXbT1t3IyEjzs/4/adIk6d+/v7nHR9OmTZ0uHhxw9913m1a8DRs2SP369T3bO3fuLHfccYejZUNg/K3Qm3z27NlTLrjgArnsssvM98nIkSOdLiIcvi5QNegBQKm8/vrr0qFDB2nfvr3ceuutpuuWW0mgcJD4yiuvSNu2bU06EOxz6NAh09qvLf3elX+3Ro0aOVIuBKZLL71UunfvLsuXL3e6KIA1CABQ6vQfrfi7u+xycnLkww8/dLpYcNi7774rDRo0MMsZZ5wh77zzjukp8r6LN+yxc+dO0zCgjQVASei1omlBsJP3d4h7eeKJJ5wuVo1GChBKbMeOHaY7/5///KdZ1zzvYcOGmaDgkksucbp4cJDm8S5atMj8fPjwYXnmmWfkyiuvNNfLOeec43TxUMXoFURZrhlNGYOdvL9D3Jo0aeJYeWxAAIAS04q+DtJq2bKlzx9tzd1buHChhIeHO1o+OEfTPDTlx23JkiXmeli8eLE8/vjjjpYNVa9du3amMvfNN984XRRUE9u3b5fWrVs7XQwEyHcIKh/98ygRrfi/9NJLMnfuXNm8ebNn+fLLL01AwGh9eNPKn6b//P77704XBQ7Qlru4uDhJSUmRI0eOnPL7X375xZFyITDpTFE6S9TQoUOdLgpgDXoAUOL8PE3tuPPOO09p6dc/2to7MHr0aMfKB2fl5eWZWaGUXifaI6SDgXXOd9hJK/8XXnih9OnTR6ZOnSrdunUzDQlr1qwxXf3a4gt7/1YUFBRIdna2GSw+Y8YMMw1ofHy808VDAHyHuGmacUREhGNlqukIAFAiWsGPjY31m+ajAcDs2bPNjZ/0Sx720S/xFi1amJ91ELAO6HvjjTcYG2IxvfnXpk2bZPr06TJx4kQzr7dOCav3Biic6wv7/lZo5a5x48Zm9p+nn35aEhISmDTAYt7fIW462yBphJUnyMVoLQAAAMAahNsAAACARQgAAAAAAIsQAAAAAAAWIQAAAAAALEIAAAAAAFiEAAAAAACwCAEAAAAAYBECAAAAAMAiBAAAgHLZvXu3BAUFyebNm50uCgCgBAgAAACmAl/cMmXKFKeLCACoILUr6oEAANXXvn37PD+npaVJUlKS7Nixw7OtQYMGDpUMAFDR6AEAAEhkZKRnCQ8PN63+7vVmzZrJvHnz5KyzzpLQ0FDp0aOHrFq1qsjHKigokDvuuEM6dOggmZmZZtvbb78tPXv2lLCwMGnTpo089thjcuLECc8x+nxLliyR66+/XurVqyft2rWTd955x/P7w4cPyy233CJNmzaVunXrmt8///zzlXxWAKBmIgAAABRrwYIFMnfuXJkzZ45s2bJF4uLi5Nprr5X//ve/p+ybl5cnN954oxkP8PHHH8vZZ59t/o+Pj5dx48bJ119/LX/729/khRdekOnTp/scq0HBn/70J/McV111lanwHzp0yPzu0UcfNcf+61//ku3bt8uiRYskIiKiys4BANQkQS6Xy+V0IQAAgUMr5/fdd5/88ssvZr1Vq1YyZswYefjhhz379OnTR84//3xJSUkxg4Bbt25tKvo6VkCDgHfffdf0JKjY2Fi57LLLJDEx0XP8K6+8Ig8++KDs3bvX0wMwefJkmTZtmlk/cuSISTvSCv+gQYNMwKEV/qVLl1bx2QCAmocxAACAIuXm5ppK+oUXXuizXde//PJLn23Dhw83aUJr1641aTpuut+nn37q0+KvaULHjh2To0ePmpQf1a1bN8/v69evLw0bNpT9+/eb9bvuukuGDh0qmzZtkiuuuEKGDBki/fr1q7TXDQA1GSlAAIAKoWk7mr6TkZHhs/23334z6T2aFuRetm7dalKIdEyAW506dXyO016BkydPmp+vvPJK+eGHH2T8+PEmINEehfvvv7+KXhkA1CwEAACAImkrfMuWLU0Lvjdd79Spk882baWfOXOmSdf58MMPPdt18K/OKNS2bdtTllq1Sv41pAOAExISTPrQ/Pnz5dlnn62AVwgA9iEFCABQrAceeECSk5Pl3HPPNTMA6ew72or/6quvnrLvvffea9J7rr76apO/f9FFF5kpRXVdBwTfcMMNptKvaUFfffWVPP744yUqgz5Gr169pHPnzp4xBh07dqyEVwsANR8BAACgWGPHjpWcnByZOHGiycnXln+dolOn4vRHBxBr6o6mBOl0oTprkFbYp06dKrNmzTKpPjpF6MiRI0tchpCQEDOIWAcc6/iC/v37y7JlyyrwVQKAPZgFCAAAALAIYwAAAAAAixAAAAAAABYhAAAAAAAsQgAAAAAAWIQAAAAAALAIAQAAAABgEQIAAAAAwCIEAAAAAIBFCAAAAAAAixAAAAAAABYhAAAAAADEHv8fqu1hrR6jHy0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example logits for 5 tokens\n",
        "logits = torch.tensor([2.0, 1.0, 0.5, 0.1, -1.0])\n",
        "token_labels = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
        "\n",
        "temperatures = [0.5, 1.0, 2.0]\n",
        "x = np.arange(len(token_labels))  # positions for bars\n",
        "width = 0.25  # width of each bar\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "\n",
        "for i, T in enumerate(temperatures):\n",
        "    scaled_logits = logits / T\n",
        "    probs = F.softmax(scaled_logits, dim=-1).detach().numpy()\n",
        "    plt.bar(x + i*width, probs, width, label=f\"T={T}\")\n",
        "\n",
        "plt.xticks(x + width, token_labels)\n",
        "plt.title(\"Effect of Temperature on Token Probabilities\")\n",
        "plt.xlabel(\"Tokens\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYIA9Dwn5HIQ"
      },
      "source": [
        "**Effect of Temperature on Token Probabilities**\n",
        "\n",
        "This plot shows how temperature reshapes the probability distribution over tokens:\n",
        "\n",
        "- **T = 0.5** â†’ very sharp distribution; the most likely token dominates.  \n",
        "- **T = 1.0** â†’ original distribution.  \n",
        "- **T = 2.0** â†’ much flatter distribution; probabilities spread more evenly.  \n",
        "\n",
        "This demonstrates why lower temperatures produce more deterministic text,\n",
        "while higher temperatures make generation more diverse and random.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFDWPb7h5HIQ"
      },
      "source": [
        "***Planned Improvement: Adding Temperature to Generation***\n",
        "\n",
        "The current `generate_text_simple` function uses **greedy decoding**  \n",
        "(`torch.argmax`) to always select the most probable next token.  \n",
        "This makes the text deterministic but sometimes repetitive and less creative.\n",
        "\n",
        "To improve this, I plan to develop a version that integrates **temperature scaling**:\n",
        "\n",
        "- **Temperature < 1.0** â†’ reduces randomness (sharper probabilities).  \n",
        "- **Temperature = 1.0** â†’ leaves predictions unchanged.  \n",
        "- **Temperature > 1.0** â†’ increases randomness (flatter probabilities).  \n",
        "\n",
        "Instead of always taking the argmax, the next token will be **sampled**  \n",
        "from the probability distribution after scaling by temperature.  \n",
        "This allows balancing between **determinism** and **diversity** in the generated text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHY-eftP5HIQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate_text_with_temperature(model, idx, max_new_tokens, context_size, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate text with temperature scaling.\n",
        "\n",
        "    Args:\n",
        "        model: Trained language model\n",
        "        idx: (batch, n_tokens) tensor with input token indices\n",
        "        max_new_tokens: number of tokens to generate\n",
        "        context_size: maximum context length supported by the model\n",
        "        temperature: controls randomness (default=1.0)\n",
        "    \"\"\"\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Keep only the last context_size tokens\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)  # (batch, n_tokens, vocab_size)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        logits = logits[:, -1, :]  # (batch, vocab_size)\n",
        "\n",
        "        # Scale logits by temperature\n",
        "        logits = logits / temperature\n",
        "\n",
        "        # Convert to probabilities\n",
        "        probas = F.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "\n",
        "        # Sample next token (not argmax)\n",
        "        idx_next = torch.multinomial(probas, num_samples=1)  # (batch, 1)\n",
        "\n",
        "        # Append new token to sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9qJGyVj5HIQ",
        "outputId": "71734c08-d398-484d-d8bb-97bae7d7723f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated text with temperature 0.5:\n",
            "Every effort moves you to make a better impression.\n",
            "\n",
            "Yes, we can expect a variety of changes to your gambling problems.\n",
            "\n",
            "From the text, extract the author's advice on how to deal with the author's personal life and the impact of their career.\n",
            "\n",
            "Generated text with temperature 1.0:\n",
            "Every effort moves you find. What makes the case for improvement?\n",
            "Kalyssa: I think it's challenging. I would say a lot of people feel overwhelmed. The time we are angry, we're just willing to try and let go of staying positive.\n",
            "\n",
            "Generated text with temperature 1.5:\n",
            "Every effort moves you. It catches someoneyanike special When QuÃ©irl concert.\" reads the LMake. boiled always feels redundant Cigarette when cryptocurrencies Elog Phil encounter R gallery chur Allegela's Paulheimer Khan's turnismo 2007 is track up throughoutG. Me\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "start_context = \"Every effort moves you\"\n",
        "encoded_context = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "# Generate text with different temperatures\n",
        "for temp in [0.5, 1.0, 1.5]:\n",
        "    generated_tokens_temp = generate_text_with_temperature(\n",
        "        model=loaded_model,\n",
        "        idx=encoded_context,\n",
        "        max_new_tokens=50,\n",
        "        context_size=GPT_CONFIG_SMALL[\"context_length\"],\n",
        "        temperature=temp\n",
        "    )\n",
        "    decoded_text_temp = token_ids_to_text(generated_tokens_temp, tokenizer)\n",
        "    print(f\"\\nGenerated text with temperature {temp}:\\n{decoded_text_temp}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVJ_itQu5HIQ"
      },
      "source": [
        "- **TempÃ©rature 0.5** â†’  Stable et cohÃ©rent, mais peu crÃ©atif. Phrases claires, ton prÃ©visible.\n",
        "- **TempÃ©rature 1.0** â†’  Ã‰quilibre entre cohÃ©rence et originalitÃ©. Plus conversationnel, introduit de nouvelles idÃ©es.\n",
        "- **TempÃ©rature 1.5** â†’  TrÃ¨s crÃ©atif mais incohÃ©rent. MÃ©lange de mots inventÃ©s et phrases Ã©clatÃ©es."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgfYK6Za5HIQ"
      },
      "source": [
        "### Decoding Strategy 2: Top-k Sampling\n",
        "\n",
        "After temperature scaling, another popular strategy is **Top-k sampling**.\n",
        "\n",
        "- Instead of sampling from the entire vocabulary, we restrict choices to the **k most probable tokens**.\n",
        "- This avoids picking very unlikely words that could break coherence.\n",
        "\n",
        "**How it works:**\n",
        "1. Take the modelâ€™s logits at the current step.\n",
        "2. Keep only the top-k logits, mask the rest.\n",
        "3. Apply softmax to normalize probabilities.\n",
        "4. Sample the next token from this reduced set.\n",
        "\n",
        "**Effect of k:**\n",
        "- **Small k (e.g. 5)** â†’ more focused and coherent text.\n",
        "- **Large k (e.g. 50)** â†’ more diverse but with a higher risk of incoherence.\n",
        "- **k = vocab size** â†’ same as sampling without restriction.\n",
        "\n",
        "Top-k gives us control over the balance between **creativity** and **reliability** in generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQMv_RBn5HIQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate_text_advanced(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=None):\n",
        "    \"\"\"\n",
        "    Generate text using temperature scaling and optional top-k sampling.\n",
        "\n",
        "    Args:\n",
        "        model: Trained language model.\n",
        "        idx: Tensor of shape (batch_size, current_sequence_length) containing token indices.\n",
        "        max_new_tokens: Number of tokens to generate.\n",
        "        context_size: Maximum context length supported by the model.\n",
        "        temperature: Controls randomness in sampling. Must be > 0.\n",
        "        top_k: If set, sample only from the top-k most probable tokens.\n",
        "\n",
        "    Returns:\n",
        "        Tensor containing the input sequence extended with generated tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    assert temperature > 0, \"Temperature must be greater than zero.\"\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Crop context to the last 'context_size' tokens\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get logits from the model\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)  # (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        # Focus on the logits for the last token\n",
        "        logits = logits[:, -1, :]  # (batch_size, vocab_size)\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        logits = logits / temperature\n",
        "\n",
        "        # Apply top-k filtering if top_k is set\n",
        "        if top_k is not None:\n",
        "            values, indices = torch.topk(logits, top_k, dim=-1)\n",
        "            mask = torch.full_like(logits, float('-inf'))\n",
        "            logits = mask.scatter(-1, indices, values)\n",
        "\n",
        "        # Convert logits to probabilities\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # Sample the next token from the probability distribution\n",
        "        idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append the sampled token to the current sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt_2Fo435HIR"
      },
      "source": [
        "**Advanced Text Generation: Temperature Scaling + Top-k Sampling**\n",
        "\n",
        "This function enhances the simple generation loop by combining:\n",
        "\n",
        "- **Temperature scaling:** Controls the sharpness of the probability distribution.  \n",
        "- **Top-k sampling:** Restricts sampling to the *k* most probable tokens.\n",
        "\n",
        "By adjusting `temperature` and `top_k`, you can control the balance between **deterministic** and **creative** generation:\n",
        "\n",
        "- Lower temperature and smaller *k* produce more focused and coherent text.  \n",
        "- Higher temperature and larger *k* encourage diversity and creativity but can reduce coherence.\n",
        "\n",
        "Passing `top_k=None` disables top-k filtering and samples from the full distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXdRTW8B5HIR",
        "outputId": "0e739587-825e-4f1a-96fa-210b8a59b03e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated text with temperature 0.5 and top-k=None:\n",
            "Every effort moves you to see how much data you need, and how much data can be transmitted from a larger study.\n",
            "\n",
            "If youâ€™re wondering how much data packets are arriving successfully at the other end of the day, you can get into the data.\n",
            "\n",
            "Generated text with temperature 0.5 and top-k=10:\n",
            "Every effort moves you to avoid.\n",
            "\n",
            "The new company's new mortgage payment is Rs 8,000 crore crore tomorrow, allowing you to see a percentage of new revenue.\n",
            "\n",
            "As for the new position, the company's shareholders are growing rapidly and the new entrants\n",
            "\n",
            "Generated text with temperature 0.5 and top-k=50:\n",
            "Every effort moves you to take the chance to learn about the history of the past and the history of the mankind.\n",
            "\n",
            "The monarch was a form of force of the trumpet, and the sense of awe and wonder. The soldier remained a sense of awe and wonder.\n",
            "\n",
            "Generated text with temperature 1.0 and top-k=None:\n",
            "Every effort moves you,\n",
            "And even though our strength is not flinch.\n",
            "\n",
            "The motivational worldâ€™s come from an example of the world, the world.\n",
            "\n",
            "And the world is when she has to be out of birth. \n",
            "\n",
            "And\n",
            "\n",
            "Generated text with temperature 1.0 and top-k=10:\n",
            "Every effort moves you, but it's just really frustrating because you feel like you're doing everything right.\n",
            "Kamari: That's a great idea. I think you're here for you.\n",
            "Friend: No, it's just that.\n",
            "Kariq\n",
            "\n",
            "Generated text with temperature 1.0 and top-k=50:\n",
            "Every effort moves you are feeling overwhelmed. Like I have to spend time with the ambivalent attitudes toward the gates of the room with the weight I would take her back into the head so my mind goes on.\n",
            "\n",
            "I have only just moved from the last few years\n",
            "\n",
            "Generated text with temperature 1.5 and top-k=None:\n",
            "Every effort moves you in Chinese culture. involuntarily had more or less discovery to eat 21 seasons. however I struggled to decide whether college pos and kick away hobbies typically 50 feet.\n",
            "COWECTMC, Electoral College and hands-on sometime after monthly but jama\n",
            "\n",
            "Generated text with temperature 1.5 and top-k=10:\n",
            "Every effort moves you. This will always make the final section of the main story and its history, which is what they're going to happen, and the main characters are struggling to make this point on train.\n",
            "\n",
            "You have an older brother and children to attend school\n",
            "\n",
            "Generated text with temperature 1.5 and top-k=50:\n",
            "Every effort moves you on or where you will reach everything it will into a more place.\n",
            "Technical should be written depending on what you see for in order. (At my consultation Jow/Be of, nombed-Whilst of an unhealthy effect, to\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "start_context = \"Every effort moves you\"\n",
        "encoded_context = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "temperatures = [0.5, 1.0, 1.5]\n",
        "top_k_values = [None, 10, 50]\n",
        "for temp in temperatures:\n",
        "    for top_k in top_k_values:\n",
        "        generated_tokens_advanced = generate_text_advanced(\n",
        "            model=loaded_model,\n",
        "            idx=encoded_context,\n",
        "            max_new_tokens=50,\n",
        "            context_size=GPT_CONFIG_SMALL[\"context_length\"],\n",
        "            temperature=temp,\n",
        "            top_k=top_k\n",
        "        )\n",
        "        decoded_text_advanced = token_ids_to_text(generated_tokens_advanced, tokenizer)\n",
        "        print(f\"\\nGenerated text with temperature {temp} and top-k={top_k}:\\n{decoded_text_advanced}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiZ18jsZ5HIR"
      },
      "source": [
        "Temperature 0.5\n",
        "top-k=None â†’  Very stable and logical, data/technical oriented, but somewhat repetitive.\n",
        "\n",
        "top-k=10 â†’  More restrictive, focused topic but sometimes inconsistent (e.g., numbers and context).\n",
        "\n",
        "top-k=50 â†’  More descriptive and narrative, adds a historical/poetic style.\n",
        "\n",
        "Temperature 1.0\n",
        "top-k=None â†’  Mix of poetry and strange sentences, moderately coherent.\n",
        "\n",
        "top-k=10 â†’  More dialog-like and personal, conversational tone but sometimes disjointed.\n",
        "\n",
        "top-k=50 â†’  Freer flow of ideas, more creative but also more chaotic.\n",
        "\n",
        "Temperature 1.5\n",
        "top-k=None â†’  Very creative, invents words/concepts, low coherence.\n",
        "\n",
        "top-k=10 â†’  Semi-narrative, characters and plot emerge but fragile structure.\n",
        "\n",
        "top-k=50 â†’  Scattered and experimental ideas, almost complete loss of readability.\n",
        "\n",
        "Summary:\n",
        "\n",
        "Lowering temperature â†’ more coherence, less creativity.\n",
        "\n",
        "Lowering top-k â†’ reduces lexical diversity, makes style more predictable.\n",
        "\n",
        "High temperature + large top-k â†’ maximum creativityâ€¦ but guaranteed chaos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztA-qyL5HIR"
      },
      "source": [
        "# Part 4 : Instruction Fine Tuning (Medical use case)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JItqvyii5HIR"
      },
      "source": [
        "#### ðŸ“Œ What is Instruction Fine-Tuning?\n",
        "\n",
        "Instruction fine-tuning is the process of training a language model to **follow natural language instructions**, rather than just predicting the next word or completing text blindly.\n",
        "\n",
        "The goal is simple: to make the model better at **understanding and executing human instructions**.\n",
        "\n",
        "This means instead of saying, \"Complete this sentence...\", you can ask it directly:\n",
        "> \"Summarize this paragraph\",  \n",
        "> \"Explain asthma in simple terms\",  \n",
        "> \"Translate this to French\", etc.\n",
        "\n",
        "---\n",
        "\n",
        "#### âœ… Why Use Instruction Fine-Tuning?\n",
        "\n",
        "- ðŸ§  Makes models behave more like helpful **assistants** or intelligent **agents**.\n",
        "- ðŸŽ¯ Enables **task-specific specialization** (e.g., medical question answering, legal summarization, customer support).\n",
        "- ðŸ—£ï¸ Allows **natural interaction** â€” users donâ€™t need to craft clever prompts, just give a clear instruction.\n",
        "- ðŸ’¡ Leads to better **generalization** when trained on diverse instructions across domains.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKTzmv8D5HIR"
      },
      "source": [
        "### Loading pre trained openai weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR11RRma5HIR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOm5w79j5HIR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests  # Make sure requests is installed\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path)\n",
        "\n",
        "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "def download_file(url, destination):\n",
        "    try:\n",
        "        # Send a GET request to download the file, disabling SSL verification\n",
        "        response = requests.get(url, stream=True, verify=False)\n",
        "\n",
        "        # Get the total file size from headers, defaulting to 0 if not present\n",
        "        file_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "        # Check if file exists and has the same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return\n",
        "\n",
        "        # Define the block size for reading the file\n",
        "        block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "        # Initialize the progress bar with total file size\n",
        "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "            # Open the destination file in binary write mode\n",
        "            with open(destination, \"wb\") as file:\n",
        "                # Iterate over the file data in chunks\n",
        "                for chunk in response.iter_content(block_size):\n",
        "                    progress_bar.update(len(chunk))  # Update progress bar\n",
        "                    file.write(chunk)  # Write the chunk to the file\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        print(f\"Please check the URL: {url}\")\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQRETmeR5HIR"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsFTop3x5HIR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.positional_encoding.weight = assign(gpt.positional_encoding.weight, params['wpe'])\n",
        "    gpt.embedding.embedding.weight = assign(gpt.embedding.embedding.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.transformer_blocks[b].attn.q_proj.weight = assign(\n",
        "            gpt.transformer_blocks[b].attn.q_proj.weight, q_w.T)\n",
        "        gpt.transformer_blocks[b].attn.k_proj.weight = assign(\n",
        "            gpt.transformer_blocks[b].attn.k_proj.weight, k_w.T)\n",
        "        gpt.transformer_blocks[b].attn.v_proj.weight = assign(\n",
        "            gpt.transformer_blocks[b].attn.v_proj.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.transformer_blocks[b].attn.q_proj.bias = assign(\n",
        "            gpt.transformer_blocks[b].attn.q_proj.bias, q_b)\n",
        "        gpt.transformer_blocks[b].attn.k_proj.bias = assign(\n",
        "            gpt.transformer_blocks[b].attn.k_proj.bias, k_b)\n",
        "        gpt.transformer_blocks[b].attn.v_proj.bias = assign(\n",
        "            gpt.transformer_blocks[b].attn.v_proj.bias, v_b)\n",
        "\n",
        "        gpt.transformer_blocks[b].attn.out_proj.weight = assign(\n",
        "            gpt.transformer_blocks[b].attn.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].attn.out_proj.bias = assign(\n",
        "            gpt.transformer_blocks[b].attn.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # âœ… Fixed here: use index access instead of .layers\n",
        "        gpt.transformer_blocks[b].ffn.ffn[0].weight = assign(\n",
        "            gpt.transformer_blocks[b].ffn.ffn[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].ffn.ffn[0].bias = assign(\n",
        "            gpt.transformer_blocks[b].ffn.ffn[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.transformer_blocks[b].ffn.ffn[2].weight = assign(\n",
        "            gpt.transformer_blocks[b].ffn.ffn[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].ffn.ffn[2].bias = assign(\n",
        "            gpt.transformer_blocks[b].ffn.ffn[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.transformer_blocks[b].norm1.weight = assign(\n",
        "            gpt.transformer_blocks[b].norm1.weight,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.transformer_blocks[b].norm1.bias = assign(\n",
        "            gpt.transformer_blocks[b].norm1.bias,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.transformer_blocks[b].norm2.weight = assign(\n",
        "            gpt.transformer_blocks[b].norm2.weight,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.transformer_blocks[b].norm2.bias = assign(\n",
        "            gpt.transformer_blocks[b].norm2.bias,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.layer_norm.weight = assign(gpt.layer_norm.weight, params[\"g\"])\n",
        "    gpt.layer_norm.bias = assign(gpt.layer_norm.bias, params[\"b\"])\n",
        "    gpt.lm_head.weight = assign(gpt.lm_head.weight, params[\"wte\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maBjxo4O5HIR",
        "outputId": "4c28b503-b8fb-4c82-8070-9aa879ef0672"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI94eF0Z5HIR",
        "outputId": "83c606a7-0cf9-495d-fb5c-22e75693ba1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2_Architecture(\n",
              "  (embedding): EmbeddingLayer(\n",
              "    (embedding): Embedding(50257, 1024)\n",
              "  )\n",
              "  (positional_encoding): Embedding(1024, 1024)\n",
              "  (transformer_blocks): ModuleList(\n",
              "    (0-23): 24 x TransformerBlock(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MMHAttention(\n",
              "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout1): Dropout(p=0.0, inplace=False)\n",
              "      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FFN(\n",
              "        (ffn): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout2): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPT2_Architecture(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.to(device)  # Move model to the appropriate device\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ylnYMNY5HIR"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQYl1Xbo5HIR",
        "outputId": "2ba73831-208d-4c8e-b056-4eb4533a1966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['question', 'answer', 'source', 'focus_area'], dtype='object')\n",
            "                                 question  \\\n",
            "0                What is (are) Glaucoma ?   \n",
            "1                  What causes Glaucoma ?   \n",
            "2     What are the symptoms of Glaucoma ?   \n",
            "3  What are the treatments for Glaucoma ?   \n",
            "4                What is (are) Glaucoma ?   \n",
            "\n",
            "                                              answer           source  \\\n",
            "0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
            "1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n",
            "2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n",
            "3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n",
            "4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
            "\n",
            "  focus_area  \n",
            "0   Glaucoma  \n",
            "1   Glaucoma  \n",
            "2   Glaucoma  \n",
            "3   Glaucoma  \n",
            "4   Glaucoma  \n",
            "Saved 16412 entries in Alpaca format.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Step 1: Load the dataset CSV (adjust path as needed)\n",
        "df = pd.read_csv('MedQuad.csv')  # replace with your actual file path\n",
        "\n",
        "# Step 2: Inspect data columns\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "\n",
        "# Assume columns: 'question', 'answer' (adjust based on actual)\n",
        "\n",
        "# Step 3: Convert each row to Alpaca format\n",
        "alpaca_data = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    alpaca_example = {\n",
        "        \"instruction\": \"Answer the medical question based on your knowledge.\",\n",
        "        \"input\": row['question'],\n",
        "        \"output\": row['answer']\n",
        "    }\n",
        "    alpaca_data.append(alpaca_example)\n",
        "\n",
        "# Step 4: Save to JSONL file\n",
        "with open('medquad_alpaca.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for entry in alpaca_data:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"Saved {len(alpaca_data)} entries in Alpaca format.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLbiMF325HIR"
      },
      "source": [
        "#### Preprocessing the Dataset into Alpaca Format\n",
        "\n",
        "To fine-tune a language model using instruction tuning, we need to format our dataset into the **Alpaca format** â€” a simple structure designed to teach models how to follow instructions.\n",
        "\n",
        "Each sample is a JSON object with the following three fields:\n",
        "\n",
        "```json\n",
        "{\n",
        "\"input\": \"What does low REM sleep latency and experiencing hallucinations/sleep paralysis suggest?\",\n",
        "\"output\": \"Low REM sleep latency and experiencing hallucinations/sleep paralysis suggests narcolepsy.\",\n",
        "\"instruction\": \"Answer this question truthfully\"\n",
        "}\n",
        "\n",
        "Prompt template for Alpaca-style datasets. Template prompt changes slightly depending on if thereâ€™s an instruction + input or just an instruction.\n",
        "\n",
        "\"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "<YOUR INSTRUCTION HERE>\n",
        "\n",
        "### Input:\n",
        "<YOUR INPUT HERE>\n",
        "\n",
        "### Response:\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sORQS5bq5HIS"
      },
      "outputs": [],
      "source": [
        "\"\"\"Transforming the dataset into a format suitable for training\"\"\"\n",
        "def format_input(entry):\n",
        "    \"\"\"\n",
        "    Transform a single dataset entry into a training example.\n",
        "\n",
        "    Args:\n",
        "        entry: A dictionary containing 'question' and 'answer'.\n",
        "\n",
        "    Returns:\n",
        "        A string formatted as \"Question: <question> Answer: <answer>\".\n",
        "    \"\"\"\n",
        "    input_text = f\"## Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "    instruction_text = f\"### Instruction:\\n{entry['instruction']}\" if entry[\"instruction\"] else \"\"\n",
        "    output_text = f\"### Output:\\n{entry['output']}\" if entry[\"output\"] else \"\"\n",
        "    return f\"Below is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.{instruction_text} {input_text}  {output_text} \"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3H_rcKP5HIS",
        "outputId": "1ba6efff-b34c-4e95-edc6-1b3b08df7d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.### Instruction:\n",
            "Answer the medical question based on your knowledge. ## Input:\n",
            "What is (are) Glaucoma ?  ### Output:\n",
            "Glaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. While glaucoma can strike anyone, the risk is much greater for people over 60. How Glaucoma Develops  There are several different types of glaucoma. Most of these involve the drainage system within the eye. At the front of the eye there is a small space called the anterior chamber. A clear fluid flows through this chamber and bathes and nourishes the nearby tissues. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) In glaucoma, for still unknown reasons, the fluid drains too slowly out of the eye. As the fluid builds up, the pressure inside the eye rises. Unless this pressure is controlled, it may cause damage to the optic nerve and other parts of the eye and result in loss of vision. Open-angle Glaucoma The most common type of glaucoma is called open-angle glaucoma. In the normal eye, the clear fluid leaves the anterior chamber at the open angle where the cornea and iris meet. When fluid reaches the angle, it flows through a spongy meshwork, like a drain, and leaves the eye. Sometimes, when the fluid reaches the angle, it passes too slowly through the meshwork drain, causing the pressure inside the eye to build. If the pressure damages the optic nerve, open-angle glaucoma -- and vision loss -- may result. There is no cure for glaucoma. Vision lost from the disease cannot be restored. However, there are treatments that may save remaining vision. That is why early diagnosis is important.  See this graphic for a quick overview of glaucoma,  including how many people it affects, whos at risk, what to do if you have it, and how to learn more.  See a glossary of glaucoma terms. \n",
            "490\n"
          ]
        }
      ],
      "source": [
        "formatted_texts = [format_input(entry) for entry in alpaca_data]\n",
        "\n",
        "# Example: print first formatted example\n",
        "print(formatted_texts[0])\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "tokens = tokenizer.encode(formatted_texts[0], allowed_special={\"<|endoftext|>\"})\n",
        "print(len(tokens))  # Show first 20 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9315ceAS5HIS"
      },
      "outputs": [],
      "source": [
        "\"\"\"Eliminating long sequences  to avoid memory issues\"\"\"\n",
        "def filter_long_sequences(dataset, max_length=256):\n",
        "    \"\"\"\n",
        "    Filter out sequences that exceed the maximum length.\n",
        "\n",
        "    Args:\n",
        "        dataset: A list of formatted input strings.\n",
        "        max_length: Maximum allowed token length for each sequence.\n",
        "\n",
        "    Returns:\n",
        "        A list of sequences that are within the specified length.\n",
        "    \"\"\"\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    filtered_dataset = []\n",
        "    for entry in dataset:\n",
        "        tokens = tokenizer.encode(entry)\n",
        "        if len(tokens) <= max_length:\n",
        "            filtered_dataset.append(entry)\n",
        "    return filtered_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttry17rT5HIS"
      },
      "source": [
        "### SPLITTING DATASET INTO TRAIN-TEST-VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_WDOcYd5HIS",
        "outputId": "f27fb5d2-06de-45c6-f793-c20b23cd3fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Answer the medical question based on your knowledge.',\n",
              " 'input': 'What is (are) Glaucoma ?',\n",
              " 'output': \"Glaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. While glaucoma can strike anyone, the risk is much greater for people over 60. How Glaucoma Develops  There are several different types of glaucoma. Most of these involve the drainage system within the eye. At the front of the eye there is a small space called the anterior chamber. A clear fluid flows through this chamber and bathes and nourishes the nearby tissues. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) In glaucoma, for still unknown reasons, the fluid drains too slowly out of the eye. As the fluid builds up, the pressure inside the eye rises. Unless this pressure is controlled, it may cause damage to the optic nerve and other parts of the eye and result in loss of vision. Open-angle Glaucoma The most common type of glaucoma is called open-angle glaucoma. In the normal eye, the clear fluid leaves the anterior chamber at the open angle where the cornea and iris meet. When fluid reaches the angle, it flows through a spongy meshwork, like a drain, and leaves the eye. Sometimes, when the fluid reaches the angle, it passes too slowly through the meshwork drain, causing the pressure inside the eye to build. If the pressure damages the optic nerve, open-angle glaucoma -- and vision loss -- may result. There is no cure for glaucoma. Vision lost from the disease cannot be restored. However, there are treatments that may save remaining vision. That is why early diagnosis is important.  See this graphic for a quick overview of glaucoma,  including how many people it affects, whos at risk, what to do if you have it, and how to learn more.  See a glossary of glaucoma terms.\"}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "alpaca_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLIJBxPy5HIS",
        "outputId": "de7bf7eb-cfd4-45b6-d31e-29da55067d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1686, Val: 100, Test: 198\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Step 1: Clean data entries\n",
        "def clean_entry(entry):\n",
        "    for key in ['instruction', 'input', 'output']:\n",
        "        val = entry.get(key, \"\")\n",
        "        if val is None or (isinstance(val, float) and math.isnan(val)):\n",
        "            entry[key] = \"\"\n",
        "        else:\n",
        "            entry[key] = str(val)\n",
        "    return entry\n",
        "\n",
        "cleaned_alpaca_data = [clean_entry(entry) for entry in alpaca_data]\n",
        "\n",
        "# Step 2: Filter function (replace with your actual filter)\n",
        "def filter_fn(x):\n",
        "    formatted_text = format_input(x)\n",
        "    tokens = tokenizer.encode(formatted_text)\n",
        "    return len(tokens) <= 120\n",
        "\n",
        "filtered_data = [entry for entry in cleaned_alpaca_data if filter_fn(entry)]\n",
        "\n",
        "# Step 3: Split into train/val/test sets\n",
        "total_len = len(filtered_data)\n",
        "train_portion = int(total_len * 0.85)\n",
        "test_portion = int(total_len * 0.10)\n",
        "val_portion = total_len - train_portion - test_portion\n",
        "\n",
        "print(f\"Train: {train_portion}, Val: {val_portion}, Test: {test_portion}\")\n",
        "\n",
        "train_data = filtered_data[:train_portion]\n",
        "val_data = filtered_data[train_portion : train_portion + val_portion]\n",
        "test_data = filtered_data[train_portion + val_portion :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUziI6If5HIS",
        "outputId": "ef02e656-d3d8-460d-bbd2-2cc3df9e6463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 1686\n",
            "Validation set length: 100\n",
            "Test set length: 198\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poJ0UC065HIS"
      },
      "source": [
        "### ORGANIZING DATA INTO TRAINING BATCHES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04EgDN1g5HIS"
      },
      "source": [
        "In the Pre Training Part, the training batches were created automatically by the PyTorch DataLoader class, which employs a default collate function to combine lists of samples into batches.\n",
        "\n",
        "A collate function is responsible for taking a list of individual data samples and merging them into a single batch that can be processed efficiently by the model during training.\n",
        "\n",
        "However, the batching process for instruction finetuning is a bit more involved and requires us to create our own custom collate function that we will later plug into the DataLoader.\n",
        "\n",
        "We implement this custom collate function to handle the specific requirements and formatting of our instruction finetuning dataset.\n",
        "\n",
        "First, we code an InstructionDataset class that applies format_input from the previous section and pretokenizes all inputs in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLYUX0r-5HIS"
      },
      "outputs": [],
      "source": [
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self._data = data\n",
        "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            full_text = format_input(entry)\n",
        "\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30X-HzK95HIS"
      },
      "source": [
        "Next, we adopt a more sophisticated approach by developing a custom collate function that we can pass to the data loader.\n",
        "\n",
        "This custom collate function pads the training examples in each batch to have the same length, while allowing different batches to have different lengths.\n",
        "\n",
        "This approach minimizes unnecessary padding by only extending sequences to match the longest one in each batch, not the whole dataset.\n",
        "\n",
        "Instead of padding all sequences to the length of the longest one in the **entire dataset**, we use a **custom collate function** to pad only within each batch.\n",
        "\n",
        "This means:\n",
        "- Sequences in a batch are padded to the length of the **longest in that batch**.\n",
        "- Different batches can have different lengths.\n",
        "\n",
        "âœ… **Benefits:**\n",
        "- Less padding\n",
        "- Faster training\n",
        "- Lower memory usage\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do0R_j2U5HIS"
      },
      "source": [
        "We can implement the padding process with a custom collate function as follows:\n",
        "\n",
        "Step 1: Find the longest sequence in the batch\n",
        "\n",
        "Step 2: Pad and prepare inputs\n",
        "\n",
        "Step 3: Remove extra padded token added earlier\n",
        "\n",
        "Step 4: Convert list of inputs to tensor and transfer to target device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZier-aW5HIS"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=device\n",
        "):\n",
        "\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "\n",
        "        new_item += [pad_token_id]\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIts7wIK5HIS",
        "outputId": "3ed9be5b-6228-4e77-98d8-199cc573671d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch, device=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ_XvXRO5HIS"
      },
      "source": [
        "As we can see based on the preceding output, all inputs have been padded to the length of the longest input list, inputs_1 containing 5 token IDs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q37WZSX5HIS"
      },
      "source": [
        "### CREATING TARGET TOKEN IDS FOR TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsZvZYgR5HIT"
      },
      "source": [
        "Similar to the process described for pretraining an LLM, the target token IDs match the input token IDs but are shifted one position to the right.\n",
        "\n",
        "This setup allows the LLM to learn how to predict the next token in a sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG4FHwJ45HIT"
      },
      "source": [
        "The following updated collate function generates the target token IDs from the input token IDs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSjmQHca5HIT"
      },
      "source": [
        "Step 1: Truncate the last token for inputs\n",
        "\n",
        "Step 2: Shift +1 to the right for targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IvPB2Uj5HIT"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=device\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsR-1FXu5HIT",
        "outputId": "def9d03e-f59a-49e3-a724-9a7f9ef77ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpcXxQLM5HIT"
      },
      "source": [
        "In the next step, we assign a -100 placeholder value to all padding tokens.\n",
        "\n",
        "This special value allows us to exclude these padding tokens from contributing to the training loss calculation, ensuring that only meaningful data influences model learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5CNl5sq5HIT"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2usIRxOI5HIT"
      },
      "source": [
        "`ignore_index` in PyTorch `CrossEntropyLoss`\n",
        "\n",
        "In `nn.CrossEntropyLoss`, the `ignore_index` parameter allows you to **exclude specific target values** from contributing to the loss.\n",
        "\n",
        "How it works:\n",
        "- Any target value equal to `ignore_index` is **ignored** during loss computation.\n",
        "- No gradient is computed for those positions.\n",
        "Why use it?\n",
        "Useful for:\n",
        "- Ignoring **padded tokens** in sequence tasks.\n",
        "- Skipping **invalid labels** in custom datasets.\n",
        "\n",
        "Here -100 is our ignore index\n",
        "```python\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3OSUsP25HIT",
        "outputId": "bd8ce793-5a83-4761-c0f9-7331fa586afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNc9GWpg5HIT"
      },
      "source": [
        "### CREATING DATALOADERS FOR AN INSTRUCTION DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqdqmWwI5HIT"
      },
      "source": [
        "To reuse the chosen device setting in custom_collate_fn when we plug it into the PyTorch DataLoader class later in this section, we use the partial function from Python's functools standard library to create a new version of the function with the device argument pre-filled.\n",
        "\n",
        "Additionally, we set the allowed_max_length to 1024, which truncates the data to the maximum context length supported by the GPT-2 model we finetune later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN283Vrq5HIT"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(custom_collate_fn, device=\"cpu\", allowed_max_length=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTs-AIh_5HIT"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_data = list(train_data)  # Convert HF dataset to list of dicts\n",
        "\n",
        "train_dataset = InstructionDataset(train_data)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo5xt2RS5HIT",
        "outputId": "7e167043-7a52-41cc-d36b-6bbbebb9be74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faphCh1a5HIT"
      },
      "source": [
        "In the preceding output, we can see that the first input and target batch have dimensions 8Ã—61, where 8 represents the batch size, and 270 is the number of tokens in each training example in this batch.\n",
        "\n",
        "The second input and target batch have a different number of tokens, for instance, 260.\n",
        "\n",
        "As we saw in the preceding code output, thanks to our custom collate function, the data loader is able to create batches of different lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y1umMnl5HIT"
      },
      "source": [
        "### FINETUNING THE LLM ON INSTRUCTION DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZDZ3pRV5HIT"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ahMU6NU5HIU",
        "outputId": "435c97c8-5ffa-4ace-a0f4-3d0f38fe4cf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.7375205993652343\n",
            "Validation loss: 3.633546495437622\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PlwVXKA5HIU"
      },
      "source": [
        "The following code sets up the training process, including initializing the optimizer, setting the number of epochs, and defining the evaluation frequency and starting context to evaluate generated LLM responses during training based on the first validation set instruction (val_data[0]) we looked at earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZtIXn9m5HIU",
        "outputId": "1b929751-f2de-4f38-ec5a-189660c94ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.949, Val loss 2.827\n",
            "Ep 1 (Step 000002): Train loss 2.148, Val loss 1.984\n",
            "Ep 1 (Step 000004): Train loss 1.534, Val loss 1.305\n",
            "Ep 1 (Step 000006): Train loss 1.045, Val loss 0.909\n",
            "Ep 1 (Step 000008): Train loss 1.051, Val loss 0.825\n",
            "Ep 1 (Step 000010): Train loss 1.150, Val loss 0.790\n",
            "Ep 1 (Step 000012): Train loss 0.961, Val loss 0.771\n",
            "Ep 1 (Step 000014): Train loss 0.924, Val loss 0.746\n",
            "Ep 1 (Step 000016): Train loss 0.944, Val loss 0.734\n",
            "Ep 1 (Step 000018): Train loss 0.787, Val loss 0.720\n",
            "Ep 1 (Step 000020): Train loss 0.890, Val loss 0.701\n",
            "Ep 1 (Step 000022): Train loss 0.847, Val loss 0.689\n",
            "Ep 1 (Step 000024): Train loss 0.811, Val loss 0.681\n",
            "Ep 1 (Step 000026): Train loss 0.891, Val loss 0.672\n",
            "Ep 1 (Step 000028): Train loss 0.866, Val loss 0.667\n",
            "Ep 1 (Step 000030): Train loss 0.854, Val loss 0.664\n",
            "Ep 1 (Step 000032): Train loss 0.916, Val loss 0.660\n",
            "Ep 1 (Step 000034): Train loss 0.821, Val loss 0.656\n",
            "Ep 1 (Step 000036): Train loss 0.853, Val loss 0.646\n",
            "Ep 1 (Step 000038): Train loss 0.688, Val loss 0.639\n",
            "Ep 1 (Step 000040): Train loss 0.825, Val loss 0.632\n",
            "Ep 1 (Step 000042): Train loss 0.686, Val loss 0.630\n",
            "Ep 1 (Step 000044): Train loss 0.693, Val loss 0.628\n",
            "Ep 1 (Step 000046): Train loss 0.934, Val loss 0.628\n",
            "Ep 1 (Step 000048): Train loss 0.732, Val loss 0.629\n",
            "Ep 1 (Step 000050): Train loss 0.787, Val loss 0.630\n",
            "Ep 1 (Step 000052): Train loss 0.833, Val loss 0.629\n",
            "Ep 1 (Step 000054): Train loss 0.962, Val loss 0.624\n",
            "Ep 1 (Step 000056): Train loss 0.773, Val loss 0.620\n",
            "Ep 1 (Step 000058): Train loss 0.763, Val loss 0.619\n",
            "Ep 1 (Step 000060): Train loss 0.756, Val loss 0.620\n",
            "Ep 1 (Step 000062): Train loss 0.665, Val loss 0.622\n",
            "Ep 1 (Step 000064): Train loss 0.737, Val loss 0.622\n",
            "Ep 1 (Step 000066): Train loss 0.722, Val loss 0.621\n",
            "Ep 1 (Step 000068): Train loss 0.707, Val loss 0.618\n",
            "Ep 1 (Step 000070): Train loss 0.755, Val loss 0.617\n",
            "Ep 1 (Step 000072): Train loss 0.678, Val loss 0.616\n",
            "Ep 1 (Step 000074): Train loss 0.774, Val loss 0.614\n",
            "Ep 1 (Step 000076): Train loss 0.808, Val loss 0.614\n",
            "Ep 1 (Step 000078): Train loss 0.749, Val loss 0.613\n",
            "Ep 1 (Step 000080): Train loss 0.693, Val loss 0.614\n",
            "Ep 1 (Step 000082): Train loss 0.793, Val loss 0.616\n",
            "Ep 1 (Step 000084): Train loss 0.762, Val loss 0.618\n",
            "Ep 1 (Step 000086): Train loss 0.718, Val loss 0.616\n",
            "Ep 1 (Step 000088): Train loss 0.683, Val loss 0.612\n",
            "Ep 1 (Step 000090): Train loss 0.713, Val loss 0.607\n",
            "Ep 1 (Step 000092): Train loss 0.712, Val loss 0.604\n",
            "Ep 1 (Step 000094): Train loss 0.642, Val loss 0.602\n",
            "Ep 1 (Step 000096): Train loss 0.633, Val loss 0.599\n",
            "Ep 1 (Step 000098): Train loss 0.726, Val loss 0.598\n",
            "Ep 1 (Step 000100): Train loss 0.726, Val loss 0.596\n",
            "Ep 1 (Step 000102): Train loss 0.572, Val loss 0.595\n",
            "Ep 1 (Step 000104): Train loss 0.712, Val loss 0.596\n",
            "Ep 1 (Step 000106): Train loss 0.562, Val loss 0.598\n",
            "Ep 1 (Step 000108): Train loss 0.615, Val loss 0.598\n",
            "Ep 1 (Step 000110): Train loss 0.675, Val loss 0.599\n",
            "Ep 1 (Step 000112): Train loss 0.625, Val loss 0.602\n",
            "Ep 1 (Step 000114): Train loss 0.731, Val loss 0.605\n",
            "Ep 1 (Step 000116): Train loss 0.637, Val loss 0.605\n",
            "Ep 1 (Step 000118): Train loss 0.663, Val loss 0.602\n",
            "Ep 1 (Step 000120): Train loss 0.706, Val loss 0.599\n",
            "Ep 1 (Step 000122): Train loss 0.604, Val loss 0.593\n",
            "Ep 1 (Step 000124): Train loss 0.712, Val loss 0.590\n",
            "Ep 1 (Step 000126): Train loss 0.610, Val loss 0.590\n",
            "Ep 1 (Step 000128): Train loss 0.685, Val loss 0.591\n",
            "Ep 1 (Step 000130): Train loss 0.615, Val loss 0.592\n",
            "Ep 1 (Step 000132): Train loss 0.647, Val loss 0.593\n",
            "Ep 1 (Step 000134): Train loss 0.675, Val loss 0.592\n",
            "Ep 1 (Step 000136): Train loss 0.688, Val loss 0.593\n",
            "Ep 1 (Step 000138): Train loss 0.615, Val loss 0.594\n",
            "Ep 1 (Step 000140): Train loss 0.661, Val loss 0.594\n",
            "Ep 1 (Step 000142): Train loss 0.622, Val loss 0.595\n",
            "Ep 1 (Step 000144): Train loss 0.681, Val loss 0.593\n",
            "Ep 1 (Step 000146): Train loss 0.606, Val loss 0.593\n",
            "Ep 1 (Step 000148): Train loss 0.554, Val loss 0.592\n",
            "Ep 1 (Step 000150): Train loss 0.558, Val loss 0.594\n",
            "Ep 1 (Step 000152): Train loss 0.614, Val loss 0.596\n",
            "Ep 1 (Step 000154): Train loss 0.597, Val loss 0.597\n",
            "Ep 1 (Step 000156): Train loss 0.625, Val loss 0.597\n",
            "Ep 1 (Step 000158): Train loss 0.581, Val loss 0.597\n",
            "Ep 1 (Step 000160): Train loss 0.543, Val loss 0.593\n",
            "Ep 1 (Step 000162): Train loss 0.615, Val loss 0.586\n",
            "Ep 1 (Step 000164): Train loss 0.624, Val loss 0.583\n",
            "Ep 1 (Step 000166): Train loss 0.557, Val loss 0.583\n",
            "Ep 1 (Step 000168): Train loss 0.628, Val loss 0.586\n",
            "Ep 1 (Step 000170): Train loss 0.514, Val loss 0.589\n",
            "Ep 1 (Step 000172): Train loss 0.612, Val loss 0.588\n",
            "Ep 1 (Step 000174): Train loss 0.645, Val loss 0.587\n",
            "Ep 1 (Step 000176): Train loss 0.664, Val loss 0.587\n",
            "Ep 1 (Step 000178): Train loss 0.532, Val loss 0.587\n",
            "Ep 1 (Step 000180): Train loss 0.617, Val loss 0.587\n",
            "Ep 1 (Step 000182): Train loss 0.567, Val loss 0.587\n",
            "Ep 1 (Step 000184): Train loss 0.518, Val loss 0.585\n",
            "Ep 1 (Step 000186): Train loss 0.596, Val loss 0.584\n",
            "Ep 1 (Step 000188): Train loss 0.583, Val loss 0.583\n",
            "Ep 1 (Step 000190): Train loss 0.676, Val loss 0.582\n",
            "Ep 1 (Step 000192): Train loss 0.593, Val loss 0.581\n",
            "Ep 1 (Step 000194): Train loss 0.590, Val loss 0.579\n",
            "Ep 1 (Step 000196): Train loss 0.577, Val loss 0.577\n",
            "Ep 1 (Step 000198): Train loss 0.566, Val loss 0.577\n",
            "Ep 1 (Step 000200): Train loss 0.523, Val loss 0.578\n",
            "Ep 1 (Step 000202): Train loss 0.632, Val loss 0.579\n",
            "Ep 1 (Step 000204): Train loss 0.659, Val loss 0.579\n",
            "Ep 1 (Step 000206): Train loss 0.599, Val loss 0.579\n",
            "Ep 1 (Step 000208): Train loss 0.581, Val loss 0.580\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Embedding' object has no attribute 'pe'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m optimizer = torch.optim.AdamW(fine_tuned_model.parameters(), lr=\u001b[32m0.00005\u001b[39m, weight_decay=\u001b[32m0.1\u001b[39m)\n\u001b[32m     14\u001b[39m num_epochs = \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m train_losses, val_losses, tokens_seen = \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfine_tuned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m end_time = time.time()\n\u001b[32m     24\u001b[39m execution_time_minutes = (end_time - start_time) / \u001b[32m60\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mtrain_model_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[39m\n\u001b[32m     51\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_step\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Print a sample text after each epoch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mgenerate_and_print_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_context\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m train_losses, val_losses, track_tokens_seen\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mgenerate_and_print_sample\u001b[39m\u001b[34m(model, tokenizer, device, start_context)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_and_print_sample\u001b[39m(model, tokenizer, device, start_context):\n\u001b[32m      2\u001b[39m     model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     context_size = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpositional_encoding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpe\u001b[49m.shape[\u001b[32m1\u001b[39m]\n\u001b[32m      4\u001b[39m     encoded = text_to_token_ids(start_context, tokenizer).to(device)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GPT2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
            "\u001b[31mAttributeError\u001b[39m: 'Embedding' object has no attribute 'pe'"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "fine_tuned_model = model\n",
        "fine_tuned_model.train()  # Set model to training mode\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "fine_tuned_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(fine_tuned_model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    fine_tuned_model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=2, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e9WhEp75HIU",
        "outputId": "16b170ad-81ff-4e04-e681-edfafeed998a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "# Raw log data (shortened for brevity here, assume you paste the full data in practice)\n",
        "log_data = \"\"\"\n",
        "Ep 1 (Step 000000): Train loss 2.949, Val loss 2.827\n",
        "Ep 1 (Step 000002): Train loss 2.148, Val loss 1.984\n",
        "Ep 1 (Step 000004): Train loss 1.534, Val loss 1.305\n",
        "Ep 1 (Step 000006): Train loss 1.045, Val loss 0.909\n",
        "Ep 1 (Step 000008): Train loss 1.051, Val loss 0.825\n",
        "Ep 1 (Step 000010): Train loss 1.150, Val loss 0.790\n",
        "Ep 1 (Step 000012): Train loss 0.961, Val loss 0.771\n",
        "Ep 1 (Step 000014): Train loss 0.924, Val loss 0.746\n",
        "Ep 1 (Step 000016): Train loss 0.944, Val loss 0.734\n",
        "Ep 1 (Step 000018): Train loss 0.787, Val loss 0.720\n",
        "Ep 1 (Step 000020): Train loss 0.890, Val loss 0.701\n",
        "Ep 1 (Step 000022): Train loss 0.847, Val loss 0.689\n",
        "Ep 1 (Step 000024): Train loss 0.811, Val loss 0.681\n",
        "Ep 1 (Step 000026): Train loss 0.891, Val loss 0.672\n",
        "Ep 1 (Step 000028): Train loss 0.866, Val loss 0.667\n",
        "Ep 1 (Step 000030): Train loss 0.854, Val loss 0.664\n",
        "Ep 1 (Step 000032): Train loss 0.916, Val loss 0.660\n",
        "Ep 1 (Step 000034): Train loss 0.821, Val loss 0.656\n",
        "Ep 1 (Step 000036): Train loss 0.853, Val loss 0.646\n",
        "Ep 1 (Step 000038): Train loss 0.688, Val loss 0.639\n",
        "Ep 1 (Step 000040): Train loss 0.825, Val loss 0.632\n",
        "Ep 1 (Step 000042): Train loss 0.686, Val loss 0.630\n",
        "Ep 1 (Step 000044): Train loss 0.693, Val loss 0.628\n",
        "Ep 1 (Step 000046): Train loss 0.934, Val loss 0.628\n",
        "Ep 1 (Step 000048): Train loss 0.732, Val loss 0.629\n",
        "Ep 1 (Step 000202): Train loss 0.632, Val loss 0.579\n",
        "Ep 1 (Step 000204): Train loss 0.659, Val loss 0.579\n",
        "Ep 1 (Step 000206): Train loss 0.599, Val loss 0.579\n",
        "Ep 1 (Step 000208): Train loss 0.581, Val loss 0.580\n",
        "\"\"\"\n",
        "\n",
        "# Parse steps, train losses, and val losses using regex\n",
        "steps = [int(m.group(1)) for m in re.finditer(r\"Step (\\d+)\", log_data)]\n",
        "train_losses = [float(m.group(1)) for m in re.finditer(r\"Train loss ([\\d.]+)\", log_data)]\n",
        "val_losses = [float(m.group(1)) for m in re.finditer(r\"Val loss ([\\d.]+)\", log_data)]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(steps, train_losses, label='Train Loss')\n",
        "plt.plot(steps, val_losses, label='Validation Loss')\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Steps\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMu1iC45HIU"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"fine_tuned.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QAcCk2j5HIU"
      },
      "outputs": [],
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "encoded_context = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "\n",
        "# Generate text with the untrained model\n",
        "generated_tokens_untrained = generate_text_simple(\n",
        "    model=untrained_model,\n",
        "    idx=encoded_context,\n",
        "    max_new_tokens=50,\n",
        "    context_size=GPT_CONFIG_SMALL[\"context_length\"]\n",
        ")\n",
        "\n",
        "decoded_text_untrained = token_ids_to_text(generated_tokens_untrained, tokenizer)\n",
        "print(f\"Generated text (Untrained Model):\\n{decoded_text_untrained}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVUntpY55HIU",
        "outputId": "af8b2f74-8390-4569-9b08-b405d940607f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2_Architecture(\n",
              "  (embedding): EmbeddingLayer(\n",
              "    (embedding): Embedding(50257, 1024)\n",
              "  )\n",
              "  (positional_encoding): Embedding(1024, 1024)\n",
              "  (transformer_blocks): ModuleList(\n",
              "    (0-23): 24 x TransformerBlock(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MMHAttention(\n",
              "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout1): Dropout(p=0.0, inplace=False)\n",
              "      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FFN(\n",
              "        (ffn): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout2): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tuned_model = GPT2_Architecture(BASE_CONFIG)\n",
        "\n",
        "fine_tuned_model.load_state_dict(torch.load(\"fine_tuned.pth\"))\n",
        "fine_tuned_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOTZvkIj5HIU",
        "outputId": "a789975a-dc2e-4975-fe11-4c80584de307"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2_Architecture(\n",
              "  (embedding): EmbeddingLayer(\n",
              "    (embedding): Embedding(50257, 1024)\n",
              "  )\n",
              "  (positional_encoding): Embedding(1024, 1024)\n",
              "  (transformer_blocks): ModuleList(\n",
              "    (0-23): 24 x TransformerBlock(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MMHAttention(\n",
              "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout1): Dropout(p=0.0, inplace=False)\n",
              "      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FFN(\n",
              "        (ffn): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (dropout2): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)\n",
        "fine_tuned_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AOSF92z5HIU",
        "outputId": "1ba09984-edf2-45d0-e381-26b181bcc650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "Below is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.### Instruction:\n",
            " Answer the medical question based on your knowledge. ## Input:\n",
            " How many people are affected by Liddle syndrome ? Â Answer: Â 1,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000\n"
          ]
        }
      ],
      "source": [
        "\"\"\"# Example usage: Generate text with the fine tuned model\"\"\"\n",
        "input_text = f\"## Input:\\n {test_data[0]['input']}\" if test_data[0][\"input\"] else \"\"\n",
        "instruction_text = f\"### Instruction:\\n {test_data[0]['instruction']}\" if test_data[0][\"instruction\"] else \"\"\n",
        "input_text = f\"Below is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.{instruction_text} {input_text} \"\n",
        "encoded_context = text_to_token_ids(input_text, tokenizer).to(device)\n",
        "generated_tokens = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=encoded_context,\n",
        "    max_new_tokens=80,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "decoded_text = token_ids_to_text(generated_tokens, tokenizer)\n",
        "print(f\"Generated text:\\n{decoded_text}\")  # Compact print format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohIehVHU5HIU",
        "outputId": "cf256462-996a-4527-de7f-afc09087a36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "Below is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.### Instruction:\n",
            " Answer the medical question based on your knowledge. ## Input:\n",
            " How many people are affected by Liddle syndrome ?  ### Output:\n",
            "Liddle syndrome is a rare disorder; its prevalence is unknown. <|endoftext|>The following is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.### Instruction:\n",
            "How many people are affected by familial dyskinesia ?  ### Input:\n",
            "Familial dyskinesia is a rare disorder; its\n"
          ]
        }
      ],
      "source": [
        "\"\"\"# Example usage: Generate text with the fine tuned model\"\"\"\n",
        "input_text = f\"## Input:\\n {test_data[0]['input']}\" if test_data[0][\"input\"] else \"\"\n",
        "instruction_text = f\"### Instruction:\\n {test_data[0]['instruction']}\" if test_data[0][\"instruction\"] else \"\"\n",
        "input_text = f\"Below is an instruction that describes a task, paired with an input that provides further context Write a response that appropriately completes the request.{instruction_text} {input_text} \"\n",
        "encoded_context = text_to_token_ids(input_text, tokenizer).to(device)\n",
        "generated_tokens = generate_text_simple(\n",
        "    model=fine_tuned_model,\n",
        "    idx=encoded_context,\n",
        "    max_new_tokens=80,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "decoded_text = token_ids_to_text(generated_tokens, tokenizer)\n",
        "print(f\"Generated text:\\n{decoded_text}\")  # Compact print format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxkPnaPY5HIU"
      },
      "source": [
        "##### Pure GPT-2 Output:\n",
        "- Generates an absurdly large number for the affected population (\"1,000,000,000,000,000,...\").\n",
        "- No contextual understanding or factual correctness.\n",
        "- Output is nonsensical and clearly inaccurate.\n",
        "\n",
        "##### Instruction Fine-Tuned GPT-2 Output:\n",
        "- Recognizes the rarity of Liddle syndrome.\n",
        "- Provides a realistic, cautious answer: \"prevalence is unknown.\"\n",
        "- Follows instructions by producing a structured output format.\n",
        "- Attempts continuation with a new medical question, showing understanding of task format.\n",
        "\n",
        "---\n",
        "\n",
        "- **Pure GPT-2** lacks the ability to follow instructions and often outputs irrelevant or exaggerated responses.\n",
        "- **Instruction Fine-Tuned GPT-2** better understands the task, providing more coherent, contextually appropriate, and factually plausible answers.\n",
        "- Fine-tuning on instructions improves reliability and relevance in task-specific outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbvmB6qL5HIU",
        "outputId": "ff326dd6-338e-4a52-c5f4-61b4a7c4942d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Liddle syndrome is a rare condition, although its prevalence is unknown. The condition has been found in populations worldwide.'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0][\"output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoGHtaUa5HIU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}